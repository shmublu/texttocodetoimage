{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/T5/Fine_tune_CodeT5_for_generating_docstrings_from_Ruby_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-7bq0hWR3ny"
   },
   "source": [
    "## Set-up environment\n",
    "\n",
    "Let's first install the required libraries:\n",
    "* HuggingFace Transformers (for the CodeT5 model)\n",
    "* HuggingFace Datasets (for loading the dataset + preprocessing it)\n",
    "* PyTorch Lightning (for training)\n",
    "* Weights and Biases (for logging training metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8n4pEe2RXFB",
    "outputId": "05a2c493-1f1c-4dc9-b8f5-cc765053e0f4"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPM1mjMVaPzy",
    "outputId": "04643557-c4a8-4302-8778-b2807e1afb9b"
   },
   "outputs": [],
   "source": [
    "!pip install -q pytorch-lightning wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8x-xYVZfR5ji"
   },
   "source": [
    "## Preprocess data\n",
    "\n",
    "Here, we load the \"code_to_text\" portion of the [CodeXGLUE](https://microsoft.github.io/CodeXGLUE/) dataset. As you may know, GLUE [(Wang et al., 2018)](https://arxiv.org/abs/1804.07461) is a famous benchmark in NLP, which led to a lot of progress (see the leaderboard [here](https://gluebenchmark.com/)). Microsoft has now created a similar benchmark called CodeXGLUE [(Lu et al., 2021)](https://arxiv.org/abs/2102.04664), but for code + natural language instead of just natural language. It consits of several subtasks (similar to GLUE).\n",
    "\n",
    "Let's only load the examples of the Ruby programming language. This is a fairly small dataset, which is ideally suited for demonstration purposes in Google Colab. The Python split has way more training examples (250,000), but training this in Google Colab isn't ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UAZ7UPCU-uk"
   },
   "source": [
    "As you can see, the \"code-to-text/ruby\" split consists of a training, validation and test set. Let's look at one particular example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset code_x_glue_ct_code_to_text (/home/shmuelaberman/.cache/huggingface/datasets/code_x_glue_ct_code_to_text/python/0.0.0/f8b7e9d51f609a87e7ec7c7431706d4ee0b402e3398560410313d4acc67060a0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a16d1bc750f431ba53882476108afc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n",
      "        num_rows: 251820\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n",
      "        num_rows: 13914\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n",
      "        num_rows: 14918\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"code_x_glue_ct_code_to_text\", \"python\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdpm7pHoU7t1",
    "outputId": "8e0bab2b-a8d9-47fe-f41c-969ff1ebeb63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code: def unregister_path(self, path):\n",
      "        \"\"\"\n",
      "        Unregisters given path.\n",
      "\n",
      "        :param path: Path name.\n",
      "        :type path: unicode\n",
      "        :return: Method success.\n",
      "        :rtype: bool\n",
      "        \"\"\"\n",
      "\n",
      "        if not path in self:\n",
      "            raise umbra.exceptions.PathExistsError(\"{0} | '{1}' path isn't registered!\".format(\n",
      "                self.__class__.__name__, path))\n",
      "\n",
      "        del (self.__paths[path])\n",
      "        return True\n",
      "Docstring: Unregisters given path.\n",
      "\n",
      "        :param path: Path name.\n",
      "        :type path: unicode\n",
      "        :return: Method success.\n",
      "        :rtype: bool\n"
     ]
    }
   ],
   "source": [
    "example = dataset['train'][5]\n",
    "\n",
    "print(\"Code:\", example[\"code\"])\n",
    "print(\"Docstring:\", example[\"docstring\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "\n",
    "prefix = \"Turn to Python: \"\n",
    "max_input_length = 256\n",
    "max_target_length = 1024\n",
    "\n",
    "def preprocess_examples(examples):\n",
    "  # encode the code-docstring pairs\n",
    "  codes = examples['code']\n",
    "  docstrings = examples['docstring']\n",
    "  \n",
    "  inputs = [prefix + docstring for docstring in docstrings]\n",
    "  model_inputs = tokenizer(inputs, max_length=max_input_length, padding=\"max_length\", truncation=True)\n",
    "\n",
    "  # encode the summaries\n",
    "  labels = tokenizer(codes, max_length=max_target_length, padding=\"max_length\", truncation=True).input_ids\n",
    "\n",
    "  # important: we need to replace the index of the padding tokens by -100\n",
    "  # such that they are not taken into account by the CrossEntropyLoss\n",
    "  labels_with_ignore_index = []\n",
    "  for labels_example in labels:\n",
    "    labels_example = [label if label != 0 else -100 for label in labels_example]\n",
    "    labels_with_ignore_index.append(labels_example)\n",
    "  \n",
    "  model_inputs[\"labels\"] = labels_with_ignore_index\n",
    "\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56tFfwcdn4A_"
   },
   "source": [
    "The goal for the model is to generate a docstring based on the provided code. \n",
    "\n",
    "Let's now prepare the examples (i.e. code-docstring pairs) for the model. As you might know, Transformer models like BERT, BART, T5 etc. don't expect text as direct input, but rather integers which are called `input_ids` in HuggingFace Transformers. These represent tokens of a certain vocabulary. The model will learn rich contextual embedding vectors for each token, allowing it to get good results.\n",
    "\n",
    "In other words, we need to turn the \"Code\" input from above into `input_ids`, and similarly, we need to turn the \"Docstring\" output from above into `input_ids`, which will serve as the `labels` for the model.\n",
    "\n",
    "In addition, as these models are trained on batches of examples rather than one example at a time, we'll need to pad/truncate both the inputs and labels, such that they are all of the same length. That's why we also will add an `attention_mask` input to the model, such that it knows not to take into account padding tokens when computing attention scores.\n",
    "\n",
    "To summarize: \n",
    "* input: code, which is turned into `input_ids` + `attention_mask`\n",
    "* output: docstrings, which are turned into `labels` (which are the `input_ids` of the docstrings).\n",
    "\n",
    "Below, we define a `preprocess_examples` function, which we can apply on the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def set_checked(self, state):\\n        \"\"\"\\n        Sets the Widget checked state.\\n\\n        :param state: New check state.\\n        :type state: bool\\n        :return: Method success.\\n        :rtype: bool\\n        \"\"\"\\n\\n        if not self.__checkable:\\n            return False\\n\\n        if state:\\n            self.__checked = True\\n            self.setPixmap(self.__active_pixmap)\\n        else:\\n            self.__checked = False\\n            self.setPixmap(self.__default_pixmap)\\n        self.toggled.emit(state)\\n        return True',\n",
       " 'def set_menu(self, menu):\\n        \"\"\"\\n        Sets the Widget menu.\\n\\n        :param menu: Menu.\\n        :type menu: QMenu\\n        :return: Method success.\\n        :rtype: bool\\n        \"\"\"\\n\\n        self.__menu = menu\\n\\n        if not self.parent():\\n            return False\\n\\n        parent = [parent for parent in umbra.ui.common.parents_walker(self)].pop()\\n        for action in self.__menu.actions():\\n            not action.shortcut().isEmpty() and parent.addAction(action)\\n        return True',\n",
       " 'def get(self, path, default=None):\\n        \"\"\"\\n        Returns given path value.\\n\\n        :param path: Path name.\\n        :type path: unicode\\n        :param default: Default value if path is not found.\\n        :type default: object\\n        :return: Action.\\n        :rtype: QAction\\n        \"\"\"\\n\\n        try:\\n            return self.__getitem__(path)\\n        except KeyError as error:\\n            return default',\n",
       " 'def __watch_file_system(self):\\n        \"\"\"\\n        Watches the file system for paths that have been changed or invalidated on disk.\\n        \"\"\"\\n\\n        for path, data in self.__paths.items():\\n            stored_modified_time, is_file = data\\n            try:\\n                if not foundations.common.path_exists(path):\\n                    LOGGER.warning(\\n                        \"!> {0} | \\'{1}\\' path has been invalidated and will be unregistered!\".format(\\n                            self.__class__.__name__, path))\\n                    del (self.__paths[path])\\n                    if is_file:\\n                        self.file_invalidated.emit(path)\\n                    else:\\n                        self.directory_invalidated.emit(path)\\n                    continue\\n            except KeyError:\\n                LOGGER.debug(\"> {0} | \\'{1}\\' path has been unregistered while iterating!\".format(\\n                    self.__class__.__name__, path))\\n                continue\\n\\n            try:\\n                modified_time = self.get_path_modified_time(path)\\n            except OSError:\\n                LOGGER.debug(\"> {0} | \\'{1}\\' path has been invalidated while iterating!\".format(\\n                    self.__class__.__name__, path))\\n                continue\\n\\n            if stored_modified_time != modified_time:\\n                self.__paths[path] = (modified_time, os.path.isfile(path))\\n                LOGGER.debug(\"> {0} | \\'{1}\\' path has been changed!\".format(self.__class__.__name__, path))\\n                if is_file:\\n                    self.file_changed.emit(path)\\n                else:\\n                    self.directory_changed.emit(path)',\n",
       " 'def register_path(self, path, modified_time=None):\\n        \"\"\"\\n        Registers given path.\\n\\n        :param path: Path name.\\n        :type path: unicode\\n        :param modified_time: Custom modified time.\\n        :type modified_time: int or float\\n        :return: Method success.\\n        :rtype: bool\\n        \"\"\"\\n\\n        if not foundations.common.path_exists(path):\\n            raise foundations.exceptions.PathExistsError(\"{0} | \\'{1}\\' path doesn\\'t exists!\".format(\\n                self.__class__.__name__, path))\\n\\n        if path in self:\\n            raise umbra.exceptions.PathRegistrationError(\"{0} | \\'{1}\\' path is already registered!\".format(\\n                self.__class__.__name__, path))\\n\\n        self.__paths[path] = (self.get_path_modified_time(\\n            path) if modified_time is None else modified_time, os.path.isfile(path))\\n        return True',\n",
       " 'def unregister_path(self, path):\\n        \"\"\"\\n        Unregisters given path.\\n\\n        :param path: Path name.\\n        :type path: unicode\\n        :return: Method success.\\n        :rtype: bool\\n        \"\"\"\\n\\n        if not path in self:\\n            raise umbra.exceptions.PathExistsError(\"{0} | \\'{1}\\' path isn\\'t registered!\".format(\\n                self.__class__.__name__, path))\\n\\n        del (self.__paths[path])\\n        return True',\n",
       " 'def get_path_modified_time(path):\\n        \"\"\"\\n        Returns given path modification time.\\n\\n        :param path: Path.\\n        :type path: unicode\\n        :return: Modification time.\\n        :rtype: int\\n        \"\"\"\\n\\n        return float(foundations.common.get_first_item(str(os.path.getmtime(path)).split(\".\")))',\n",
       " 'def _post_login_page(self):\\n        \"\"\"Login to Janrain.\"\"\"\\n        # Prepare post data\\n        data = {\\n            \"form\": \"signInForm\",\\n            \"client_id\": JANRAIN_CLIENT_ID,\\n            \"redirect_uri\": \"https://www.fido.ca/pages/#/\",\\n            \"response_type\": \"token\",\\n            \"locale\": \"en-US\",\\n            \"userID\": self.username,\\n            \"currentPassword\": self.password,\\n        }\\n        # HTTP request\\n        try:\\n            raw_res = yield from self._session.post(LOGIN_URL,\\n                                                    headers=self._headers,\\n                                                    data=data,\\n                                                    timeout=self._timeout)\\n        except OSError:\\n            raise PyFidoError(\"Can not sign in\")\\n\\n        return True',\n",
       " 'def _get_token(self):\\n        \"\"\"Get token from JanRain.\"\"\"\\n        # HTTP request\\n        try:\\n            raw_res = yield from self._session.get(TOKEN_URL,\\n                                                   headers=self._headers,\\n                                                   timeout=self._timeout)\\n        except OSError:\\n            raise PyFidoError(\"Can not get token\")\\n        # Research for json in answer\\n        content = yield from raw_res.text()\\n        reg_res = re.search(r\"\\\\({.*}\\\\)\", content)\\n        if reg_res is None:\\n            raise PyFidoError(\"Can not finf token json\")\\n        # Load data as json\\n        return_data = json.loads(reg_res.group()[1:-1])\\n        # Get token and uuid\\n        token = return_data.get(\\'result\\', {}).get(\\'accessToken\\')\\n        uuid = return_data.get(\\'result\\', {}).get(\\'userData\\', {}).get(\\'uuid\\')\\n        # Check values\\n        if token is None or uuid is None:\\n            raise PyFidoError(\"Can not get token or uuid\")\\n\\n        return token, uuid',\n",
       " 'def _get_account_number(self, token, uuid):\\n        \"\"\"Get fido account number.\"\"\"\\n        # Data\\n        data = {\"accessToken\": token,\\n                \"uuid\": uuid}\\n        # Http request\\n        try:\\n            raw_res = yield from self._session.post(ACCOUNT_URL,\\n                                                    data=data,\\n                                                    headers=self._headers,\\n                                                    timeout=self._timeout)\\n        except OSError:\\n            raise PyFidoError(\"Can not get account number\")\\n        # Load answer as json\\n        try:\\n            json_content = yield from raw_res.json()\\n            account_number = json_content\\\\\\n                            .get(\\'getCustomerAccounts\\', {})\\\\\\n                            .get(\\'accounts\\', [{}])[0]\\\\\\n                            .get(\\'accountNumber\\')\\n        except (OSError, ValueError):\\n            raise PyFidoError(\"Bad json getting account number\")\\n        # Check collected data\\n        if account_number is None:\\n            raise PyFidoError(\"Can not get account number\")\\n\\n        return account_number',\n",
       " 'def _get_balance(self, account_number):\\n        \"\"\"Get current balance from Fido.\"\"\"\\n        # Prepare data\\n        data = {\"ctn\": self.username,\\n                \"language\": \"en-US\",\\n                \"accountNumber\": account_number}\\n        # Http request\\n        try:\\n            raw_res = yield from self._session.post(BALANCE_URL,\\n                                                    data=data,\\n                                                    headers=self._headers,\\n                                                    timeout=self._timeout)\\n        except OSError:\\n            raise PyFidoError(\"Can not get balance\")\\n        # Get balance\\n        try:\\n            json_content = yield from raw_res.json()\\n            balance_str = json_content\\\\\\n                            .get(\"getAccountInfo\", {})\\\\\\n                            .get(\"balance\")\\n        except (OSError, ValueError):\\n            raise PyFidoError(\"Can not get balance as json\")\\n        if balance_str is None:\\n            raise PyFidoError(\"Can not get balance\")\\n        # Casting to float\\n        try:\\n            balance = float(balance_str)\\n        except ValueError:\\n            raise PyFidoError(\"Can not get balance as float\")\\n\\n        return balance',\n",
       " 'def _get_fido_dollar(self, account_number, number):\\n        \"\"\"Get current Fido dollar balance.\"\"\"\\n        # Prepare data\\n        data = json.dumps({\"fidoDollarBalanceFormList\":\\n                           [{\"phoneNumber\": number,\\n                             \"accountNumber\": account_number}]})\\n        # Prepare headers\\n        headers_json = self._headers.copy()\\n        headers_json[\"Content-Type\"] = \"application/json;charset=UTF-8\"\\n        # Http request\\n        try:\\n            raw_res = yield from self._session.post(FIDO_DOLLAR_URL,\\n                                                    data=data,\\n                                                    headers=headers_json,\\n                                                    timeout=self._timeout)\\n        except OSError:\\n            raise PyFidoError(\"Can not get fido dollar\")\\n        # Get fido dollar\\n        try:\\n            json_content = yield from raw_res.json()\\n            fido_dollar_str = json_content\\\\\\n                        .get(\"fidoDollarBalanceInfoList\", [{}])[0]\\\\\\n                        .get(\"fidoDollarBalance\")\\n        except (OSError, ValueError):\\n            raise PyFidoError(\"Can not get fido dollar as json\")\\n        if fido_dollar_str is None:\\n            raise PyFidoError(\"Can not get fido dollar\")\\n        # Casting to float\\n        try:\\n            fido_dollar = float(fido_dollar_str)\\n        except ValueError:\\n            raise PyFidoError(\"Can not get fido dollar\")\\n\\n        return fido_dollar',\n",
       " 'def _get_usage(self, account_number, number):\\n        \"\"\"Get Fido usage.\\n\\n        Get the following data\\n        - talk\\n        - text\\n        - data\\n\\n        Roaming data is not supported yet\\n        \"\"\"\\n        # Prepare data\\n        data = {\"ctn\": number,\\n                \"language\": \"en-US\",\\n                \"accountNumber\": account_number}\\n        # Http request\\n        try:\\n            raw_res = yield from self._session.post(USAGE_URL,\\n                                                    data=data,\\n                                                    headers=self._headers,\\n                                                    timeout=self._timeout)\\n        except OSError:\\n            raise PyFidoError(\"Can not get usage\")\\n        # Load answer as json\\n        try:\\n            output = yield from raw_res.json()\\n        except (OSError, ValueError):\\n            raise PyFidoError(\"Can not get usage as json\")\\n        # Format data\\n        ret_data = {}\\n        for data_name, keys in DATA_MAP.items():\\n            key, subkey = keys\\n            for data in output.get(key)[0].get(\\'wirelessUsageSummaryInfoList\\'):\\n                if data.get(\\'usageSummaryType\\') == subkey:\\n                    # Prepare keys:\\n                    used_key = \"{}_used\".format(data_name)\\n                    remaining_key = \"{}_remaining\".format(data_name)\\n                    limit_key = \"{}_limit\".format(data_name)\\n                    # Get values\\n                    ret_data[used_key] = data.get(\\'used\\', 0.0)\\n                    if data.get(\\'remaining\\') >= 0:\\n                        ret_data[remaining_key] = data.get(\\'remaining\\')\\n                    else:\\n                        ret_data[remaining_key] = None\\n                    if data.get(\\'total\\') >= 0:\\n                        ret_data[limit_key] = data.get(\\'total\\')\\n                    else:\\n                        ret_data[limit_key] = None\\n\\n        return ret_data',\n",
       " 'def fetch_data(self):\\n        \"\"\"Fetch the latest data from Fido.\"\"\"\\n        # Get http session\\n        yield from self._get_httpsession()\\n        # Post login page\\n        yield from self._post_login_page()\\n        # Get token\\n        token_uuid = yield from self._get_token()\\n        # Get account number\\n        account_number = yield from self._get_account_number(*token_uuid)\\n        # List phone numbers\\n        self._phone_numbers = yield from self._list_phone_numbers(account_number)\\n        # Get balance\\n        balance = yield from self._get_balance(account_number)\\n        self._data[\\'balance\\'] = balance\\n        # Get fido dollar\\n        for number in self._phone_numbers:\\n            fido_dollar = yield from self._get_fido_dollar(account_number,\\n                                                           number)\\n            self._data[number]= {\\'fido_dollar\\': fido_dollar}\\n        # Get usage\\n        for number in self._phone_numbers:\\n            usage = yield from self._get_usage(account_number, number)\\n            self._data[number].update(usage)',\n",
       " 'def execute(\\n    command,\\n    abort=True,\\n    capture=False,\\n    verbose=False,\\n    echo=False,\\n    stream=None,\\n):\\n    \"\"\"Run a command locally.\\n\\n    Arguments:\\n        command: a command to execute.\\n        abort: If True, a non-zero return code will trigger an exception.\\n        capture: If True, returns the output of the command.\\n            If False, returns a subprocess result.\\n        echo: if True, prints the command before executing it.\\n        verbose: If True, prints the output of the command.\\n        stream: If set, stdout/stderr will be redirected to the given stream.\\n            Ignored if `capture` is True.\\n    \"\"\"\\n    stream = stream or sys.stdout\\n\\n    if echo:\\n        out = stream\\n        out.write(u\\'$ %s\\' % command)\\n\\n    # Capture stdout and stderr in the same stream\\n    command = u\\'%s 2>&1\\' % command\\n\\n    if verbose:\\n        out = stream\\n        err = stream\\n    else:\\n        out = subprocess.PIPE\\n        err = subprocess.PIPE\\n\\n    process = subprocess.Popen(\\n        command,\\n        shell=True,\\n        stdout=out,\\n        stderr=err,\\n    )\\n    # propagate SIGTERM to all child processes within\\n    # the process group. this prevents subprocesses from\\n    # being orphaned when the current process is terminated\\n    signal.signal(\\n        signal.SIGTERM,\\n        make_terminate_handler(process)\\n    )\\n\\n    # Wait for the process to complete\\n    stdout, _ = process.communicate()\\n    stdout = stdout.strip() if stdout else \\'\\'\\n    if not isinstance(stdout, unicode):\\n        stdout = stdout.decode(\\'utf-8\\')\\n\\n    if abort and process.returncode != 0:\\n        message = (\\n            u\\'Error #%d running \"%s\"%s\\' % (\\n                process.returncode,\\n                command,\\n                \\':\\\\n====================\\\\n\\'\\n                \\'%s\\\\n\\'\\n                \\'====================\\\\n\\' % (\\n                    stdout\\n                ) if stdout else \\'\\'\\n            )\\n        )\\n        raise Exception(message)\\n    if capture:\\n        return stdout\\n    else:\\n        return process',\n",
       " 'def to_message(base):\\n    \"\"\"\\n    Given a MailBase, this will construct a MIME part that is canonicalized for\\n    use with the Python email API.\\n    \"\"\"\\n    ctype, ctparams = base.get_content_type()\\n\\n    if not ctype:\\n        if base.parts:\\n            ctype = \\'multipart/mixed\\'\\n        else:\\n            ctype = \\'text/plain\\'\\n\\n    maintype, subtype = ctype.split(\\'/\\')\\n    is_text = maintype == \\'text\\'\\n    is_multipart = maintype == \\'multipart\\'\\n\\n    if base.parts and not is_multipart:\\n        raise RuntimeError(\\n            \\'Content type should be multipart, not %r\\' % ctype\\n            )\\n\\n    body = base.get_body()\\n    ctenc = base.get_transfer_encoding()\\n    charset = ctparams.get(\\'charset\\')\\n\\n    if is_multipart:\\n        out = MIMEMultipart(subtype, **ctparams)\\n    else:\\n        out = MIMENonMultipart(maintype, subtype, **ctparams)\\n        if ctenc:\\n            out[\\'Content-Transfer-Encoding\\'] = ctenc\\n        if isinstance(body, text_type):\\n            if not charset:\\n                if is_text:\\n                    charset, _ = best_charset(body)\\n                else:\\n                    charset = \\'utf-8\\'\\n            if PY2:\\n                body = body.encode(charset)\\n            else: # pragma: no cover\\n                body = body.encode(charset, \\'surrogateescape\\')\\n        if body is not None:\\n            if ctenc:\\n                body = transfer_encode(ctenc, body)\\n            if not PY2: # pragma: no cover\\n                body = body.decode(charset or \\'ascii\\', \\'replace\\')\\n        out.set_payload(body, charset) \\n\\n    for k in base.keys(): # returned sorted\\n        value = base[k]\\n        if not value:\\n            continue\\n        out[k] = value\\n\\n    cdisp, cdisp_params = base.get_content_disposition()\\n\\n    if cdisp:\\n        out.add_header(\\'Content-Disposition\\', cdisp, **cdisp_params)\\n\\n    # go through the children\\n    for part in base.parts:\\n        sub = to_message(part)\\n        out.attach(sub)\\n\\n    return out',\n",
       " 'def to_message(self):\\n        \"\"\"\\n        Returns raw email.Message instance.  Validates message first.\\n        \"\"\"\\n\\n        self.validate()\\n        \\n        bodies = [(self.body, \\'text/plain\\'), (self.html, \\'text/html\\')]\\n\\n        for idx, (val, content_type) in enumerate(bodies):\\n            if val is None:\\n                bodies[idx] = None\\n            elif isinstance(val, Attachment):\\n                bodies[idx] = val.to_mailbase(content_type)\\n            else:\\n                # presumed to be a textual val\\n                attachment = Attachment(\\n                    data=val,\\n                    content_type=content_type,\\n                    transfer_encoding=\\'quoted-printable\\',\\n                    disposition=\\'inline\\'\\n                    )\\n                bodies[idx] = attachment.to_mailbase(content_type)\\n\\n        body, html = bodies\\n\\n        base = MailBase([\\n            (\\'To\\', \\', \\'.join(self.recipients)),\\n            (\\'From\\', self.sender),\\n            (\\'Subject\\', self.subject),\\n            ])\\n\\n        # base represents the outermost mime part; it will be one of the\\n        # following types:\\n        #\\n        # - a multipart/mixed type if there are attachments.  this\\n        #   part will contain a single multipart/alternative type if there\\n        #   is both an html part and a plaintext part (the alternative part\\n        #   will contain both the text and html), it will contain\\n        #   a single text/plain part if there is only a plaintext part,\\n        #   or it will contain a single text/html part if there is only\\n        #   an html part.  it will also contain N parts representing\\n        #   each attachment as children of the base mixed type.\\n        #\\n        # - a multipart/alternative type if there are no attachments but\\n        #   both an html part and a plaintext part.  it will contain\\n        #   a single text/plain part if there is only a plaintext part,\\n        #   or it will contain a single text/html part if there is only\\n        #   an html part.\\n        #\\n        # - a text/plain type if there is only a plaintext part\\n        #\\n        # - a text/html type if there is only an html part\\n\\n        if self.cc:\\n            base[\\'Cc\\'] = \\', \\'.join(self.cc)\\n            \\n        if self.extra_headers:\\n            base.update(dict(self.extra_headers))\\n\\n        if self.attachments:\\n            base.set_content_type(\\'multipart/mixed\\')\\n            altpart = MailBase()\\n            base.attach_part(altpart)\\n        else:\\n            altpart = base\\n            \\n        if body and html:\\n            altpart.set_content_type(\\'multipart/alternative\\')\\n            altpart.set_body(None)\\n            # Per RFC2046, HTML part comes last in multipart/alternative\\n            altpart.attach_part(body)\\n            altpart.attach_part(html)\\n        elif body is not None:\\n            altpart.merge_part(body)\\n        elif html is not None:\\n            altpart.merge_part(html)\\n\\n        for attachment in self.attachments:\\n            attachment_mailbase = attachment.to_mailbase()\\n            base.attach_part(attachment_mailbase)\\n\\n        return to_message(base)',\n",
       " 'def is_bad_headers(self):\\n        \"\"\"\\n        Checks for bad headers i.e. newlines in subject, sender or recipients.\\n        \"\"\"\\n\\n        headers = [self.subject, self.sender]\\n        headers += list(self.send_to)\\n        headers += dict(self.extra_headers).values()\\n\\n        for val in headers:\\n            for c in \\'\\\\r\\\\n\\':\\n                if c in val:\\n                    return True\\n        return False',\n",
       " 'def validate(self):\\n        \"\"\"\\n        Checks if message is valid and raises appropriate exception.\\n        \"\"\"\\n\\n        if not (self.recipients or self.cc or self.bcc):\\n            raise InvalidMessage(\"No recipients have been added\")\\n\\n        if not self.body and not self.html:\\n            raise InvalidMessage(\"No body has been set\")\\n\\n        if not self.sender:\\n            raise InvalidMessage(\"No sender address has been set\")\\n\\n        if self.is_bad_headers():\\n            raise BadHeaders',\n",
       " 'def from_settings(cls, settings, prefix=\\'mail.\\'):\\n        \"\"\"Create a new instance of \\'DebugMailer\\' from settings dict.\\n\\n        :param settings: a settings dict-like\\n        :param prefix: prefix separating \\'tgext.mailer\\' settings\\n        \"\"\"\\n        settings = settings or {}\\n        top_level_directory = settings.get(prefix+\\'top_level_directory\\')\\n        if top_level_directory is None:\\n            raise ValueError(\"DebugMailer:  must specify \"\\n                             \"\\'%stop_level_directory\\'\" % prefix)\\n        return cls(top_level_directory)',\n",
       " 'def _send(self, message, fail_silently=False):\\n        \"\"\"Save message to a file for debugging\\n        \"\"\"\\n        seeds = \\'1234567890qwertyuiopasdfghjklzxcvbnm\\'\\n        file_part1 = datetime.now().strftime(\\'%Y%m%d%H%M%S\\')\\n        file_part2 = \\'\\'.join(sample(seeds, 4))\\n        filename = join(self.tld, \\'%s_%s.msg\\' % (file_part1, file_part2))\\n        with open(filename, \\'w\\') as fd:\\n            fd.write(str(message.to_message()))',\n",
       " 'def from_settings(cls, settings, prefix=\\'mail.\\'):\\n        \"\"\"Create a new instance of \\'Mailer\\' from settings dict.\\n\\n        :param settings: a settings dict-like\\n        :param prefix: prefix separating \\'tgext.mailer\\' settings\\n        \"\"\"\\n        settings = settings or {}\\n\\n        kwarg_names = [prefix + k for k in (\\n                       \\'host\\', \\'port\\', \\'username\\',\\n                       \\'password\\', \\'tls\\', \\'ssl\\', \\'keyfile\\',\\n                       \\'certfile\\', \\'queue_path\\', \\'debug\\', \\'default_sender\\')]\\n\\n        size = len(prefix)\\n\\n        kwargs = dict(((k[size:], settings[k]) for k in settings.keys() if\\n                        k in kwarg_names))\\n\\n        for key in (\\'tls\\', \\'ssl\\'):\\n            val = kwargs.get(key)\\n            if val:\\n                kwargs[key] = asbool(val)\\n\\n        return cls(**kwargs)',\n",
       " 'def send_immediately(self, message, fail_silently=False):\\n        \"\"\"Send a message immediately, outside the transaction manager.\\n\\n        If there is a connection error to the mail server this will have to\\n        be handled manually. However if you pass ``fail_silently`` the error\\n        will be swallowed.\\n\\n        :versionadded: 0.3\\n\\n        :param message: a \\'Message\\' instance.\\n\\n        :param fail_silently: silently handle connection errors.\\n        \"\"\"\\n        try:\\n            return self.smtp_mailer.send(*self._message_args(message))\\n        except smtplib.socket.error:\\n            if not fail_silently:\\n                raise',\n",
       " 'def send_to_queue(self, message):\\n        \"\"\"Add a message to a maildir queue.\\n\\n        In order to handle this, the setting \\'mail.queue_path\\' must be\\n        provided and must point to a valid maildir.\\n\\n        :param message: a \\'Message\\' instance.\\n        \"\"\"\\n        if not self.queue_delivery:\\n            raise RuntimeError(\"No queue_path provided\")\\n\\n        return self.queue_delivery.send(*self._message_args(message))',\n",
       " 'def is_seq(obj):\\n    \"\"\"\\n    Check if an object is a sequence.\\n    \"\"\"\\n    return (not is_str(obj) and not is_dict(obj) and\\n            (hasattr(obj, \"__getitem__\") or hasattr(obj, \"__iter__\")))',\n",
       " 'def update(dst, src):\\n    \"\"\"\\n    Recursively update values in dst from src.\\n\\n    Unlike the builtin dict.update() function, this method will decend into\\n    nested dicts, updating all nested values.\\n\\n    Arguments:\\n        dst (dict): Destination dict.\\n        src (dict): Source dict.\\n\\n    Returns:\\n        dict: dst updated with entries from src.\\n    \"\"\"\\n    for k, v in src.items():\\n        if isinstance(v, Mapping):\\n            r = update(dst.get(k, {}), v)\\n            dst[k] = r\\n        else:\\n            dst[k] = src[k]\\n    return dst',\n",
       " 'def dict_values(src):\\n    \"\"\"\\n    Recursively get values in dict.\\n\\n    Unlike the builtin dict.values() function, this method will descend into\\n    nested dicts, returning all nested values.\\n\\n    Arguments:\\n        src (dict): Source dict.\\n\\n    Returns:\\n        list: List of values.\\n    \"\"\"\\n    for v in src.values():\\n        if isinstance(v, dict):\\n            for v in dict_values(v):\\n                yield v\\n        else:\\n            yield v',\n",
       " 'def find_path_package(thepath):\\n    \"\"\"\\n        Takes a file system path and returns the module object of the python\\n        package the said path belongs to. If the said path can not be\\n        determined, it returns None.\\n    \"\"\"\\n    pname = find_path_package_name(thepath)\\n    if not pname:\\n        return None\\n    fromlist = b\\'\\' if six.PY2 else \\'\\'\\n    return __import__(pname, globals(), locals(), [fromlist])',\n",
       " 'def find_path_package_name(thepath):\\n    \"\"\"\\n        Takes a file system path and returns the name of the python package\\n        the said path belongs to.  If the said path can not be determined, it\\n        returns None.\\n    \"\"\"\\n    module_found = False\\n    last_module_found = None\\n    continue_ = True\\n    while continue_:\\n        module_found = is_path_python_module(thepath)\\n        next_path = path.dirname(thepath)\\n        if next_path == thepath:\\n            continue_ = False\\n        if module_found:\\n            init_names = [\\'__init__%s\\' % suffix.lower() for suffix in _py_suffixes]\\n            if path.basename(thepath).lower() in init_names:\\n                last_module_found = path.basename(path.dirname(thepath))\\n            else:\\n                last_module_found = path.basename(thepath)\\n        if last_module_found and not module_found:\\n            continue_ = False\\n        thepath = next_path\\n    return last_module_found',\n",
       " 'def is_path_python_module(thepath):\\n    \"\"\"\\n        Given a path, find out of the path is a python module or is inside\\n        a python module.\\n    \"\"\"\\n    thepath = path.normpath(thepath)\\n\\n    if path.isfile(thepath):\\n        base, ext = path.splitext(thepath)\\n        if ext in _py_suffixes:\\n            return True\\n        return False\\n\\n    if path.isdir(thepath):\\n        for suffix in _py_suffixes:\\n            if path.isfile(path.join(thepath, \\'__init__%s\\' % suffix)):\\n                return True\\n    return False',\n",
       " 'def find_files(root, pattern):\\n    \"\"\"Find all files matching the glob pattern recursively\\n\\n    :param root: string\\n    :param pattern: string\\n    :return: list of file paths relative to root\\n    \"\"\"\\n    results = []\\n    for base, dirs, files in os.walk(root):\\n        matched = fnmatch.filter(files, pattern)\\n        results.extend(os.path.join(base, f) for f in matched)\\n    return results',\n",
       " 'def find_directories(root, pattern):\\n    \"\"\"Find all directories matching the glob pattern recursively\\n\\n    :param root: string\\n    :param pattern: string\\n    :return: list of dir paths relative to root\\n    \"\"\"\\n    results = []\\n    for base, dirs, files in os.walk(root):\\n        matched = fnmatch.filter(dirs, pattern)\\n        results.extend(os.path.join(base, d) for d in matched)\\n    return results',\n",
       " 'def posargs_limiter(func, *args):\\n    \"\"\" takes a function a positional arguments and sends only the number of\\n    positional arguments the function is expecting\\n    \"\"\"\\n    posargs = inspect.getargspec(func)[0]\\n    length = len(posargs)\\n    if inspect.ismethod(func):\\n        length -= 1\\n    if length == 0:\\n        return func()\\n    return func(*args[0:length])',\n",
       " 'def compose(*functions):\\n    \"\"\"Function composition on a series of functions.\\n\\n    Remember that function composition runs right-to-left: `f . g . h = f(g(h(x)))`. As a unix\\n    pipeline, it would be written: `h | g | f`.\\n\\n    From https://mathieularose.com/function-composition-in-python/.\\n    \"\"\"\\n    return functools.reduce(lambda f, g: lambda x: f(g(x)), functions, identity)',\n",
       " 'def first_where(pred, iterable, default=None):\\n    \"\"\"Returns the first element in an iterable that meets the given predicate.\\n\\n    :param default: is the default value to use if the predicate matches none of the elements.\\n    \"\"\"\\n    return next(six.moves.filter(pred, iterable), default)',\n",
       " 'def partition_iter(pred, iterable):\\n    \"\"\"Partitions an iterable with a predicate into two iterables, one with elements satisfying\\n    the predicate and one with elements that do not satisfy it.\\n\\n    :returns: a tuple (satisfiers, unsatisfiers).\\n    \"\"\"\\n    left, right = itertools.tee(iterable, 2)\\n    return (\\n        (x for x in left if pred(x)),\\n        (y for y in right if not pred(y))\\n    )',\n",
       " 'def partition_list(pred, iterable):\\n    \"\"\"Partitions an iterable with a predicate into two lists, one with elements satisfying\\n    the predicate and one with elements that do not satisfy it.\\n\\n    .. note: this just converts the results of partition_iter to a list for you so that you don\\'t\\n    have to in most cases using `partition_iter` is a better option.\\n\\n    :returns: a tuple (satisfiers, unsatisfiers).\\n    \"\"\"\\n    left, right = partition_iter(pred, iterable)\\n    return list(left), list(right)',\n",
       " 'def split_every(n, iterable):\\n    \"\"\"Returns a generator that spits an iteratable into n-sized chunks. The last chunk may have\\n    less than n elements.\\n\\n    See http://stackoverflow.com/a/22919323/503377.\"\"\"\\n    items = iter(iterable)\\n    return itertools.takewhile(bool, (list(itertools.islice(items, n)) for _ in itertools.count()))',\n",
       " 'def unique(iterable, key=identity):\\n    \"\"\"Yields all the unique values in an iterable maintaining order\"\"\"\\n    seen = set()\\n    for item in iterable:\\n        item_key = key(item)\\n        if item_key not in seen:\\n            seen.add(item_key)\\n            yield item',\n",
       " 'def iteritems(self):\\n        \"\"\" Sort and then iterate the dictionary \"\"\"\\n        sorted_data = sorted(self.data.iteritems(), self.cmp, self.key,\\n                             self.reverse)\\n        for k,v in sorted_data:\\n            yield k,v',\n",
       " 'def _adapt_param(self, key, val):\\n        \"\"\"\\n        Adapt the value if an adapter is defined.\\n        \"\"\"\\n        if key in self.param_adapters:\\n            try:\\n                return self.param_adapters[key](val)\\n            except (AdaptError, AdaptErrors, TypeError, ValueError) as e:\\n                if hasattr(e, \\'errors\\'):\\n                    errors = e.errors\\n                else:\\n                    errors = [e]\\n\\n                raise AnticipateParamError(\\n                    message=\\'Input value %r for parameter `%s` does not match \\'\\n                        \\'anticipated type %r\\' % (type(val), key, self.params[key]),\\n                    name=key,\\n                    value=val,\\n                    anticipated=self.params[key],\\n                    errors=errors)\\n        else:\\n            return val',\n",
       " 'def input(self, *args, **kwargs):\\n        \"\"\"\\n        Adapt the input and check for errors.\\n\\n        Returns a tuple of adapted (args, kwargs) or raises\\n        AnticipateErrors\\n        \"\"\"\\n        errors = []\\n\\n        if args and self.arg_names:\\n            args = list(args)\\n            # Replace args inline that have adapters\\n            for i, (key, val) in enumerate(izip(self.arg_names, args)):\\n                try:\\n                    args[i] = self._adapt_param(key, val)\\n                except AnticipateParamError as e:\\n                    errors.append(e)\\n            args = tuple(args)\\n\\n        if kwargs and self.params:\\n            # Adapt all adaptable arguments\\n            for key, val in kwargs.items():\\n                try:\\n                    kwargs[key] = self._adapt_param(key, val)\\n                except AnticipateParamError as e:\\n                    errors.append(e)\\n\\n        if errors:\\n            raise AnticipateErrors(\\n                message=\\'Invalid input for %s\\' % self.func,\\n                errors=errors)\\n\\n        return args, kwargs',\n",
       " 'def output(self, result):\\n        \"\"\"\\n        Adapts the result of a function based on the returns definition.\\n        \"\"\"\\n        if self.returns:\\n            errors = None\\n            try:\\n                return self._adapt_result(result)\\n            except AdaptErrors as e:\\n                errors = e.errors\\n            except AdaptError as e:\\n                errors = [e]\\n\\n            raise AnticipateErrors(\\n                message=\\'Return value %r does not match anticipated type %r\\'\\n                    % (type(result), self.returns),\\n                errors=errors)\\n        elif self.strict:\\n            if result is not None:\\n                raise AnticipateErrors(\\n                    message=\\'Return value %r does not match anticipated value \\'\\n                    \\'of None\\' % type(result),\\n                    errors=None)\\n            return None\\n        else:\\n            return result',\n",
       " 'def clean(self, value):\\n        \"\"\"Passes the value to FileField and resizes the image at the path the parent\\n        returns if needed.\\n\\n        \"\"\"\\n        path = super(Image, self).clean(value)\\n        if path and self.size:\\n            self.resize_image(join(self.base_path, path))\\n        return path',\n",
       " 'def calculate_dimensions(image_size, desired_size):\\n        \"\"\"Return the Tuple with the arguments to pass to Image.crop.\\n\\n        If the image is smaller than than the desired_size Don\\'t do\\n        anything. Otherwise, first calculate the (truncated) center and then\\n        take half the width and height (truncated again) for x and y.\\n\\n        x0, y0: the center coordinates\\n        \"\"\"\\n\\n        current_x, current_y = image_size\\n        target_x, target_y = desired_size\\n\\n        if current_x < target_x and current_y < target_y:\\n            return None\\n\\n        if current_x > target_x:\\n            new_x0 = floor(current_x / 2)\\n            new_x = new_x0 - ceil(target_x / 2)\\n            new_width = target_x\\n        else:\\n            new_x = 0\\n            new_width = current_x\\n\\n        if current_y > target_y:\\n            new_y0 = floor(current_y / 2)\\n            new_y = new_y0 - ceil(target_y / 2)\\n            new_height = target_y\\n        else:\\n            new_y = 0\\n            new_height = current_y\\n\\n        return (int(new_x), int(new_y), new_width, new_height)',\n",
       " 'def options(self, *args, **kwargs):\\n        \"\"\"Default OPTIONS response\\n\\n        If the \\'cors\\' option is True, will respond with an empty response and\\n        set the \\'Access-Control-Allow-Headers\\' and\\n        \\'Access-Control-Allow-Methods\\' headers\\n        \"\"\"\\n        if getattr(options, \\'cors\\', False):\\n            self.set_header(\\'Access-Control-Allow-Headers\\',\\n                            \\'Content-Type, Authorization, \\'\\n                            \\'Accept, X-Requested-With\\')\\n            self.set_header(\\'Access-Control-Allow-Methods\\',\\n                            \\'OPTIONS, TRACE, GET, HEAD, POST, \\'\\n                            \\'PUT, PATCH, DELETE\\')\\n\\n        self.finish()',\n",
       " 'def write_error(self, status_code, **kwargs):\\n        \"\"\"Override `write_error` in order to output JSON errors\\n\\n        :param status_code: the response\\'s status code, e.g. 500\\n        \"\"\"\\n        http_error = _get_http_error(kwargs)\\n        if http_error:\\n            self.finish(self._error_template(status_code,\\n                                             http_error.errors,\\n                                             http_error.source))\\n        else:\\n            source = kwargs.get(\\'source\\', getattr(options, \\'name\\', None))\\n            # Slightly annoyed that have to rely on the internal self._reason\\n            # to deal with unhandled exceptions. On the dev version of\\n            # tornado self._reason is always set, while in the current version\\n            # a reason kwarg is passed down from `send_error` but not set\\n            # on the instance.\\n            reason = kwargs.get(\\'reason\\', self._reason)\\n            self.finish(self._error_template(status_code, reason, source))',\n",
       " 'def _error_template(cls, status_code, errors, source=None):\\n        \"\"\"Construct JSON error response\\n\\n        :param status_code: the http status code\\n        :param errors: string or list of error strings\\n        :param source: source of the error\\n        :returns: dictionary, e.g.\\n            {\\n                \\'status\\': 400,\\n                \\'errors\\': [\\n                    {\\n                        \\'source\\': \\'accounts\\' ,\\n                        \\'message\\':\\'errormsg1\\'\\n                    },\\n                    {\\n                        \\'source\\': \\'accounts\\',\\n                        \\'message\\':\\'errormsg2\\'\\n                    }\\n                ]\\n            }\\n        \"\"\"\\n        # this handles unhandled exceptions\\n        if isinstance(errors, basestring):\\n            errors_out = {\\'errors\\': [{\\'message\\': errors}]}\\n        elif isinstance(errors, (list, tuple)):\\n            errors_out = {\\'errors\\': [{\\'message\\': e} for e in errors]}\\n        else:\\n            errors_out = errors\\n        errors_out[\\'status\\'] = status_code\\n\\n        for error in errors_out[\\'errors\\']:\\n            if not error.get(\\'source\\'):\\n                error[\\'source\\'] = source\\n\\n        logging.error(json.dumps(errors_out))\\n        return errors_out',\n",
       " 'def get_json_body(self, required=None, validators=None):\\n        \"\"\"Get JSON from the request body\\n\\n        :param required: optionally provide a list of keys that should be\\n        in the JSON body (raises a 400 HTTPError if any are missing)\\n        :param validator: optionally provide a dictionary of items that should\\n        be in the body with a method that validates the item.\\n        The method must be synchronous and return a boolean, no exceptions.\\n        :raises: HTTPError\\n        \"\"\"\\n        content_type = self.request.headers.get(\\'Content-Type\\',\\n                                                \\'application/json\\')\\n        if \\'application/json\\' not in content_type.split(\\';\\'):\\n            raise HTTPError(415, \\'Content-Type should be application/json\\')\\n        if not self.request.body:\\n            error = \\'Request body is empty\\'\\n            logging.warning(error)\\n            raise HTTPError(400, error)\\n\\n        try:\\n            body = json.loads(self.request.body)\\n        except (ValueError, TypeError):\\n            error = \\'Error parsing JSON\\'\\n            logging.warning(error)\\n            raise HTTPError(400, error)\\n\\n        if required:\\n            _check_required(body, required)\\n\\n        if validators:\\n            _validate(body, validators)\\n\\n        return body',\n",
       " 'def verify_token(self, token, requested_access):\\n        \"\"\"\\n        Check the token bearer is permitted to access the resource\\n\\n        :param token: Access token\\n        :param requested_access: the access level the client has requested\\n        :returns: boolean\\n        \"\"\"\\n        client = API(options.url_auth,\\n                     auth_username=options.service_id,\\n                     auth_password=options.client_secret,\\n                     ssl_options=ssl_server_options())\\n        headers = {\\'Content-Type\\': \\'application/x-www-form-urlencoded\\',\\n                   \\'Accept\\': \\'application/json\\'}\\n        body = urllib.urlencode({\\'token\\': token, \\'requested_access\\': requested_access})\\n\\n        client.auth.verify.prepare_request(headers=headers, request_timeout=180)\\n\\n        try:\\n            result = yield client.auth.verify.post(body=body)\\n        except tornado.httpclient.HTTPError as ex:\\n            # Must be converted to a tornado.web.HTTPError for the server\\n            # to handle it correctly\\n            logging.exception(ex.message)\\n            raise HTTPError(500, \\'Internal Server Error\\')\\n\\n        raise Return(result[\\'has_access\\'])',\n",
       " 'def prepare(self):\\n        \"\"\"If OAuth verification is required, validate provided token\\n\\n        :raise: HTTPError if token does not have access\\n        \"\"\"\\n        requested_access = self.endpoint_access(self.request.method)\\n        use_oauth = getattr(options, \\'use_oauth\\', None)\\n        if use_oauth and requested_access is not self.UNAUTHENTICATED_ACCESS:\\n            token = self.request.headers.get(\\'Authorization\\', \\'\\').split(\\' \\')[-1]\\n            if token:\\n                has_access = yield self.verify_token(token, requested_access)\\n                if not has_access:\\n                    msg = \"\\'{}\\' access not granted.\".format(requested_access)\\n                    raise HTTPError(403, msg)\\n            else:\\n                msg = \\'OAuth token not provided\\'\\n                raise HTTPError(401, msg)',\n",
       " 'def parse_fast(xmlfile, element_name, attrnames, warn=False, optional=False):\\n    \"\"\"\\n    Parses the given attrnames from all elements with element_name\\n    @Note: The element must be on its own line and the attributes must appear in\\n    the given order.\\n    @Example: parse_fast(\\'plain.edg.xml\\', \\'edge\\', [\\'id\\', \\'speed\\'])\\n    \"\"\"\\n    prefixedAttrnames = [_prefix_keyword(a, warn) for a in attrnames]\\n    if optional:\\n        pattern = \\'\\'.join([\\'<%s\\' % element_name] +\\n                          [\\'(\\\\\\\\s+%s=\"(?P<%s>[^\"]*?)\")?\\' % a for a in zip(attrnames, prefixedAttrnames)])\\n    else:\\n        pattern = \\'.*\\'.join([\\'<%s\\' % element_name] +\\n                            [\\'%s=\"([^\"]*)\"\\' % attr for attr in attrnames])\\n    Record = namedtuple(element_name, prefixedAttrnames)\\n    reprog = re.compile(pattern)\\n    for line in open(xmlfile):\\n        m = reprog.search(line)\\n        if m:\\n            if optional:\\n                yield Record(**m.groupdict())\\n            else:\\n                yield Record(*m.groups())',\n",
       " 'def tracing(pattern=None, out=None):\\n    \"\"\"Print executed lines to stdout.\"\"\"\\n    _trace = partial(trace_line, pattern)\\n\\n    if out is None:\\n        out = sys.stdout\\n\\n    with redirect_stdout(out):\\n        sys.settrace(_trace)\\n        try:\\n            yield\\n        finally:\\n            sys.settrace(None)',\n",
       " 'def override_params(opening_char=\\'{\\', closing_char=\\'}\\', separator_char=\\'|\\'):\\n    \"\"\"\\n    Override some character settings\\n\\n    @type opening_char: str\\n    @param opening_char: Opening character. Default: \\'{\\'\\n    @type closing_char: str\\n    @param closing_char: Closing character. Default: \\'}\\'\\n    @type separator_char: str\\n    @param separator_char: Separator char. Default: \\'|\\'\\n    \"\"\"\\n    global char_separator, char_opening, char_closing\\n    char_separator = separator_char\\n    char_opening = opening_char\\n    char_closing = closing_char',\n",
       " 'def unique(text):\\n    \"\"\"\\n    Return an unique text\\n\\n    @type text: str\\n    @param text: Text written used spin syntax.\\n    @return: An unique text\\n\\n    # Generate an unique sentence\\n    >>> unique(\\'The {quick|fast} {brown|gray|red} fox jumped over the lazy dog.\\')\\n    \\'The quick red fox jumped over the lazy dog\\'\\n\\n\\n    \"\"\"\\n\\n    # check if the text is correct\\n    correct, error = _is_correct(text)\\n    if not correct:\\n        raise Exception(error)\\n\\n    s = []\\n    _all_unique_texts(text, s)\\n    return s[0]',\n",
       " 'def _all_unique_texts(text, final):\\n    \"\"\"\\n    Compute all the possible unique texts\\n\\n    @type text: str\\n    @param text: Text written used spin syntax\\n\\n    @type final: list\\n    @param final: An empty list where all the unique texts will be stored\\n    @return: Nothing. The result will be in the \\'final\\' list\\n    \"\"\"\\n    if not char_opening in text:\\n        if not text in final:\\n            final.append(text)\\n        return\\n\\n    stack = []\\n    indexes = []\\n    for i, c in enumerate(text):\\n        if c == char_closing:\\n            if stack[-1] == char_opening:\\n                start_index = indexes.pop()\\n                substring = \\'\\' if i == start_index + 1 else text[start_index:i + 1]\\n                # get some random combination\\n                combination = next(_choices(substring))\\n                new_text = text.replace(substring, combination)\\n                _all_unique_texts(new_text, final)\\n                return\\n        elif c == char_opening:\\n            stack.append(c)\\n            indexes.append(i)',\n",
       " 'def _is_correct(text):\\n    \"\"\"\\n    Check if the specified text has a correct spin syntax\\n\\n    @type text: str\\n    @param text: Text written used spin syntax\\n\\n    @rtype: tuple\\n    @return: A tuple: (is_correct, error). First position contains the result, and second one the error if not correct.\\n    \"\"\"\\n    error = \\'\\'\\n    stack = []\\n    for i, c in enumerate(text):\\n        if c == char_opening:\\n            stack.append(c)\\n        elif c == char_closing:\\n            if stack.count == 0:\\n                error = \\'Syntax incorrect. Found \"}\" before \"{\"\\'\\n                break\\n            last_char = stack.pop()\\n            if last_char != char_opening:\\n                error = \\'Syntax incorrect. Found \"}\" before \"{\"\\'\\n                break\\n    if len(stack) > 0:\\n        error = \\'Syntax incorrect. Some \"{\" were not closed\\'\\n    return not error, error',\n",
       " 'def visit_FunctionBody(self, node):\\n        \"\"\"Visitor for `FunctionBody` AST node.\"\"\"\\n        for child in node.children:\\n            return_value = self.visit(child)\\n\\n            if isinstance(child, ReturnStatement):\\n                return return_value\\n\\n            if isinstance(child, (IfStatement, WhileStatement)):\\n                if return_value is not None:\\n                    return return_value\\n\\n        return NoneType()',\n",
       " 'def visit_WhileStatement(self, node):\\n        \"\"\"Visitor for `WhileStatement` AST node.\"\"\"\\n        while self.visit(node.condition):\\n            result = self.visit(node.compound)\\n            if result is not None:\\n                return result',\n",
       " 'def visit_Compound(self, node):\\n        \"\"\"Visitor for `Compound` AST node.\"\"\"\\n        self.memory.append_scope()\\n        for child in node.children:\\n            return_value = self.visit(child)\\n\\n            if isinstance(child, ReturnStatement):\\n                return return_value\\n\\n            if isinstance(child, (IfStatement, WhileStatement)):\\n                if return_value is not None:\\n                    return return_value\\n        self.memory.pop_scope()',\n",
       " 'def visit_UnaryOperation(self, node):\\n        \"\"\"Visitor for `UnaryOperation` AST node.\"\"\"\\n        if node.op.nature == Nature.PLUS:\\n            return +self.visit(node.right)\\n        elif node.op.nature == Nature.MINUS:\\n            return -self.visit(node.right)\\n        elif node.op.nature == Nature.NOT:\\n            return Bool(not self.visit(node.right))',\n",
       " 'def visit_Boolean(self, node):\\n        \"\"\"Visitor for `Boolean` AST node.\"\"\"\\n        if node.value == \\'true\\':\\n            return Bool(True)\\n        elif node.value == \\'false\\':\\n            return Bool(False)',\n",
       " 'def interpret(self):\\n        \"\"\"Generic entrypoint of `Interpreter` class.\"\"\"\\n        self.load_builtins()\\n        self.load_functions(self.tree)\\n        self.visit(self.tree)',\n",
       " \"def up(name, debug=False):\\n    '''\\n    Create servers and containers as required to meet the configuration\\n    specified in _name_.\\n\\n    Args:\\n        * name: The name of the yaml config file (you can omit the .yml extension for convenience)\\n\\n    Example:\\n        fab ensemble.up:wordpress\\n    '''\\n\\n    if debug:\\n        env.ensemble_debug = True\\n\\n    filenames_to_try = [\\n        name,\\n        '%s.yml' % name,\\n        '%s.yaml' % name,\\n    ]\\n\\n    for filename in filenames_to_try:\\n        if os.path.exists(filename):\\n            with open(filename, 'r') as f:\\n                config = yaml.load(f)\\n            break\\n    else:\\n        abort('Ensemble manifest not found: %s' % name)\\n\\n    uncache()\\n    try:\\n        do_up(config)\\n    except exceptions.ConfigException, e:\\n        abort('Config error: ' + str(e))\",\n",
       " 'def stop(name, file=sys.stderr):\\n    \"\"\"\\n    Stop a profiling timer.\\n\\n    Arguments:\\n\\n        name (str): The name of the timer to stop. If no name is given, stop\\n            the global anonymous timer.\\n\\n    Returns:\\n\\n        bool: Whether or not profiling is enabled.\\n\\n    Raises:\\n\\n        KeyError: If the named timer does not exist.\\n    \"\"\"\\n    if is_enabled():\\n        elapsed = (time() - __TIMERS[name])\\n        if elapsed > 60:\\n            elapsed_str = \\'{:.1f} m\\'.format(elapsed / 60)\\n        elif elapsed > 1:\\n            elapsed_str = \\'{:.1f} s\\'.format(elapsed)\\n        else:\\n            elapsed_str = \\'{:.1f} ms\\'.format(elapsed * 1000)\\n\\n        del __TIMERS[name]\\n        print(\"[prof]\", name, elapsed_str, file=file)\\n    return is_enabled()',\n",
       " 'def profile(fun, *args, **kwargs):\\n    \"\"\"\\n    Profile a function.\\n    \"\"\"\\n    timer_name = kwargs.pop(\"prof_name\", None)\\n\\n    if not timer_name:\\n        module = inspect.getmodule(fun)\\n        c = [module.__name__]\\n        parentclass = labtypes.get_class_that_defined_method(fun)\\n        if parentclass:\\n            c.append(parentclass.__name__)\\n        c.append(fun.__name__)\\n        timer_name = \".\".join(c)\\n\\n    start(timer_name)\\n    ret = fun(*args, **kwargs)\\n    stop(timer_name)\\n    return ret',\n",
       " 'def geh(m, c):\\n    \"\"\"Error function for hourly traffic flow measures after Geoffrey E. Havers\"\"\"\\n    if m + c == 0:\\n        return 0\\n    else:\\n        return math.sqrt(2 * (m - c) * (m - c) / (m + c))',\n",
       " 'def avg(self):\\n        \"\"\"return the mean value\"\"\"\\n        # XXX rename this method\\n        if len(self.values) > 0:\\n            return sum(self.values) / float(len(self.values))\\n        else:\\n            return None',\n",
       " 'def avg_abs(self):\\n        \"\"\"return the mean of absolute values\"\"\"\\n        # XXX rename this method\\n        if len(self.values) > 0:\\n            return sum(map(abs, self.values)) / float(len(self.values))\\n        else:\\n            return None',\n",
       " 'def meanAndStdDev(self, limit=None):\\n        \"\"\"return the mean and the standard deviation optionally limited to the last limit values\"\"\"\\n        if limit is None or len(self.values) < limit:\\n            limit = len(self.values)\\n        if limit > 0:\\n            mean = sum(self.values[-limit:]) / float(limit)\\n            sumSq = 0.\\n            for v in self.values[-limit:]:\\n                sumSq += (v - mean) * (v - mean)\\n            return mean, math.sqrt(sumSq / limit)\\n        else:\\n            return None',\n",
       " 'def relStdDev(self, limit=None):\\n        \"\"\"return the relative standard deviation optionally limited to the last limit values\"\"\"\\n        moments = self.meanAndStdDev(limit)\\n        if moments is None:\\n            return None\\n        return moments[1] / moments[0]',\n",
       " 'def mean(self):\\n        \"\"\"return the median value\"\"\"\\n        # XXX rename this method\\n        if len(self.values) > 0:\\n            return sorted(self.values)[len(self.values) / 2]\\n        else:\\n            return None',\n",
       " 'def mean_abs(self):\\n        \"\"\"return the median of absolute values\"\"\"\\n        # XXX rename this method\\n        if len(self.values) > 0:\\n            return sorted(map(abs, self.values))[len(self.values) / 2]\\n        else:\\n            return None',\n",
       " 'def copy_resources_to_log_dir(log_dir):\\n        \"\"\"Copies the necessary static assets to the log_dir and returns the path \\n        of the main css file.\"\"\"\\n        css_path = resource_filename(Requirement.parse(\"egat\"), \"/egat/data/default.css\")\\n        header_path = resource_filename(Requirement.parse(\"egat\"), \"/egat/data/egat_header.png\")\\n        shutil.copyfile(css_path, log_dir + \"/style.css\")\\n        shutil.copyfile(header_path, log_dir + \"/egat_header.png\")\\n\\n        return log_dir + os.sep + \"style.css\"',\n",
       " 'def dump_queue(queue):\\n        \"\"\"\\n        Empties all pending items in a queue and returns them in a list.\\n        \"\"\"\\n        result = []\\n\\n        try:\\n            while True:\\n                item = queue.get_nowait()\\n                result.append(item)\\n        except: Empty\\n\\n        return result',\n",
       " 'def execute(command, cwd=os.path.curdir, **options):\\n    \"\"\"\\n    Run the system command with optional options.\\n\\n    Args:\\n        * command: system command.\\n        * cwd: current working directory.\\n        * verbose: direct options for :func:`subprocess.Popen`.\\n\\n    Returns:\\n        Opened process, standard output & error.\\n    \"\"\"\\n    process = subprocess.Popen(shlex.split(command), cwd=cwd, **options)\\n    stdout, stderr = process.communicate() \\n    return process, stdout, stderr',\n",
       " 'def to_dict(self, copy=False):\\n        \"\"\"Convert the struct to a dictionary.\\n\\n        If `copy == True`, returns a deep copy of the values.\\n\\n        \"\"\"\\n        new_dict = {}\\n        for attr, value in self:\\n            if copy:\\n                value = deepcopy(value)\\n            new_dict[attr] = value\\n\\n        return new_dict',\n",
       " 'def start(self):\\n        \"\"\"Start the process, essentially forks and calls target function.\"\"\" \\n        logger.info(\"starting process\")\\n        process = os.fork()\\n        time.sleep(0.01)\\n        if process != 0:\\n            logger.debug(\\'starting child watcher\\')\\n            self.loop.reset()\\n            self.child_pid = process\\n            self.watcher = pyev.Child(self.child_pid, False, self.loop, self._child)\\n            self.watcher.start()\\n        else:\\n            self.loop.reset()\\n            logger.debug(\\'running main function\\')\\n            self.run(*self.args, **self.kwargs) \\n            logger.debug(\\'quitting\\')\\n            sys.exit(0)',\n",
       " 'def setup(settings):\\n    \"\"\"\\n    Setup the database connection.\\n    \"\"\"\\n    connector = settings.get(\\'db_connector\\')\\n    if connector == \\'postgres\\':\\n        from playhouse.pool import PooledPostgresqlExtDatabase\\n        return PooledPostgresqlExtDatabase(settings[\\'db_name\\'],\\n                           user=settings[\\'db_user\\'],\\n                           password=settings[\\'db_password\\'],\\n                           host=settings[\\'db_host\\'],\\n                           port=settings.get(\\'db_port\\'),\\n                           max_connections=settings.get(\\'db_max_conn\\'),\\n                           stale_timeout=settings.get(\\'db_stale_timeout\\'),\\n                           timeout=settings.get(\\'db_timeout\\'),\\n                           register_hstore=False)',\n",
       " 'def init(module, db):\\n    \"\"\"\\n    Initialize the models.\\n    \"\"\"\\n    for model in farine.discovery.import_models(module):\\n        model._meta.database = db',\n",
       " 'def to_json(self, extras=None):\\n        \"\"\"\\n        Convert a model into a json using the playhouse shortcut.\\n        \"\"\"\\n        extras = extras or {}\\n        to_dict = model_to_dict(self)\\n        to_dict.update(extras)\\n        return json.dumps(to_dict, cls=sel.serializers.JsonEncoder)',\n",
       " 'def lazy(func):\\n    \"\"\" Decorator, which can be used for lazy imports\\n\\n            @lazy\\n            def yaml():\\n                import yaml\\n                return yaml \"\"\"\\n    try:\\n        frame = sys._getframe(1)\\n    except Exception:\\n        _locals = None\\n    else:\\n        _locals = frame.f_locals\\n    func_name = func.func_name if six.PY2 else func.__name__\\n    return LazyStub(func_name, func, _locals)',\n",
       " 'def add_reftrack(self, reftrack):\\n        \"\"\"Add a reftrack object to the root.\\n\\n        This will not handle row insertion in the model!\\n        It is automatically done when setting the parent of the :class:`Reftrack` object.\\n\\n        :param reftrack: the reftrack object to add\\n        :type reftrack: :class:`Reftrack`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self._reftracks.add(reftrack)\\n        refobj = reftrack.get_refobj()\\n        if refobj:\\n            self._parentsearchdict[refobj] = reftrack',\n",
       " 'def remove_reftrack(self, reftrack):\\n        \"\"\"Remove the reftrack from the root.\\n\\n        This will not handle row deletion in the model!\\n        It is automatically done when calling :meth:`Reftrack.delete`.\\n\\n        :param reftrack: the reftrack object to remove\\n        :type reftrack: :class:`Reftrack`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self._reftracks.remove(reftrack)\\n        refobj = reftrack.get_refobj()\\n        if refobj and refobj in self._parentsearchdict:\\n            del self._parentsearchdict[refobj]',\n",
       " 'def update_refobj(self, old, new, reftrack):\\n        \"\"\"Update the parent search dict so that the reftrack can be found\\n        with the new refobj and delete the entry for the old refobj.\\n\\n        Old or new can also be None.\\n\\n        :param old: the old refobj of reftrack\\n        :param new: the new refobj of reftrack\\n        :param reftrack: The reftrack, which refobj was updated\\n        :type reftrack: :class:`Reftrack`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if old:\\n            del self._parentsearchdict[old]\\n        if new:\\n            self._parentsearchdict[new] = reftrack',\n",
       " 'def get_scene_suggestions(self, refobjinter):\\n        \"\"\"Return a list of suggested Reftracks for the current scene, that are not already\\n        in this root.\\n\\n        A suggestion is a combination of type and element.\\n\\n        :param refobjinter: a programm specific reftrack object interface\\n        :type refobjinter: :class:`RefobjInterface`\\n        :returns: A list of suggestions\\n        :rtype: :class:`list`\\n        :raises: None\\n        \"\"\"\\n        sugs = []\\n        cur = refobjinter.get_current_element()\\n        if not cur:\\n            return sugs\\n        for typ in refobjinter.types:\\n            inter = refobjinter.get_typ_interface(typ)\\n            elements = inter.get_scene_suggestions(cur)\\n            for e in elements:\\n                for r in self._reftracks:\\n                    if not r.get_parent() and typ == r.get_typ() and e == r.get_element():\\n                        break\\n                else:\\n                    sugs.append((typ, e))\\n        return sugs',\n",
       " 'def get_unwrapped(self, root, refobjinter):\\n        \"\"\"Return a set with all refobjects in the scene that are not in already\\n        wrapped in root.\\n\\n        :param root: the root that groups all reftracks and makes it possible to search for parents\\n        :type root: :class:`ReftrackRoot`\\n        :param refobjinter: a programm specific reftrack object interface\\n        :type refobjinter: :class:`RefobjInterface`\\n        :returns: a set with unwrapped refobjects\\n        :rtype: set\\n        :raises: None\\n        \"\"\"\\n        all_refobjs = set(refobjinter.get_all_refobjs())\\n        wrapped = set(root._parentsearchdict.keys())\\n        return all_refobjs - wrapped',\n",
       " 'def set_refobj(self, refobj, setParent=True):\\n        \"\"\"Set the reftrack object.\\n\\n        The reftrack object interface will determine typ, element, taskfileinfo, status and parent and set these values.\\n        If the reftrack object is None, the :class:`Reftrack` object will keep the initial typ,\\n        element but will loose it\\\\\\'s parent, status and taskfileinfo\\n\\n        :param refobj: a reftrack object or None\\n        :type refobj: None | reftrack object\\n        :param setParent: If True, set also the parent\\n        :type setParent: :class:`bool`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        root = self.get_root()\\n        old = self._refobj\\n        self._refobj = refobj\\n        refobjinter = self.get_refobjinter()\\n        if self._refobj:\\n            self.set_typ(refobjinter.get_typ(self._refobj))\\n            self.set_taskfileinfo(refobjinter.get_taskfileinfo(self._refobj))\\n            self.set_element(refobjinter.get_element(self._refobj))\\n            if setParent:\\n                parentrefobj = refobjinter.get_parent(self._refobj)\\n                parentreftrack = root.get_reftrack(parentrefobj)\\n                self.set_parent(parentreftrack)\\n            self.set_status(refobjinter.get_status(self._refobj))\\n        else:\\n            self.set_taskfileinfo(None)\\n            if setParent:\\n                self.set_parent(None)\\n            self.set_status(None)\\n        root.update_refobj(old, refobj, self)\\n        self.fetch_uptodate()',\n",
       " 'def set_typ(self, typ):\\n        \"\"\"Set the type of the entity\\n\\n        Make sure the type is registered in the :class:`RefobjInterface`.\\n\\n        :param typ: the type of the entity\\n        :type typ: str\\n        :returns: None\\n        :rtype: None\\n        :raises: ValueError\\n        \"\"\"\\n        if typ not in self._refobjinter.types:\\n            raise ValueError(\"The given typ is not supported by RefobjInterface. Given %s, supported: %s\" %\\n                             (typ, self._refobjinter.types.keys()))\\n        self._typ = typ\\n        self._typicon = self.get_refobjinter().get_typ_icon(typ)',\n",
       " 'def set_parent(self, parent):\\n        \"\"\"Set the parent reftrack object\\n\\n        If a parent gets deleted, the children will be deleted too.\\n\\n        .. Note:: Once the parent is set, it cannot be set again!\\n\\n        :param parent: the parent reftrack object\\n        :type parent: :class:`Reftrack` | None\\n        :returns: None\\n        :rtype: None\\n        :raises: AssertionError\\n        \"\"\"\\n        assert self._parent is None or self._parent is parent,\\\\\\n            \"Cannot change the parent. Can only set from None.\"\\n        if parent and self._parent is parent:\\n            return\\n        self._parent = parent\\n        if parent:\\n            refobjinter = self.get_refobjinter()\\n            refobj = self.get_refobj()\\n            # set the parent of the refobj only if it is not already set\\n            # and only if there is one! oO\\n            if refobj and not refobjinter.get_parent(refobj):\\n                refobjinter.set_parent(refobj, parent.get_refobj())\\n            # add to parent\\n            self._parent.add_child(self)\\n        if not self.get_refobj():\\n            self.set_id(self.fetch_new_id())\\n\\n        pitem = self._parent._treeitem if self._parent else self.get_root().get_rootitem()\\n        self._treeitem.set_parent(pitem)\\n        self.fetch_alien()',\n",
       " 'def set_id(self, identifier):\\n        \"\"\"Set the id of the given reftrack\\n\\n        This will set the id on the refobject\\n\\n        :param identifier: the identifier number\\n        :type identifier: int\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self._id = identifier\\n        refobj = self.get_refobj()\\n        if refobj:\\n            self.get_refobjinter().set_id(refobj, identifier)',\n",
       " 'def fetch_new_id(self, ):\\n        \"\"\"Return a new id for the given reftrack to be set on the refobject\\n\\n        The id can identify reftracks that share the same parent, type and element.\\n\\n        :returns: A new id\\n        :rtype: int\\n        :raises: None\\n        \"\"\"\\n        parent = self.get_parent()\\n        if parent:\\n            others = parent._children\\n        else:\\n            others = [r for r in self.get_root()._reftracks if r.get_parent() is None]\\n        others = [r for r in others\\n                  if r != self\\n                  and r.get_typ() == self.get_typ()\\n                  and r.get_element() == self.get_element()]\\n        highest = -1\\n        for r in others:\\n            identifier = r.get_id()\\n            if identifier > highest:\\n                highest = identifier\\n        return highest + 1',\n",
       " 'def create_treeitem(self, ):\\n        \"\"\"Create a new treeitem for this reftrack instance.\\n\\n        .. Note:: Parent should be set, Parent should already have a treeitem.\\n                  If there is no parent, the root tree item is used as parent for the treeitem.\\n\\n        :returns: a new treeitem that contains a itemdata with the reftrack instanec.\\n        :rtype: :class:`TreeItem`\\n        :raises: None\\n        \"\"\"\\n        p = self.get_parent()\\n        root = self.get_root()\\n        if p:\\n            pitem = p.get_treeitem()\\n        else:\\n            pitem = root.get_rootitem()\\n        idata = root.create_itemdata(self)\\n        item = TreeItem(idata, parent=pitem)\\n        return item',\n",
       " 'def fetch_options(self, ):\\n        \"\"\"Set and return the options for possible files to\\n        load, replace etc. The stored element will determine the options.\\n\\n        The refobjinterface and typinterface are responsible for providing the options\\n\\n        :returns: the options\\n        :rtype: :class:`jukeboxcore.gui.treemodel.TreeModel`\\n        :raises: None\\n        \"\"\"\\n        self._options, self._taskfileinfo_options = self.get_refobjinter().fetch_options(self.get_typ(), self.get_element())\\n        return self._options',\n",
       " 'def fetch_uptodate(self, ):\\n        \"\"\"Set and return whether the currently loaded entity is\\n        the newest version in the department.\\n\\n        :returns: True, if newest version. False, if there is a newer version.\\n                  None, if there is nothing loaded yet.\\n        :rtype: bool | None\\n        :raises: None\\n        \"\"\"\\n        tfi = self.get_taskfileinfo()\\n        if tfi:\\n            self._uptodate = tfi.is_latest()\\n        else:\\n            self._uptodate = None\\n        return self._uptodate',\n",
       " 'def fetch_alien(self, ):\\n        \"\"\"Set and return, if the reftrack element is linked to the current scene.\\n\\n        Askes the refobj interface for the current scene.\\n        If there is no current scene then True is returned.\\n\\n        :returns: whether the element is linked to the current scene\\n        :rtype: bool\\n        :raises: None\\n        \"\"\"\\n        parent = self.get_parent()\\n        if parent:\\n            parentelement = parent.get_element()\\n        else:\\n            parentelement = self.get_refobjinter().get_current_element()\\n            if not parentelement:\\n                self._alien = True\\n                return self._alien\\n        element = self.get_element()\\n        if element == parentelement:\\n            self._alien = False\\n        # test if it is the element is a global shot\\n        # first test if we have a shot\\n        # then test if it is in a global sequence. then the shot is global too.\\n        # test if the parent element is a shot, if they share the sequence, and element is global\\n        elif isinstance(element, djadapter.models.Shot)\\\\\\n            and (element.sequence.name == djadapter.GLOBAL_NAME\\\\\\n            or (isinstance(parentelement, djadapter.models.Shot)\\\\\\n                and parentelement.sequence == element.sequence and element.name == djadapter.GLOBAL_NAME)):\\n            self._alien = False\\n        else:\\n            assets = parentelement.assets.all()\\n            self._alien = element not in assets\\n        return self._alien',\n",
       " 'def reference(self, taskfileinfo):\\n        \"\"\"Reference the entity into the scene. Only possible if the current status is None.\\n\\n        This will create a new refobject, then call :meth:`RefobjInterface.reference` and\\n        afterwards set the refobj on the :class:`Reftrack` instance.\\n\\n        :param taskfileinfo: the taskfileinfo to reference\\n        :type taskfileinfo: :class:`jukeboxcore.filesys.TaskFileInfo`\\n        :returns: None\\n        :rtype: None\\n        :raises: :class:`ReftrackIntegrityError`\\n        \"\"\"\\n        assert self.status() is None,\\\\\\n            \"Can only reference, if the entity is not already referenced/imported. Use replace instead.\"\\n        refobj = self.create_refobject()\\n        with self.set_parent_on_new(refobj):\\n            self.get_refobjinter().reference(taskfileinfo, refobj)\\n        self.set_refobj(refobj)\\n        self.fetch_new_children()\\n        self.update_restrictions()\\n        self.emit_data_changed()',\n",
       " 'def load(self, ):\\n        \"\"\"If the reference is in the scene but unloaded, load it.\\n\\n        .. Note:: Do not confuse this with reference or import. Load means that it is already referenced.\\n                  But the data from the reference was not read until now. Load loads the data from the reference.\\n\\n        This will call :meth:`RefobjInterface.load` and set the status to :data:`Reftrack.LOADED`.\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: :class:`ReftrackIntegrityError`\\n        \"\"\"\\n        assert self.status() == self.UNLOADED,\\\\\\n            \"Cannot load if there is no unloaded reference. Use reference instead.\"\\n        self.get_refobjinter().load(self._refobj)\\n        self.set_status(self.LOADED)\\n        self.fetch_new_children()\\n        self.update_restrictions()\\n        self.emit_data_changed()',\n",
       " 'def unload(self, ):\\n        \"\"\"If the reference is loaded, unload it.\\n\\n        .. Note:: Do not confuse this with a delete. This means, that the reference stays in the\\n                  scene, but no data is read from the reference.\\n\\n        This will call :meth:`RefobjInterface.unload` and set the status to :data:`Reftrack.UNLOADED`.\\n        It will also throw away all children :class:`Reftrack`. They will return after :meth:`Reftrack.load`.\\n\\n        The problem might be that children depend on their parent, but will not get unloaded.\\n        E.g. you imported a child. It will stay in the scene after the unload and become an orphan.\\n        In this case an error is raised. It is not possible to unload such an entity.\\n        The orphan might get its parents back after you call load, but it will introduce bugs when\\n        wrapping children of unloaded entities. So we simply disable the feature in that case and raise\\n        an :class:`IntegrityError`\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: :class:`ReftrackIntegrityError`\\n        \"\"\"\\n        assert self.status() == self.LOADED,\\\\\\n            \"Cannot unload if there is no loaded reference. \\\\\\nUse delete if you want to get rid of a reference or import.\"\\n        childrentodelete = self.get_children_to_delete()\\n        if childrentodelete:\\n            raise ReftrackIntegrityError(\"Cannot unload because children of the reference would become orphans.\", childrentodelete)\\n        self.get_refobjinter().unload(self._refobj)\\n        self.set_status(self.UNLOADED)\\n        self.throw_children_away()\\n        self.update_restrictions()\\n        self.emit_data_changed()',\n",
       " 'def import_file(self, taskfileinfo):\\n        \"\"\"Import the file for the given taskfileinfo\\n\\n        This will also update the status to :data:`Reftrack.IMPORTED`. This will also call\\n        :meth:`fetch_new_children`. Because after the import, we might have new children.\\n\\n        :param taskfileinfo: the taskfileinfo to import. If None is given, try to import\\n                             the current reference\\n        :type taskfileinfo: :class:`jukeboxcore.filesys.TaskFileInfo` | None\\n        :returns: None\\n        :rtype: None\\n        :raises: :class:`ReftrackIntegrityError`\\n        \"\"\"\\n        assert self.status() is None,\\\\\\n            \"Entity is already in scene. Use replace instead.\"\\n        refobjinter = self.get_refobjinter()\\n        refobj = self.create_refobject()\\n        with self.set_parent_on_new(refobj):\\n            refobjinter.import_taskfile(refobj, taskfileinfo)\\n        self.set_refobj(refobj)\\n        self.set_status(self.IMPORTED)\\n        self.fetch_new_children()\\n        self.update_restrictions()\\n        self.emit_data_changed()',\n",
       " 'def import_reference(self, ):\\n        \"\"\"Import the currently loaded reference\\n\\n        This will also update the status to :data:`Reftrack.IMPORTED`.\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: :class:`ReftrackIntegrityError`\\n        \"\"\"\\n        assert self.status() in (self.LOADED, self.UNLOADED),\\\\\\n            \"There is no reference for this entity.\"\\n        refobjinter = self.get_refobjinter()\\n        refobjinter.import_reference(self.get_refobj())\\n        self.set_status(self.IMPORTED)\\n        self.update_restrictions()\\n        for c in self.get_all_children():\\n            c.update_restrictions()\\n        self.emit_data_changed()',\n",
       " 'def replace(self, taskfileinfo):\\n        \"\"\"Replace the current reference or imported entity.\\n\\n        If the given refobj is not replaceable, e.g. it might be imported\\n        or it is not possible to switch the data, then the entity will be deleted,\\n        then referenced or imported again, depending on the current status.\\n\\n        A replaced entity might have other children. This introduces a problem:\\n\\n          A child might get deleted, e.g. an asset which itself has another child,\\n          that will not get deleted, e.g. an imported shader. In this case the imported\\n          shader will be left as an orphan.\\n          This will check all children that will not be deleted (:meth:`Reftrack.get_children_to_delete`)\\n          and checks if they are orphans after the replace. If they are, they will get deleted!\\n\\n        After the replace, all children will be reset. This will simply throw away all children reftracks\\n        (the content will not be deleted) and wrap all new children again. See: :meth:`Reftrack.fetch_new_children`.\\n\\n        :param taskfileinfo: the taskfileinfo that will replace the old entity\\n        :type taskfileinfo: :class:`jukeboxcore.filesys.TaskFileInfo`\\n        :returns: None\\n        :rtype: None\\n        :raises: ReftrackIntegrityError\\n        \"\"\"\\n        assert self.status() is not None,\\\\\\n            \"Can only replace entities that are already in the scene.\"\\n        refobjinter = self.get_refobjinter()\\n        refobj = self.get_refobj()\\n        if self.status() in (self.LOADED, self.UNLOADED) and refobjinter.is_replaceable(refobj):\\n            # possible orphans will not get replaced, by replace\\n            # but their parent might dissapear in the process\\n            possibleorphans = self.get_children_to_delete()\\n            with self.set_parent_on_new(refobj):\\n                refobjinter.replace(refobj, taskfileinfo)\\n            self.set_taskfileinfo(taskfileinfo)\\n            self.fetch_uptodate()\\n            for o in possibleorphans:\\n                # find if orphans were created and delete them\\n                # we get the refobj of the parent\\n                # if it still exists, it is no orphan\\n                parent = o.get_parent()\\n                refobj = parent.get_refobj()\\n                if not parent.get_refobjinter().exists(refobj):\\n                    # orphans will be deleted!\\n                    # this is politically incorrect, i know!\\n                    # the world of programming is a harsh place.\\n                    o.delete()\\n            # reset the children\\n            # throw them away at first\\n            self.throw_children_away()\\n            # gather them again\\n            self.fetch_new_children()\\n        else:\\n            status = self.status()\\n            self.delete(removealien=False)\\n            if status == self.IMPORTED:\\n                self.import_file(taskfileinfo)\\n            else:\\n                self.reference(taskfileinfo)\\n        self.update_restrictions()\\n        self.emit_data_changed()',\n",
       " 'def _delete(self, ):\\n        \"\"\"Internal implementation for deleting a reftrack.\\n\\n        This will just delete the reftrack, set the children to None,\\n        update the status, and the rootobject. If the object is an alien,\\n        it will also set the parent to None, so it dissapears from the model.\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        refobjinter = self.get_refobjinter()\\n        refobjinter.delete(self.get_refobj())\\n        self.set_refobj(None, setParent=False)\\n        if self.alien():\\n            # it should not be in the scene\\n            # so also remove it from the model\\n            # so we cannot load it again\\n            parent = self.get_parent()\\n            if parent:\\n                parent.remove_child(self)\\n            self._treeitem.parent().remove_child(self._treeitem)\\n        else:\\n            # only remove all children from the model and set their parent to None\\n            for c in self.get_all_children():\\n                c._parent = None\\n                self._treeitem.remove_child(c._treeitem)\\n        # this should not have any children anymore\\n        self._children = []\\n        self.set_status(None)',\n",
       " 'def get_all_children(self):\\n        \"\"\"Get all children including children of children\\n\\n        :returns: all children including children of children\\n        :rtype: list of :class:`Reftrack`\\n        :raises: None\\n        \"\"\"\\n        children = self._children[:]\\n        oldlen = 0\\n        newlen = len(children)\\n        while oldlen != newlen:\\n            start = oldlen\\n            oldlen = len(children)\\n            for i in range(start, len(children)):\\n                children.extend(children[i]._children)\\n            newlen = len(children)\\n        return children',\n",
       " 'def get_children_to_delete(self):\\n        \"\"\"Return all children that are not referenced\\n\\n        :returns: list or :class:`Reftrack`\\n        :rtype: list\\n        :raises: None\\n        \"\"\"\\n        refobjinter = self.get_refobjinter()\\n        children = self.get_all_children()\\n\\n        todelete = []\\n        for c in children:\\n            if c.status() is None:\\n                # if child is not in scene we do not have to delete it\\n                continue\\n            rby = refobjinter.referenced_by(c.get_refobj())\\n            if rby is None:\\n                # child is not part of another reference.\\n                # we have to delete it for sure\\n                todelete.append(c)\\n                continue\\n            # check if child is referenced by any parent up to self\\n            # if it is not referenced by any refrence of a parent, then we\\n            # can assume it is referenced by a parent of a greater scope,\\n            # e.g. the parent of self. because we do not delete anything above self\\n            # we would have to delete the child manually\\n            parent = c.get_parent()\\n            while parent != self.get_parent():\\n                if refobjinter.get_reference(parent.get_refobj()) == rby:\\n                    # is referenced by a parent so it will get delted when the parent is deleted.\\n                    break\\n                parent = parent.get_parent()\\n            else:\\n                todelete.append(c)\\n        return todelete',\n",
       " 'def fetch_new_children(self, ):\\n        \"\"\"Collect all new children and add the suggestions to the children as well\\n\\n        When an entity is loaded, referenced, imported etc there might be new children.\\n        Also it might want to suggest children itself, like a Shader for an asset.\\n\\n        First we wrap all unwrapped children. See: :meth:`Reftrack.get_unwrapped`, :meth:`Reftrack.wrap`.\\n        Then we get the suggestions. See: :meth:`Reftrack.get_suggestions`. All suggestions that are not\\n        already a child of this Reftrack instance, will be used to create a new Reftrack with the type\\n        and element of the suggestion and the this instance as parent.\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        root = self.get_root()\\n        refobjinter = self.get_refobjinter()\\n        unwrapped = self.get_unwrapped(root, refobjinter)\\n        self.wrap(self.get_root(), self.get_refobjinter(), unwrapped)\\n\\n        suggestions = self.get_suggestions()\\n        for typ, element in suggestions:\\n            for c in self._children:\\n                if typ == c.get_typ() and element == c.get_element():\\n                    break\\n            else:\\n                Reftrack(root=root, refobjinter=refobjinter, typ=typ, element=element, parent=self)',\n",
       " 'def set_parent_on_new(self, parentrefobj):\\n        \"\"\"Contextmanager that on close will get all new\\n        unwrapped refobjects, and for every refobject with no parent\\n        sets is to the given one.\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        refobjinter = self.get_refobjinter()\\n        # to make sure we only get the new one\\n        # we get all current unwrapped first\\n        old = self.get_unwrapped(self.get_root(), refobjinter)\\n        yield\\n        new = self.get_unwrapped(self.get_root(), refobjinter) - old\\n        for refobj in new:\\n            if refobjinter.get_parent(refobj) is None:\\n                refobjinter.set_parent(refobj, parentrefobj)',\n",
       " 'def set_restricted(self, obj, restricted):\\n        \"\"\"Set the restriction on the given object.\\n\\n        You can use this to signal that a certain function is restricted.\\n        Then you can query the restriction later with :meth:`Reftrack.is_restricted`.\\n\\n        :param obj: a hashable object\\n        :param restricted: True, if you want to restrict the object.\\n        :type restricted: :class:`bool`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if restricted:\\n            self._restricted.add(obj)\\n        elif obj in self._restricted:\\n            self._restricted.remove(obj)',\n",
       " 'def fetch_reference_restriction(self, ):\\n        \"\"\"Fetch whether referencing is restricted\\n\\n        :returns: True, if referencing is restricted\\n        :rtype: :class:`bool`\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_refobjinter()\\n        restricted = self.status() is not None\\n        return restricted or inter.fetch_action_restriction(self, \\'reference\\')',\n",
       " 'def fetch_load_restriction(self, ):\\n        \"\"\"Fetch whether loading is restricted\\n\\n        :returns: True, if loading is restricted\\n        :rtype: :class:`bool`\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_refobjinter()\\n        restricted = self.status() != self.UNLOADED\\n        return restricted or inter.fetch_action_restriction(self, \\'load\\')',\n",
       " 'def fetch_import_ref_restriction(self,):\\n        \"\"\"Fetch whether importing the reference is restricted\\n\\n        :returns: True, if importing the reference is restricted\\n        :rtype: :class:`bool`\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_refobjinter()\\n        restricted = self.status() not in (self.LOADED, self.UNLOADED)\\n        return restricted or inter.fetch_action_restriction(self, \\'import_reference\\')',\n",
       " 'def fetch_import_f_restriction(self,):\\n        \"\"\"Fetch whether importing a file is restricted\\n\\n        :returns: True, if import is restricted\\n        :rtype: :class:`bool`\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_refobjinter()\\n        restricted = self.status() is not None\\n        return restricted or inter.fetch_action_restriction(self, \\'import_taskfile\\')',\n",
       " 'def emit_data_changed(self):\\n        \"\"\"Emit the data changed signal on the model of the treeitem\\n        if the treeitem has a model.\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        item = self.get_treeitem()\\n        m = item.get_model()\\n        if m:\\n            start = m.index_of_item(item)\\n            parent = start.parent()\\n            end = m.index(start.row(), item.column_count()-1, parent)\\n            m.dataChanged.emit(start, end)',\n",
       " 'def create(self, typ, identifier, parent=None):\\n        \"\"\"Create a new refobj with the given typ and parent\\n\\n        :param typ: the entity type\\n        :type typ: str\\n        :param identifier: the refobj id. Used to identify refobjects of the same parent, element and type in the UI\\n        :type identifier: int\\n        :param parent: the parent refobject\\n        :type parent: refobj\\n        :returns: The created refobj\\n        :rtype: refobj\\n        :raises: None\\n        \"\"\"\\n        refobj = self.create_refobj()\\n        self.set_typ(refobj, typ)\\n        self.set_id(refobj, identifier)\\n        if parent:\\n            self.set_parent(refobj, parent)\\n        return refobj',\n",
       " 'def delete(self, refobj):\\n        \"\"\"Delete the given refobj and the contents of the entity\\n\\n        :param refobj: the refobj to delete\\n        :type refobj: refobj\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        i = self.get_typ_interface(self.get_typ(refobj))\\n        i.delete(refobj)\\n        self.delete_refobj(refobj)',\n",
       " 'def reference(self, taskfileinfo, refobj):\\n        \"\"\"Reference the given taskfile info and\\n        set the created reference on the refobj\\n\\n        This will call :meth:`ReftypeInterface.reference`, then :meth:`ReftypeInterface.set_reference`.\\n\\n        :param taskfileinfo: The taskfileinfo that holds the information for what to reference\\n        :type taskfileinfo: :class:`jukeboxcore.filesys.TaskFileInfo`\\n        :param refobj: the refobj that should represent the new reference\\n        :type refobj: refobj\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_typ_interface(self.get_typ(refobj))\\n        ref = inter.reference(refobj, taskfileinfo)\\n        self.set_reference(refobj, ref)',\n",
       " 'def replace(self, refobj, taskfileinfo):\\n        \"\"\"Replace the given refobjs reference with the taskfileinfo\\n\\n        This will call :meth:`ReftypeInterface.replace`.\\n\\n        :param refobj: the refobject\\n        :type refobj: refobj\\n        :param taskfileinfo: the taskfileinfo that will replace the old entity\\n        :type taskfileinfo: :class:`jukeboxcore.filesys.TaskFileInfo`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_typ_interface(self.get_typ(refobj))\\n        ref = self.get_reference(refobj)\\n        inter.replace(refobj, ref, taskfileinfo)',\n",
       " 'def is_replaceable(self, refobj):\\n        \"\"\"Return whether the given reference of the refobject is replaceable or\\n        if it should just get deleted and loaded again.\\n\\n        This will call :meth:`ReftypeInterface.is_replaceable`.\\n\\n        :param refobj: the refobject to query\\n        :type refobj: refobj\\n        :returns: True, if replaceable\\n        :rtype: bool\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_typ_interface(self.get_typ(refobj))\\n        return inter.is_replaceable(refobj)',\n",
       " 'def import_reference(self, refobj):\\n        \"\"\"Import the reference of the given refobj\\n\\n        Here we assume, that the reference is already in the scene and\\n        we break the encapsulation and pull the data from the reference into\\n        the current scene.\\n        This will call :meth:`ReftypeInterface.import_reference` and set the\\n        reference on the refobj to None.\\n\\n        :param refobj: the refobj with a reference\\n        :type refobj: refobj\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_typ_interface(self.get_typ(refobj))\\n        ref = self.get_reference(refobj)\\n        inter.import_reference(refobj, ref)\\n        self.set_reference(refobj, None)',\n",
       " 'def get_element(self, refobj):\\n        \"\"\"Return the element the refobj represents.\\n\\n        The element is either an Asset or a Shot.\\n\\n        :param refobj: the refobject to query\\n        :type refobj: refobj\\n        :returns: The element the reftrack represents\\n        :rtype: :class:`jukeboxcore.djadapter.models.Asset` | :class:`jukeboxcore.djadapter.models.Shot`\\n        :raises: None\\n        \"\"\"\\n        tf = self.get_taskfile(refobj)\\n        return tf.task.element',\n",
       " 'def get_option_labels(self, typ, element):\\n        \"\"\"Return labels for each level of the option model.\\n\\n        The options returned by :meth:`RefobjInterface.fetch_options` is a treemodel\\n        with ``n`` levels. Each level should get a label to describe what is displays.\\n\\n        E.g. if you organize your options, so that the first level shows the tasks, the second\\n        level shows the descriptors and the third one shows the versions, then\\n        your labels should be: ``[\"Task\", \"Descriptor\", \"Version\"]``.\\n\\n        :param typ: the typ of options. E.g. Asset, Alembic, Camera etc\\n        :type typ: str\\n        :param element: The element for which the options should be fetched.\\n        :type element: :class:`jukeboxcore.djadapter.models.Asset` | :class:`jukeboxcore.djadapter.models.Shot`\\n        :returns: label strings for all levels\\n        :rtype: list\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_typ_interface(typ)\\n        return inter.get_option_labels(element)',\n",
       " 'def get_option_columns(self, typ, element):\\n        \"\"\"Return the column of the model to show for each level\\n\\n        Because each level might be displayed in a combobox. So you might want to provide the column\\n        to show.\\n\\n        :param typ: the typ of options. E.g. Asset, Alembic, Camera etc\\n        :type typ: str\\n        :param element: The element for wich the options should be fetched.\\n        :type element: :class:`jukeboxcore.djadapter.models.Asset` | :class:`jukeboxcore.djadapter.models.Shot`\\n        :returns: a list of columns\\n        :rtype: list\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_typ_interface(typ)\\n        return inter.get_option_columns(element)',\n",
       " 'def get_suggestions(self, reftrack):\\n        \"\"\"Return a list with possible children for this reftrack\\n\\n        Each Reftrack may want different children. E.g. a Asset wants\\n        to suggest a shader for itself and all assets that are linked in\\n        to it in the database. Suggestions only apply for enities with status\\n        other than None.\\n\\n        A suggestion is a tuple of typ and element. It will be used to create a newlen\\n        :class:`Reftrack`. The parent will be this instance, root and interface will\\n        of course be the same.\\n\\n        This will delegate the call to the  appropriate :class:`ReftypeInterface`.\\n        So suggestions may vary for every typ and might depend on the\\n        status of the reftrack.\\n\\n        :param reftrack: the reftrack which needs suggestions\\n        :type reftrack: :class:`Reftrack`\\n        :returns: list of suggestions, tuples of type and element.\\n        :rtype: list\\n        :raises: None\\n        \"\"\"\\n        inter = self.get_typ_interface(reftrack.get_typ())\\n        return inter.get_suggestions(reftrack)',\n",
       " 'def get_available_types_for_scene(self, element):\\n        \"\"\"Return a list of types that can be used in combination with the given element\\n        to add new reftracks to the scene.\\n\\n        This allows for example the user, to add new reftracks (aliens) to the scene.\\n        So e.g. for a shader, it wouldn\\'t make sense to make it available to be added to the scene, because\\n        one would use them only as children of let\\'s say an asset or cache.\\n        Some types might only be available for shots or assets etc.\\n\\n        :param element: the element that could be used in conjuction with the returned types to create new reftracks.\\n        :type element: :class:`jukeboxcore.djadapter.models.Asset` | :class:`jukeboxcore.djadapter.models.Shot`\\n        :returns: a list of types\\n        :rtype: :class:`list`\\n        :raises: None\\n        \"\"\"\\n        available = []\\n        for typ, inter in self.types.items():\\n            if inter(self).is_available_for_scene(element):\\n                available.append(typ)\\n        return available',\n",
       " 'def _pre_process_call(self, name=\"Unknown\", endpoint_params=None):\\n        \"\"\"\\n        This is called by the method_decorator within the Endpoint.\\n        The point is to capture a slot for the endpoint.method to put\\n        it\\'s final _calls.\\n        It also allows for some special new arguments that will be extracted\\n        before the endpoint is called\\n\\n        :param name: str of the name of the endpoint calling function\\n        :param endpoint_params: dict of the arguments passed to the\\n                                endpoint method\\n        \"\"\"\\n        call_temps = self._call_temps.get(self._get_thread_id(), None)\\n        call_params = call_temps and call_temps.pop() or {}\\n        default_params = dict(name=name,\\n                              label=\\'ID_\\' + str(self._count),\\n                              base_uri=self.base_uri,\\n                              timeout=self.timeout,\\n                              headers={},\\n                              cookies={},\\n                              proxies=self.proxies,\\n                              accepted_return=self.accepted_return or \\'json\\')\\n\\n        for k, v in default_params.items():\\n            if call_params.get(k, None) is None:\\n                call_params[k] = v\\n\\n        sub_base_uri = call_params.pop(\\'sub_base_uri\\', None)\\n        if sub_base_uri:\\n            call_params[\\'base_uri\\'] = self.clean_base_uri(sub_base_uri)\\n\\n        endpoint_params = endpoint_params or {}\\n        for k, v in (call_temps and call_temps.pop().items() or []):\\n            if v is not None and k not in endpoint_params:\\n                endpoint_params.setdefault(k, v)\\n\\n        for k, v in self.cookies.items():\\n            call_params[\\'cookies\\'].setdefault(k, v)\\n\\n        for k, v in self.headers.items():\\n            call_params[\\'headers\\'].setdefault(k, v)\\n\\n        api_call = self.ApiCall(**call_params)\\n\\n        self._call_queue.setdefault(self._get_thread_id(), []).append(api_call)\\n\\n        if self.max_history is not 0:\\n            self._count += 1  # count of _calls\\n            if len(self) > self.max_history:\\n                self._calls.popitem(0)\\n            self._calls[call_params[\\'label\\']] = api_call\\n        return api_call',\n",
       " 'def function(fname):\\n    \"\"\"\\n    Make a function to Function class\\n    \"\"\"\\n    def _f(func):\\n        class WrapFunction(Function):\\n            name = fname\\n\\n            def __call__(self, *args, **kwargs):\\n                return func(*args, **kwargs)\\n\\n        return WrapFunction\\n\\n    return _f',\n",
       " 'def parse_cookie(header, charset=\\'utf-8\\', errors=\\'ignore\\'):\\n    \"\"\"Parse a cookie.\\n\\n    :param header: the header to be used to parse the cookie.\\n    :param charset: the charset for the cookie values.\\n    :param errors: the error behavior for the charset decoding.\\n    \"\"\"\\n    cookie = _ExtendedCookie()\\n    if header:\\n        cookie.load(header)\\n    result = {}\\n\\n    # decode to unicode and skip broken items.  Our extended morsel\\n    # and extended cookie will catch CookieErrors and convert them to\\n    # `None` items which we have to skip here.\\n    for key, value in cookie.iteritems():\\n        if value.value is not None:\\n            result[key] = unquote_header_value(value.value) \\\\\\n                .decode(charset, errors)\\n\\n    return result',\n",
       " 'def equals_as(self, value_type, other):\\n        \"\"\"\\n        Compares this object value to specified specified value.\\n        When direct comparison gives negative results it converts\\n        values to type specified by type code and compare them again.\\n\\n        :param value_type: the Typecode type that defined the type of the result\\n\\n        :param other: the value to be compared with.\\n\\n        :return: true when objects are equal and false otherwise.\\n        \"\"\"\\n        if other == None and self.value == None:\\n            return True\\n        if other == None or self.value == None:\\n            return False\\n\\n        if isinstance(other, AnyValue):\\n            other = other._value\\n\\n        if other == self.value:\\n            return True\\n        \\n        value1 = TypeConverter.to_type(value_type, self.value)\\n        value2 = TypeConverter.to_type(value_type, other)\\n\\n        if value1 == None or value2 == None:\\n            return False\\n\\n        return value1 == value2',\n",
       " 'def _collect_images(self, content: str, md_file_path: Path) -> str:\\n        \\'\\'\\'Find images outside the source directory, copy them into the source directory,\\n        and replace the paths in the source.\\n\\n        This is necessary because MkDocs can\\'t deal with images outside the project\\'s doc_dir.\\n\\n        :param content: Markdown content\\n        :param md_file_path: Path to the Markdown file with content ``content``\\n\\n        :returns: Markdown content with image paths pointing within the source directory\\n        \\'\\'\\'\\n\\n        self.logger.debug(f\\'Looking for images in {md_file_path}.\\')\\n\\n        def _sub(image):\\n            image_caption = image.group(\\'caption\\')\\n            image_path = (md_file_path.parent / Path(image.group(\\'path\\'))).resolve()\\n\\n            self.logger.debug(f\\'Detected image: caption=\"{image_caption}\", path={image_path}\\')\\n\\n            if self.working_dir.resolve() not in image_path.parents:\\n                self.logger.debug(\\'Image outside source directory.\\')\\n\\n                self._collected_imgs_path.mkdir(exist_ok=True)\\n\\n                collected_img_path = (\\n                    self._collected_imgs_path/f\\'{image_path.stem}_{str(uuid1())}\\'\\n                ).with_suffix(image_path.suffix)\\n\\n                copy(image_path, collected_img_path)\\n\\n                self.logger.debug(f\\'Image copied to {collected_img_path}\\')\\n\\n                rel_img_path = Path(relpath(collected_img_path, md_file_path.parent)).as_posix()\\n\\n            else:\\n                self.logger.debug(\\'Image inside source directory.\\')\\n                rel_img_path = Path(relpath(image_path, md_file_path.parent)).as_posix()\\n\\n            img_ref = f\\'![{image_caption}]({rel_img_path})\\'\\n\\n            self.logger.debug(f\\'Replacing with: {img_ref}\\')\\n\\n            return img_ref\\n\\n        return self._image_pattern.sub(_sub, content)',\n",
       " 'def has_prop_attribute(cls, prop_name):  # @NoSelf\\n        \"\"\"This methods returns True if there exists a class attribute\\n        for the given property. The attribute is searched locally\\n        only\"\"\"\\n        return (prop_name in cls.__dict__ and\\n                not isinstance(cls.__dict__[prop_name], types.FunctionType))',\n",
       " 'def check_value_change(cls, old, new):  # @NoSelf\\n        \"\"\"Checks whether the value of the property changed in type\\n        or if the instance has been changed to a different instance.\\n        If true, a call to model._reset_property_notification should\\n        be called in order to re-register the new property instance\\n        or type\"\"\"\\n        return (type(old) != type(new) or\\n                isinstance(old, wrappers.ObsWrapperBase) and old != new)',\n",
       " 'def get_getter(cls, prop_name,  # @NoSelf\\n                   user_getter=None, getter_takes_name=False):\\n        \"\"\"Returns a function wich is a getter for a property.\\n        prop_name is the name off the property.\\n\\n        user_getter is an optional function doing the work. If\\n        specified, that function will be called instead of getting\\n        the attribute whose name is in \\'prop_name\\'.\\n\\n        If user_getter is specified with a False value for\\n        getter_takes_name (default), than the method is used to get\\n        the value of the property. If True is specified for\\n        getter_takes_name, then the user_getter is called by\\n        passing the property name (i.e. it is considered a general\\n        method which receive the property name whose value has to\\n        be returned.)\\n        \"\"\"\\n        if user_getter:\\n            if getter_takes_name:  # wraps the property name\\n                _deps = type(cls)._get_old_style_getter_deps(cls, prop_name,\\n                                                             user_getter)\\n\\n                def _getter(self, deps=_deps):\\n                    return user_getter(self, prop_name)\\n            else:\\n                _getter = user_getter\\n            return _getter\\n\\n        def _getter(self):  # @DuplicatedSignature\\n            return getattr(self, PROP_NAME % {\\'prop_name\\' : prop_name})\\n        return _getter',\n",
       " \"def coneSearch(self, center, radius=3*u.arcmin, magnitudelimit=25):\\n        '''\\n        Run a cone search of the GALEX archive\\n        '''\\n\\n\\n        self.magnitudelimit = magnitudelimit\\n\\n        # run the query\\n        self.speak('querying GALEX, centered on {} with radius {}'.format(center, radius, magnitudelimit))\\n\\n        coordinatetosearch = '{0.ra.deg} {0.dec.deg}'.format(center)\\n        table = astroquery.mast.Catalogs.query_region(coordinates=center, radius=radius, catalog='GALEX')\\n\\n\\n\\n        # the gaia DR2 epoch is 2015.5\\n        epoch = 2005#???\\n\\n        # create skycoord objects\\n        self.coordinates = coord.SkyCoord(  ra=table['ra'].data*u.deg,\\n                                        dec=table['dec'].data*u.deg,\\n                                        obstime=Time(epoch, format='decimalyear'))\\n\\n        self.magnitudes = dict(NUV=table['nuv_mag'].data, FUV=table['fuv_mag'].data)\\n        self.magnitude = self.magnitudes['NUV']\",\n",
       " 'def upload_nginx_site_conf(site_name, template_name=None, context=None, enable=True):\\n    \"\"\"Upload Nginx site configuration from a template.\"\"\"\\n    \\n    template_name = template_name or [u\\'nginx/%s.conf\\' % site_name, u\\'nginx/site.conf\\']\\n    site_available = u\\'/etc/nginx/sites-available/%s\\' % site_name\\n    upload_template(template_name, site_available, context=context, use_sudo=True)\\n    if enable:\\n        enable_site(site_name)',\n",
       " 'def enable_site(site_name):\\n    \"\"\"Enable an available Nginx site.\"\"\"\\n\\n    site_available = u\\'/etc/nginx/sites-available/%s\\' % site_name\\n    site_enabled = u\\'/etc/nginx/sites-enabled/%s\\' % site_name\\n    if files.exists(site_available):\\n        sudo(u\\'ln -s -f %s %s\\' % (site_available, site_enabled))\\n        restart_service(u\\'nginx\\')\\n    else:\\n        abort(u\\'%s site configuration is not available\\' % site_name)',\n",
       " 'def disable_site(site_name):\\n    \"\"\"Disables Nginx site configuration.\"\"\"\\n\\n    site = u\\'/etc/nginx/sites-enabled/%s\\' % site_name\\n    if files.exists(site):\\n        sudo(u\\'rm %s\\' % site)\\n        restart_service(u\\'nginx\\')',\n",
       " 'def suppressConsoleOut(meth):\\n    \"\"\"Disable console output during the method is run.\"\"\"\\n    @wraps(meth)\\n    def decorate(*args, **kwargs):\\n        \"\"\"Decorate\"\"\"\\n        # Disable ansible console output\\n        _stdout = sys.stdout\\n        fptr = open(os.devnull, \\'w\\')\\n        sys.stdout = fptr\\n        try:\\n            return meth(*args, **kwargs)\\n        except Exception as e:\\n            raise e\\n        finally:\\n            # Enable console output\\n            sys.stdout = _stdout\\n    return decorate',\n",
       " 'def mount(cls, mount_point, lower_dir, upper_dir, mount_table=None):\\n        \"\"\"Execute the mount. This requires root\"\"\"\\n        ensure_directories(mount_point, lower_dir, upper_dir)\\n        # Load the mount table if it isn\\'t given\\n        if not mount_table:\\n            mount_table = MountTable.load()\\n        # Check if the mount_point is in use\\n        if mount_table.is_mounted(mount_point):\\n            # Throw an error if it is\\n            raise AlreadyMounted()\\n        # Build mount options\\n        options = \"rw,lowerdir=%s,upperdir=%s\" % (lower_dir, upper_dir)\\n        # Run the actual mount\\n        subwrap.run([\\'mount\\', \\'-t\\', \\'overlayfs\\', \\'-o\\', options,\\n            \\'olyfs%s\\' % random_name(), mount_point])\\n        return cls(mount_point, lower_dir, upper_dir)',\n",
       " 'def is_opened(components):\\n        \"\"\"\\n        Checks if all components are opened.\\n\\n        To be checked components must implement [[IOpenable]] interface.\\n        If they don\\'t the call to this method returns true.\\n\\n        :param components: a list of components that are to be checked.\\n\\n        :return: true if all components are opened and false if at least one component is closed.\\n        \"\"\"\\n        if components == None:\\n            return True\\n\\n        result = True\\n        for component in components:\\n            result = result and Opener.is_opened_one(component)\\n\\n        return result',\n",
       " 'def open(correlation_id, components):\\n        \"\"\"\\n        Opens multiple components.\\n\\n        To be opened components must implement [[IOpenable]] interface.\\n        If they don\\'t the call to this method has no effect.\\n\\n        :param correlation_id: (optional) transaction id to trace execution through call chain.\\n\\n        :param components: the list of components that are to be closed.\\n        \"\"\"\\n        if components == None:\\n            return\\n\\n        for component in components:\\n            Opener.open_one(correlation_id, component)',\n",
       " 'def read_temperature(self):\\n        \"\"\"Gets the compensated temperature in degrees celsius.\"\"\"\\n        UT = self.read_raw_temp()\\n        # Datasheet value for debugging:\\n        #UT = 27898\\n        # Calculations below are taken straight from section 3.5 of the datasheet.\\n        X1 = ((UT - self.cal_AC6) * self.cal_AC5) >> 15\\n        X2 = (self.cal_MC << 11) // (X1 + self.cal_MD)\\n        B5 = X1 + X2\\n        temp = ((B5 + 8) >> 4) / 10.0\\n        self.logger.debug(\\'Calibrated temperature {0} C\\', temp)\\n        return temp',\n",
       " 'def read_pressure(self):\\n        \"\"\"Gets the compensated pressure in Pascals.\"\"\"\\n        UT = self.read_raw_temp()\\n        UP = self.read_raw_pressure()\\n        # Datasheet values for debugging:\\n        #UT = 27898\\n        #UP = 23843\\n        # Calculations below are taken straight from section 3.5 of the datasheet.\\n        # Calculate true temperature coefficient B5.\\n        X1 = ((UT - self.cal_AC6) * self.cal_AC5) >> 15\\n        X2 = (self.cal_MC << 11) // (X1 + self.cal_MD)\\n        B5 = X1 + X2\\n        self.logger.debug(\\'B5 = {0}\\', B5)\\n        # Pressure Calculations\\n        B6 = B5 - 4000\\n        self.logger.debug(\\'B6 = {0}\\', B6)\\n        X1 = (self.cal_B2 * (B6 * B6) >> 12) >> 11\\n        X2 = (self.cal_AC2 * B6) >> 11\\n        X3 = X1 + X2\\n        B3 = (((self.cal_AC1 * 4 + X3) << self._mode) + 2) // 4\\n        self.logger.debug(\\'B3 = {0}\\', B3)\\n        X1 = (self.cal_AC3 * B6) >> 13\\n        X2 = (self.cal_B1 * ((B6 * B6) >> 12)) >> 16\\n        X3 = ((X1 + X2) + 2) >> 2\\n        B4 = (self.cal_AC4 * (X3 + 32768)) >> 15\\n        self.logger.debug(\\'B4 = {0}\\', B4)\\n        B7 = (UP - B3) * (50000 >> self._mode)\\n        self.logger.debug(\\'B7 = {0}\\', B7)\\n        if B7 < 0x80000000:\\n            p = (B7 * 2) // B4\\n        else:\\n            p = (B7 // B4) * 2\\n        X1 = (p >> 8) * (p >> 8)\\n        X1 = (X1 * 3038) >> 16\\n        X2 = (-7357 * p) >> 16\\n        p = p + ((X1 + X2 + 3791) >> 4)\\n        self.logger.debug(\\'Pressure {0} Pa\\', p)\\n        return p/100',\n",
       " \"def get_rendition_url(request, image_id, target_width=0, target_height=0):\\n    '''\\n    get a rendition url\\n\\n    if the rendition does nto exist it will be created in the storage\\n    if dimensions do not fit master's aspect ratio\\n    then image will be cropped with a centered anchor\\n\\n    if one dimensions is omitted (0)\\n    the other one will be generated accordind to master's aspect ratio\\n\\n    :param request: http GET request\\n        /renderer/rendition/url/<image_id>/<target_width>/<target_height>/\\n    :param image_id: the master image primary key\\n    :param target_width: target image width\\n        if 0 renderer will use target_height\\n        to generate a image with correct aspect ratio\\n    :param target_height: target image height\\n        if 0 renderer will use target_width\\n        to generate a image height correct aspect ratio\\n    :return: rendition url in a json dictionary\\n    '''\\n    im = get_object_or_404(MasterImage, pk=image_id)\\n\\n    return JsonResponse({\\n        'url': im.get_rendition_url(target_width, target_height)\\n    })\",\n",
       " \"def get_master_url(request, image_id):\\n    '''\\n    get image's master url\\n\\n    ...\\n\\n    :param request: http GET request /renderer/master/url/<image_id>/\\n    :param image_id: the master image primary key\\n    :return: master url in a json dictionary\\n    '''\\n    im = get_object_or_404(MasterImage, pk=image_id)\\n\\n    return JsonResponse({'url': im.get_master_url()})\",\n",
       " 'def __parse_results(self,results):\\n        \"\"\"\\n        The resolve server responds with some basic HTML formatting, where the actual\\n        results are listed as an HTML list. The regular expression RE_RESULT captures\\n        each entry\\n        \"\"\"\\n        reslist = []\\n        cursor = 0\\n        match  = RE_RESULTS.search(results,cursor)\\n        while match:\\n            doc = {}\\n            doc[\\'bibcode\\'] = match.group(\\'bibcode\\')\\n            doc[\\'confidence\\'] = self.__get_confidence_level(match.group(\\'confidence\\'))\\n            doc[\\'refstring\\'] = match.group(\\'refstring\\')\\n            reslist.append(doc)\\n            cursor = match.end()\\n            match  = RE_RESULTS.search(results,cursor)\\n        return reslist',\n",
       " 'def get_domain_config(self, domain):\\n        \"\"\"Makes a discovery of domain name and resolves configuration of DNS provider\\n\\n        :param domain: str\\n            domain name\\n        :return: DomainConnectConfig\\n            domain connect config\\n        :raises: NoDomainConnectRecordException\\n            when no _domainconnect record found\\n        :raises: NoDomainConnectSettingsException\\n            when settings are not found\\n        \"\"\"\\n        domain_root = self.identify_domain_root(domain)\\n\\n        host = \\'\\'\\n        if len(domain_root) != len(domain):\\n            host = domain.replace(\\'.\\' + domain_root, \\'\\')\\n\\n        domain_connect_api = self._identify_domain_connect_api(domain_root)\\n\\n        ret = self._get_domain_config_for_root(domain_root, domain_connect_api)\\n        return DomainConnectConfig(domain, domain_root, host, ret)',\n",
       " 'def get_domain_connect_template_sync_url(self, domain, provider_id, service_id, redirect_uri=None, params=None,\\n                                             state=None, group_ids=None):\\n        \"\"\"Makes full Domain Connect discovery of a domain and returns full url to request sync consent.\\n\\n        :param domain: str\\n        :param provider_id: str\\n        :param service_id: str\\n        :param redirect_uri: str\\n        :param params: dict\\n        :param state: str\\n        :param group_ids: list(str)\\n        :return: (str, str)\\n            first field is an url which shall be used to redirect the browser to\\n            second field is an indication of error\\n        :raises: NoDomainConnectRecordException\\n            when no _domainconnect record found\\n        :raises: NoDomainConnectSettingsException\\n            when settings are not found\\n        :raises: InvalidDomainConnectSettingsException\\n            when settings contain missing fields\\n        \"\"\"\\n        # TODO: support for signatures\\n        # TODO: support for provider_name (for shared templates)\\n\\n        if params is None:\\n            params = {}\\n\\n        config = self.get_domain_config(domain)\\n\\n        self.check_template_supported(config, provider_id, service_id)\\n\\n        if config.urlSyncUX is None:\\n            raise InvalidDomainConnectSettingsException(\"No sync URL in config\")\\n\\n        sync_url_format = \\'{}/v2/domainTemplates/providers/{}/services/{}/\\' \\\\\\n                          \\'apply?domain={}&host={}&{}\\'\\n\\n        if redirect_uri is not None:\\n            params[\"redirect_uri\"] = redirect_uri\\n        if state is not None:\\n            params[\"state\"] = state\\n        if group_ids is not None:\\n            params[\"groupId\"] = \",\".join(group_ids)\\n\\n        return sync_url_format.format(config.urlSyncUX, provider_id, service_id, config.domain_root, config.host,\\n                                      urllib.parse.urlencode(sorted(params.items(), key=lambda val: val[0])))',\n",
       " 'def get_domain_connect_template_async_context(self, domain, provider_id, service_id, redirect_uri, params=None,\\n                                                  state=None, service_id_in_path=False):\\n        \"\"\"Makes full Domain Connect discovery of a domain and returns full context to request async consent.\\n\\n        :param domain: str\\n        :param provider_id: str\\n        :param service_id: str\\n        :param redirect_uri: str\\n        :param params: dict\\n        :param state: str\\n        :param service_id_in_path: bool\\n        :return: (DomainConnectAsyncContext, str)\\n            asyncConsentUrl field of returned context shall be used to redirect the browser to\\n            second field is an indication of error\\n        :raises: NoDomainConnectRecordException\\n            when no _domainconnect record found\\n        :raises: NoDomainConnectSettingsException\\n            when settings are not found\\n        :raises: TemplateNotSupportedException\\n            when template is not found\\n        :raises: InvalidDomainConnectSettingsException\\n            when parts of the settings are missing\\n        :raises: DomainConnectException\\n            on other domain connect issues\\n        \"\"\"\\n        if params is None:\\n            params = {}\\n\\n        config = self.get_domain_config(domain)\\n\\n        self.check_template_supported(config, provider_id, service_id)\\n\\n        if config.urlAsyncUX is None:\\n            raise InvalidDomainConnectSettingsException(\"No asynch UX URL in config\")\\n\\n        if service_id_in_path:\\n            if type(service_id) is list:\\n                raise DomainConnectException(\"Multiple services are only supported with service_id_in_path=false\")\\n            async_url_format = \\'{0}/v2/domainTemplates/providers/{1}/services/{2}\\' \\\\\\n                               \\'?client_id={1}&scope={2}&domain={3}&host={4}&{5}\\'\\n        else:\\n            if type(service_id) is list:\\n                service_id = \\'+\\'.join(service_id)\\n            async_url_format = \\'{0}/v2/domainTemplates/providers/{1}\\' \\\\\\n                               \\'?client_id={1}&scope={2}&domain={3}&host={4}&{5}\\'\\n\\n        if redirect_uri is not None:\\n            params[\"redirect_uri\"] = redirect_uri\\n        if state is not None:\\n            params[\"state\"] = state\\n\\n        ret = DomainConnectAsyncContext(config, provider_id, service_id, redirect_uri, params)\\n        ret.asyncConsentUrl = async_url_format.format(config.urlAsyncUX, provider_id, service_id,\\n                                                      config.domain_root, config.host,\\n                                                      urllib.parse.urlencode(\\n                                                          sorted(params.items(), key=lambda val: val[0])))\\n        return ret',\n",
       " 'def get_async_token(self, context, credentials):\\n        \"\"\"Gets access_token in async process\\n\\n        :param context: DomainConnectAsyncContext\\n        :param credentials: DomainConnectAsyncCredentials\\n        :return: DomainConnectAsyncContext\\n            context enriched with access_token and refresh_token if existing\\n        :raises: AsyncTokenException\\n        \"\"\"\\n        params = {\\'code\\': context.code, \\'grant_type\\': \\'authorization_code\\'}\\n        if getattr(context, \\'iat\\', None) and getattr(context, \\'access_token_expires_in\\', None) and \\\\\\n                getattr(context, \\'refresh_token\\', None):\\n            now = int(time.time()) + 60\\n            if now > context.iat + context.access_token_expires_in:\\n                params = {\\'refresh_token\\': context.refresh_token, \\'grant_type\\': \\'refresh_token\\',\\n                          \\'client_id\\': credentials.client_id, \\'client_secret\\': credentials.client_secret\\n                }\\n            else:\\n                logger.debug(\\'Context has a valid access token\\')\\n                return context\\n        params[\\'redirect_uri\\'] = context.return_url\\n\\n        url_get_access_token = \\'{}/v2/oauth/access_token?{}\\'.format(context.config.urlAPI,\\n                                                                    urllib.parse.urlencode(\\n                                                                        sorted(params.items(), key=lambda val: val[0])))\\n        try:\\n            # this has to be checked to avoid secret leakage by spoofed \"settings\" end-point\\n            if credentials.api_url != context.config.urlAPI:\\n                raise AsyncTokenException(\"URL API for provider does not match registered one with credentials\")\\n            data, status = http_request_json(self._networkContext,\\n                                             method=\\'POST\\',\\n                                             content_type=\\'application/json\\',\\n                                             body=json.dumps({\\n                                                 \\'client_id\\': credentials.client_id,\\n                                                 \\'client_secret\\': credentials.client_secret,\\n                                             }),\\n                                             url=url_get_access_token\\n                                             )\\n        except Exception as ex:\\n            logger.debug(\\'Cannot get async token: {}\\'.format(ex))\\n            raise AsyncTokenException(\\'Cannot get async token: {}\\'.format(ex))\\n\\n        if \\'access_token\\' not in data \\\\\\n                or \\'expires_in\\' not in data \\\\\\n                or \\'token_type\\' not in data \\\\\\n                or data[\\'token_type\\'].lower() != \\'bearer\\':\\n            logger.debug(\\'Token not complete: {}\\'.format(data))\\n            raise AsyncTokenException(\\'Token not complete: {}\\'.format(data))\\n\\n        context.access_token = data[\\'access_token\\']\\n        context.access_token_expires_in = data[\\'expires_in\\']\\n        context.iat = int(time.time())\\n\\n        if \\'refresh_token\\' in data:\\n            context.refresh_token = data[\\'refresh_token\\']\\n\\n        return context',\n",
       " 'def httpretty_callback(request, uri, headers):\\n    \"\"\"httpretty request handler.\\n\\n    converts a call intercepted by httpretty to\\n    the stack-in-a-box infrastructure\\n\\n    :param request: request object\\n    :param uri: the uri of the request\\n    :param headers: headers for the response\\n\\n    :returns: tuple - (int, dict, string) containing:\\n                      int - the http response status code\\n                      dict - the headers for the http response\\n                      string - http string response\\n\\n    \"\"\"\\n    method = request.method\\n    response_headers = CaseInsensitiveDict()\\n    response_headers.update(headers)\\n    request_headers = CaseInsensitiveDict()\\n    request_headers.update(request.headers)\\n    request.headers = request_headers\\n    return StackInABox.call_into(method,\\n                                 request,\\n                                 uri,\\n                                 response_headers)',\n",
       " 'def registration(uri):\\n    \"\"\"httpretty handler registration.\\n\\n    registers a handler for a given uri with httpretty\\n    so that it can be intercepted and handed to\\n    stack-in-a-box.\\n\\n    :param uri: uri used for the base of the http requests\\n\\n    :returns: n/a\\n\\n    \"\"\"\\n\\n    # add the stack-in-a-box specific response codes to\\n    # http\\'s status information\\n    status_data = {\\n        595: \\'StackInABoxService - Unknown Route\\',\\n        596: \\'StackInABox - Exception in Service Handler\\',\\n        597: \\'StackInABox - Unknown Service\\'\\n    }\\n    for k, v in six.iteritems(status_data):\\n        if k not in httpretty.http.STATUSES:\\n            httpretty.http.STATUSES[k] = v\\n\\n    # log the uri that is used to access the stack-in-a-box services\\n    logger.debug(\\'Registering Stack-In-A-Box at {0} under Python HTTPretty\\'\\n                 .format(uri))\\n    # tell stack-in-a-box what uri to match with\\n    StackInABox.update_uri(uri)\\n\\n    # build the regex for the uri and register all http verbs\\n    # with httpretty\\n    regex = re.compile(\\'(http)?s?(://)?{0}:?(\\\\d+)?/\\'.format(uri),\\n                       re.I)\\n    for method in HttpBaseClass.METHODS:\\n        register_uri(method, regex, body=httpretty_callback)',\n",
       " 'def value(self):\\n        \"\"\"\\n        Return the value of the redirect response\\n        \"\"\"\\n        user = self.trigger.agentml.request_log.most_recent().user\\n        groups = self.trigger.agentml.request_log.most_recent().groups\\n\\n        # Does the redirect statement have tags to parse?\\n        if len(self._element):\\n            message = \\'\\'.join(map(str, self.trigger.agentml.parse_tags(self._element, self.trigger)))\\n        else:\\n            message = self._element.text\\n\\n        # Is there a default value defined?\\n        default = attribute(self._element, \\'default\\', \\'\\')\\n        response = self.trigger.agentml.get_reply(user.id, message, groups)\\n\\n        return response or default',\n",
       " 'def onHello(self, realm, details):\\n        \"\"\"\\n        Callback fired when client wants to attach session.\\n        \"\"\"\\n        log.msg(\"onHello: {} {}\".format(realm, details))\\n\\n        self._pending_auth = None\\n\\n        if details.authmethods:\\n            for authmethod in details.authmethods:\\n                if authmethod == u\"wampcra\":\\n\\n                    ## lookup user in user DB\\n                    salt, key, role, uid = yield self.factory.userdb.get(details.authid)\\n                    log.msg(\"salt, key, role: {} {} {} {}\".format(salt, key, role, uid))\\n\\n                    ## if user found ..\\n                    if key:\\n\\n                        log.msg(\"found key\")\\n\\n                        ## setup pending auth\\n                        self._pending_auth = PendingAuth(key, details.pending_session,\\n                            details.authid, role, authmethod, u\"userdb\", uid)\\n\\n                        log.msg(\"setting challenge\")\\n                        ## send challenge to client\\n                        extra = {\\n                            u\\'challenge\\': self._pending_auth.challenge\\n                        }\\n\\n                        ## when using salted passwords, provide the client with\\n                        ## the salt and then PBKDF2 parameters used\\n                        if salt:\\n                            extra[u\\'salt\\'] = salt\\n                            extra[u\\'iterations\\'] = 1000\\n                            extra[u\\'keylen\\'] = 32\\n\\n                        defer.returnValue(types.Challenge(u\\'wampcra\\', extra))\\n\\n        ## deny client\\n        defer.returnValue(types.Deny())',\n",
       " 'def onAuthenticate(self, signature, extra):\\n        \"\"\"\\n        Callback fired when a client responds to an authentication challenge.\\n        \"\"\"\\n        log.msg(\"onAuthenticate: {} {}\".format(signature, extra))\\n\\n        ## if there is a pending auth, and the signature provided by client matches ..\\n        if self._pending_auth:\\n\\n            if signature == self._pending_auth.signature:\\n\\n                ## accept the client\\n                return types.Accept(authid = self._pending_auth.uid,\\n                    authrole = self._pending_auth.authrole,\\n                    authmethod = self._pending_auth.authmethod,\\n                    authprovider = self._pending_auth.authprovider)\\n            else:\\n\\n                ## deny client\\n                return types.Deny(message = u\"signature is invalid\")\\n        else:\\n\\n            ## deny client\\n            return types.Deny(message = u\"no pending authentication\")',\n",
       " 'def configure_stdout_logger(log_level=logging.DEBUG):\\n    \"\"\"Configures logging to use STDOUT\"\"\"\\n    root = logging.getLogger()\\n    root.setLevel(log_level)\\n\\n    handler = logging.StreamHandler()\\n    handler.setLevel(log_level)\\n    handler.setFormatter(logging.Formatter(LOG_FORMAT_ESCAPED))\\n\\n    root.addHandler(handler)',\n",
       " 'def silence_logging(method):\\n    \"\"\"Disables logging for the duration of what is being wrapped.  This is\\n    particularly useful when testing if a test method is supposed to issue an\\n    error message which is confusing that the error shows for a successful\\n    test.\\n    \"\"\"\\n    @wraps(method)\\n    def wrapper(*args, **kwargs):\\n        logging.disable(logging.ERROR)\\n        result = method(*args, **kwargs)\\n        logging.disable(logging.NOTSET)\\n        return result\\n    return wrapper',\n",
       " 'def do_create_tool_item(self):\\n        \"\"\"This is called by the UIManager when it is time to\\n        instantiate the proxy\"\"\"\\n        proxy = SpinToolItem(*self._args_for_toolitem)\\n        self.connect_proxy(proxy)\\n        return proxy',\n",
       " 'def set_value(self, value):\\n        \"\"\"Set value to action.\"\"\"\\n        self._value = value\\n\\n        for proxy in self.get_proxies():\\n            proxy.handler_block(self._changed_handlers[proxy])\\n            proxy.set_value(self._value)\\n            proxy.handler_unblock(self._changed_handlers[proxy])\\n            pass\\n\\n        self.emit(\\'changed\\')\\n        return',\n",
       " 'def clean(ctx):\\n    \"\"\"\\n    clean generated project files\\n    \"\"\"\\n    os.chdir(PROJECT_DIR)\\n    patterns = [\\'.cache\\',\\n                \\'.coverage\\',\\n                \\'.eggs\\',\\n                \\'build\\',\\n                \\'dist\\']\\n    ctx.run(\\'rm -vrf {0}\\'.format(\\' \\'.join(patterns)))\\n    ctx.run(\\'\\'\\'find . \\\\( -name \\'*,cover\\' -o -name \\'__pycache__\\' -o -name \\'*.py[co]\\' -o -name \\'_work\\' \\\\) \\'\\'\\'\\n            \\'\\'\\'-exec rm -vrf \\'{}\\' \\\\; || true\\'\\'\\')',\n",
       " 'def build_docker_sshd(ctx):\\n    \"\"\"\\n    build docker image sshd-mssh-copy-id\\n    \"\"\"\\n    dinfo = DOCKER_SSHD_IMG\\n    ctx.run(\\'docker rmi -f {0}\\'.format(dinfo[\\'name\\']), warn=True)\\n    ctx.run(\\'docker build -t {0} {1}\\'.format(dinfo[\\'name\\'], dinfo[\\'path\\']))',\n",
       " 'def build_docker(ctx, image):\\n    \"\"\"\\n    build docker images\\n    \"\"\"\\n    if image not in DOCKER_IMGS:\\n        print(\\'Error: unknown docker image \"{0}\"!\\'.format(image), file=sys.stderr)\\n        sys.exit(1)\\n\\n    dinfo = DOCKER_IMGS[image]\\n    ctx.run(\\'docker rmi -f {0}\\'.format(dinfo[\\'name\\']), warn=True)\\n    dinfo_work_dir = os.path.join(dinfo[\\'path\\'], \\'_work\\')\\n    ctx.run(\\'mkdir -p {0}\\'.format(dinfo_work_dir))\\n    ctx.run(\\'cp {0} {1}\\'.format(os.path.join(DOCKER_COMMON_DIR, \\'sudo-as-user.sh\\'), dinfo_work_dir))\\n    ctx.run(\\'docker build -t {0} {1}\\'.format(dinfo[\\'name\\'], dinfo[\\'path\\']))',\n",
       " 'def build_deb(ctx, target):\\n    \"\"\"\\n    build a deb package\\n    \"\"\"\\n    if target not in (\\'ubuntu-trusty\\',):\\n        print(\\'Error: unknown target \"{0}\"!\\'.format(target), file=sys.stderr)\\n        sys.exit(1)\\n\\n    os.chdir(PROJECT_DIR)\\n    debbuild_dir = os.path.join(DIST_DIR, \\'deb\\')\\n\\n    # Create directories layout\\n    ctx.run(\\'mkdir -p {0}\\'.format(debbuild_dir))\\n\\n    # Copy the sources\\n    build_src(ctx, dest=debbuild_dir)\\n    src_archive = glob.glob(os.path.join(debbuild_dir, \\'mssh-copy-id-*.tar.gz\\'))[0]\\n    ctx.run(\\'tar -xvf {0} -C {1}\\'.format(src_archive, debbuild_dir))\\n    src_dir = src_archive[:-7]  # uncompressed directory\\n    ctx.run(\\'cp -r {0} {1}\\'.format(os.path.join(PROJECT_DIR, \\'deb/debian\\'), src_dir))\\n\\n    # Build the deb\\n    ctx.run(\\'docker run -e LOCAL_USER_ID={local_user_id} -v {local}:{cont} {img}\\'\\n            .format(local_user_id=os.getuid(),\\n                    local=debbuild_dir,\\n                    cont=\\'/deb\\',\\n                    img=DOCKER_IMGS[target][\\'name\\']))\\n\\n    ctx.run(\\'mv -f {0} {1}\\'.format(os.path.join(debbuild_dir, \\'mssh-copy-id_*.deb\\'), DIST_DIR))',\n",
       " 'def build_rpm(ctx, target):\\n    \"\"\"\\n    build an RPM package\\n    \"\"\"\\n    if target not in (\\'centos6\\', \\'centos7\\'):\\n        print(\\'Error: unknown target \"{0}\"!\\'.format(target), file=sys.stderr)\\n        sys.exit(1)\\n\\n    os.chdir(PROJECT_DIR)\\n    rpmbuild_dir = os.path.join(DIST_DIR, \\'rpmbuild\\')\\n\\n    # Create directories layout\\n    ctx.run(\\'mkdir -p {0}\\'.format(\\' \\'.join(os.path.join(rpmbuild_dir, d)\\n                                           for d in (\\'BUILD\\', \\'RPMS\\', \\'SOURCES\\', \\'SPECS\\', \\'SRPMS\\'))))\\n\\n    # Copy the sources & spec file\\n    build_src(ctx, dest=os.path.join(rpmbuild_dir, \\'SOURCES\\'))\\n    ctx.run(\\'cp -f {0} {1}\\'.format(os.path.join(PROJECT_DIR, \\'rpm/centos/mssh-copy-id.spec\\'),\\n                                   os.path.join(rpmbuild_dir, \\'SPECS\\')))\\n\\n    # Build the RPM\\n    ctx.run(\\'docker run -e LOCAL_USER_ID={local_user_id} -v {local}:{cont} {img}\\'\\n            .format(local_user_id=os.getuid(),\\n                    local=rpmbuild_dir,\\n                    cont=\\'/rpmbuild\\',\\n                    img=DOCKER_IMGS[target][\\'name\\']))\\n\\n    ctx.run(\\'mv -f {0} {1}\\'.format(os.path.join(rpmbuild_dir, \\'RPMS/noarch/mssh-copy-id-*.rpm\\'), DIST_DIR))',\n",
       " 'def build_src(ctx, dest=None):\\n    \"\"\"\\n    build source archive\\n    \"\"\"\\n    if dest:\\n        if not dest.startswith(\\'/\\'):\\n            # Relative\\n            dest = os.path.join(os.getcwd(), dest)\\n\\n        os.chdir(PROJECT_DIR)\\n        ctx.run(\\'python setup.py sdist --dist-dir {0}\\'.format(dest))\\n    else:\\n        os.chdir(PROJECT_DIR)\\n        ctx.run(\\'python setup.py sdist\\')',\n",
       " 'def run_gendoc(source, dest, args):\\n    \"\"\"Starts gendoc which reads source and creates rst files in dest with the given args.\\n\\n    :param source: The python source directory for gendoc. Can be a relative path.\\n    :type source: str\\n    :param dest: The destination for the rst files. Can be a relative path.\\n    :type dest: str\\n    :param args: Arguments for gendoc. See gendoc for more information.\\n    :type args: list\\n    :returns: None\\n    :rtype: None\\n    :raises: SystemExit\\n    \"\"\"\\n    args.insert(0, \\'gendoc.py\\')\\n    args.append(dest)\\n    args.append(source)\\n    print \\'Running gendoc.main with: %s\\' % args\\n    gendoc.main(args)',\n",
       " 'def main(argv=sys.argv[1:]):\\n    \"\"\"Parse commandline arguments and run the tool\\n\\n    :param argv: the commandline arguments.\\n    :type argv: list\\n    :returns: None\\n    :rtype: None\\n    :raises: None\\n    \"\"\"\\n    parser = setup_argparse()\\n    args = parser.parse_args(argv)\\n    if args.gendochelp:\\n        sys.argv[0] = \\'gendoc.py\\'\\n        genparser = gendoc.setup_parser()\\n        genparser.print_help()\\n        sys.exit(0)\\n    print \\'Preparing output directories\\'\\n    print \\'=\\'*80\\n    for odir in args.output:\\n        prepare_dir(odir, not args.nodelete)\\n    print \\'\\\\nRunning gendoc\\'\\n    print \\'=\\'*80\\n    for i, idir in enumerate(args.input):\\n        if i >= len(args.output):\\n            odir = args.output[-1]\\n        else:\\n            odir = args.output[i]\\n        run_gendoc(idir, odir, args.gendocargs)',\n",
       " 'def get_migrations(path):\\n    \\'\\'\\'\\n    In the specified directory, get all the files which match the pattern\\n    0001_migration.py\\n    \\'\\'\\'\\n    pattern = re.compile(r\"\\\\d+_[\\\\w\\\\d]+\")\\n    modules = [name for _, name, _ in pkgutil.iter_modules([path])\\n                if pattern.match(name)\\n            ]\\n\\n    return sorted(modules, key=lambda name: int(name.split(\"_\")[0]))',\n",
       " \"def migrate(engine, database, module, **kwargs):\\n    '''\\n    Execute the migrations. Pass in kwargs\\n    '''\\n    validate_args(engine, database, module)\\n\\n    options = {\\n        'direction': kwargs.get('direction', 'up'),\\n        'fake': kwargs.get('fake', False),\\n        'force': kwargs.get('force', False),\\n        'migration': kwargs.get('migration', None),\\n        'transaction': kwargs.get('transaction', True),\\n    }\\n\\n    Migration._meta.database = database\\n    migrator = DATABASE_MAP[engine](database, module, **options)\\n    migrator.run()\",\n",
       " \"def generate(engine, database, models, **kwargs):\\n    '''\\n    Generate the migrations by introspecting the db\\n    '''\\n    validate_args(engine, database, models)\\n    generator = Generator(engine, database, models)\\n    generator.run()\",\n",
       " 'def apply_migration(self, migration, **kwargs):\\n        \\'\\'\\'\\n        Apply a particular migration\\n        \\'\\'\\'\\n        cprint(\"\\\\nAttempting to run %s\" % migration, \"cyan\")\\n        # First check if the migration has already been applied\\n        exists = Migration.select().where(Migration.name == migration).limit(1).first()\\n        if exists and self.direction == \\'up\\':\\n            cprint(\"This migration has already been run on this server\", \"red\")\\n            if not self.force or self.fake:\\n                return False\\n            else:\\n                cprint(\"Force running this migration again\", \"yellow\")\\n\\n        # Load the module\\n        module_name = \"%s.%s\" % (self.module_name, migration)\\n        try:\\n            module = importlib.import_module(module_name)\\n            if not hasattr(module, self.direction):\\n                raise MigrationException(\"%s doesn\\'t have %s migration defined\" %\\n                    (migration, self.direction)\\n                )\\n            # Actually execute the direction method\\n            # Note that this doesn\\'t actually run the migrations in the DB yet.\\n            # This merely collects the steps in the migration, so that if needed\\n            # we can just fake it and print out the SQL query as well.\\n            getattr(module, self.direction)(self)\\n            # Print out each migration and execute it\\n            for op in self.operations:\\n                self.execute_operation(op)\\n\\n            if not self.fake:\\n                # If successful, create the entry in our log\\n                if self.direction == \\'up\\' and not exists:\\n                    Migration.create(name=migration)\\n                elif self.direction == \\'down\\' and exists:\\n                    exists.delete_instance()\\n\\n            cprint(\"Done\", \"green\")\\n\\n        except ImportError:\\n            raise MigrationException(\"%s migration not found\" % migration)',\n",
       " \"def get_tables(self, models):\\n        '''\\n        Extract all peewee models from the passed in module\\n        '''\\n        return { obj._meta.db_table : obj for obj in\\n                models.__dict__.itervalues() if\\n                isinstance(obj, peewee.BaseModel) and\\n                len(obj._meta.fields) > 1\\n            }\",\n",
       " \"def get_pwiz_tables(self, engine, database):\\n        '''\\n        Run the pwiz introspector and get the models defined\\n        in the DB.\\n        '''\\n        introspector = pwiz.make_introspector(engine, database.database,\\n            **database.connect_kwargs)\\n        out_file = '/tmp/db_models.py'\\n\\n        with Capturing() as code:\\n            pwiz.print_models(introspector)\\n        code = '\\\\n'.join(code)\\n        # Unfortunately, introspect.getsource doesn't seem to work\\n        # with dynamically created classes unless it is written out\\n        # to a file. So write it out to a temporary file\\n        with open(out_file, 'w') as file_:\\n            file_.write(code)\\n        # Load up the DB models as a new module so that we can\\n        # compare them with those in the model definition\\n        return imp.load_source('db_models', out_file)\",\n",
       " 'def update_subject_identifier_on_save(self):\\n        \"\"\"Overridden to not set the subject identifier on save.\\n        \"\"\"\\n        if not self.subject_identifier:\\n            self.subject_identifier = self.subject_identifier_as_pk.hex\\n        elif re.match(UUID_PATTERN, self.subject_identifier):\\n            pass\\n        return self.subject_identifier',\n",
       " 'def raise_on_changed_subject_identifier(self):\\n        \"\"\"Raises an exception if there is an attempt to change\\n        the subject identifier for an existing instance if the subject\\n        identifier is already set.\\n        \"\"\"\\n        if self.id and self.subject_identifier_is_set():\\n            with transaction.atomic():\\n                obj = self.__class__.objects.get(pk=self.id)\\n                if obj.subject_identifier != self.subject_identifier_as_pk.hex:\\n                    if self.subject_identifier != obj.subject_identifier:\\n                        raise RegisteredSubjectError(\\n                            \\'Subject identifier cannot be changed for \\'\\n                            \\'existing registered subject. Got {} <> {}.\\'.format(\\n                                self.subject_identifier, obj.subject_identifier))',\n",
       " 'def resolve(config, default_name = None):\\n        \"\"\"\\n        Resolves a component name from configuration parameters.\\n        The name can be stored in \"id\", \"name\" fields or inside a component descriptor.\\n        If name cannot be determined it returns a defaultName.\\n\\n        :param config: configuration parameters that may contain a component name.\\n\\n        :param default_name: (optional) a default component name.\\n\\n        :return: resolved name or default name if the name cannot be determined.\\n        \"\"\"\\n        name = config.get_as_nullable_string(\"name\")\\n        name = name if name != None else config.get_as_nullable_string(\"id\")\\n\\n        if name == None:\\n            descriptor_str = config.get_as_nullable_string(\"descriptor\")\\n            descriptor = Descriptor.from_string(descriptor_str)\\n            if descriptor != None:\\n                name = descriptor.get_name()\\n\\n        return name if name != None else default_name',\n",
       " 'def get_or_create_environment(self, repo: str, branch: str, git_repo: Repo, repo_path: Path) -> str:\\n        \"\"\" Returns the path to the current Python executable.\\n        \"\"\"\\n        return sys.executable',\n",
       " 'def count_leaves(x):\\n    \"\"\"\\n    Return the number of non-sequence items in a given recursive sequence.\\n    \"\"\"\\n    if hasattr(x, \\'keys\\'):\\n        x = list(x.values())\\n    if hasattr(x, \\'__getitem__\\'):\\n        return sum(map(count_leaves, x))\\n\\n    return 1',\n",
       " 'def reprkwargs(kwargs, sep=\\', \\', fmt=\"{0!s}={1!r}\"):\\n    \"\"\"Display kwargs.\"\"\"\\n    return sep.join(fmt.format(k, v) for k, v in kwargs.iteritems())',\n",
       " 'def reprcall(name, args=(), kwargs=(), keywords=\\'\\', sep=\\', \\',\\n        argfilter=repr):\\n    \"\"\"Format a function call for display.\"\"\"\\n    if keywords:\\n        keywords = ((\\', \\' if (args or kwargs) else \\'\\') +\\n                    \\'**\\' + keywords)\\n    argfilter = argfilter or repr\\n    return \"{name}({args}{sep}{kwargs}{keywords})\".format(\\n            name=name, args=reprargs(args, filter=argfilter),\\n            sep=(args and kwargs) and sep or \"\",\\n            kwargs=reprkwargs(kwargs, sep), keywords=keywords or \\'\\')',\n",
       " 'def reprsig(fun, name=None, method=False):\\n    \"\"\"Format a methods signature for display.\"\"\"\\n    args, varargs, keywords, defs, kwargs = [], [], None, [], {}\\n    argspec = fun\\n    if callable(fun):\\n        name = fun.__name__ if name is None else name\\n        argspec = getargspec(fun)\\n    try:\\n        args = argspec[0]\\n        varargs = argspec[1]\\n        keywords = argspec[2]\\n        defs = argspec[3]\\n    except IndexError:\\n        pass\\n    if defs:\\n        args, kwkeys = args[:-len(defs)], args[-len(defs):]\\n        kwargs = dict(zip(kwkeys, defs))\\n    if varargs:\\n        args.append(\\'*\\' + varargs)\\n    if method:\\n        args.insert(0, \\'self\\')\\n    return reprcall(name, map(str, args), kwargs, keywords,\\n                    argfilter=str)',\n",
       " 'def get_input(input_func, input_str):\\n    \"\"\"\\n    Get input from the user given an input function and an input string\\n    \"\"\"\\n    val = input_func(\"Please enter your {0}: \".format(input_str))\\n    while not val or not len(val.strip()):\\n        val = input_func(\"You didn\\'t enter a valid {0}, please try again: \".format(input_str))\\n    return val',\n",
       " 'def working_cycletime(start, end, workday_start=datetime.timedelta(hours=0), workday_end=datetime.timedelta(hours=24)):\\n    \"\"\"\\n    Get the working time between a beginning and an end point subtracting out non-office time\\n    \"\"\"\\n    def clamp(t, start, end):\\n        \"Return \\'t\\' clamped to the range [\\'start\\', \\'end\\']\"\\n        return max(start, min(end, t))\\n\\n    def day_part(t):\\n        \"Return timedelta between midnight and \\'t\\'.\"\\n        return t - t.replace(hour=0, minute=0, second=0)\\n\\n    if not start:\\n        return None\\n    if not end:\\n        end = datetime.datetime.now()\\n\\n    zero = datetime.timedelta(0)\\n    # Make sure that the work day is valid\\n    assert(zero <= workday_start <= workday_end <= datetime.timedelta(1))\\n    # Get the workday delta\\n    workday = workday_end - workday_start\\n    # Get the number of days it took\\n    days = (end - start).days + 1\\n    # Number of weeks\\n    weeks = days // 7\\n    # Get the number of days in addition to weeks\\n    extra = (max(0, 5 - start.weekday()) + min(5, 1 + end.weekday())) % 5\\n    # Get the number of working days\\n    weekdays = weeks * 5 + extra\\n    # Get the total time spent accounting for the workday\\n    total = workday * weekdays\\n    if start.weekday() < 5:\\n        # Figuring out how much time it wasn\\'t being worked on and subtracting\\n        total -= clamp(day_part(start) - workday_start, zero, workday)\\n    if end.weekday() < 5:\\n        # Figuring out how much time it wasn\\'t being worked on and subtracting\\n        total -= clamp(workday_end - day_part(end), zero, workday)\\n\\n    cycle_time = timedelta_total_seconds(total) / timedelta_total_seconds(workday)\\n    return cycle_time',\n",
       " 'def parse_definition_expr(expr, default_value=None):\\n    \"\"\"\\n    Parses a definition expression and returns a key-value pair\\n    as a tuple.\\n\\n    Each definition expression should be in one of these two formats:\\n\\n        * <variable>=<value>\\n        * <variable>\\n\\n    :param expr:\\n        String expression to be parsed.\\n    :param default_value:\\n        (Default None) When a definition is encountered that has no value, this\\n        will be used as its value.\\n    :return:\\n        A (define, value) tuple\\n\\n        or raises a ``ValueError`` if an invalid\\n        definition expression is provided.\\n\\n        or raises ``AttributeError`` if None is provided for ``expr``.\\n\\n    Usage:\\n\\n        >>> parse_definition_expr(\\'DEBUG=1\\')\\n        (\\'DEBUG\\', 1)\\n        >>> parse_definition_expr(\\'FOOBAR=0x40\\')\\n        (\\'FOOBAR\\', 64)\\n        >>> parse_definition_expr(\\'FOOBAR=whatever\\')\\n        (\\'FOOBAR\\', \\'whatever\\')\\n        >>> parse_definition_expr(\\'FOOBAR=false\\')\\n        (\\'FOOBAR\\', False)\\n        >>> parse_definition_expr(\\'FOOBAR=TRUE\\')\\n        (\\'FOOBAR\\', True)\\n        >>> parse_definition_expr(\\'FOOBAR\\', default_value=None)\\n        (\\'FOOBAR\\', None)\\n        >>> parse_definition_expr(\\'FOOBAR\\', default_value=1)\\n        (\\'FOOBAR\\', 1)\\n        >>> parse_definition_expr(\\'FOOBAR=ah=3\\')\\n        (\\'FOOBAR\\', \\'ah=3\\')\\n        >>> parse_definition_expr(\\' FOOBAR=ah=3 \\')\\n        (\\'FOOBAR\\', \\'ah=3 \\')\\n        >>> parse_definition_expr(\\' FOOBAR =ah=3 \\')\\n        (\\'FOOBAR\\', \\'ah=3 \\')\\n        >>> parse_definition_expr(\\' FOOBAR = ah=3 \\')\\n        (\\'FOOBAR\\', \\' ah=3 \\')\\n        >>> parse_definition_expr(\" \")\\n        Traceback (most recent call last):\\n            ...\\n        ValueError: Invalid definition symbol ` `\\n        >>> parse_definition_expr(None)\\n        Traceback (most recent call last):\\n            ...\\n        AttributeError: \\'NoneType\\' object has no attribute \\'split\\'\\n    \"\"\"\\n    try:\\n        define, value = expr.split(\\'=\\', 1)\\n        try:\\n            value = parse_number_token(value)\\n        except ValueError:\\n            value = parse_bool_token(value)\\n    except ValueError:\\n        if expr:\\n            define, value = expr, default_value\\n        else:\\n            raise ValueError(\"Invalid definition expression `%s`\" % str(expr))\\n    d = define.strip()\\n    if d:\\n        return d, value\\n    else:\\n        raise ValueError(\"Invalid definition symbol `%s`\" % str(define))',\n",
       " 'def parse_definitions(definitions):\\n    \"\"\"\\n    Parses a list of macro definitions and returns a \"symbol table\"\\n    as a dictionary.\\n\\n    :params definitions:\\n        A list of command line macro definitions.\\n        Each item in the list should be in one of these two formats:\\n\\n            * <variable>=<value>\\n            * <variable>\\n    :return:\\n        ``dict`` as symbol table or raises an exception thrown by\\n        :func:``parse_definition_expr``.\\n\\n    Usage::\\n\\n        >>> parse_definitions([\\'DEBUG=1\\'])\\n        {\\'DEBUG\\': 1}\\n        >>> parse_definitions([\\'FOOBAR=0x40\\', \\'DEBUG=false\\'])\\n        {\\'DEBUG\\': False, \\'FOOBAR\\': 64}\\n        >>> parse_definitions([\\'FOOBAR=whatever\\'])\\n        {\\'FOOBAR\\': \\'whatever\\'}\\n        >>> parse_definitions([\\'FOOBAR\\'])\\n        {\\'FOOBAR\\': None}\\n        >>> parse_definitions([\\'FOOBAR=ah=3\\'])\\n        {\\'FOOBAR\\': \\'ah=3\\'}\\n        >>> parse_definitions(None)\\n        {}\\n        >>> parse_definitions([])\\n        {}\\n    \"\"\"\\n    defines = {}\\n    if definitions:\\n        for definition in definitions:\\n            define, value = parse_definition_expr(definition,\\n                                                  default_value=None)\\n            defines[define] = value\\n    return defines',\n",
       " 'def set_up_logging(logger, level, should_be_quiet):\\n    \"\"\"\\n    Sets up logging for pepe.\\n\\n    :param logger:\\n        The logger object to update.\\n    :param level:\\n        Logging level specified at command line.\\n    :param should_be_quiet:\\n        Boolean value for the -q option.\\n    :return:\\n        logging level ``int`` or None\\n    \"\"\"\\n    LOGGING_LEVELS = {\\n        \\'DEBUG\\': logging.DEBUG,\\n        \\'INFO\\': logging.INFO,\\n        \\'WARNING\\': logging.WARNING,\\n        \\'ERROR\\': logging.ERROR,\\n        \\'CRITICAL\\': logging.CRITICAL,\\n        \\'NONE\\': None,\\n    }\\n\\n    logging_level = LOGGING_LEVELS.get(level)\\n    if should_be_quiet or logging_level is None:\\n        logging_handler = NullLoggingHandler()\\n    else:\\n        logger.setLevel(logging_level)\\n        logging_handler = logging.StreamHandler()\\n        logging_handler.setLevel(logging_level)\\n        logging_handler.setFormatter(\\n            logging.Formatter(\\n                \"%(asctime)s:%(name)s:%(levelname)s: %(message)s\"\\n                )\\n            )\\n\\n    logger.addHandler(logging_handler)\\n    return logging_level',\n",
       " 'def main():\\n    \"\"\"\\n    Entry-point function.\\n    \"\"\"\\n    args = parse_command_line()\\n\\n    logging_level = set_up_logging(logger, args.logging_level, args.should_be_quiet)\\n    defines = parse_definitions(args.definitions)\\n\\n    try:\\n        content_types_db = ContentTypesDatabase(DEFAULT_CONTENT_TYPES_FILE)\\n        for config_file in args.content_types_config_files:\\n            content_types_db.add_config_file(config_file)\\n\\n        output_filename = args.output_filename\\n\\n        with open(args.input_filename, \\'rb\\') as input_file:\\n            if output_filename is None:\\n                # No output file specified. Will output to stdout.\\n                preprocess(input_file=input_file,\\n                           output_file=sys.stdout,\\n                           defines=defines,\\n                           options=args,\\n                           content_types_db=content_types_db)\\n            else:\\n                if os.path.exists(output_filename):\\n                    if args.should_force_overwrite:\\n                        # Overwrite existing file.\\n                        with open(output_filename, \\'wb\\') as output_file:\\n                            preprocess(input_file=input_file,\\n                                       output_file=output_file,\\n                                       defines=defines,\\n                                       options=args,\\n                                       content_types_db=content_types_db)\\n                    else:\\n                        raise IOError(\"File `%s` exists - cannot overwrite. (Use -f to force overwrite.)\" % args.output_filename)\\n                else:\\n                    # File doesn\\'t exist and output file is provided, so write.\\n                    with open(output_filename, \\'wb\\') as output_file:\\n                        preprocess(input_file=input_file,\\n                                   output_file=output_file,\\n                                   defines=defines,\\n                                   options=args,\\n                                   content_types_db=content_types_db)\\n    except PreprocessorError, ex:\\n        if logging_level == logging.DEBUG:\\n            import traceback\\n            traceback.print_exc(file=sys.stderr)\\n        else:\\n            sys.stderr.write(\"pepe: error: %s\\\\n\" % str(ex))\\n        return 1\\n\\n    return 0',\n",
       " 'def register(self, service, provider, singleton=False):\\n        \"\"\"\\n        Registers a service provider for a given service.\\n\\n        @param service\\n            A key that identifies the service being registered.\\n        @param provider\\n            This is either the service being registered, or a callable that will\\n            either instantiate it or return it.\\n        @param singleton\\n            Indicates that the service is to be registered as a singleton.\\n            This is only relevant if the provider is a callable. Services that\\n            are not callable will always be registered as singletons.\\n        \"\"\"\\n\\n        def get_singleton(*args, **kwargs):\\n            result = self._get_singleton(service)\\n            if not result:\\n                instantiator = self._get_instantiator(provider)\\n                result = instantiator(*args, **kwargs)\\n                self._set_singleton(service, result)\\n            return result\\n\\n        # Providers are always registered in self.providers  as callable methods\\n\\n        if not callable(provider):\\n            self._set_provider(service, lambda *args, **kwargs: provider)\\n        elif singleton:\\n            self._set_provider(service, get_singleton)\\n        else:\\n            self._set_provider(service, self._get_instantiator(provider))',\n",
       " 'def dictionary_based_metrics(metrics):\\n    \"\"\"\\n    Higher order function creating a result type and collection function from\\n    the given metrics.\\n\\n    Args:\\n        metrics (iterable): Sequence of callable metrics, each\\n            accepting the algorithm state as parameter and returning the\\n            measured value with its label:\\n            measurement(state) -> (label, value).\\n\\n    Returns:\\n        tuple(dict, callable): dictionary result type and a collection\\n            function accepting the current results and the state as arguments\\n            and returning updated result.\\n\\n    Examples:\\n        >>> state = State()\\n        >>> metrics = [lambda state_: state_.iterations]\\n        >>> (results, collect) = dictionary_based_metrics(metrics)\\n        >>> results = collect(results, state)\\n\\n    \"\"\"\\n\\n    def collect(results, state):\\n        \"\"\"\\n        Measurement collection function for dictionary based metrics.\\n\\n        Args:\\n            results (dict): Storing results of metrics.\\n            state (cipy.algorithms.core.State): Current state of the algorithm.\\n\\n        Returns:\\n            dict: Updated results containing new metrics.\\n        \"\"\"\\n        for measurement in metrics:\\n            (label, value) = measurement(state)\\n            iteration_dict = results.get(state.iterations, {})\\n            iteration_dict[label] = str(value)\\n            results[state.iterations] = iteration_dict\\n        return results\\n\\n    return {}, collect',\n",
       " 'def comparator(objective):\\n    \"\"\"\\n    Higher order function creating a compare function for objectives.\\n\\n    Args:\\n        objective (cipy.algorithms.core.Objective): The objective to create a\\n            compare for.\\n\\n    Returns:\\n        callable: Function accepting two objectives to compare.\\n\\n    Examples:\\n        >>> a = Minimum(0.1)\\n        >>> b = Minimum(0.2)\\n        >>> compare = comparator(a)\\n        >>> comparison = compare(a, b) # False\\n    \"\"\"\\n\\n    if isinstance(objective, Minimum):\\n        return lambda l, r: l < r\\n    else:\\n        return lambda l, r: l > r',\n",
       " 'def _get_jenks_config():\\n    \"\"\" retrieve the jenks configuration object \"\"\"\\n    config_file = (get_configuration_file() or\\n                   os.path.expanduser(os.path.join(\"~\", CONFIG_FILE_NAME)))\\n\\n    if not os.path.exists(config_file):\\n        open(config_file, \\'w\\').close()\\n\\n    with open(config_file, \\'r\\') as fh:\\n        return JenksData(\\n            yaml.load(fh.read()),\\n            write_method=generate_write_yaml_to_file(config_file)\\n        )',\n",
       " 'def set_placeholder(self, text):\\n        \"\"\"Set the placeholder text that will be displayed\\n        when the text is empty and the widget is out of focus\\n\\n        :param text: The text for the placeholder\\n        :type text: str\\n        :raises: None\\n        \"\"\"\\n        if self._placeholder != text:\\n            self._placeholder = text\\n            if not self.hasFocus():\\n                self.update()',\n",
       " 'def paintEvent(self, event):\\n        \"\"\"Paint the widget\\n\\n        :param event:\\n        :type event:\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if not self.toPlainText() and not self.hasFocus() and self._placeholder:\\n            p = QtGui.QPainter(self.viewport())\\n            p.setClipping(False)\\n            col = self.palette().text().color()\\n            col.setAlpha(128)\\n            oldpen = p.pen()\\n            p.setPen(col)\\n            p.drawText(self.viewport().geometry(), QtCore.Qt.AlignLeft | QtCore.Qt.AlignTop, self._placeholder)\\n            p.setPen(oldpen)\\n        else:\\n            return super(JB_PlainTextEdit, self).paintEvent(event)',\n",
       " 'def calcEvenAnchors(args):\\n    \"\"\"\\n    Calculates anchor points evenly spaced across the world, given\\n    user-specified parameters.\\n\\n    Note: May not be exactly even if world size is not divisible by\\n    patches+1.\\n    Note: Eveness is based on bounded world, not toroidal.\\n    \"\"\"\\n    anchors = []\\n    dist = int((args.worldSize)/(args.patchesPerSide+1))\\n    for i in range(dist, args.worldSize, dist):\\n        for j in range(dist, args.worldSize, dist):\\n            anchors.append((i, j))\\n    return anchors',\n",
       " 'def calcRandomAnchors(args, inworld=True):\\n    \"\"\"\\n    Generates a list of random anchor points such that all circles will fit\\n    in the world, given the specified radius and worldsize.\\n    The number of anchors to generate is given by nPatches\\n    \"\"\"\\n    anchors = []\\n    rng = (args.patchRadius, args.worldSize - args.patchRadius)\\n    if not inworld:\\n        rng = (0, args.worldSize)\\n    for i in range(args.nPatches):\\n        anchors.append((random.randrange(rng[0], rng[1]),\\n                        random.randrange(rng[0], rng[1])))\\n\\n    return anchors',\n",
       " 'def pairwise_point_combinations(xs, ys, anchors):\\n    \"\"\"\\n    Does an in-place addition of the four points that can be composed by\\n    combining coordinates from the two lists to the given list of anchors\\n    \"\"\"\\n    for i in xs:\\n        anchors.append((i, max(ys)))\\n        anchors.append((i, min(ys)))\\n    for i in ys:\\n        anchors.append((max(xs), i))\\n        anchors.append((min(xs), i))',\n",
       " 'def calcTightAnchors(args, d, patches):\\n    \"\"\"\\n    Recursively generates the number of anchor points specified in the\\n    patches argument, such that all patches are d cells away\\n    from their nearest neighbors.\\n    \"\"\"\\n    centerPoint = (int(args.worldSize/2), int(args.worldSize/2))\\n    anchors = []\\n    if patches == 0:\\n        pass\\n\\n    elif patches == 1:\\n        anchors.append(centerPoint)\\n\\n    elif patches % 2 == 0:\\n        dsout = int((patches-2)//2) + 1\\n        add_anchors(centerPoint, d, dsout, anchors, True)\\n        if d != 0:\\n            anchors = list(set(anchors))\\n        anchors.sort()\\n        if dsout != 1:\\n            return (anchors +\\n                    calcTightAnchors(args, d, patches-2)\\n                    )[:patches*patches]\\n            # to cut off the extras in the case where d=0\\n\\n    else:\\n        # Note - an odd number of args.patchesPerSide requires that there be\\n        # a patch at the centerpoint\\n        dsout = int((patches-1)//2)\\n        add_anchors(centerPoint, d, dsout, anchors, False)\\n        if dsout != 1:\\n            return anchors + calcTightAnchors(d, patches-2)\\n\\n    return anchors',\n",
       " 'def genRandResources(args, resources):\\n    \"\"\"\\n    Generates a list of the appropriate length containing a roughly equal\\n    number of all resources in a random order\\n    \"\"\"\\n    randResources = []\\n    nEach = int(args.nPatches // len(resources))\\n    extras = int(args.nPatches % len(resources))\\n    for i in range(nEach):\\n        for res in resources:\\n            randResources.append(res + str(i))\\n\\n    additional = random.sample(resources, extras)\\n    for res in additional:\\n        randResources.append(res + str(nEach))\\n\\n    random.shuffle(randResources)\\n    return randResources',\n",
       " 'def add_ppas_from_file(file_name, update=True):\\n    \"\"\"Add personal package archive from a file list.\"\"\"\\n\\n    for ppa in _read_lines_from_file(file_name):\\n        add_ppa(ppa, update=False)\\n    if update:\\n        update_apt_sources()',\n",
       " 'def add_apt_source(source, key=None, update=True):\\n    \"\"\"Adds source url to apt sources.list. Optional to pass the key url.\"\"\"\\n\\n    # Make a backup of list\\n    source_list = u\\'/etc/apt/sources.list\\'\\n    sudo(\"cp %s{,.bak}\" % source_list)\\n    files.append(source_list, source, use_sudo=True)\\n    if key:\\n        # Fecth key from url and add\\n        sudo(u\"wget -q %s -O - | sudo apt-key add -\" % key)\\n    if update:\\n        update_apt_sources()',\n",
       " 'def add_sources_from_file(file_name, update=True):\\n    \"\"\"\\n    Add source urls from a file list.\\n    The file should contain the source line to add followed by the\\n    key url, if any, enclosed in parentheses.\\n\\n    Ex:\\n    deb http://example.com/deb lucid main (http://example.com/key)\\n    \"\"\"\\n\\n    key_regex = re.compile(r\\'(?P<source>[^()]*)(\\\\s+\\\\((?P<key>.*)\\\\))?$\\')\\n    for line in _read_lines_from_file(file_name):\\n        kwargs = key_regex.match(line).groupdict()\\n        kwargs[\\'update\\'] = False\\n        add_apt_source(**kwargs)\\n    if update:\\n        update_apt_sources()',\n",
       " 'def create_user(name, groups=None, key_file=None):\\n    \"\"\"Create a user. Adds a key file to authorized_keys if given.\"\"\"\\n\\n    groups = groups or []\\n    if not user_exists(name):\\n        for group in groups:\\n            if not group_exists(group):\\n                sudo(u\"addgroup %s\" % group)\\n        groups = groups and u\\'-G %s\\' % u\\',\\'.join(groups) or \\'\\'\\n        sudo(u\"useradd -m %s -s /bin/bash %s\" % (groups, name))\\n        sudo(u\"passwd -d %s\" % name)\\n    if key_file:\\n        sudo(u\"mkdir -p /home/%s/.ssh\" % name)\\n        put(key_file, u\"/home/%s/.ssh/authorized_keys\" % name, use_sudo=True)\\n        sudo(u\"chown -R %(name)s:%(name)s /home/%(name)s/.ssh\" % {\\'name\\': name})',\n",
       " 'def authenticate(self, username, password):\\n        \"\"\"\\n        Authenticate the user with a bind on the LDAP server\\n        \"\"\"\\n\\n        if username is None or password is None:\\n            return False\\n\\n        # check the username\\n        if not re.match(\"^[A-Za-z0-9_-]*$\", username):\\n            return False\\n\\n        user_dn = self.get_user_dn(username)\\n\\n        server = ldap3.Server(\\n                self.uri,\\n                use_ssl=self.use_ssl\\n            )\\n\\n        connection = ldap3.Connection(server, user=user_dn, password=password)\\n\\n        return connection.bind()',\n",
       " 'def binary_guesser(handle, num_bytes=512):\\n    \"\"\"Raise error if file not likely binary\\n\\n    Guesses if a file is binary, raises error if file is not likely binary,\\n    then returns to location in file when handle passed to binary_guesser.\\n\\n    Args:\\n        handle (file): File handle of file thought to be binary\\n\\n        num_bytes (int): Bytes of file to read to guess binary, more bytes\\n                         is often better but takes longer\\n\\n    Raises:\\n        FormatError: Error raised if file is not likely binary\\n\\n    Example:\\n        The following example demonstrate how to use binary_guesser.\\n        Note: These doctests will not pass, examples are only in doctest\\n        format as per convention. bio_utils uses pytests for testing.\\n\\n        >>> binary_guesser(open(\\'test.binary\\'))\\n    \"\"\"\\n\\n    text_chars = \\'\\'.join(map(chr, range(32, 127))) + \\'\\\\n\\\\r\\\\t\\\\b\\'\\n    byte_chars = text_chars.encode()\\n    handle_location = handle.tell()\\n    first_block = handle.read(num_bytes)\\n    if type(first_block) is str:\\n        first_block = first_block.encode()\\n    filtered_block = first_block.translate(None, delete=byte_chars)\\n    handle.seek(handle_location)  # Return to original handle location\\n    if float(len(filtered_block)) / float(len(first_block)) > 0.30:\\n        pass  # File is likely binary\\n    else:\\n        msg = \\'{0} is probably not a binary file\\'.format(handle.name)\\n        raise FormatError(message=msg)',\n",
       " 'def compile_ui(uifile):\\n    \"\"\"Compile the given Qt designer file. The compiled file will be in the same directory but ends with _ui.py.\\n\\n    :param uifile: filepath to the uifile\\n    :type uifile: str\\n    :returns: None\\n    :rtype: None\\n    :raises: None\\n    \"\"\"\\n    print \"Compileing: %s\" % uifile\\n    outputpath = uifile.rsplit(os.path.extsep, 1)[0] + \"_ui.py\"\\n    print \"Outputfile: %s\" % outputpath\\n    outputfile = open(os.path.abspath(outputpath), \"w\")\\n    pysideuic.compileUi(os.path.abspath(uifile), outputfile)\\n    print \"Done!\"',\n",
       " 'def parse(code, filename=\\'<unknown>\\', mode=\\'exec\\', tree=None):\\n    \"\"\"Parse the source into an AST node with PyPosAST.\\n    Enhance nodes with positions\\n\\n\\n    Arguments:\\n    code -- code text\\n\\n\\n    Keyword Arguments:\\n    filename -- code path\\n    mode -- execution mode (exec, eval, single)\\n    tree -- current tree, if it was optimized\\n    \"\"\"\\n    visitor = Visitor(code, filename, mode, tree=tree)\\n    return visitor.tree',\n",
       " 'def get_nodes(code, desired_type, path=\"__main__\", mode=\"exec\", tree=None):\\n    \"\"\"Find all nodes of a given type\\n\\n\\n    Arguments:\\n    code -- code text\\n    desired_type -- ast Node or tuple\\n\\n\\n    Keyword Arguments:\\n    path -- code path\\n    mode -- execution mode (exec, eval, single)\\n    tree -- current tree, if it was optimized\\n    \"\"\"\\n    return _GetVisitor(parse(code, path, mode, tree), desired_type).result',\n",
       " 'def add(self, path):\\n        \"\"\"Add the given path to the decided place in sys.path\"\"\"\\n        \\n        # sys.path always has absolute paths.\\n        path = os.path.abspath(path)\\n        \\n        # It must exist.\\n        if not os.path.exists(path):\\n            return\\n        \\n        # It must not already be in sys.path.\\n        if path in sys.path:\\n            return\\n\\n        if self.index is not None:\\n            sys.path.insert(self.index, path)\\n            self.index += 1\\n        else:\\n            sys.path.append(path)',\n",
       " 'def generate(data, algorithms=(DEFAULT_ALOGRITHM,)):\\n    \"\"\"Yields subresource integrity Hash objects for the given data &\\n    algorithms\\n\\n    >>> for ihash in generate(b\"alert(\\'Hello, world.\\');\"):\\n    ...     print (\\'%s %s\\' % (ihash.algorithm, ihash.b58digest))\\n    sha384 H8BRh8j48O9oYatfu5AZzq6A9RINhZO5H16dQZngK7T62em8MUt1FLm52t+eX6xO\\n\\n    >>> list(generate(b\"alert(\\'Hello, world.\\');\", [\\'sha256\\', \\'sha384\\']))\\n    ... # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\\n    [subresource_integrity.Hash(\\'sha256\\', \\'qz.../Tng=\\', \\'\\'),\\n     subresource_integrity.Hash(\\'sha384\\', \\'H8BR...+eX6xO\\', \\'\\')]\\n    \"\"\"\\n    return (Hash.fromresource(data, algorithm) for algorithm in algorithms)',\n",
       " 'def render(data, algorithms=(DEFAULT_ALOGRITHM,), seperator=\\' \\'):\\n    \"\"\"Returns a subresource integrity string for the given data &\\n    algorithms\\n\\n    >>> data = b\"alert(\\'Hello, world.\\');\"\\n    >>> render(data)\\n    \\'sha384-H8BRh8j48O9oYatfu5AZzq6A9RINhZO5H16dQZngK7T62em8MUt1FLm52t+eX6xO\\'\\n\\n    >>> print(render(data, [\\'sha256\\', \\'sha384\\'], seperator=\\'\\\\\\\\n\\'))\\n    sha256-qznLcsROx4GACP2dm0UCKCzCG+HiZ1guq6ZZDob/Tng=\\n    sha384-H8BRh8j48O9oYatfu5AZzq6A9RINhZO5H16dQZngK7T62em8MUt1FLm52t+eX6xO\\n    \"\"\"\\n    return seperator.join(str(ihash) for ihash in generate(data, algorithms))',\n",
       " 'def parse(integrity):\\n    \"\"\"Returns a list of subresource integrity Hash objects parsed from a str\\n\\n    >>> parse(\\'  sha256-47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU= \\')\\n    ... # doctest: +ELLIPSIS\\n    [subresource_integrity.Hash(\\'sha256\\', \\'47DEQp...SuFU=\\', \\'\\')]\\n\\n    Hash objects are put in descending order of algorithmic strength\\n\\n    >>> parse(\\'sha384-dOTZf16X8p34q2/kYyEFm0jh89uTjikhnzjeLeF0FHsEaYKb\\'\\n    ...       \\'1A1cv+Lyv4Hk8vHd\\'\\n    ...       \\' \\'\\n    ...       \\'sha512-Q2bFTOhEALkN8hOms2FKTDLy7eugP2zFZ1T8LCvX42Fp3WoN\\'\\n    ...       \\'r3bjZSAHeOsHrbV1Fu9/A0EzCinRE7Af1ofPrw==\\'\\n    ... )\\n    ... # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\\n    [subresource_integrity.Hash(\\'sha512\\', \\'Q2b...zCinRE7Af1ofPrw==\\', \\'\\'),\\n     subresource_integrity.Hash(\\'sha384\\', \\'dOT...Hk8vHd\\', \\'\\')]\\n\\n    Unrecognised hash algorithms are discarded\\n\\n    >>> parse(\\'sha1-2jmj7l5rSw0yVb/vlWAYkK/YBwk=\\')\\n    []\\n    \"\"\"\\n    matches = _INTEGRITY_PATTERN.findall(integrity)\\n    matches.sort(key=lambda t: RECOGNISED_ALGORITHMS.index(t[0]))\\n    return [Hash.fromhash(*match) for match in matches]',\n",
       " 'def login(self, username=None, password=None, login_url=None,\\n              auth_url=None):\\n        \"\"\"\\n        This will automatically log the user into the pre-defined account\\n\\n        Feel free to overwrite this with an endpoint on endpoint load\\n\\n        :param username:  str of the user name to login in as\\n        :param password:  str of the password to login as\\n        :param login_url: str of the url for the server\\'s login\\n        :param auth_url:  str of the url for the server\\'s authorization login\\n        :return: str of self._status\\n        \"\"\"\\n        return super(ConnectionBasic, self).login(username, password,\\n                                                  login_url, auth_url)',\n",
       " 'def last_change(self):\\n        \"\"\"\\n        queries the database for the most recent time an object was either created or\\n        updated\\n\\n        returns datetime or None if db is empty\\n        \"\"\"\\n        try:\\n            cdt = self.latest(\\'created\\')\\n            udt = self.latest(\\'updated\\')\\n            #print cdt, udt\\n            return max(cdt.created, udt.updated)\\n\\n        except ObjectDoesNotExist:\\n            return None',\n",
       " 'def since(self, timestamp=None, version=None, deleted=False):\\n        \"\"\"\\n        Queries the database for objects updated since timestamp or version\\n\\n        Arguments:\\n\\n        timestamp <DateTime=None|int=None> if specified return all objects modified since\\n        that specified time. If integer is submitted it is treated like a unix timestamp\\n\\n        version <int=None> if specified return all objects with a version greater\\n        then the one specified\\n\\n        deleted <bool=False> if true include soft-deleted objects in the result\\n\\n        Either timestamp or version needs to be provided\\n        \"\"\"\\n\\n        qset = self\\n\\n        if timestamp is not None:\\n\\n            if isinstance(timestamp, numbers.Real):\\n                timestamp = datetime.datetime.fromtimestamp(timestamp)\\n\\n            qset = qset.filter(\\n                models.Q(created__gt=timestamp) |\\n                models.Q(updated__gt=timestamp)\\n            )\\n\\n        if version is not None:\\n\\n            qset = qset.filter(version__gt=version)\\n\\n        if not deleted:\\n\\n            qset = qset.undeleted()\\n\\n        return qset',\n",
       " 'def fastq_verifier(entries, ambiguous=False):\\n    \"\"\"Raises error if invalid FASTQ format detected\\n\\n    Args:\\n        entries (list): A list of FastqEntry instances\\n\\n        ambiguous (bool): Permit ambiguous bases, i.e. permit non-ACGTU bases\\n\\n    Raises:\\n        FormatError: Error when FASTQ format incorrect with descriptive message\\n\\n    Example:\\n        >>> from bio_utils.iterators import fastq_iter\\n        >>> import os\\n        >>> entries = r\\'@entry1{0}AAGGATTCG{0}+{0}112234432{0}\\' \\\\\\n        ...           r\\'@entry{0}AGGTCCCCCG{0}+{0}4229888884{0}\\' \\\\\\n        ...           r\\'@entry3{0}GCCTAGC{0}9ddsa5n\\'.format(os.linesep)\\n        >>> fastq_entries = fastq_iter(iter(entries.split(os.linesep)))\\n        >>> fastq_verifier(fastq_entries)\\n    \"\"\"\\n\\n    if ambiguous:\\n        regex = r\\'^@.+{0}[ACGTURYKMSWBDHVNX]+{0}\\' \\\\\\n                r\\'\\\\+.*{0}[!\"#$%&\\\\\\'()*+,-./0123456\\' \\\\\\n                r\\'789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ\\' \\\\\\n                r\\'[\\\\]^_`abcdefghijklmnopqrstuvwxyz\\' \\\\\\n                r\\'{{|}}~]+{0}$\\'.format(os.linesep)\\n    else:\\n        regex = r\\'^@.+{0}[ACGTU]+{0}\\' \\\\\\n                r\\'\\\\+.*{0}[!-~]+{0}$\\'.format(os.linesep)\\n    delimiter = r\\'{0}\\'.format(os.linesep)\\n\\n    for entry in entries:\\n        if len(entry.sequence) != len(entry.quality):\\n            msg = \\'The number of bases in {0} does not match the number \\' \\\\\\n                  \\'of quality scores\\'.format(entry.id)\\n            raise FormatError(message=msg)\\n        try:\\n            entry_verifier([entry.write()], regex, delimiter)\\n        except FormatError as error:\\n            if error.part == 0:\\n                msg = \\'Unknown Header Error with {0}\\'.format(entry.id)\\n                raise FormatError(message=msg)\\n            elif error.part == 1 and ambiguous:\\n                msg = \\'{0} contains a base not in \\' \\\\\\n                      \\'[ACGTURYKMSWBDHVNX]\\'.format(entry.id)\\n                raise FormatError(message=msg)\\n            elif error.part == 1 and not ambiguous:\\n                msg = \\'{0} contains a base not in \\' \\\\\\n                      \\'[ACGTU]\\'.format(entry.id)\\n                raise FormatError(message=msg)\\n            elif error.part == 2:\\n                msg = \\'Unknown error with line 3 of {0}\\'.format(entry.id)\\n                raise FormatError(message=msg)\\n            elif error.part == 3:\\n                msg = r\\'{0} contains a quality score not in \\' \\\\\\n                      r\\'[!-~]\\'.format(entry.id)\\n                raise FormatError(message=msg)\\n            else:\\n                msg = \\'{0}: Unknown Error: Likely a Bug\\'.format(entry.id)\\n                raise FormatError(message=msg)',\n",
       " 'def validate_configuration(self):\\n        \"\"\"\\n        Validates the provided settings.\\n\\n        * Checks ``inherit_image`` format.\\n        * Checks ``use_registry_name`` format.\\n        * Checks that ``apt_dependencies`` is not set when ``inherit_image`` is set.\\n\\n        :raise ArcaMisconfigured: If some of the settings aren\\'t valid.\\n        \"\"\"\\n        super().validate_configuration()\\n\\n        if self.inherit_image is not None:\\n            try:\\n                assert len(str(self.inherit_image).split(\":\")) == 2\\n            except (ValueError, AssertionError):\\n                raise ArcaMisconfigured(f\"Image \\'{self.inherit_image}\\' is not a valid value for the \\'inherit_image\\'\"\\n                                        f\"setting\")\\n\\n        if self.inherit_image is not None and self.get_dependencies() is not None:\\n            raise ArcaMisconfigured(\"An external image is used as a base image, \"\\n                                    \"therefore Arca can\\'t install dependencies.\")\\n\\n        if self.use_registry_name is not None:\\n            try:\\n                assert 2 >= len(str(self.inherit_image).split(\"/\")) <= 3\\n            except ValueError:\\n                raise ArcaMisconfigured(f\"Registry \\'{self.use_registry_name}\\' is not valid value for the \"\\n                                        f\"\\'use_registry_name\\' setting.\")',\n",
       " 'def get_dependencies(self) -> Optional[List[str]]:\\n        \"\"\" Returns the ``apt_dependencies`` setting to a standardized format.\\n\\n        :raise ArcaMisconfigured: if the dependencies can\\'t be converted into a list of strings\\n        :return: List of dependencies, ``None`` if there are none.\\n        \"\"\"\\n\\n        if not self.apt_dependencies:\\n            return None\\n\\n        try:\\n            dependencies = list([str(x).strip() for x in self.apt_dependencies])\\n        except (TypeError, ValueError):\\n            raise ArcaMisconfigured(\"Apk dependencies can\\'t be converted into a list of strings\")\\n\\n        if not len(dependencies):\\n            return None\\n\\n        dependencies.sort()\\n\\n        return dependencies',\n",
       " 'def get_image_name(self,\\n                       repo_path: Path,\\n                       requirements_option: RequirementsOptions,\\n                       dependencies: Optional[List[str]]) -> str:\\n        \"\"\" Returns the name for images with installed requirements and dependencies.\\n        \"\"\"\\n        if self.inherit_image is None:\\n            return self.get_arca_base_name()\\n        else:\\n            name, tag = str(self.inherit_image).split(\":\")\\n\\n            return f\"arca_{name}_{tag}\"',\n",
       " 'def get_image_tag(self,\\n                      requirements_option: RequirementsOptions,\\n                      requirements_hash: Optional[str],\\n                      dependencies: Optional[List[str]]) -> str:\\n        \"\"\" Returns the tag for images with the dependencies and requirements installed.\\n\\n        64-byte hexadecimal strings cannot be used as docker tags, so the prefixes are necessary.\\n        Double hashing the dependencies and requirements hash to make the final tag shorter.\\n\\n        Prefixes:\\n\\n        * Image type:\\n\\n          * i  Inherited image\\n          * a  Arca base image\\n\\n        * Requirements:\\n\\n          * r  Does have some kind of requirements\\n          * s  Doesn\\'t have requirements\\n\\n        * Dependencies:\\n\\n          * d  Does have dependencies\\n          * e  Doesn\\'t have dependencies\\n\\n        Possible outputs:\\n\\n        * Inherited images:\\n\\n          * `ise`  no requirements\\n          * `ide_<hash(requirements)>`  with requirements\\n\\n        * From Arca base image:\\n\\n          * `<Arca version>_<Python version>_ase`  no requirements and no dependencies\\n          * `<Arca version>_<Python version>_asd_<hash(dependencies)>`  only dependencies\\n          * `<Arca version>_<Python version>_are_<hash(requirements)>`  only requirements\\n          * `<Arca version>_<Python version>_ard_<hash(hash(dependencies) + hash(requirements))>`\\n             both requirements and dependencies\\n\\n        \"\"\"\\n        prefix = \"\"\\n\\n        if self.inherit_image is None:\\n            prefix = \"{}_{}_\".format(arca.__version__, self.get_python_version())\\n\\n        prefix += \"i\" if self.inherit_image is not None else \"a\"\\n        prefix += \"r\" if requirements_option != RequirementsOptions.no_requirements else \"s\"\\n        prefix += \"d\" if dependencies is not None else \"e\"\\n\\n        if self.inherit_image is not None:\\n            if requirements_hash:\\n                return prefix + \"_\" + requirements_hash\\n            return prefix\\n\\n        if dependencies is None:\\n            dependencies_hash = \"\"\\n        else:\\n            dependencies_hash = self.get_dependencies_hash(dependencies)\\n\\n        if requirements_hash and dependencies_hash:\\n            return prefix + \"_\" + hashlib.sha256(bytes(requirements_hash + dependencies_hash, \"utf-8\")).hexdigest()\\n        elif requirements_hash:\\n            return f\"{prefix}_{requirements_hash}\"\\n        elif dependencies_hash:\\n            return f\"{prefix}_{dependencies_hash}\"\\n        else:\\n            return prefix',\n",
       " 'def get_or_build_image(self, name: str, tag: str, dockerfile: Union[str, Callable[..., str]], *,\\n                           pull=True, build_context: Optional[Path]=None):\\n        \"\"\"\\n        A proxy for commonly built images, returns them from the local system if they exist, tries to pull them if\\n        pull isn\\'t disabled, otherwise builds them by the definition in ``dockerfile``.\\n\\n        :param name: Name of the image\\n        :param tag: Image tag\\n        :param dockerfile: Dockerfile text or a callable (no arguments) that produces Dockerfile text\\n        :param pull: If the image is not present locally, allow pulling from registry (default is ``True``)\\n        :param build_context: A path to a folder. If it\\'s provided, docker will build the image in the context\\n            of this folder. (eg. if ``ADD`` is needed)\\n        \"\"\"\\n        if self.image_exists(name, tag):\\n            logger.info(\"Image %s:%s exists\", name, tag)\\n            return\\n\\n        elif pull:\\n            logger.info(\"Trying to pull image %s:%s\", name, tag)\\n\\n            try:\\n                self.client.images.pull(name, tag=tag)\\n                logger.info(\"The image %s:%s was pulled from registry\", name, tag)\\n                return\\n            except docker.errors.APIError:\\n                logger.info(\"The image %s:%s can\\'t be pulled, building locally.\", name, tag)\\n\\n        if callable(dockerfile):\\n            dockerfile = dockerfile()\\n\\n        try:\\n            if build_context is None:\\n                fileobj = BytesIO(bytes(dockerfile, \"utf-8\"))  # required by the docker library\\n\\n                self.client.images.build(\\n                    fileobj=fileobj,\\n                    tag=f\"{name}:{tag}\"\\n                )\\n            else:\\n                dockerfile_file = build_context / \"dockerfile\"\\n                dockerfile_file.write_text(dockerfile)\\n\\n                self.client.images.build(\\n                    path=str(build_context.resolve()),\\n                    dockerfile=dockerfile_file.name,\\n                    tag=f\"{name}:{tag}\"\\n                )\\n\\n                dockerfile_file.unlink()\\n        except docker.errors.BuildError as e:\\n            for line in e.build_log:\\n                if isinstance(line, dict) and line.get(\"errorDetail\") and line[\"errorDetail\"].get(\"code\") in {124, 143}:\\n                    raise BuildTimeoutError(f\"Installing of requirements timeouted after \"\\n                                            f\"{self.requirements_timeout} seconds.\")\\n\\n            logger.exception(e)\\n\\n            raise BuildError(\"Building docker image failed, see extra info for details.\", extra_info={\\n                \"build_log\": e.build_log\\n            })',\n",
       " 'def get_inherit_image(self) -> Tuple[str, str]:\\n        \"\"\" Parses the ``inherit_image`` setting, checks if the image is present locally and pulls it otherwise.\\n\\n        :return: Returns the name and the tag of the image.\\n        :raise ArcaMisconfiguration: If the image can\\'t be pulled from registries.\\n        \"\"\"\\n        name, tag = str(self.inherit_image).split(\":\")\\n\\n        if self.image_exists(name, tag):\\n            return name, tag\\n        try:\\n            self.client.images.pull(name, tag)\\n        except docker.errors.APIError:\\n            raise ArcaMisconfigured(f\"The specified image {self.inherit_image} from which Arca should inherit \"\\n                                    f\"can\\'t be pulled\")\\n\\n        return name, tag',\n",
       " 'def get_image_with_installed_dependencies(self, image_name: str,\\n                                              dependencies: Optional[List[str]]) -> Tuple[str, str]:\\n        \"\"\"\\n        Return name and tag of a image, based on the Arca python image, with installed dependencies defined\\n        by ``apt_dependencies``.\\n\\n        :param image_name: Name of the image which will be ultimately used for the image.\\n        :param dependencies: List of dependencies in the standardized format.\\n        \"\"\"\\n        python_version = self.get_python_version()\\n\\n        if dependencies is not None:\\n            def install_dependencies_dockerfile():\\n                python_name, python_tag = self.get_python_base(python_version,\\n                                                               pull=not self.disable_pull)\\n\\n                return self.INSTALL_DEPENDENCIES.format(\\n                    name=python_name,\\n                    tag=python_tag,\\n                    dependencies=\" \".join(self.get_dependencies())\\n                )\\n\\n            image_tag = self.get_image_tag(RequirementsOptions.no_requirements, None, dependencies)\\n            self.get_or_build_image(image_name, image_tag, install_dependencies_dockerfile,\\n                                    pull=not self.disable_pull)\\n\\n            return image_name, image_tag\\n        else:\\n            return self.get_python_base(python_version, pull=not self.disable_pull)',\n",
       " 'def build_image(self, image_name: str, image_tag: str,\\n                    repo_path: Path,\\n                    requirements_option: RequirementsOptions,\\n                    dependencies: Optional[List[str]]):\\n        \"\"\" Builds an image for specific requirements and dependencies, based on the settings.\\n\\n        :param image_name: How the image should be named\\n        :param image_tag: And what tag it should have.\\n        :param repo_path: Path to the cloned repository.\\n        :param requirements_option: How requirements are set in the repository.\\n        :param dependencies: List of dependencies (in the formalized format)\\n        :return: The Image instance.\\n        :rtype: docker.models.images.Image\\n        \"\"\"\\n        if self.inherit_image is not None:\\n            return self.build_image_from_inherited_image(image_name, image_tag, repo_path, requirements_option)\\n\\n        if requirements_option == RequirementsOptions.no_requirements:\\n\\n            python_version = self.get_python_version()\\n\\n            # no requirements and no dependencies, just return the basic image with the correct python installed\\n            if dependencies is None:\\n                base_name, base_tag = self.get_python_base(python_version, pull=not self.disable_pull)\\n                image = self.get_image(base_name, base_tag)\\n\\n                # tag the image so ``build_image`` doesn\\'t have to be called next time\\n                image.tag(image_name, image_tag)\\n\\n                return image\\n\\n            # extend the image with correct python by installing the dependencies\\n            def install_dependencies_dockerfile():\\n                base_name, base_tag = self.get_python_base(python_version, pull=not self.disable_pull)\\n\\n                return self.INSTALL_DEPENDENCIES.format(\\n                    name=base_name,\\n                    tag=base_tag,\\n                    dependencies=\" \".join(dependencies)\\n                )\\n\\n            self.get_or_build_image(image_name, image_tag, install_dependencies_dockerfile)\\n\\n            return self.get_image(image_name, image_tag)\\n\\n        else:  # doesn\\'t have to be here, but the return right above was confusing\\n            def install_requirements_dockerfile():\\n                \"\"\" Returns a Dockerfile for installing pip requirements,\\n                    based on a image with installed dependencies (or no extra dependencies)\\n                \"\"\"\\n                dependencies_name, dependencies_tag = self.get_image_with_installed_dependencies(image_name,\\n                                                                                                 dependencies)\\n\\n                return self.get_install_requirements_dockerfile(\\n                    name=dependencies_name,\\n                    tag=dependencies_tag,\\n                    repo_path=repo_path,\\n                    requirements_option=requirements_option,\\n                )\\n\\n            self.get_or_build_image(image_name, image_tag, install_requirements_dockerfile,\\n                                    build_context=repo_path.parent, pull=False)\\n\\n            return self.get_image(image_name, image_tag)',\n",
       " 'def push_to_registry(self, image, image_tag: str):\\n        \"\"\" Pushes a local image to a registry based on the ``use_registry_name`` setting.\\n\\n        :type image: docker.models.images.Image\\n        :raise PushToRegistryError: If the push fails.\\n        \"\"\"\\n        # already tagged, so it\\'s already pushed\\n        if f\"{self.use_registry_name}:{image_tag}\" in image.tags:\\n            return\\n\\n        image.tag(self.use_registry_name, image_tag)\\n\\n        result = self.client.images.push(self.use_registry_name, image_tag)\\n\\n        result = result.strip()  # remove empty line at the end of output\\n\\n        # the last can have one of two outputs, either\\n        # {\"progressDetail\":{},\"aux\":{\"Tag\":\"<tag>\",\"Digest\":\"sha256:<hash>\",\"Size\":<size>}}\\n        # when the push is successful, or\\n        # {\"errorDetail\": {\"message\":\"<error_msg>\"},\"error\":\"<error_msg>\"}\\n        # when the push is not successful\\n\\n        last_line = json.loads(result.split(\"\\\\n\")[-1])\\n\\n        if \"error\" in last_line:\\n            self.client.images.remove(f\"{self.use_registry_name}:{image_tag}\")\\n            raise PushToRegistryError(f\"Push of the image failed because of: {last_line[\\'error\\']}\", full_output=result)\\n\\n        logger.info(\"Pushed image to registry %s:%s\", self.use_registry_name, image_tag)\\n        logger.debug(\"Info:\\\\n%s\", result)',\n",
       " 'def image_exists(self, image_name, image_tag):\\n        \"\"\" Returns if the image exists locally.\\n        \"\"\"\\n        try:\\n            self.get_image(image_name, image_tag)\\n            return True\\n        except docker.errors.ImageNotFound:\\n            return False',\n",
       " 'def container_running(self, container_name):\\n        \"\"\"\\n        Finds out if a container with name ``container_name`` is running.\\n\\n        :return: :class:`Container <docker.models.containers.Container>` if it\\'s running, ``None`` otherwise.\\n        :rtype: Optional[docker.models.container.Container]\\n        \"\"\"\\n        filters = {\\n            \"name\": container_name,\\n            \"status\": \"running\",\\n        }\\n\\n        for container in self.client.containers.list(filters=filters):\\n            if container_name == container.name:\\n                return container\\n        return None',\n",
       " 'def tar_files(self, path: Path) -> bytes:\\n        \"\"\" Returns a tar with the git repository.\\n        \"\"\"\\n        tarstream = BytesIO()\\n        tar = tarfile.TarFile(fileobj=tarstream, mode=\\'w\\')\\n        tar.add(str(path), arcname=\"data\", recursive=True)\\n        tar.close()\\n        return tarstream.getvalue()',\n",
       " 'def tar_runner(self):\\n        \"\"\" Returns a tar with the runner script.\\n        \"\"\"\\n        script_bytes = self.RUNNER.read_bytes()\\n\\n        tarstream = BytesIO()\\n        tar = tarfile.TarFile(fileobj=tarstream, mode=\\'w\\')\\n\\n        tarinfo = tarfile.TarInfo(name=\"runner.py\")\\n        tarinfo.size = len(script_bytes)\\n        tarinfo.mtime = int(time.time())\\n\\n        tar.addfile(tarinfo, BytesIO(script_bytes))\\n        tar.close()\\n\\n        return tarstream.getvalue()',\n",
       " 'def tar_task_definition(self, name: str, contents: str) -> bytes:\\n        \"\"\" Returns a tar with the task definition.\\n\\n        :param name: Name of the file\\n        :param contents: Contens of the definition, utf-8\\n        \"\"\"\\n        tarstream = BytesIO()\\n        tar = tarfile.TarFile(fileobj=tarstream, mode=\\'w\\')\\n        tarinfo = tarfile.TarInfo(name=name)\\n\\n        script_bytes = contents.encode(\"utf-8\")\\n\\n        tarinfo.size = len(script_bytes)\\n        tarinfo.mtime = int(time.time())\\n        tar.addfile(tarinfo, BytesIO(script_bytes))\\n        tar.close()\\n\\n        return tarstream.getvalue()',\n",
       " 'def start_container(self, image, container_name: str, repo_path: Path):\\n        \"\"\" Starts a container with the image and name ``container_name`` and copies the repository into the container.\\n\\n        :type image: docker.models.images.Image\\n        :rtype: docker.models.container.Container\\n        \"\"\"\\n        command = \"bash -i\"\\n\\n        if self.inherit_image:\\n            command = \"sh -i\"\\n\\n        container = self.client.containers.run(image, command=command, detach=True, tty=True, name=container_name,\\n                                               working_dir=str((Path(\"/srv/data\") / self.cwd).resolve()),\\n                                               auto_remove=True)\\n\\n        container.exec_run([\"mkdir\", \"-p\", \"/srv/scripts\"])\\n        container.put_archive(\"/srv\", self.tar_files(repo_path))\\n        container.put_archive(\"/srv/scripts\", self.tar_runner())\\n\\n        return container',\n",
       " 'def get_container_name(self, repo: str, branch: str, git_repo: Repo):\\n        \"\"\" Returns the name of the container used for the repo.\\n        \"\"\"\\n        return \"arca_{}_{}_{}\".format(\\n            self._arca.repo_id(repo),\\n            branch,\\n            self._arca.current_git_hash(repo, branch, git_repo, short=True)\\n        )',\n",
       " 'def run(self, repo: str, branch: str, task: Task, git_repo: Repo, repo_path: Path) -> Result:\\n        \"\"\" Gets or builds an image for the repo, gets or starts a container for the image and runs the script.\\n\\n        :param repo: Repository URL\\n        :param branch: Branch ane\\n        :param task: :class:`Task` to run.\\n        :param git_repo: :class:`Repo <git.repo.base.Repo>` of the cloned repository.\\n        :param repo_path: :class:`Path <pathlib.Path>` to the cloned location.\\n        \"\"\"\\n        self.check_docker_access()\\n\\n        container_name = self.get_container_name(repo, branch, git_repo)\\n\\n        container = self.container_running(container_name)\\n        if container is None:\\n            image = self.get_image_for_repo(repo, branch, git_repo, repo_path)\\n\\n            container = self.start_container(image, container_name, repo_path)\\n\\n        task_filename, task_json = self.serialized_task(task)\\n\\n        container.put_archive(\"/srv/scripts\", self.tar_task_definition(task_filename, task_json))\\n\\n        res = None\\n\\n        try:\\n            command = [\"timeout\"]\\n\\n            if self.inherit_image:\\n                if self.alpine_inherited or b\"Alpine\" in container.exec_run([\"cat\", \"/etc/issue\"], tty=True).output:\\n                    self.alpine_inherited = True\\n                    command = [\"timeout\", \"-t\"]\\n\\n            command += [str(task.timeout),\\n                        \"python\",\\n                        \"/srv/scripts/runner.py\",\\n                        f\"/srv/scripts/{task_filename}\"]\\n\\n            logger.debug(\"Running command %s\", \" \".join(command))\\n\\n            res = container.exec_run(command, tty=True)\\n\\n            # 124 is the standard, 143 on alpine\\n            if res.exit_code in {124, 143}:\\n                raise BuildTimeoutError(f\"The task timeouted after {task.timeout} seconds.\")\\n\\n            return Result(res.output)\\n        except BuildError:  # can be raised by  :meth:`Result.__init__`\\n            raise\\n        except Exception as e:\\n            logger.exception(e)\\n            if res is not None:\\n                logger.warning(res.output)\\n\\n            raise BuildError(\"The build failed\", extra_info={\\n                \"exception\": e,\\n                \"output\": res if res is None else res.output\\n            })\\n        finally:\\n            if not self.keep_container_running:\\n                container.kill(signal.SIGKILL)\\n            else:\\n                self._containers.add(container)',\n",
       " 'def stop_containers(self):\\n        \"\"\" Stops all containers used by this instance of the backend.\\n        \"\"\"\\n        while len(self._containers):\\n            container = self._containers.pop()\\n            try:\\n                container.kill(signal.SIGKILL)\\n            except docker.errors.APIError:  # probably doesn\\'t exist anymore\\n                pass',\n",
       " 'def get_install_requirements_dockerfile(self, name: str, tag: str, repo_path: Path,\\n                                            requirements_option: RequirementsOptions) -> str:\\n        \"\"\"\\n        Returns the content of a Dockerfile that will install requirements based on the repository,\\n        prioritizing Pipfile or Pipfile.lock and falling back on requirements.txt files\\n        \"\"\"\\n        if requirements_option == RequirementsOptions.requirements_txt:\\n            target_file = \"requirements.txt\"\\n            requirements_files = [repo_path / self.requirements_location]\\n\\n            install_cmd = \"pip\"\\n            cmd_arguments = \"install -r /srv/requirements.txt\"\\n\\n        elif requirements_option == RequirementsOptions.pipfile:\\n            target_file = \"\"\\n            requirements_files = [repo_path / self.pipfile_location / \"Pipfile\",\\n                                  repo_path / self.pipfile_location / \"Pipfile.lock\"]\\n\\n            install_cmd = \"pipenv\"\\n            cmd_arguments = \"install --system --ignore-pipfile --deploy\"\\n        else:\\n            raise ValueError(\"Invalid requirements_option\")\\n\\n        dockerfile = self.INSTALL_REQUIREMENTS.format(\\n            name=name,\\n            tag=tag,\\n            timeout=self.requirements_timeout,\\n            target_file=target_file,\\n            requirements_files=\" \".join(str(x.relative_to(repo_path.parent)) for x in requirements_files),\\n            cmd_arguments=cmd_arguments,\\n            install_cmd=install_cmd\\n        )\\n\\n        logger.debug(\"Installing Python requirements with Dockerfile: %s\", dockerfile)\\n\\n        return dockerfile',\n",
       " 'def status():\\n    \"\"\"\\n    Gets the worklog status for the current branch\\n    \"\"\"\\n    import pdb; pdb.set_trace()\\n    branch = git.branch\\n    issue = jira.get_issue(branch)\\n    if not issue:\\n        return\\n\\n    # Print the title\\n    title = issue.fields.summary\\n    print \"(%s) %s\" % (branch, title)\\n\\n    # Print the status\\n    status = issue.fields.status.name\\n    assignee = issue.fields.assignee.name\\n    in_progress = jira.get_datetime_issue_in_progress(issue)\\n\\n    if in_progress:\\n        in_progress_string = in_progress.strftime(\"%a %x %I:%M %p\")\\n        print \\'  Status: %s as of %s\\' % (status, in_progress_string)\\n    else:\\n        print \\'  Status: %s\\' % status\\n\\n    print \\'  Assignee: %s\\' % assignee\\n\\n    # Print the worklogs\\n\\n    # Get the timespent and return 0m if it does not exist\\n    time_spent = \\'0m\\'\\n    try:\\n        time_spent = issue.fields.timetracking.timeSpent\\n    except:\\n        pass\\n\\n    worklogs = jira.get_worklog(issue)\\n    print \"\\\\nTime logged (%s):\" % time_spent\\n    if worklogs:\\n        for worklog in worklogs:\\n            worklog_hash = worklog.raw\\n\\n            author = worklog_hash[\\'author\\'][\\'name\\']\\n\\n            time_spent = worklog_hash.get(\\'timeSpent\\', \\'0m\\')\\n\\n            created = dateutil.parser.parse(worklog_hash[\\'started\\'])\\n            created_pattern = \\'%a %x         \\'  # Adding extra space for formatting\\n            if not created.hour == created.minute == created.second == 0:\\n                created = created.astimezone(tzlocal())\\n                created_pattern = \\'%a %x %I:%M %p\\'\\n            comment = worklog_hash.get(\\'comment\\', \\'<no comment>\\')\\n\\n            updated_string = created.strftime(created_pattern)\\n            print \"  %s - %s (%s): %s\" % (updated_string, author, time_spent, comment)\\n    else:\\n        print \"  No worklogs\"\\n\\n    cycle_time = jira.get_cycle_time(issue)\\n    if cycle_time:\\n        print \\'\\\\nCycle Time: %.1f days\\' % cycle_time\\n\\n    # Print the time elapsed since the last mark\\n    elapsed_time = jira.get_elapsed_time(issue)\\n    if elapsed_time:\\n        print \\'\\\\n\\\\033[0;32m%s elapsed\\\\033[00m (use \"jtime log .\" to log elapsed time or \"jtime log <duration> (ex. 30m, 1h etc.)\" to log a specific amount of time)\\' % (elapsed_time)\\n    else:\\n        print \\'\\\\n\\\\033[0;32m0m elapsed\\\\033[00m\\'',\n",
       " 'def log(duration, message=None, use_last_commit_message=False):\\n    \"\"\"\\n    Log time against the current active issue\\n    \"\"\"\\n    branch = git.branch\\n    issue = jira.get_issue(branch)\\n    # Create the comment\\n    comment = \"Working on issue %s\" % branch\\n    if message:\\n        comment = message\\n    elif use_last_commit_message:\\n        comment = git.get_last_commit_message()\\n\\n    if issue:\\n        # If the duration is provided use it, otherwise use the elapsed time since the last mark\\n        duration = jira.get_elapsed_time(issue) if duration == \\'.\\' else duration\\n\\n        if duration:\\n            # Add the worklog\\n            jira.add_worklog(issue, timeSpent=duration, adjustEstimate=None, newEstimate=None, reduceBy=None,\\n                             comment=comment)\\n\\n            print \"Logged %s against issue %s (%s)\" % (duration, branch, comment)\\n        else:\\n            print \"No time logged, less than 0m elapsed.\"',\n",
       " 'def mark():\\n    \"\"\"\\n    Mark the start time for active work on an issue\\n    \"\"\"\\n    branch = git.branch\\n    issue = jira.get_issue(branch)\\n    if not issue:\\n        return\\n    worklogs = jira.get_worklog(issue)\\n\\n    marked = False\\n    if worklogs:\\n        # If we have worklogs, change the updated time of the last log to the mark\\n        marked = jira.touch_last_worklog(issue)\\n        mark_time = datetime.datetime.now(dateutil.tz.tzlocal()).strftime(\"%I:%M %p\")\\n        print \"Set mark at %s on %s by touching last work log\" % (mark_time, branch)\\n    else:\\n        # If we don\\'t have worklogs, mark the issue as in progress if that is an available transition\\n        jira.workflow_transition(issue, \\'Open\\')\\n        marked = jira.workflow_transition(issue, \\'In Progress\\')\\n        mark_time = datetime.datetime.now(dateutil.tz.tzlocal()).strftime(\"%I:%M %p\")\\n        print \\'Set mark at %s on %s by changing status to \"In Progress\"\\' % (mark_time, branch)\\n\\n    if not marked:\\n        print \"ERROR: Issue %s is has a status of %s and has no worklogs.  You must log some time or re-open the issue to proceed.\" % \\\\\\n            (branch, issue.fields.status.name)',\n",
       " 'def main():\\n    \"\"\"\\n    Set up the context and connectors\\n    \"\"\"\\n    try:\\n        init()\\n    except custom_exceptions.NotConfigured:\\n        configure()\\n        init()\\n    # Adding this in case users are trying to run without adding a jira url.\\n    # I would like to take this out in a release or two.\\n    # TODO: REMOVE\\n    except (AttributeError, ConfigParser.NoOptionError):\\n        logging.error(\\'It appears that your configuration is invalid, please reconfigure the app and try again.\\')\\n        configure()\\n        init()\\n\\n    parser = argparse.ArgumentParser()\\n\\n    # Now simply auto-discovering the methods listed in this module\\n    current_module = sys.modules[__name__]\\n    module_methods = [getattr(current_module, a, None) for a in dir(current_module)\\n                      if isinstance(getattr(current_module, a, None), types.FunctionType)\\n                      and a != \\'main\\']\\n    argh.add_commands(parser, module_methods)\\n\\n    # Putting the error logging after the app is initialized because\\n    # we want to adhere to the user\\'s preferences\\n    try:\\n        argh.dispatch(parser)\\n    # We don\\'t want to report keyboard interrupts to rollbar\\n    except (KeyboardInterrupt, SystemExit):\\n        raise\\n    except Exception as e:\\n        if isinstance(e, jira.exceptions.JIRAError) and \"HTTP 400\" in e:\\n            logging.warning(\\'It appears that your authentication with {0} is invalid. Please re-configure jtime: `jtime configure` with the correct credentials\\'.format(configuration.load_config[\\'jira\\'].get(\\'url\\')))\\n        elif configured.get(\\'jira\\').get(\\'error_reporting\\', True):\\n            # Configure rollbar so that we report errors\\n            import rollbar\\n            from . import __version__ as version\\n            root_path = os.path.dirname(os.path.realpath(__file__))\\n            rollbar.init(\\'7541b8e188044831b6728fa8475eab9f\\', \\'v%s\\' % version, root=root_path)\\n            logging.error(\\'Sorry. It appears that there was an error when handling your command. \\'\\n                          \\'This error has been reported to our error tracking system. To disable \\'\\n                          \\'this reporting, please re-configure the app: `jtime config`.\\')\\n            extra_data = {\\n                # grab the command that we\\'re running\\n                \\'cmd\\': sys.argv[1],\\n                # we really don\\'t want to see jtime in the args\\n                \\'args\\': sys.argv[2:],\\n                # lets grab anything useful, python version?\\n                \\'python\\': str(sys.version),\\n            }\\n            # We really shouldn\\'t thit this line of code when running tests, so let\\'s not cover it.\\n            rollbar.report_exc_info(extra_data=extra_data)  # pragma: no cover\\n        else:\\n            logging.error(\\'It appears that there was an error when handling your command.\\')\\n            raise',\n",
       " 'def from_string(cls, contents, **kwargs):\\n\\t\\t\"\"\"\\n\\t\\tGiven a markdown string, create an Entry object.\\n\\n\\t\\tUsually subclasses will want to customize the parts of the markdown\\n\\t\\twhere you provide values for attributes like public - this can be done\\n\\t\\tby overriding the process_meta method.\\n\\t\\t\"\"\"\\n\\t\\tlines = contents.splitlines()\\n\\t\\ttitle = None\\n\\t\\tdescription = None\\n\\n\\t\\tline = lines.pop(0)\\n\\t\\twhile line != \\'\\':\\n\\t\\t\\tif not title and line.startswith(\\'#\\'):\\n\\t\\t\\t\\ttitle = line[1:].strip()\\n\\t\\t\\telif line.startswith(\\'title:\\'):\\n\\t\\t\\t\\ttitle = line[6:].strip()\\n\\t\\t\\telif line.startswith(\\'description:\\'):\\n\\t\\t\\t\\tdescription = line[12:].strip()\\n\\t\\t\\telif line.startswith(\\'subtitle:\\'):\\n\\t\\t\\t\\tkwargs[\\'subtitle\\'] = line[9:].strip()\\n\\t\\t\\telif line.startswith(\\'comments:\\'):\\n\\t\\t\\t\\ttry:\\n\\t\\t\\t\\t\\tkwargs[\\'allow_comments\\'] = _str_to_bool(line[9:])\\n\\t\\t\\t\\texcept ValueError:\\n\\t\\t\\t\\t\\tLOG.warning(\\'invalid boolean value for comments\\', exc_info=True)\\n\\n\\t\\t\\tcls.process_meta(line, kwargs)\\n\\n\\t\\t\\tline = lines.pop(0)\\n\\n\\t\\t# the only lines left should be the actual contents\\n\\t\\tbody = \\'\\\\n\\'.join(lines).strip()\\n\\t\\texcerpt = _get_excerpt(body)\\n\\t\\tif description is None:\\n\\t\\t\\tdescription = _get_description(excerpt, 160)\\n\\t\\tif issubclass(cls, Post):\\n\\t\\t\\tkwargs[\\'excerpt\\'] = render_markdown(excerpt)\\n\\t\\tbody = render_markdown(body)\\n\\n\\t\\treturn cls(title=title, body=body, description=description, **kwargs)',\n",
       " 'def process_meta(cls, line, kwargs):\\n\\t\\t\"\"\"\\n\\t\\tProcess a line of metadata found in the markdown.\\n\\n\\t\\tLines are usually in the format of \"key: value\".\\n\\n\\t\\tModify the kwargs dict in order to change or add new kwargs that should\\n\\t\\tbe passed to the class\\'s constructor.\\n\\t\\t\"\"\"\\n\\t\\tif line.startswith(\\'slug:\\'):\\n\\t\\t\\tkwargs[\\'slug\\'] = line[5:].strip()\\n\\n\\t\\telif line.startswith(\\'public:\\'):\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tkwargs[\\'public\\'] = _str_to_bool(line[7:])\\n\\t\\t\\texcept ValueError:\\n\\t\\t\\t\\tLOG.warning(\\'invalid boolean value for public\\', exc_info=True)\\n\\n\\t\\telif line.startswith(\\'private:\\'):\\n\\t\\t\\ttry:\\n\\t\\t\\t\\tkwargs[\\'public\\'] = not _str_to_bool(line[8:])\\n\\t\\t\\texcept ValueError:\\n\\t\\t\\t\\tLOG.warning(\\'invalid boolean value for private\\', exc_info=True)',\n",
       " 'def from_file(cls, path, **kwargs):\\n\\t\\t\"\"\"\\n\\t\\tGiven a markdown file, get an Entry object.\\n\\t\\t\"\"\"\\n\\t\\tLOG.debug(\\'creating %s from \"%s\"\\', cls, path)\\n\\n\\t\\t# the filename will be the default slug - can be overridden later\\n\\t\\tkwargs[\\'slug\\'] = os.path.splitext(os.path.basename(path))[0]\\n\\n\\t\\t# TODO: ideally this should be part of the Post class.\\n\\t\\t# if a pubdate isn\\'t explicitly passed, get it from the file metadata\\n\\t\\t# instead. note that it might still be overriden later on while reading\\n\\t\\t# the file contents.\\n\\t\\tif issubclass(cls, Post) and not kwargs.get(\\'pubdate\\'):\\n\\t\\t\\t# you would think creation always comes before modification, but you\\n\\t\\t\\t# can manually modify a file\\'s modification date to one earlier than\\n\\t\\t\\t# the creation date. this lets you set a post\\'s pubdate by running\\n\\t\\t\\t# the command `touch`. we support this behaviour by simply finding\\n\\t\\t\\t# the chronologically earliest date of creation and modification.\\n\\t\\t\\ttimestamp = min(os.path.getctime(path), os.path.getmtime(path))\\n\\t\\t\\tkwargs[\\'pubdate\\'] = datetime.fromtimestamp(timestamp)\\n\\n\\t\\twith open(path, \\'r\\') as file:\\n\\t\\t\\tentry = cls.from_string(file.read(), **kwargs)\\n\\n\\t\\treturn entry',\n",
       " 'def make_tag(cls, tag_name):\\n\\t\\t\"\"\"\\n\\t\\tMake a Tag object from a tag name. Registers it with the content manager\\n\\t\\tif possible.\\n\\t\\t\"\"\"\\n\\t\\tif cls.cm:\\n\\t\\t\\treturn cls.cm.make_tag(tag_name)\\n\\t\\treturn Tag(tag_name.strip())',\n",
       " 'def set_model(self, m):\\n        \"\"\"Set the model for the level\\n\\n        :param m: the model that the level should use\\n        :type m: QtCore.QAbstractItemModel\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self._model = m\\n        self.new_root.emit(QtCore.QModelIndex())\\n        self.model_changed(m)',\n",
       " 'def set_model(self, model):\\n        \"\"\"Set all levels\\\\\\' model to the given one\\n\\n        :param m: the model that the levels should use\\n        :type m: QtCore.QAbstractItemModel\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        # do the set model in reverse!\\n        # set model might trigger an update for the lower levels\\n        # but the lower ones have a different model, so it will fail anyways\\n        # this way the initial state after set_model is correct.\\n        self.model = model\\n        self._levels[0].set_model(model)',\n",
       " 'def set_root(self, depth, index):\\n        \"\"\"Set the level\\\\\\'s root of the given depth to index\\n\\n        :param depth: the depth level\\n        :type depth: int\\n        :param index: the new root index\\n        :type index: QtCore.QModelIndex\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if depth < len(self._levels):\\n            self._levels[depth].set_root(index)',\n",
       " 'def _new_level(self, depth):\\n        \"\"\"Create a new level and header and connect signals\\n\\n        :param depth: the depth level\\n        :type depth: int\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        l = self.create_level(depth)\\n        h = self.create_header(depth)\\n        self.add_lvl_to_ui(l, h)\\n        l.new_root.connect(partial(self.set_root, depth+1))\\n        self._levels.append(l)',\n",
       " 'def set_root(self, index):\\n        \"\"\"Set the given index as root index of the combobox\\n\\n        :param index: the new root index\\n        :type index: QtCore.QModelIndex\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if not index.isValid():\\n            self.setCurrentIndex(-1)\\n            return\\n        if self.model() != index.model():\\n            self.setModel(index.model())\\n        self.setRootModelIndex(index)\\n        if self.model().rowCount(index):\\n            self.setCurrentIndex(0)\\n        else:\\n            self.setCurrentIndex(-1)',\n",
       " 'def selected_indexes(self, ):\\n        \"\"\"Return the current index\\n\\n        :returns: the current index in a list\\n        :rtype: list of QtCore.QModelIndex\\n        :raises: None\\n        \"\"\"\\n        i = self.model().index(self.currentIndex(), 0, self.rootModelIndex())\\n        return [i]',\n",
       " 'def create_header(self, depth):\\n        \"\"\"Create and return a widget that will be used as a header for the given depth\\n\\n        Override this method if you want to have header widgets.\\n        The default implementation returns None.\\n        You can return None if you do not want a header for the given depth\\n\\n        :param depth: the depth level\\n        :type depth: int\\n        :returns: a Widget that is used for the header or None\\n        :rtype: QtGui.QWidget|None\\n        :raises: None\\n        \"\"\"\\n        if not (depth >= 0 and depth < len(self._headertexts)):\\n            return\\n        txt = self._headertexts[depth]\\n        if txt is None:\\n            return\\n        lbl = QtGui.QLabel(txt, self)\\n        return lbl',\n",
       " 'def model_changed(self, model):\\n        \"\"\"Apply the model to the combobox\\n\\n        When a level instance is created, the model is None. So it has to be set afterwards.\\n        Then this method will be called and your level should somehow use the model\\n\\n        :param model: the model that the level should use\\n        :type model: QtCore.QAbstractItemModel\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self.setModel(model)\\n        # to update all lists belwo\\n        # current changed is not triggered by setModel somehow\\n        if model is not None:\\n            self.setCurrentIndex(self.model().index(0, 0))',\n",
       " 'def set_root(self, index):\\n        \"\"\"Set the given index as root index of list\\n\\n        :param index: the new root index\\n        :type index: QtCore.QModelIndex\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if not index.isValid():\\n            self.setModel(None) # so we will not see toplevel stuff\\n            self.setCurrentIndex(QtCore.QModelIndex())\\n            self.new_root.emit(QtCore.QModelIndex())\\n            return\\n        if self.model() != index.model():\\n            self.setModel(index.model())\\n        self.setRootIndex(index)\\n        if self.model().hasChildren(index):\\n            self.setCurrentIndex(self.model().index(0, 0, index))\\n            self.new_root.emit(self.model().index(0, 0, index))\\n        else:\\n            self.new_root.emit(QtCore.QModelIndex())',\n",
       " 'def set_index(self, index):\\n        \"\"\"Set the current index to the row of the given index\\n\\n        :param index: the index to set the level to\\n        :type index: QtCore.QModelIndex\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self.setCurrentIndex(index)\\n        self.new_root.emit(index)\\n        self.scrollTo(index)',\n",
       " 'def resizeEvent(self, event):\\n        \"\"\"Schedules an item layout if resize mode is \\\\\"adjust\\\\\". Somehow this is\\n        needed for correctly scaling down items.\\n\\n        The reason this was reimplemented was the CommentDelegate.\\n\\n        :param event: the resize event\\n        :type event: QtCore.QEvent\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if self.resizeMode() == self.Adjust:\\n            self.scheduleDelayedItemsLayout()\\n        return super(ListLevel, self).resizeEvent(event)',\n",
       " 'def create_level(self, depth):\\n        \"\"\"Create and return a level for the given depth\\n\\n        The model and root of the level will be automatically set by the browser.\\n\\n        :param depth: the depth level that the level should handle\\n        :type depth: int\\n        :returns: a new level for the given depth\\n        :rtype: :class:`jukeboxcore.gui.widgets.browser.AbstractLevel`\\n        :raises: None\\n        \"\"\"\\n        ll = ListLevel(parent=self)\\n        ll.setEditTriggers(ll.DoubleClicked | ll.SelectedClicked | ll.CurrentChanged)\\n        #ll.setSelectionBehavior(ll.SelectRows)\\n        ll.setResizeMode(ll.Adjust)\\n        self.delegate = CommentDelegate(ll)\\n        ll.setItemDelegate(self.delegate)\\n        ll.setVerticalScrollMode(ll.ScrollPerPixel)\\n        return ll',\n",
       " 'def get_first_lang():\\n    \"\"\"Get the first lang of Accept-Language Header.\\n    \"\"\"\\n    request_lang = request.headers.get(\\'Accept-Language\\').split(\\',\\')\\n    if request_lang:\\n        lang = locale.normalize(request_lang[0]).split(\\'.\\')[0]\\n    else:\\n        lang = False\\n    return lang',\n",
       " 'def set_dict(dictionary, value, command=\\'set\\', *keys):\\n    \"\"\"\\n    set_dict takes a dictionary, the value to\\n    enter into the dictionary, a command of what\\n    to do with the value, and a sequence of keys.\\n\\n    d = {}\\n\\n    set_dict(d,1,\\'append\\',\\'level 1\\',\\'level 2\\')\\n\\n    -> d[\\'level 1\\'][\\'level 2\\'] = [1]\\n\\n    set_dict(d,2,\\'append\\',\\'level 1\\',\\'level 2\\')\\n\\n    -> d[\\'level 1\\'][\\'level 2\\'] = [1,2]\\n\\n    \"\"\"\\n\\n    existing = dictionary\\n    for i in range(0, len(keys) - 1):\\n        if keys[i] in existing:\\n            existing = existing[keys[i]]\\n        else:\\n            existing[keys[i]] = existing.__class__()\\n            existing = existing[keys[i]]\\n    if command == \\'set\\':\\n        existing[keys[len(keys) - 1]] = value\\n    elif command == \\'append\\':\\n        if keys[len(keys) - 1] in existing:\\n            existing[keys[len(keys) - 1]].append(value)\\n        else:\\n            existing[keys[len(keys) - 1]] = [value]\\n    elif command == \\'set_or_append\\':\\n        if keys[len(keys) - 1] in existing:\\n            if type(keys[len(keys) - 1]) == type([]):\\n                existing[keys[len(keys) - 1]].append(value)\\n            else:\\n                existing[keys[len(keys) - 1]] = [existing[keys[len(keys) - 1]], value]\\n        else:\\n            existing[keys[len(keys) - 1]] = value\\n    elif command == \\'insert\\':\\n        if keys[len(keys) - 1] in existing:\\n            if not value in existing[keys[len(keys) - 1]]:\\n                existing[keys[len(keys) - 1]].append(value)\\n        else:\\n            existing[keys[len(keys) - 1]] = [value]',\n",
       " 'def search_by_re_list(re_list, text):\\n    \"\"\"\\n    Given a list of compiled regular expressions,\\n    try to search in text with each matcher until the first\\n    match occurs. Return the group-dict for that first match.\\n    \"\"\"\\n    for matcher in re_list:\\n        m = matcher.search(text)\\n        if m:\\n            return m.groupdict()\\n    return None',\n",
       " 'def extract_code(lines, node, lstrip=\"\", ljoin=\"\\\\n\", strip=\"\"):\\n    \"\"\"Get corresponding text in the code\\n\\n\\n    Arguments:\\n    lines -- code splitted by linebreak\\n    node -- PyPosAST enhanced node\\n\\n\\n    Keyword Arguments:\\n    lstrip -- During extraction, strip lines with this arg (default=\"\")\\n    ljoin -- During extraction, join lines with this arg (default=\"\\\\n\")\\n    strip -- After extraction, strip all code with this arg (default=\"\")\\n    \"\"\"\\n    first_line, first_col = node.first_line - 1, node.first_col\\n    last_line, last_col = node.last_line - 1, node.last_col\\n    if first_line == last_line:\\n        return lines[first_line][first_col:last_col].strip(strip)\\n\\n    result = []\\n    # Add first line\\n    result.append(lines[first_line][first_col:].strip(lstrip))\\n    # Add middle lines\\n    if first_line + 1 != last_line:\\n        for line in range(first_line + 1, last_line):\\n            result.append(lines[line].strip(lstrip))\\n    # Add last line\\n    result.append(lines[last_line][:last_col].strip(lstrip))\\n    return ljoin.join(result).strip(strip)',\n",
       " 'def dnode(self, node):\\n        \"\"\"Duplicate node and adjust it for deslocated line and column\"\"\"\\n        new_node = copy(node)\\n        new_node.lineno += self.dline\\n        new_node.col_offset += self.dcol\\n        return new_node',\n",
       " 'def dposition(self, node, dcol=0):\\n        \"\"\"Return deslocated line and column\"\"\"\\n        nnode = self.dnode(node)\\n        return (nnode.lineno, nnode.col_offset + dcol)',\n",
       " 'def calculate_infixop(self, node, previous, next_node):\\n        \"\"\"Create new node for infixop\"\"\"\\n        previous_position = (previous.last_line, previous.last_col - 1)\\n        position = (next_node.first_line, next_node.first_col + 1)\\n        possible = []\\n        for ch in OPERATORS[node.__class__]:\\n            try:\\n                pos = self.operators[ch].find_previous(position)\\n                if previous_position < pos[1] < position:\\n                    possible.append(pos)\\n            except KeyError:\\n                pass\\n\\n        if not possible:\\n            raise ValueError(\"not a single {} between {} and {}\".format(\\n                OPERATORS[node.__class__], previous_position, position))\\n\\n        return NodeWithPosition(\\n            *min(possible, key=lambda x: tuple(map(sub, position, x[0])))\\n        )',\n",
       " 'def calculate_unaryop(self, node, next_node):\\n        \"\"\"Create new node for unaryop\"\"\"\\n        position = (next_node.first_line, next_node.first_col + 1)\\n        possible = []\\n        for ch in OPERATORS[node.__class__]:\\n            try:\\n                pos = self.operators[ch].find_previous(position)\\n                if pos[1] < position:\\n                    possible.append(pos)\\n            except KeyError:\\n                pass\\n\\n        return NodeWithPosition(\\n            *min(possible, key=lambda x: tuple(map(sub, position, x[0])))\\n        )',\n",
       " 'def uid_something_colon(self, node):\\n        \"\"\" Creates op_pos for node from uid to colon \"\"\"\\n        node.op_pos = [\\n            NodeWithPosition(node.uid, (node.first_line, node.first_col))\\n        ]\\n        position = (node.body[0].first_line, node.body[0].first_col)\\n        last, first = self.operators[\\':\\'].find_previous(position)\\n        node.op_pos.append(NodeWithPosition(last, first))\\n        return last',\n",
       " 'def optional_else(self, node, last):\\n        \"\"\" Create op_pos for optional else \"\"\"\\n        if node.orelse:\\n            min_first_max_last(node, node.orelse[-1])\\n            if \\'else\\' in self.operators:\\n                position = (node.orelse[0].first_line, node.orelse[0].first_col)\\n                _, efirst = self.operators[\\'else\\'].find_previous(position)\\n                if efirst and efirst > last:\\n                    elast, _ = self.operators[\\':\\'].find_previous(position)\\n                    node.op_pos.append(NodeWithPosition(elast, efirst))',\n",
       " 'def comma_separated_list(self, node, subnodes):\\n        \"\"\"Process comma separated list \"\"\"\\n        for item in subnodes:\\n            position = (item.last_line, item.last_col)\\n            first, last = find_next_comma(self.lcode, position)\\n            if first:  # comma exists\\n                node.op_pos.append(NodeWithPosition(last, first))',\n",
       " 'def find_next_comma(self, node, sub):\\n        \"\"\"Find comma after sub andd add NodeWithPosition in node\"\"\"\\n        position = (sub.last_line, sub.last_col)\\n        first, last = find_next_comma(self.lcode, position)\\n        if first:  # comma exists\\n            node.op_pos.append(NodeWithPosition(last, first))',\n",
       " 'def fields(self):\\n        \"\"\"\\n        Provides an iterable for all model fields.\\n        \"\"\"\\n        for attr, value in self._meta.fields.items():\\n            if isinstance(value, Field):\\n                yield attr, value',\n",
       " 'def wrap(self, data):\\n        \"\"\"\\n        Wraps and consumes an arbitrary dictionary into the model.\\n        \"\"\"\\n        for name, field in self.fields:\\n            try:\\n                self._state[name] = field.consume(\\n                    self._state.get(name, None), data[name])\\n            except KeyError:\\n                self._state[name] = None',\n",
       " 'def validate(self):\\n        \"\"\"\\n        Validates all field values for the model.\\n        \"\"\"\\n\\n        errors = {}\\n\\n        for name, field in self.fields:\\n            try:\\n                field.validate(self._state.get(name))\\n            except Exception as e:\\n                errors[name] = e\\n\\n        if len(errors) is not 0:\\n            raise Exception(errors)\\n\\n        return True',\n",
       " 'async def save(self):\\n        \"\"\"\\n        Persists the model to the database. If the model holds no primary key,\\n        a new one will automatically created by RethinkDB. Otherwise it will\\n        overwrite the current model persisted to the database.\\n        \"\"\"\\n\\n        if hasattr(self, \"before_save\"):\\n            self.before_save()\\n\\n        query = r.table(self.table_name)\\n\\n        if self._state.get(\"id\"):\\n            query = query \\\\\\n                .get(self._state.get(\"id\")) \\\\\\n                .update(self.__db_repr, return_changes=True)\\n        else:\\n            query = query \\\\\\n                .insert(self.__db_repr, return_changes=True)\\n\\n        resp = await query.run(await conn.get())\\n\\n        try:\\n            changes = resp[\"changes\"]\\n\\n            if len(changes) > 0:\\n                self.wrap(resp[\"changes\"][0][\"new_val\"])\\n        except KeyError:\\n            raise UnexpectedDbResponse()\\n\\n        if resp[\"skipped\"] > 0:\\n            raise UnexpectedDbResponse(\\n                \"Model with id `%s` not found in the database.\" %\\n                self._state.get(\"id\"))\\n\\n        return self',\n",
       " 'async def delete(self):\\n        \"\"\"\\n        Deletes the model from the database.\\n        \"\"\"\\n        await r.table_name(self.table_name) \\\\\\n            .get(self.id) \\\\\\n            .delete() \\\\\\n            .run(await conn.get())',\n",
       " 'def _raw_split(itxt):\\n    \"\"\"\\n    Parse HTML from text into array filled with tags end text.\\n\\n    Source code is little bit unintutive, because it is state machine parser.\\n\\n    For better understanding, look at http://bit.ly/1rXRcJj\\n\\n    Example::\\n\\n        >>> dhtmlparser._raw_split(\\'<html><tag params=\"true\"></html>\\')\\n        [\\'<html>\\', \\'<tag params=\"true\">\\', \\'</html>\\']\\n\\n    Args:\\n        itxt (str): Input HTML text, which will be parsed.\\n\\n    Returns:\\n        list: List of strings (input splitted to tags and text).\\n    \"\"\"\\n    echr = \"\"\\n    buff = [\"\", \"\", \"\", \"\"]\\n    content = \"\"\\n    array = []\\n    next_state = 0\\n    inside_tag = False\\n    escaped = False\\n\\n    COMMENT_START = [\"-\", \"!\", \"<\"]\\n    COMMENT_END = [\"-\", \"-\"]\\n\\n    gc.disable()\\n\\n    for c in itxt:\\n        # content\\n        if next_state == StateEnum.content:\\n            if c == \"<\":\\n                if content:\\n                    array.append(content)\\n\\n                content = c\\n                next_state = StateEnum.tag\\n                inside_tag = False\\n\\n            else:\\n                content += c\\n\\n        # html tag\\n        elif next_state == StateEnum.tag:\\n            if c == \">\":\\n                array.append(content + c)\\n                content = \"\"\\n                next_state = StateEnum.content\\n\\n            elif c == \"\\'\" or c == \\'\"\\':\\n                echr = c\\n                content += c\\n                next_state = StateEnum.parameter\\n\\n            elif c == \"-\" and buff[:3] == COMMENT_START:\\n                if content[:-3]:\\n                    array.append(content[:-3])\\n\\n                content = content[-3:] + c\\n                next_state = StateEnum.comment\\n\\n            else:\\n                if c == \"<\":   # jump back into tag instead of content\\n                    array.append(content)\\n                    inside_tag = True\\n                    content = \"\"\\n\\n                content += c\\n\\n        # quotes \"\" / \\'\\'\\n        elif next_state == StateEnum.parameter:\\n            if c == echr and not escaped:  # end of quotes\\n                next_state = StateEnum.tag\\n\\n            # unescaped end of line - this is good for invalid HTML like\\n            # <a href=something\">..., because it allows recovery\\n            if c == \"\\\\n\" and not escaped and buff[0] == \">\":\\n                next_state = StateEnum.content\\n                inside_tag = False\\n\\n            content += c\\n            escaped = not escaped if c == \"\\\\\\\\\" else False\\n\\n        # html comments\\n        elif next_state == StateEnum.comment:\\n            if c == \">\" and buff[:2] == COMMENT_END:\\n                next_state = StateEnum.tag if inside_tag else StateEnum.content\\n                inside_tag = False\\n\\n                array.append(content + c)\\n                content = \"\"\\n            else:\\n                content += c\\n\\n        # rotate buffer\\n        buff = _rotate_buff(buff)\\n        buff[0] = c\\n\\n    gc.enable()\\n\\n    if content:\\n        array.append(content)\\n\\n    return array',\n",
       " 'def _indexOfEndTag(istack):\\n    \"\"\"\\n    Go through `istack` and search endtag. Element at first index is considered\\n    as opening tag.\\n\\n    Args:\\n        istack (list): List of :class:`.HTMLElement` objects.\\n\\n    Returns:\\n        int: Index of end tag or 0 if not found.\\n    \"\"\"\\n    if len(istack) <= 0:\\n        return 0\\n\\n    if not istack[0].isOpeningTag():\\n        return 0\\n\\n    cnt = 0\\n    opener = istack[0]\\n    for index, el in enumerate(istack[1:]):\\n        if el.isOpeningTag() and \\\\\\n           el.getTagName().lower() == opener.getTagName().lower():\\n            cnt += 1\\n\\n        elif el.isEndTagTo(opener):\\n            if cnt == 0:\\n                return index + 1\\n\\n            cnt -= 1\\n\\n    return 0',\n",
       " 'def _parseDOM(istack):\\n    \"\"\"\\n    Recursively go through element array and create DOM.\\n\\n    Args:\\n        istack (list): List of :class:`.HTMLElement` objects.\\n\\n    Returns:\\n        list: DOM tree as list.\\n    \"\"\"\\n    ostack = []\\n    end_tag_index = 0\\n\\n    def neither_nonpair_or_end_or_comment(el):\\n        return not (el.isNonPairTag() or el.isEndTag() or el.isComment())\\n\\n    index = 0\\n    while index < len(istack):\\n        el = istack[index]\\n\\n        # check if this is pair tag\\n        end_tag_index = _indexOfEndTag(istack[index:])\\n\\n        if end_tag_index == 0 and neither_nonpair_or_end_or_comment(el):\\n            el.isNonPairTag(True)\\n\\n        if end_tag_index == 0:\\n            if not el.isEndTag():\\n                ostack.append(el)\\n        else:\\n            el.childs = _parseDOM(istack[index + 1: end_tag_index + index])\\n            el.endtag = istack[end_tag_index + index]  # reference to endtag\\n            el.endtag.openertag = el\\n\\n            ostack.append(el)\\n            ostack.append(el.endtag)\\n\\n            index = end_tag_index + index\\n\\n        index += 1\\n\\n    return ostack',\n",
       " 'def makeDoubleLinked(dom, parent=None):\\n    \"\"\"\\n    Standard output from `dhtmlparser` is single-linked tree. This will make it\\n    double-linked.\\n\\n    Args:\\n        dom (obj): :class:`.HTMLElement` instance.\\n        parent (obj, default None): Don\\'t use this, it is used in recursive\\n               call.\\n    \"\"\"\\n    dom.parent = parent\\n\\n    for child in dom.childs:\\n        child.parent = dom\\n        makeDoubleLinked(child, dom)',\n",
       " 'def removeTags(dom):\\n    \"\"\"\\n    Remove all tags from `dom` and obtain plaintext representation.\\n\\n    Args:\\n        dom (str, obj, array): str, HTMLElement instance or array of elements.\\n\\n    Returns:\\n        str: Plain string without tags.\\n    \"\"\"\\n    # python 2 / 3 shill\\n    try:\\n        string_type = basestring\\n    except NameError:\\n        string_type = str\\n\\n    # initialize stack with proper value (based on dom parameter)\\n    element_stack = None\\n    if type(dom) in [list, tuple]:\\n        element_stack = dom\\n    elif isinstance(dom, HTMLElement):\\n        element_stack = dom.childs if dom.isTag() else [dom]\\n    elif isinstance(dom, string_type):\\n        element_stack = parseString(dom).childs\\n    else:\\n        element_stack = dom\\n\\n    # remove all tags\\n    output = \"\"\\n    while element_stack:\\n        el = element_stack.pop(0)\\n\\n        if not (el.isTag() or el.isComment() or not el.getTagName()):\\n            output += el.__str__()\\n\\n        if el.childs:\\n            element_stack = el.childs + element_stack\\n\\n    return output',\n",
       " 'def has_method(obj, name):\\n        \"\"\"\\n        Checks if object has a method with specified name.\\n\\n        :param obj: an object to introspect.\\n\\n        :param name: a name of the method to check.\\n\\n        :return: true if the object has the method and false if it doesn\\'t.\\n        \"\"\"\\n        if obj == None:\\n            raise Exception(\"Object cannot be null\")\\n        if name == None:\\n            raise Exception(\"Method name cannot be null\")\\n\\n        name = name.lower()\\n\\n        for method_name in dir(obj): \\n            if method_name.lower() != name:\\n                continue\\n\\n            method = getattr(obj, method_name)\\n\\n            if MethodReflector._is_method(method, method_name):\\n                return True\\n        \\n        return False',\n",
       " 'def invoke_method(obj, name, *args):\\n        \"\"\"\\n        Invokes an object method by its name with specified parameters.\\n\\n        :param obj: an object to invoke.\\n\\n        :param name: a name of the method to invoke.\\n\\n        :param args: a list of method arguments.\\n\\n        :return: the result of the method invocation or null if method returns void.\\n        \"\"\"\\n        if obj == None:\\n            raise Exception(\"Object cannot be null\")\\n        if name == None:\\n            raise Exception(\"Method name cannot be null\")\\n        \\n        name = name.lower()\\n        \\n        try:\\n            for method_name in dir(obj): \\n                if method_name.lower() != name:\\n                    continue\\n\\n                method = getattr(obj, method_name)\\n\\n                if MethodReflector._is_method(method, method_name):\\n                    return method(*args)\\n        except:\\n            pass\\n        \\n        return None',\n",
       " 'def get_method_names(obj):\\n        \"\"\"\\n        Gets names of all methods implemented in specified object.\\n\\n        :param obj: an object to introspect.\\n\\n        :return: a list with method names.\\n        \"\"\"\\n        method_names = []\\n        \\n        for method_name in dir(obj):\\n\\n            method = getattr(obj, method_name)\\n\\n            if MethodReflector._is_method(method, method_name):\\n                method_names.append(method_name)\\n\\n        return method_names',\n",
       " 'def send_to_delivery_stream(events, stream_name):\\n    \"\"\"Sends a list of events to a Firehose delivery stream.\"\"\"\\n    if not events:\\n        logger.info(\"No events provided: nothing delivered to Firehose\")\\n        return\\n\\n    records = []\\n    for event in events:\\n        if not isinstance(event, str):\\n            # csv events already have a newline\\n            event = json.dumps(event) + \"\\\\n\"\\n        records.append({\"Data\": event})\\n    firehose = boto3.client(\"firehose\")\\n    logger.info(\"Delivering %s records to Firehose stream \\'%s\\'\",\\n                len(records), stream_name)\\n    resp = firehose.put_record_batch(\\n        DeliveryStreamName=stream_name,\\n        Records=records)\\n    return resp',\n",
       " 'def send_to_kinesis_stream(events, stream_name, partition_key=None,\\n                           packer=None, serializer=json.dumps):\\n    \"\"\"Sends events to a Kinesis stream.\"\"\"\\n    if not events:\\n        logger.info(\"No events provided: nothing delivered to Firehose\")\\n        return\\n\\n    records = []\\n    for event in events:\\n        if not partition_key:\\n            partition_key_value = str(uuid.uuid4())\\n        elif hasattr(partition_key, \"__call__\"):\\n            partition_key_value = partition_key(event)\\n        else:\\n            partition_key_value = partition_key\\n\\n        if not isinstance(event, str):\\n            event = serializer(event)\\n\\n        if packer:\\n            event = packer(event)\\n\\n        record = {\"Data\": event,\\n                  \"PartitionKey\": partition_key_value}\\n        records.append(record)\\n\\n    kinesis = boto3.client(\"kinesis\")\\n    resp = kinesis.put_records(StreamName=stream_name, Records=records)\\n    return resp',\n",
       " 'def init_app(self, app):\\n        \"\"\"Register the extension with the application.\\n\\n        Args:\\n            app (flask.Flask): The application to register with.\\n        \"\"\"\\n        app.url_rule_class = partial(NavigationRule, copilot=self)\\n        app.context_processor(self.inject_context)',\n",
       " 'def inject_context(self):\\n        \"\"\"Return a dict used for a template context.\"\"\"\\n        navbar = filter(lambda entry: entry.visible, self.navbar_entries)\\n        return {\\'navbar\\': navbar}',\n",
       " 'def register_entry(self, navbar_kwargs):\\n        \"\"\"Register a navbar entry with the copilot.\\n\\n        Args:\\n            navbar_kwargs (dict): Arguments passed to the\\n                :class:`NavbarEntry` instance.\\n        \"\"\"\\n        # Add a new rule for each level in the path.\\n        path = navbar_kwargs.pop(\\'path\\')\\n        # If a single object is used rather than an iterable (including\\n        # a single string), wrap it before using.\\n        if not hasattr(path, \\'__iter__\\') or isinstance(path, basestring):\\n            path = [path]\\n\\n        entry_group = self.navbar_entries\\n        # HACK: I\\'d like to intelligently replace the URL rule in the\\n        # case where the intended rule is provided, but the function has\\n        # already created a blank \"placeholder\" rule for it. There are\\n        # probably nicer ways to approach this, but it works.\\n        for name, is_last in iter_islast(path):\\n            kwargs = deepcopy(navbar_kwargs)\\n            kwargs[\\'name\\'] = name\\n            for existing_entry in entry_group:\\n                # If there\\'s an existing entry for this \"link\", use it\\n                # instead of creating a new one. If this existing entry\\n                # has no rule and this is the last item in ``path``, the\\n                # rule was intended to be assigned to this entry, so\\n                # overwrite the blank rule with the one provided via\\n                # ``navbar_kwargs``.\\n                if existing_entry.name == name:\\n                    entry = existing_entry\\n                    if is_last:\\n                        entry.endpoint = kwargs[\\'endpoint\\']\\n                    break\\n            else:\\n                # If we can\\'t find an existing entry, create one with a\\n                # blank endpoint. If this rule is not the final one in\\n                # the list, the endpoint was not intended for this, so\\n                # don\\'t assign it.\\n                if not is_last:\\n                    kwargs[\\'endpoint\\'] = None\\n                entry = NavbarEntry(**kwargs)\\n                entry_group.add(entry)\\n            entry_group = entry.children',\n",
       " 'def reversed(self):\\n        \"\"\"Create a connectivity matrix where each incoming edge becomes outgoing.\"\"\"\\n        n_rows = len(self)\\n        reversed = DirectedAdjacencyMatrix(n_rows, self.dtype)\\n        for r, row in enumerate(py.prog_iter(self)):\\n            for c in row:\\n                reversed[c].append(r)\\n                \\n        return reversed',\n",
       " 'def crc7(data):\\n    \"\"\"\\n    Compute CRC of a whole message.\\n    \"\"\"\\n    crc = 0\\n\\n    for c in data:\\n        crc = CRC7_TABLE[crc ^ c]\\n\\n    return crc',\n",
       " 'def _unhandledInput(event, workbench, launcher):\\n    \"\"\"Handles input events that weren\\'t handled anywhere else.\\n\\n    \"\"\"\\n    if event == \"ctrl w\":\\n        raise urwid.ExitMainLoop()\\n    elif event == \"esc\":\\n        workbench.clear()\\n        workbench.display(launcher)\\n        return True',\n",
       " 'def _runPopUp(workbench, popUp):\\n    \"\"\"Displays the pop-up on the workbench and gets a completion\\n    notification deferred. When that fires, undisplay the pop-up and\\n    return the result of the notification deferred verbatim.\\n\\n    \"\"\"\\n    workbench.display(popUp)\\n\\n    d = popUp.notifyCompleted()\\n    d.addCallback(_popUpCompleted, workbench)\\n    return d',\n",
       " 'def display(self, tool):\\n        \"\"\"Displays the given tool above the current layer, and sets the\\n        title to its name.\\n\\n        \"\"\"\\n        self._tools.append(tool)\\n        self._justDisplay(tool)',\n",
       " 'def _justDisplay(self, tool):\\n        \"\"\"\\n        Displays the given tool. Does not register it in the tools list.\\n        \"\"\"\\n        self.header.title.set_text(tool.name)\\n\\n        body, _options = self.widget.contents[\"body\"]\\n        overlay = urwid.Overlay(tool.widget, body, *tool.position)\\n        self._surface = urwid.AttrMap(overlay, \"foreground\")\\n        self.widget.contents[\"body\"] = self._surface, None',\n",
       " 'def undisplay(self):\\n        \"\"\"Undisplays the top tool.\\n\\n        This actually forces a complete re-render.\\n        \"\"\"\\n        self._tools.pop()\\n        self._justClear()\\n        for tool in self._tools:\\n            self._justDisplay(tool)',\n",
       " 'def _makeButtons(self):\\n        \"\"\"Makes buttons and wires them up.\\n\\n        \"\"\"\\n        self.button = button = urwid.Button(u\"OK\")\\n        urwid.connect_signal(button, \"click\", self._completed)\\n        return [self.button]',\n",
       " 'def _makeTextWidgets(self):\\n        \"\"\"Makes an editable prompt widget.\\n\\n        \"\"\"\\n        self.prompt = urwid.Edit(self.promptText, multiline=False)\\n        return [self.prompt]',\n",
       " 'def _secrets_table_name(environment=None, stage=None):\\n    \"\"\"Name of the secrets table associated to a humilis deployment.\"\"\"\\n    if environment is None:\\n        environment = os.environ.get(\"HUMILIS_ENVIRONMENT\")\\n\\n    if stage is None:\\n        stage = os.environ.get(\"HUMILIS_STAGE\")\\n\\n    if environment:\\n        if stage:\\n            return \"{environment}-{stage}-secrets\".format(**locals())\\n        else:\\n            return \"{environment}-secrets\".format(**locals())',\n",
       " 'def _state_table_name(environment=None, layer=None, stage=None):\\n    \"\"\"The name of the state table associated to a humilis deployment.\"\"\"\\n    if environment is None:\\n        # For backwards compatiblity\\n        environment = os.environ.get(\"HUMILIS_ENVIRONMENT\")\\n    if layer is None:\\n        layer = os.environ.get(\"HUMILIS_LAYER\")\\n\\n    if stage is None:\\n        stage = os.environ.get(\"HUMILIS_STAGE\")\\n\\n    if environment:\\n        if stage:\\n            return \"{environment}-{layer}-{stage}-state\".format(\\n                **locals())\\n        else:\\n            return \"{environment}-{layer}-state\".format(**locals())',\n",
       " 'def _get_secret_from_vault(\\n        key, environment=None, stage=None, namespace=None,\\n        wait_exponential_multiplier=50, wait_exponential_max=5000,\\n        stop_max_delay=10000):\\n    \"\"\"Retrieves a secret from the secrets vault.\"\"\"\\n    # Get the encrypted secret from DynamoDB\\n    table_name = _secrets_table_name(environment=environment, stage=stage)\\n\\n    if namespace:\\n        key = \"{}:{}\".format(namespace, key)\\n\\n    if table_name is None:\\n        logger.warning(\"Can\\'t produce secrets table name: unable to retrieve \"\\n                       \"secret \\'{}\\'\".format(key))\\n        return\\n\\n    client = boto3.client(\\'dynamodb\\')\\n    logger.info(\"Retriving key \\'{}\\' from table \\'{}\\'\".format(\\n        key, table_name))\\n\\n    @retry(retry_on_exception=_is_critical_exception,\\n           wait_exponential_multiplier=wait_exponential_multiplier,\\n           wait_exponential_max=wait_exponential_max,\\n           stop_max_delay=stop_max_delay)\\n    def get_item():\\n        try:\\n            return client.get_item(\\n                TableName=table_name,\\n                Key={\\'id\\': {\\'S\\': key}}).get(\\'Item\\', {}).get(\\n                    \\'value\\', {}).get(\\'B\\')\\n        except Exception as err:\\n            if _is_dynamodb_critical_exception(err):\\n                raise CriticalError(err)\\n            else:\\n                raise\\n\\n    encrypted = get_item()\\n\\n    if encrypted is None:\\n        return\\n\\n    # Decrypt using KMS\\n    client = boto3.client(\\'kms\\')\\n    try:\\n        value = client.decrypt(CiphertextBlob=encrypted)[\\'Plaintext\\'].decode()\\n    except ClientError:\\n        logger.error(\"KMS error when trying to decrypt secret\")\\n        traceback.print_exc()\\n        return\\n\\n    try:\\n        value = json.loads(value)\\n    except (TypeError, ValueError):\\n        # It\\'s ok, the client should know how to deal with the value\\n        pass\\n\\n    return value',\n",
       " 'def get_secret(key, *args, **kwargs):\\n    \"\"\"Retrieves a secret.\"\"\"\\n    env_value = os.environ.get(key.replace(\\'.\\', \\'_\\').upper())\\n    if not env_value:\\n        # Backwards compatibility: the deprecated secrets vault\\n        return _get_secret_from_vault(key, *args, **kwargs)\\n    return env_value',\n",
       " 'def get_state_batch(keys, namespace=None, consistent=True):\\n    \"\"\"Get a batch of items from the state store.\"\"\"\\n\\n    ukeys = set(keys)\\n\\n    if namespace:\\n        ns_keys = [\"{}:{}\".format(namespace, key) for key in ukeys]\\n\\n    uvalues = {k: v for k, v\\n               in zip(ukeys, get_item_batch(ns_keys, consistent=consistent))}\\n    return list(zip(keys, (uvalues[k] for k in keys)))',\n",
       " 'def set_state_batch(keys, values, namespace=None, ttl=3600*24*365):\\n    \"\"\"Set a batch of items in the state store.\"\"\"\\n\\n    keys, values = zip(*{k: v for k, v in zip(keys, values)}.items())\\n\\n    if namespace:\\n        keys = [\"{}:{}\".format(namespace, key) for key in keys]\\n\\n    return set_item_batch(keys, values, ttl)',\n",
       " 'def set_state(key, value, namespace=None, table_name=None, environment=None,\\n              layer=None, stage=None, shard_id=None, consistent=True,\\n              serializer=json.dumps, wait_exponential_multiplier=500,\\n              wait_exponential_max=5000, stop_max_delay=10000, ttl=None):\\n    \"\"\"Set Lambda state value.\"\"\"\\n    if table_name is None:\\n        table_name = _state_table_name(environment=environment, layer=layer,\\n                                       stage=stage)\\n\\n    if not table_name:\\n        msg = (\"Can\\'t produce state table name: unable to set state \"\\n               \"item \\'{}\\'\".format(key))\\n        logger.error(msg)\\n        raise StateTableError(msg)\\n        return\\n\\n    dynamodb = boto3.resource(\"dynamodb\")\\n    table = dynamodb.Table(table_name)\\n    logger.info(\"Putting {} -> {} in DynamoDB table {}\".format(key, value,\\n                                                               table_name))\\n    if serializer:\\n        try:\\n            value = serializer(value)\\n        except TypeError:\\n            logger.error(\\n                \"Value for state key \\'{}\\' is not json-serializable\".format(\\n                    key))\\n            raise\\n\\n    if namespace:\\n        key = \"{}:{}\".format(namespace, key)\\n\\n    if shard_id:\\n        key = \"{}:{}\".format(shard_id, key)\\n\\n    item = {\"id\": key, \"value\": value}\\n    if ttl:\\n        item[\"ttl\"] = {\"N\": str(int(time.time() + ttl))}\\n    @retry(retry_on_exception=_is_critical_exception,\\n           wait_exponential_multiplier=500,\\n           wait_exponential_max=5000,\\n           stop_max_delay=10000)\\n    def put_item():\\n        try:\\n            return table.put_item(Item=item)\\n        except Exception as err:\\n            if _is_dynamodb_critical_exception(err):\\n                raise CriticalError(err)\\n            else:\\n                raise\\n\\n    resp = put_item()\\n\\n    logger.info(\"Response from DynamoDB: \\'{}\\'\".format(resp))\\n    return resp',\n",
       " 'def delete_state(key, namespace=None, table_name=None, environment=None,\\n                 layer=None, stage=None, shard_id=None, consistent=True,\\n                 wait_exponential_multiplier=500,\\n                 wait_exponential_max=5000, stop_max_delay=10000):\\n    \"\"\"Delete Lambda state value.\"\"\"\\n    if table_name is None:\\n        table_name = _state_table_name(environment=environment, layer=layer,\\n                                       stage=stage)\\n\\n    if not table_name:\\n        msg = (\"Can\\'t produce state table name: unable to set state \"\\n               \"item \\'{}\\'\".format(key))\\n        logger.error(msg)\\n        raise StateTableError(msg)\\n        return\\n\\n    dynamodb = boto3.resource(\"dynamodb\")\\n    table = dynamodb.Table(table_name)\\n    logger.info(\"Deleting {} in DynamoDB table {}\".format(key, table_name))\\n\\n    if namespace:\\n        key = \"{}:{}\".format(namespace, key)\\n\\n    if shard_id:\\n        key = \"{}:{}\".format(shard_id, key)\\n\\n    @retry(retry_on_exception=_is_critical_exception,\\n           wait_exponential_multiplier=500,\\n           wait_exponential_max=5000,\\n           stop_max_delay=10000)\\n    def delete_item():\\n        try:\\n            return table.delete_item(Key={\"id\": key})\\n        except Exception as err:\\n            if _is_dynamodb_critical_exception(err):\\n                raise CriticalError(err)\\n            else:\\n                raise\\n\\n    resp = delete_item()\\n\\n    logger.info(\"Response from DynamoDB: \\'{}\\'\".format(resp))\\n    return resp',\n",
       " 'def produce_context(namespace, context_id, max_delay=None):\\n    \"\"\"Produce event context.\"\"\"\\n    try:\\n        context_obj = get_context(namespace, context_id)\\n        logger.info(\"Found context \\'%s:%s\\'\", namespace, context_id)\\n    except ContextError:\\n        logger.info(\"Context \\'%s:%s\\' not found\", namespace, context_id)\\n        if max_delay is not None:\\n            max_delay = float(max_delay)\\n        logger.info(\"Context error handled with max_delay=%s\", max_delay)\\n        if not max_delay \\\\\\n                or arrival_delay_greater_than(context_id, max_delay):\\n            context_obj = {}\\n            logger.info(\\n                \"Timeout: waited %s seconds for context \\'%s\\'\",\\n                max_delay, context_id)\\n        else:\\n            msg = \"Context \\'{}\\' not found: resorting\".format(context_id)\\n            raise OutOfOrderError(msg)\\n\\n    return context_obj',\n",
       " 'def get_context(namespace, context_id):\\n    \"\"\"Get stored context object.\"\"\"\\n    context_obj = get_state(context_id, namespace=namespace)\\n    if not context_obj:\\n        raise ContextError(\"Context \\'{}\\' not found in namespace \\'{}\\'\".format(\\n            context_id, namespace))\\n    return context_obj',\n",
       " 'def arrival_delay_greater_than(item_id, delay, namespace=\"_expected_arrival\"):\\n    \"\"\"Check if an item arrival is delayed more than a given amount.\"\"\"\\n    expected = get_state(item_id, namespace=namespace)\\n    now = time.time()\\n    if expected and (now - expected) > delay:\\n        logger.error(\"Timeout: waited %s seconds for parent.\", delay)\\n        return True\\n    elif expected:\\n        logger.info(\"Still out of order but no timeout: %s-%s <= %s.\",\\n                    now, expected, delay)\\n        return False\\n    elif delay > 0:\\n        logger.info(\"Storing expected arrival time (%s) for context \\'%s\\'\",\\n                    datetime.fromtimestamp(now).isoformat(), item_id)\\n        set_state(item_id, now, namespace=namespace)\\n        return False\\n    else:\\n        logger.info(\"Event is out of order but not waiting for parent.\")\\n        return True',\n",
       " 'def get(name, stype, **kwargs):\\n    \"\"\"Returns the rcParams specified in the style file given by `name` and `stype`.\\n\\n    Parameters\\n    ----------\\n    name: str\\n        The name of the style.\\n    stype: str\\n        Any of (\\'context\\', \\'style\\', \\'palette\\').\\n    kwargs:\\n    - stylelib_url: str\\n        Overwrite the value in the local config with the specified url.\\n    - ignore_cache: bool\\n        Ignore files in the cache and force loading from the stylelib.\\n\\n    Raises\\n    ------\\n    ValueError:\\n        If `stype` is not any of (\\'context\\', \\'style\\', \\'palette\\')\\n\\n    Returns\\n    -------\\n    rcParams: dict\\n        The parameter dict of the file.\\n    \"\"\"\\n    stype = str(stype)\\n\\n    params = {}\\n    if stype in MPLS_STYPES:\\n        params.update(__get(name, stype, **kwargs))\\n    else:\\n        raise ValueError(\\'unexpected stype: {}! Must be any of {!r}\\'.format(stype, MPLS_STYPES))\\n\\n    # color palette hack\\n    if params.get(\\'axes.prop_cycle\\'):\\n        params[\\'axes.prop_cycle\\'] = mpl.rcsetup.cycler(\\'color\\', params[\\'axes.prop_cycle\\'])\\n\\n    return params',\n",
       " 'def collect(context=None, style=None, palette=None, **kwargs):\\n    \"\"\"Returns the merged rcParams dict of the specified context, style, and palette.\\n\\n    Parameters\\n    ----------\\n    context: str\\n\\n    style: str\\n\\n    palette: str\\n\\n    kwargs:\\n    -\\n\\n    Returns\\n    -------\\n    rcParams: dict\\n        The merged parameter dicts of the specified context, style, and palette.\\n\\n    Notes\\n    -----\\n    The rcParams dicts are loaded and updated in the order: context, style, palette. That means if\\n    a context parameter is also defined in the style or palette dict, it will be overwritten. There\\n    is currently no checking being done to avoid this.\\n    \"\"\"\\n    params = {}\\n    if context:\\n        params.update(get(context, \\'context\\', **kwargs))\\n    if style:\\n        params.update(get(style, \\'style\\', **kwargs))\\n    if palette:\\n        params.update(get(palette, \\'palette\\', **kwargs))\\n    return params',\n",
       " 'def str_to_num(i, exact_match=True):\\n    \"\"\"\\n    Attempts to convert a str to either an int or float\\n    \"\"\"\\n    # TODO: Cleanup -- this is really ugly\\n    if not isinstance(i, str):\\n        return i\\n    try:\\n        if not exact_match:\\n            return int(i)\\n        elif str(int(i)) == i:\\n            return int(i)\\n        elif str(float(i)) == i:\\n            return float(i)\\n        else:\\n            pass\\n    except ValueError:\\n        pass\\n    return i',\n",
       " 'def make_link(title, url, blank=False):\\n\\t\"\"\"\\n\\tMake a HTML link out of an URL.\\n\\n\\tArgs:\\n\\t  title (str): Text to show for the link.\\n\\t  url (str): URL the link will point to.\\n\\t  blank (bool): If True, appends target=_blank, noopener and noreferrer to\\n\\t    the <a> element. Defaults to False.\\n\\t\"\"\"\\n\\tattrs = \\'href=\"%s\"\\' % url\\n\\tif blank:\\n\\t\\tattrs += \\' target=\"_blank\" rel=\"noopener noreferrer\"\\'\\n\\treturn \\'<a %s>%s</a>\\' % (attrs, title)',\n",
       " 'def get_asset_url(self, path):\\n\\t\\t\"\"\"\\n\\t\\tGet the URL of an asset. If asset hashes are added and one exists for\\n\\t\\tthe path, it will be appended as a query string.\\n\\n\\t\\tArgs:\\n\\t\\t  path (str): Path to the file, relative to your \"assets\" directory.\\n\\t\\t\"\"\"\\n\\t\\turl = self.root_url + \\'/assets/\\' + path\\n\\t\\tif path in self.asset_hash:\\n\\t\\t\\turl += \\'?\\' + self.asset_hash[path]\\n\\t\\treturn url',\n",
       " 'def add_pages(self, path=\\'pages\\'):\\n\\t\\t\"\"\"\\n\\t\\tLook through a directory for markdown files and add them as pages.\\n\\t\\t\"\"\"\\n\\t\\tpages_path = os.path.join(self.root_path, path)\\n\\t\\tpages = []\\n\\t\\tfor file in _listfiles(pages_path):\\n\\t\\t\\tpage_dir = os.path.relpath(os.path.dirname(file), pages_path)\\n\\t\\t\\tif page_dir == \\'.\\':\\n\\t\\t\\t\\tpage_dir = None\\n\\t\\t\\tpages.append(self.cm.Page.from_file(file, directory=page_dir))\\n\\t\\tself.cm.add_pages(pages)',\n",
       " 'def add_posts(self, path=\\'posts\\'):\\n\\t\\t\"\"\"\\n\\t\\tLook through a directory for markdown files and add them as posts.\\n\\t\\t\"\"\"\\n\\t\\tpath = os.path.join(self.root_path, path)\\n\\t\\tself.cm.add_posts([\\n\\t\\t\\tself.cm.Post.from_file(file)\\n\\t\\t\\tfor file in _listfiles(path)\\n\\t\\t])',\n",
       " 'def copy_assets(self, path=\\'assets\\'):\\n\\t\\t\"\"\"\\n\\t\\tCopy assets into the destination directory.\\n\\t\\t\"\"\"\\n\\t\\tpath = os.path.join(self.root_path, path)\\n\\t\\tfor root, _, files in os.walk(path):\\n\\t\\t\\tfor file in files:\\n\\t\\t\\t\\tfullpath = os.path.join(root, file)\\n\\t\\t\\t\\trelpath = os.path.relpath(fullpath, path)\\n\\t\\t\\t\\tcopy_to = os.path.join(self._get_dist_path(relpath, directory=\\'assets\\'))\\n\\t\\t\\t\\tLOG.debug(\\'copying %r to %r\\', fullpath, copy_to)\\n\\t\\t\\t\\tshutil.copyfile(fullpath, copy_to)',\n",
       " 'def add_asset_hashes(self, path=\\'dist/assets\\'):\\n\\t\\t\"\"\"\\n\\t\\tScan through a directory and add hashes for each file found.\\n\\t\\t\"\"\"\\n\\t\\tfor fullpath in _listfiles(os.path.join(self.root_path, path)):\\n\\t\\t\\trelpath = fullpath.replace(self.root_path + \\'/\\' + path + \\'/\\', \\'\\')\\n\\t\\t\\tmd5sum = hashlib.md5(open(fullpath, \\'rb\\').read()).hexdigest()\\n\\t\\t\\tLOG.debug(\\'MD5 of %s (%s): %s\\', fullpath, relpath, md5sum)\\n\\t\\t\\tself.asset_hash[relpath] = md5sum',\n",
       " 'def get_posts(self, num=None, tag=None, private=False):\\n\\t\\t\"\"\"\\n\\t\\tGet all the posts added to the blog.\\n\\n\\t\\tArgs:\\n\\t\\t  num (int): Optional. If provided, only return N posts (sorted by date,\\n\\t\\t    most recent first).\\n\\t\\t  tag (Tag): Optional. If provided, only return posts that have a\\n\\t\\t    specific tag.\\n\\t\\t  private (bool): By default (if False), private posts are not included.\\n\\t\\t    If set to True, private posts will also be included.\\n\\t\\t\"\"\"\\n\\t\\tposts = self.posts\\n\\n\\t\\tif not private:\\n\\t\\t\\tposts = [post for post in posts if post.public]\\n\\n\\t\\tif tag:\\n\\t\\t\\tposts = [post for post in posts if tag in post.tags]\\n\\n\\t\\tif num:\\n\\t\\t\\treturn posts[:num]\\n\\t\\treturn posts',\n",
       " 'def generate_pages(self):\\n\\t\\t\"\"\"\\n\\t\\tGenerate HTML out of the pages added to the blog.\\n\\t\\t\"\"\"\\n\\t\\tfor page in self.pages:\\n\\t\\t\\tself.generate_page(page.slug, template=\\'page.html.jinja\\', page=page)',\n",
       " 'def generate_posts(self):\\n\\t\\t\"\"\"\\n\\t\\tGenerate single-post HTML files out of posts added to the blog. Will not\\n\\t\\tgenerate front page, archives or tag files - those have to be generated\\n\\t\\tseparately.\\n\\t\\t\"\"\"\\n\\t\\tfor post in self.posts:\\n\\t\\t\\tself.generate_page(\\n\\t\\t\\t\\t[\\'posts\\', post.slug],\\n\\t\\t\\t\\ttemplate=\\'post.html.jinja\\',\\n\\t\\t\\t\\tpost=post,\\n\\t\\t\\t)',\n",
       " 'def generate_tags(self):\\n\\t\\t\"\"\"\\n\\t\\tGenerate one HTML page for each tag, each containing all posts that\\n\\t\\tmatch that tag.\\n\\t\\t\"\"\"\\n\\t\\tfor tag in self.tags:\\n\\t\\t\\tposts = self.get_posts(tag=tag, private=True)\\n\\t\\t\\tself.generate_page([\\'tags\\', tag.slug],\\n\\t\\t\\t\\ttemplate=\\'archive.html.jinja\\', posts=posts)',\n",
       " 'def generate_page(self, path, template, **kwargs):\\n\\t\\t\"\"\"\\n\\t\\tGenerate the HTML for a single page. You usually don\\'t need to call this\\n\\t\\tmethod manually, it is used by a lot of other, more end-user friendly\\n\\t\\tmethods.\\n\\n\\t\\tArgs:\\n\\t\\t  path (str): Where to place the page relative to the root URL. Usually\\n\\t\\t    something like \"index\", \"about-me\", \"projects/example\", etc.\\n\\t\\t  template (str): Which jinja template to use to render the page.\\n\\t\\t  **kwargs: Kwargs will be passed on to the jinja template. Also, if\\n\\t\\t    the `page` kwarg is passed, its directory attribute will be\\n\\t\\t    prepended to the path.\\n\\t\\t\"\"\"\\n\\t\\tdirectory = None\\n\\t\\tif kwargs.get(\\'page\\'):\\n\\t\\t\\tdirectory = kwargs[\\'page\\'].dir\\n\\n\\t\\tpath = self._get_dist_path(path, directory=directory)\\n\\t\\tif not path.endswith(\\'.html\\'):\\n\\t\\t\\tpath = path + \\'.html\\'\\n\\n\\t\\tif not os.path.isdir(os.path.dirname(path)):\\n\\t\\t\\tos.makedirs(os.path.dirname(path))\\n\\n\\t\\thtml = self._get_template(template).render(**kwargs)\\n\\n\\t\\twith open(path, \\'w+\\') as file:\\n\\t\\t\\tfile.write(html)',\n",
       " 'def generate_index(self, num_posts=5):\\n\\t\\t\"\"\"\\n\\t\\tGenerate the front page, aka index.html.\\n\\t\\t\"\"\"\\n\\t\\tposts = self.get_posts(num=num_posts)\\n\\t\\tself.generate_page(\\'index\\', template=\\'index.html.jinja\\', posts=posts)',\n",
       " 'def generate_rss(self, path=\\'rss.xml\\', only_excerpt=True, https=False):\\n\\t\\t\"\"\"\\n\\t\\tGenerate the RSS feed.\\n\\n\\t\\tArgs:\\n\\t\\t  path (str): Where to save the RSS file. Make sure that your jinja\\n\\t\\t    templates refer to the same path using <link>.\\n\\t\\t  only_excerpt (bool): If True (the default), don\\'t include the full\\n\\t\\t    body of posts in the RSS. Instead, include the first paragraph and\\n\\t\\t    a \"read more\" link to your website.\\n\\t\\t  https (bool): If True, links inside the RSS with relative scheme (e.g.\\n\\t\\t    //example.com/something) will be set to HTTPS. If False (the\\n\\t\\t    default), they will be set to plain HTTP.\\n\\t\\t\"\"\"\\n\\t\\tfeed = russell.feed.get_rss_feed(self, only_excerpt=only_excerpt, https=https)\\n\\t\\tfeed.rss_file(self._get_dist_path(path))',\n",
       " 'def generate_sitemap(self, path=\\'sitemap.xml\\', https=False):\\n\\t\\t\"\"\"\\n\\t\\tGenerate an XML sitemap.\\n\\n\\t\\tArgs:\\n\\t\\t  path (str): The name of the file to write to.\\n\\t\\t  https (bool): If True, links inside the sitemap with relative scheme\\n\\t\\t    (e.g. example.com/something) will be set to HTTPS. If False (the\\n\\t\\t    default), they will be set to plain HTTP.\\n\\t\\t\"\"\"\\n\\t\\tsitemap = russell.sitemap.generate_sitemap(self, https=https)\\n\\t\\tself.write_file(path, sitemap)',\n",
       " 'def write_file(self, path, contents):\\n\\t\\t\"\"\"\\n\\t\\tWrite a file of any type to the destination path. Useful for files like\\n\\t\\trobots.txt, manifest.json, and so on.\\n\\n\\t\\tArgs:\\n\\t\\t  path (str): The name of the file to write to.\\n\\t\\t  contents (str or bytes): The contents to write.\\n\\t\\t\"\"\"\\n\\t\\tpath = self._get_dist_path(path)\\n\\t\\tif not os.path.isdir(os.path.dirname(path)):\\n\\t\\t\\tos.makedirs(os.path.dirname(path))\\n\\t\\tif isinstance(contents, bytes):\\n\\t\\t\\tmode = \\'wb+\\'\\n\\t\\telse:\\n\\t\\t\\tmode = \\'w\\'\\n\\t\\twith open(path, mode) as file:\\n\\t\\t\\tfile.write(contents)',\n",
       " 'def enable_travis(token, slug, log):\\n    \"\"\"\\n    Enable Travis automatically for the given repo.\\n\\n    this need to have access to the GitHub token.\\n    \"\"\"\\n\\n    # Done with github directly. Login to travis\\n\\n    travis = TravisPy.github_auth(token, uri=\\'https://api.travis-ci.org\\')\\n    user = travis.user()\\n    log.info(\\'Travis user: %s\\', user.name)\\n\\n    # Ask travis to sync with github, try to fetch created repo with exponentially decaying time.\\n\\n    last_sync = user.synced_at\\n    log.info(\\'syncing Travis with Github, this can take a while...\\')\\n    repo = travis._session.post(travis._session.uri+\\'/users/sync\\')\\n    for i in range(10):\\n        try:\\n            sleep((1.5)**i)\\n            repo = travis.repo(slug)\\n            if travis.user().synced_at == last_sync:\\n                raise ValueError(\\'synced not really done, travis.repo() can be a duplicate\\')\\n            log.info(\\'\\\\nsyncing done\\')\\n            break\\n        # TODO: find the right exception here\\n        except Exception:\\n            pass\\n    ## todo , warn if not found\\n\\n\\n    #  Enable travis hook for this repository\\n\\n    log.info(\\'Enabling Travis-CI hook for this repository\\')\\n    resp = travis._session.put(travis._session.uri+\"/hooks/\",\\n                        json={\\n                            \"hook\": {\\n                                \"id\": repo.id ,\\n                                \"active\": True\\n                            }\\n                        },\\n                      )\\n    if resp.json()[\\'result\\'] is True:\\n        log.info(\\'Travis hook for this repository is now enabled.\\')\\n        log.info(\\'Continuous integration test should be triggered every time you push code to github\\')\\n    else:\\n        log.info(\"I was not able to set up Travis hooks... something went wrong.\")\\n\\n    return user',\n",
       " 'def project_layout(proposal, user=None, repo=None, log=None):\\n    \"\"\"\\n    generate the project template\\n\\n    proposal is the name of the project, \\n    user is an object containing some information about the user. \\n        - full name, \\n        - github username\\n        - email\\n\\n\\n\\n    \"\"\"\\n\\n    proposal = proposal.lower()\\n\\n    #context_file = os.path.expanduser(\\'~/.cookiecutters/cookiecutter-pypackage/cookiecutter.json\\')\\n    #context = generate_context(context_file)\\n\\n    # os.chdir(\\'..\\')\\n    # context[\\'cookiecutter\\'][\\'full_name\\'] = user.name\\n    # context[\\'cookiecutter\\'][\\'email\\'] = user.email\\n    # context[\\'cookiecutter\\'][\\'github_username\\'] = user.login\\n    # context[\\'cookiecutter\\'][\\'project_name\\'] = proposal\\n    # context[\\'cookiecutter\\'][\\'repo_name\\'] = proposal.lower()\\n\\n    try:\\n        os.mkdir(proposal)\\n    except FileExistsError:\\n        log.info(\\'Skip directory structure, as project seem to already exists\\')\\n\\n    with open(\\'.gitignore\\', \\'w\\') as f:\\n        f.write(\\'\\'\\'\\n*.pyc\\n__pycache__\\n/build/\\n/dist/\\n\\'\\'\\')\\n\\n    with open( \\'/\\'.join([proposal, \\'__init__.py\\']), \\'w\\') as f: \\n        f.write(\\'\\'\\'\\n\"\"\"\\na simple package\\n\"\"\"\\n\\n\\n__version__ = \\'0.0.1\\'\\n\\n        \\'\\'\\')\\n\\n\\n    travis_yml()\\n\\n    #generate_files(\\n    #        repo_dir=os.path.expanduser(\\'~/.cookiecutters/cookiecutter-pypackage/\\'),\\n    #        context=context\\n    #    )\\n\\n    log.info(\\'Workig in %s\\', os.getcwd())\\n    os.listdir(\\'.\\')\\n\\n    subprocess.call([\\'git\\',\\'add\\',\\'.\\'], )\\n\\n    subprocess.call([\\'git\\',\\'commit\\',\"-am\\'initial commit of %s\\'\" % proposal])\\n\\n    subprocess.call([\\'git\\', \"push\", \"origin\", \"master:master\"])',\n",
       " 'def create_db_user(username, password=None, flags=None):\\n    \"\"\"Create a databse user.\"\"\"\\n\\n    flags = flags or u\\'-D -A -R\\'\\n    sudo(u\\'createuser %s %s\\' % (flags, username), user=u\\'postgres\\')\\n    if password:\\n        change_db_user_password(username, password)',\n",
       " 'def excute_query(query, db=None, flags=None, use_sudo=False, **kwargs):\\n    \"\"\"Execute remote psql query.\"\"\"\\n\\n    flags = flags or u\\'\\'\\n    if db:\\n        flags = u\"%s -d %s\" % (flags, db)\\n    command = u\\'psql %s -c \"%s\"\\' % (flags, query)\\n    if use_sudo:\\n        sudo(command, user=\\'postgres\\', **kwargs)\\n    else:\\n        run(command, **kwargs)',\n",
       " 'def db_user_exists(username):\\n    \"\"\"Return True if the DB user already exists.\\n    \"\"\"\\n    qry = u\"\"\"SELECT COUNT(*) FROM pg_roles where rolname = \\\\\\'{username}\\\\\\';\"\"\"\\n    output = StringIO()\\n    excute_query(\\n        qry.format(username=username),\\n        flags=\"-Aqt\",\\n        use_sudo=True,\\n        stdout=output\\n    )\\n    # FIXME: is there a way to get fabric to not clutter the output\\n    # with \"[127.0.0.1] out:\" on each line?\\n    lines = output.getvalue().splitlines()\\n    return lines and lines[0].endswith(\\'out: 1\\')',\n",
       " 'def change_db_user_password(username, password):\\n    \"\"\"Change a db user\\'s password.\"\"\"\\n\\n    sql = \"ALTER USER %s WITH PASSWORD \\'%s\\'\" % (username, password)\\n    excute_query(sql, use_sudo=True)',\n",
       " 'def create_db(name, owner=None, encoding=u\\'UTF-8\\', template=\\'template1\\',\\n              **kwargs):\\n    \"\"\"Create a Postgres database.\"\"\"\\n\\n    flags = u\\'\\'\\n    if encoding:\\n        flags = u\\'-E %s\\' % encoding\\n    if owner:\\n        flags = u\\'%s -O %s\\' % (flags, owner)\\n    if template and template != \\'template1\\':\\n        flags = u\\'%s --template=%s\\' % (flags, template)\\n    sudo(\\'createdb %s %s\\' % (flags, name), user=\\'postgres\\', **kwargs)',\n",
       " 'def upload_pg_hba_conf(template_name=None, pg_version=None, pg_cluster=\\'main\\', restart=True):\\n    \"\"\"\\n    Upload configuration for pg_hba.conf\\n    If the version is not given it will be guessed.\\n    \"\"\"\\n\\n    template_name = template_name or u\\'postgres/pg_hba.conf\\'\\n    version = pg_version or detect_version()\\n    config = {\\'version\\': version, \\'cluster\\': pg_cluster}\\n    destination = u\\'/etc/postgresql/%(version)s/%(cluster)s/pg_hba.conf\\' % config\\n    upload_template(template_name, destination, use_sudo=True)\\n    if restart:\\n        restart_service(u\\'postgresql\\')',\n",
       " 'def detect_version():\\n    \"\"\"Parse the output of psql to detect Postgres version.\"\"\"\\n    version_regex = re.compile(r\\'\\\\(PostgreSQL\\\\) (?P<major>\\\\d)\\\\.(?P<minor>\\\\d)\\\\.(?P<bugfix>\\\\d)\\')\\n    pg_version = None\\n    with hide(\\'running\\', \\'stdout\\', \\'stderr\\'):\\n        output = run(\\'psql --version\\')\\n    match = version_regex.search(output)\\n    if match:\\n        result = match.groupdict()\\n        if \\'major\\' in result and \\'minor\\' in result:\\n            pg_version = u\\'%(major)s.%(minor)s\\' % result\\n    if not pg_version:\\n        abort(u\"Error: Could not determine Postgres version of the server.\")\\n    return pg_version',\n",
       " 'def reset_cluster(pg_cluster=\\'main\\', pg_version=None, encoding=u\\'UTF-8\\',\\n                  locale=u\\'en_US.UTF-8\\'):\\n    \"\"\"Drop and restore a given cluster.\"\"\"\\n    warning = u\\'You are about to drop the %s cluster. This cannot be undone.\\' \\\\\\n              u\\' Are you sure you want to continue?\\' % pg_cluster\\n    if confirm(warning, default=False):\\n        version = pg_version or detect_version()\\n        config = {\\'version\\': version, \\'cluster\\': pg_cluster,\\n                  \\'encoding\\': encoding, \\'locale\\': locale}\\n        sudo(u\\'pg_dropcluster --stop %(version)s %(cluster)s\\' % config,\\n             user=\\'postgres\\', warn_only=True)\\n        sudo(u\\'pg_createcluster --start -e %(encoding)s --locale %(locale)s\\'\\n             u\\' %(version)s %(cluster)s\\' % config, user=\\'postgres\\')\\n    else:\\n        abort(u\"Dropping %s cluster aborted by user input.\" % pg_cluster)',\n",
       " 'def require_request_model(cls, validate=True):\\n    \"\"\"\\n    Makes a handler require that a request body that map towards the given\\n    model is provided. Unless the ``validate`` option is set to ``False`` the\\n    data will be validated against the model\\'s fields.\\n\\n    The model will be passed to the handler as the last positional argument. ::\\n\\n        @require_request_model(Model)\\n        async def handle_model(request, model):\\n            return 200, model\\n    \"\"\"\\n    def decorator(handler):\\n        async def new_handler(request, *args, **kwargs):\\n            body = await request.json()\\n            model = cls(**body)\\n\\n            if validate:\\n                model.validate()\\n\\n            return await handler(request, model, *args, **kwargs)\\n        return new_handler\\n    return decorator',\n",
       " 'def read_csv(csv_file, options, ensemble_list=None):\\n    \"\"\"\\n\\tRead csv and return molList, otherwise print error and exit.\\n\\t\"\"\"\\n    name, ext = os.path.splitext(csv_file)\\n    try:\\n        if ext == \\'.gz\\':\\n            f = gzip.open(csv_file, \\'rb\\')\\n        else:\\n            f = open(csv_file, \\'rU\\')\\n    except IOError:\\n        print(\" \\\\n \\'{f}\\' could not be opened\\\\n\".format(f=os.path.basename(csv_file)))\\n        sys.exit(1)\\n\\n\\n    csv_reader = csv.reader(f)\\n    molList = []\\n    line_number = 1\\n\\n    for line in csv_reader:\\n\\n        if line_number == 1:\\n            if ensemble_list:\\n                prop_indices = read_header(line, options, ensemble_list)\\n            else:\\n                prop_indices = read_header(line, options)\\n        else:\\n            mol = Molecule()\\n            if ensemble_list:\\n                mol = read_line(line, options, prop_indices, mol, ensemble_list)\\n            else:\\n                mol = read_line(line, options, prop_indices, mol)\\n            if mol == 1:\\n                print(\" skipping molecule {m}\\\\n\".format(m=(line_number - 1)))\\n            else:\\n                molList.append(mol)\\n        line_number += 1\\n\\n    return molList',\n",
       " 'def _build_rules(specs):\\n    \"\"\"Adapts the list of anillo urlmapping specs into\\n    a list of werkzeug rules or rules subclasses.\\n\\n    :param list specs: A list of anillo url mapping specs.\\n    :return: generator\\n    \"\"\"\\n    for spec in specs:\\n        if \"context\" in spec:\\n            yield Context(spec[\"context\"], list(_build_rules(spec.get(\"routes\", []))))\\n        else:\\n            rulespec = spec.copy()\\n            match = rulespec.pop(\"match\")\\n            name = rulespec.pop(\"name\")\\n            yield Rule(match, endpoint=name, **rulespec)',\n",
       " 'def _build_urlmapping(urls, strict_slashes=False, **kwargs):\\n    \"\"\"Convers the anillo urlmappings list into\\n    werkzeug Map instance.\\n\\n    :return: a werkzeug Map instance\\n    :rtype: Map\\n    \"\"\"\\n\\n    rules = _build_rules(urls)\\n    return Map(rules=list(rules), strict_slashes=strict_slashes, **kwargs)',\n",
       " 'def default_match_error_handler(exc):\\n    \"\"\"\\n    Default implementation for match error handling.\\n    \"\"\"\\n    if isinstance(exc, NotFound):\\n        return http.NotFound()\\n    elif isinstance(exc, MethodNotAllowed):\\n        return http.MethodNotAllowed()\\n    elif isinstance(exc, RequestRedirect):\\n        return redirect(exc.new_url)\\n    else:\\n        raise exc',\n",
       " 'def r_oauth_login(self):\\n        \"\"\"\\n        Route for OAuth2 Login\\n\\n        :param next next url\\n        :type str\\n\\n        :return: Redirects to OAuth Provider Login URL\\n        \"\"\"\\n        session[\\'next\\'] = request.args.get(\\'next\\',\\'\\')\\n        callback_url = self.authcallback\\n        if callback_url is None:\\n            callback_url = url_for(\\'.r_oauth_authorized\\', _external=True)\\n        return self.authobj.authorize(callback=callback_url)',\n",
       " 'def wrap_session(func=None, *, storage=MemoryStorage):\\n    \"\"\"\\n    A middleware that adds the session management to the\\n    request.\\n\\n    This middleware optionally accepts a `storage` keyword\\n    only parameter for provide own session storage\\n    implementation. If it is not provided, the in memory\\n    session storage will be used.\\n\\n    :param storage: A storage factory/constructor.\\n    :type storage: callable or class\\n    \"\"\"\\n\\n    if func is None:\\n        return functools.partial(wrap_session, storage=storage)\\n\\n    # Initialize the storage\\n    storage = storage()\\n\\n    def wrapper(request, *args, **kwargs):\\n        session_key = storage.get_session_key(request)\\n        request.session = storage.retrieve(request, session_key)\\n        response = func(request, *args, **kwargs)\\n\\n        storage.store(request, response, session_key, request.session)\\n        storage.persist_session_key(request, response, session_key)\\n        return response\\n\\n    return wrapper',\n",
       " 'def with_added_dimensions(self, n):\\n        \"\"\"\\n        Adds n dimensions and returns the Rect.  If n < 0, removes\\n        dimensions.\\n        \"\"\"\\n        if n > 0:\\n            return Rect(np.pad(self.data, ((0, 0), (0, n)), \\'constant\\'))\\n        return Rect(self.data[:, :self.dimensions + n])',\n",
       " 'def clamped(self, point_or_rect):\\n        \"\"\"\\n        Returns the point or rectangle clamped to this rectangle.\\n        \"\"\"\\n        if isinstance(point_or_rect, Rect):\\n            return Rect(np.minimum(self.mins, point_or_rect.mins),\\n                        np.maximum(self.maxes, point_or_rect.maxes))\\n        return np.clip(point_or_rect, self.mins, self.maxes)',\n",
       " 'def rectified(self):\\n        \"\"\"\\n        Fixes swaped min-max pairs.\\n        \"\"\"\\n        return Rect(np.minimum(self.mins, self.maxes),\\n                    np.maximum(self.maxes, self.mins))',\n",
       " 'def start(self, *args, **kwargs):#pylint:disable=unused-argument\\n        \"\"\"\\n        | Launch the SSE consumer.\\n        | It can listen forever for messages or just wait for one.\\n\\n        :param limit: If set, the consumer listens for a limited number of events.\\n        :type limit: int\\n        :param timeout: If set, the consumer listens for an event for a limited time.\\n        :type timeout: int\\n        :rtype: None\\n        \"\"\"\\n        limit = kwargs.get(\\'limit\\', None)\\n        timeout = kwargs.get(\\'timeout\\', None)\\n        self.run(limit=limit, timeout=timeout)',\n",
       " 'def phrase(min_size, max_size = None):\\n        \"\"\"\\n        Generates a random phrase which consists of few words separated by spaces.\\n        The first word is capitalized, others are not.\\n\\n        :param min_size: (optional) minimum string length.\\n\\n        :param max_size: maximum string length.\\n\\n        :return: a random phrase.\\n        \"\"\"\\n        max_size = max_size if max_size != None else min_size\\n        size = RandomInteger.next_integer(min_size, max_size)\\n        if size <= 0:\\n            return \"\"\\n        \\n        result = \"\"\\n        result += random.choice(_all_words)\\n        while len(result) < size:\\n            result += \" \" + random.choice(_all_words).lower()\\n\\n        return result',\n",
       " 'def words(min_size, max_size = None):\\n        \"\"\"\\n        Generates a random text that consists of random number of random words separated by spaces.\\n\\n        :param min_size: (optional) a minimum number of words.\\n\\n        :param max_size: a maximum number of words.\\n\\n        :return: a random text.\\n        \"\"\"\\n        max_size = max_size if max_size != None else min_size\\n        result = \"\"\\n        \\n        count = RandomInteger.next_integer(min_size, max_size)\\n        for i in range(count):\\n            result += random.choice(_all_words)\\n\\n        return result',\n",
       " 'def text(min_size, max_size):\\n        \"\"\"\\n        Generates a random text, consisting of first names, last names, colors, stuffs, adjectives, verbs,\\n        and punctuation marks.\\n\\n        :param min_size: minimum amount of words to generate. Text will contain \\'minSize\\' words if \\'maxSize\\' is omitted.\\n\\n        :param max_size: (optional) maximum amount of words to generate.\\n\\n        :return: a random text.\\n        \"\"\"\\n        max_size = max_size if max_size != None else min_size\\n        size = RandomInteger.next_integer(min_size, max_size)\\n\\n        result = \"\"\\n        result += random.choice(_all_words)\\n        \\n        while len(result) < size:\\n            next = random.choice(_all_words)\\n            if RandomBoolean.chance(4, 6):\\n                next = \" \" + next.lower()\\n            elif RandomBoolean.chance(2, 5):\\n                next = random.choice(\":,-\") + next.lower()\\n            elif RandomBoolean.chance(3, 5):\\n                next = random.choice(\":,-\") + \" \" + next.lower()\\n            else:\\n                next = random.choice(\".!?\") + \" \" + next\\n\\n            result += next\\n\\n        return result',\n",
       " 'def wrap_form_params(func):\\n    \"\"\"\\n    A middleware that parses the url-encoded body and attach\\n    the result to the request `form_params` attribute.\\n\\n    This middleware also merges the parsed value with the existing\\n    `params` attribute in same way as `wrap_query_params` is doing.\\n    \"\"\"\\n\\n    @functools.wraps(func)\\n    def wrapper(request, *args, **kwargs):\\n        ctype, pdict = parse_header(request.headers.get(\\'Content-Type\\', \\'\\'))\\n        if ctype == \"application/x-www-form-urlencoded\":\\n            params = {}\\n            for key, value in parse_qs(request.body.decode(\"utf-8\")).items():\\n                if len(value) == 1:\\n                    params[key] = value[0]\\n                else:\\n                    params[key] = value\\n\\n            request.params = merge_dicts(getattr(request, \"params\", None), params)\\n            request.form_params = params\\n        return func(request, *args, **kwargs)\\n    return wrapper',\n",
       " 'def wrap_query_params(func):\\n    \"\"\"\\n    A middleware that parses the urlencoded params from the querystring\\n    and attach it to the request `query_params` attribute.\\n\\n    This middleware also merges the parsed value with the existing\\n    `params` attribute in same way as `wrap_form_params` is doing.\\n    \"\"\"\\n\\n    @functools.wraps(func)\\n    def wrapper(request, *args, **kwargs):\\n        params = {}\\n        for key, value in parse_qs(request.query_string.decode(\"utf-8\")).items():\\n            if len(value) == 1:\\n                params[key] = value[0]\\n            else:\\n                params[key] = value\\n\\n        request.params = merge_dicts(getattr(request, \"params\", None), params)\\n        request.query_params = params\\n        return func(request, *args, **kwargs)\\n    return wrapper',\n",
       " 'def init_node(cls, *args, **kwargs):\\n    \"\"\"Initializes an ast node with the provided attributes.\\n    \\n    Python 2.6+ supports this in the node class initializers, but Python 2.5 \\n    does not, so this is intended to be an equivalent.\\n    \"\"\"\\n    node = cls()\\n    for name, value in zip(cls._fields, args):\\n        setattr(node, name, value)\\n    for name, value in kwargs:\\n        setattr(node, name, value)\\n    return node',\n",
       " 'def extract_the(node, node_type):\\n    \"\"\"Extracts the node of type node_type from the provided node.\\n    \\n    - If the node is itself of node_type, returns node.\\n    - If the node is a suite, it must contain exactly one node of the provided\\n      type in its body.\\n    \\n    \"\"\"\\n    if isinstance(node, node_type):\\n        return node\\n    try:\\n        body = node.body\\n    except AttributeError:\\n        raise cypy.Error(\\n            \"Expecting suite containing a single %s, or a %s, but got %s.\" %\\n            (node_type.__name__, node_type.__name__, type(node).__name__))\\n    \\n    if len(body) != 1 or not isinstance(body[0], node_type):\\n        raise cypy.Error(\\n            \"The body must contain exactly one node of type %s.\" %\\n            node_type.__name__)\\n    return body[0]',\n",
       " 'def get_version():\\n    \"\"\"Use git describe to get version from tag\"\"\"\\n    proc = subprocess.Popen(\\n        (\"git\", \"describe\", \"--tag\", \"--always\"), \\n        stdout=subprocess.PIPE, stderr=subprocess.STDOUT\\n    )\\n    output, _ = proc.communicate()\\n    result = output.decode(\"utf-8\").strip()\\n    if proc.returncode != 0:\\n        sys.stderr.write(\\n            \">>> Git Describe Error:\\\\n    \" +\\n            result\\n        )\\n        return \"1+unknown\"\\n    split = result.split(\"-\", 1)\\n    version = \"+\".join(split).replace(\"-\", \".\")\\n\\n    if len(split) > 1:\\n        sys.stderr.write(\\n            \">>> Please verify the commit tag:\\\\n    \" +\\n            version + \"\\\\n\"\\n        )\\n    return version',\n",
       " 'def get_file(fn):\\n    \"\"\"Returns file contents in unicode as list.\"\"\"\\n    fn = os.path.join(os.path.dirname(__file__), \\'data\\', fn)\\n    f = open(fn, \\'rb\\')\\n    lines = [line.decode(\\'utf-8\\').strip() for line in f.readlines()]\\n    return lines',\n",
       " 'def name_generator(names=None):\\n    \"\"\"Creates a generator for generating names.\\n\\n    :arg names:\\n\\n        list or tuple of names you want to use; defaults to ENGLISH_MONARCHS\\n\\n    :returns: generator for names\\n\\n    Example::\\n\\n        from eadred.helpers import name_generator\\n\\n        gen = name_generator()\\n        for i in range(50):\\n            mymodel = SomeModel(name=gen.next())\\n            mymodel.save()\\n\\n\\n    Example 2:\\n\\n    >>> gen = name_generator()\\n    >>> gen.next()\\n    u\\'James II\\'\\n    >>> gen.next()\\n    u\\'Stephen of Blois\\'\\n    >>> gen.next()\\n    u\\'James I\\'\\n\\n    .. Note::\\n\\n       This gives full names for a \"name\" field. It\\'s probably not\\n       useful for broken down name fields like \"firstname\",\\n       \"lastname\", etc.\\n\\n    \"\"\"\\n    if names is None:\\n        names = ENGLISH_MONARCHS\\n\\n    while True:\\n        yield text_type(random.choice(names))',\n",
       " 'def email_generator(names=None, domains=None, unique=False):\\n    \"\"\"Creates a generator for generating email addresses.\\n\\n    :arg names: list of names to use; defaults to ENGLISH_MONARCHS\\n        lowercased, ascii-fied, and stripped of whitespace\\n\\n    :arg domains: list of domains to use; defaults to DOMAINS\\n\\n    :arg unique: True if you want the username part of the email\\n        addresses to be unique\\n\\n    :returns: generator\\n\\n    Example::\\n\\n        from eadred.helpers import email_generator\\n\\n        gen = email_generator()\\n        for i in range(50):\\n            mymodel = SomeModel(email=gen.next())\\n            mymodel.save()\\n\\n\\n    Example 2:\\n\\n    >>> gen = email_generator()\\n    >>> gen.next()\\n    \\'eadwig@example.net\\'\\n    >>> gen.next()\\n    \\'henrybeauclerc@mail1.example.org\\'\\n    >>> gen.next()\\n    \\'williamrufus@example.com\\'\\n\\n    \"\"\"\\n    if names is None:\\n        names = [name.encode(\\'ascii\\', \\'ignore\\').lower().replace(b\\' \\', b\\'\\')\\n                 for name in ENGLISH_MONARCHS]\\n    if domains is None:\\n        domains = DOMAINS\\n\\n    if unique:\\n        uniquifyer = lambda: str(next(_unique_counter))\\n    else:\\n        uniquifyer = lambda: \\'\\'\\n\\n    while True:\\n        yield \\'{0}{1}@{2}\\'.format(\\n            random.choice(names), uniquifyer(), random.choice(domains))',\n",
       " 'def paragraph_generator(sentences=None):\\n    \"\"\"Creates a generator for generating paragraphs.\\n\\n    :arg sentences: list or tuple of sentences you want to use;\\n        defaults to LOREM\\n\\n    :returns: generator\\n\\n    Example::\\n\\n        from eadred.helpers import paragraph_generator\\n\\n        gen = paragraph_generator()\\n        for i in range(50):\\n            mymodel = SomeModel(description=gen.next())\\n            mymodel.save()\\n\\n    \"\"\"\\n    if sentences is None:\\n        sentences = LOREM\\n\\n    while True:\\n        # Paragraph consists of 1-7 sentences.\\n        paragraph = [random.choice(sentences)\\n                     for num in range(random.randint(1, 7))]\\n        yield u\\' \\'.join(paragraph)',\n",
       " 'def import_dotted_path(path):\\n    \"\"\"\\n    Takes a dotted path to a member name in a module, and returns\\n    the member after importing it.\\n    \"\"\"\\n    # stolen from Mezzanine (mezzanine.utils.importing.import_dotted_path)\\n    try:\\n        module_path, member_name = path.rsplit(\".\", 1)\\n        module = import_module(module_path)\\n        return getattr(module, member_name)\\n    except (ValueError, ImportError, AttributeError) as e:\\n        raise ImportError(\\'Could not import the name: {}: {}\\'.format(path, e))',\n",
       " 'def discoverAuthEndpoints(authDomain, content=None, look_in={\\'name\\': \\'link\\'}, test_urls=True, validateCerts=True, headers={}):\\n    \"\"\"Find the authorization or redirect_uri endpoints for the given authDomain.\\n    Only scan html element matching all criteria in look_in.\\n\\n    optionally the content to be scanned can be given as an argument.\\n\\n    :param authDomain: the URL of the domain to handle\\n    :param content: the content to be scanned for the authorization endpoint\\n    :param look_in: dictionary with name, id and class_. only element matching all of these will be scanned\\n    :param test_urls: optional flag to test URLs for validation\\n    :param validateCerts: optional flag to enforce HTTPS certificates if present\\n    :param headers: optional headers to send with any request\\n    :rtype: list of authorization endpoints\\n    \"\"\"\\n    if test_urls:\\n        ronkyuu.URLValidator(message=\\'invalid domain URL\\')(authDomain)\\n\\n    if content:\\n        result = {\\'status\\':   requests.codes.ok,\\n                  \\'headers\\':  None,\\n                  \\'content\\':  content\\n                  }\\n    else:\\n        r = requests.get(authDomain, verify=validateCerts, headers=headers)\\n        result = {\\'status\\':   r.status_code,\\n                  \\'headers\\':  r.headers\\n                  }\\n        # check for character encodings and use \\'correct\\' data\\n        if \\'charset\\' in r.headers.get(\\'content-type\\', \\'\\'):\\n            result[\\'content\\'] = r.text\\n        else:\\n            result[\\'content\\'] = r.content\\n\\n    result.update({\\'authorization_endpoint\\': set(), \\'redirect_uri\\': set(), \\'authDomain\\': authDomain})\\n\\n    if result[\\'status\\'] == requests.codes.ok:\\n        if \\'link\\' in r.headers:\\n            all_links = r.headers[\\'link\\'].split(\\',\\', 1)\\n\\n            for link in all_links:\\n                if \\';\\' in link:\\n                    link_parts = link.split(\\';\\')\\n                    for s in link_parts[1:]:\\n                        if \\'rel=\\' in s:\\n                            href = link_parts[0].strip()\\n                            rel  = s.strip().replace(\\'rel=\\', \\'\\').replace(\\'\"\\', \\'\\')\\n                            break\\n                    url = urlparse(href[1:-1])\\n\\n                    if url.scheme in (\\'http\\', \\'https\\') and rel in (\\'authorization_endpoint\\', \\'redirect_uri\\'):\\n                        result[rel].add(url)\\n\\n        all_links = BeautifulSoup(result[\\'content\\'], _html_parser, parse_only=SoupStrainer(**look_in)).find_all(\\'link\\')\\n        for link in all_links:\\n            rel = link.get(\\'rel\\', None)[0]\\n\\n            if rel in (\\'authorization_endpoint\\', \\'redirect_uri\\'):\\n                href = link.get(\\'href\\', None)\\n                if href:\\n                    url = urlparse(href)\\n\\n                    if url.scheme in (\\'http\\', \\'https\\'):\\n                        result[rel].add(url)\\n    return result',\n",
       " 'def validateAuthCode(code, redirect_uri, client_id, state=None, validationEndpoint=\\'https://indieauth.com/auth\\', headers={}):\\n    \"\"\"Call authorization endpoint to validate given auth code.\\n\\n    :param code: the auth code to validate\\n    :param redirect_uri: redirect_uri for the given auth code\\n    :param client_id: where to find the auth endpoint for the given auth code\\n    :param state: state for the given auth code\\n    :param validationEndpoint: URL to make the validation request at\\n    :param headers: optional headers to send with any request\\n    :rtype: True if auth code is valid\\n    \"\"\"\\n    payload = {\\'code\\':         code,\\n               \\'redirect_uri\\': redirect_uri,\\n               \\'client_id\\':    client_id,\\n              }\\n    if state is not None:\\n        payload[\\'state\\'] = state\\n\\n    authURL = None\\n    authEndpoints = discoverAuthEndpoints(client_id, headers=headers)\\n    for url in authEndpoints[\\'authorization_endpoint\\']:\\n        authURL = url\\n        break\\n    if authURL is not None:\\n        validationEndpoint = ParseResult(authURL.scheme, authURL.netloc, authURL.path, \\'\\', \\'\\', \\'\\').geturl()\\n\\n    r = requests.post(validationEndpoint, verify=True, data=payload, headers=headers)\\n    result = { \\'status\\':  r.status_code,\\n               \\'headers\\': r.headers\\n             }\\n    if \\'charset\\' in r.headers.get(\\'content-type\\', \\'\\'):\\n        result[\\'content\\'] = r.text\\n    else:\\n        result[\\'content\\'] = r.content\\n    if r.status_code == requests.codes.ok:\\n        result[\\'response\\'] = parse_qs(result[\\'content\\'])\\n\\n    return result',\n",
       " 'def get_params(url, ignore_empty=False):\\n        \"\"\"\\n        Static method that parses a given `url` and retrieves `url`\\'s parameters. Could also ignore empty value parameters.\\n        Handles parameters-only urls as `q=banana&peel=false`.\\n\\n        :param str url: url to parse\\n        :param bool ignore_empty: ignore empty value parameter or not\\n        :return: dictionary of params and their values\\n        :rtype: dict\\n        \"\"\"\\n        try:\\n            params_start_index = url.index(\\'?\\')\\n        except ValueError:\\n            params_start_index = 0\\n        params_string = url[params_start_index + 1:]\\n\\n        params_dict = {}\\n        for pair in params_string.split(\\'&\\'):\\n            if not pair:\\n                continue\\n            splitted = pair.split(\\'=\\')\\n            param, value = splitted\\n            if not value and ignore_empty:\\n                continue\\n            value = int(value) if value.isdigit() else value\\n            params_dict[param] = value\\n        return params_dict',\n",
       " 'def parse_date(table_data):\\n        \"\"\"\\n        Static method that parses a given table data element with `Url.DATE_STRPTIME_FORMAT` and creates a `date` object from td\\'s text contnet.\\n\\n        :param lxml.HtmlElement table_data: table_data tag to parse\\n        :return: date object from td\\'s text date\\n        :rtype: datetime.date\\n        \"\"\"\\n        text = table_data.text.split(\\'Added on \\')\\n        # Then it\\'s \\'Added today\\'. Hacky\\n        if len(text) < 2:\\n            return date.today()\\n        # Looks like [\\'\\', \\'Thursday, Mar 05, 2015\\']\\n        return datetime.strptime(text[1], Parser.DATE_STRPTIME_FORMAT).date()',\n",
       " 'def parse_first_row(row, url_instance):\\n        \"\"\"\\n        Static method that parses a given table row element by executing `Parser.FIRST_ROW_XPATH` and scrapping torrent\\'s\\n        id, title, tracked by status, category url and torrent url. Used specifically with a torrent\\'s first table row.\\n\\n        :param lxml.HtmlElement row: row to parse\\n        :param urls.Url url_instance: Url used to combine base url\\'s with scrapped links from tr\\n        :return: scrapped id, title, tracked by status, category url and torrent url\\n        :rtype: list\\n        \"\"\"\\n        tags = row.xpath(Parser.FIRST_ROW_XPATH)\\n        category_url = url_instance.combine(tags[0].get(\\'href\\'))\\n        title = unicode(tags[1].text)\\n        # work with the incomplete URL to get str_id\\n        torrent_url = tags[1].get(\\'href\\')\\n        str_id = torrent_url.split(\\'details/\\')[1]\\n        str_id = str_id[:-1] if str_id.endswith(\\'/\\') else str_id\\n        # complete the torrent URL with BASE_URL\\n        torrent_url = url_instance.combine(torrent_url)\\n\\n        # means that torrent has external property\\n        if len(tags) == 3:\\n            # monkey patch the missing external query param\\n            category_url += \\'&external=1\\'\\n            tracked_by = \\'(external)\\'\\n        else:\\n            tracked_by = \\'Demonoid\\'\\n        return [str_id, title, tracked_by, category_url, torrent_url]',\n",
       " 'def parse_second_row(row, url):\\n        \"\"\"\\n        Static method that parses a given table row element by using helper methods `Parser.parse_category_subcategory_and_or_quality`,\\n        `Parser.parse_torrent_link` and scrapping torrent\\'s category, subcategory, quality, language, user, user url, torrent link, size,\\n        comments, times completed, seeders and leechers. Used specifically with a torrent\\'s second table row.\\n\\n        :param lxml.HtmlElement row: row to parse\\n        :param urls.Url url_instance: Url used to combine base url\\'s with scrapped links from tr\\n        :return: scrapped category, subcategory, quality, language, user, user url, torrent link, size, comments, times completed,\\n         seeders and leechers\\n        :rtype: list\\n        \"\"\"\\n        tags = row.findall(\\'./td\\')\\n        category, subcategory, quality, language = Parser.parse_torrent_properties(tags[0])\\n        user_info = tags[1].find(\\'./a\\')\\n        user = user_info.text_content()\\n        user_url = url.combine(user_info.get(\\'href\\'))\\n\\n        # Two urls - one is spam, second is torrent url.\\n        # Don\\'t combine it with BASE_URL, since it\\'s an absolute url.\\n        torrent_link = Parser.parse_torrent_link(tags[2])\\n        size = tags[3].text  # as 10.5 GB\\n        comments = tags[4].text\\n        times_completed = tags[5].text\\n        seeders = tags[6].text\\n        leechers = tags[7].text\\n        return [category, subcategory, quality, language, user, user_url, torrent_link,\\n                size, comments, times_completed, seeders, leechers]',\n",
       " 'def parse_torrent_properties(table_datas):\\n        \"\"\"\\n        Static method that parses a given list of table data elements and using helper methods\\n        `Parser.is_subcategory`, `Parser.is_quality`, `Parser.is_language`, collects torrent properties.\\n\\n        :param list lxml.HtmlElement table_datas: table_datas to parse\\n        :return: identified category, subcategory, quality and languages.\\n        :rtype: dict\\n        \"\"\"\\n        output = {\\'category\\': table_datas[0].text, \\'subcategory\\': None, \\'quality\\': None, \\'language\\': None}\\n        for i in range(1, len(table_datas)):\\n            td = table_datas[i]\\n            url = td.get(\\'href\\')\\n            params = Parser.get_params(url)\\n            if Parser.is_subcategory(params) and not output[\\'subcategory\\']:\\n                output[\\'subcategory\\'] = td.text\\n            elif Parser.is_quality(params) and not output[\\'quality\\']:\\n                output[\\'quality\\'] = td.text\\n            elif Parser.is_language(params) and not output[\\'language\\']:\\n                output[\\'language\\'] = td.text\\n        return output',\n",
       " 'def parse_torrent_link(table_data):\\n        \"\"\"\\n        Static method that parses list of table data, finds all anchor elements\\n        and gets the torrent url. However the torrent url is usually hidden behind a fake spam ad url,\\n        this is handled.\\n\\n        :param list lxml.HtmlElement table_data: table_data tag to parse\\n        :return: torrent url from anchor (link) element\\n        :rtype: str\\n        \"\"\"\\n        anchors = table_data.findall(\\'./a\\')\\n        link_tag = anchors[0] if len(anchors) < 2 else anchors[1]\\n        return link_tag.get(\\'href\\')',\n",
       " 'def get(url, max_backoff=32, verbose=False, **kwargs):\\n    \"\"\"Adding retries to requests.get with exponential backoff.\\n\\n    Args:\\n        url (str): The URL to fetch\\n        max_backoff (int): The number of seconds to sleep at maximums\\n        verbose (bool): Whether to print exceptions.\\n\\n    Returns:\\n        Response: For successful requests return requests\\' response. `None` otherwise.\\n    \"\"\"\\n    sleep_seconds = 1\\n    while sleep_seconds <= max_backoff:\\n        try:\\n            # you may overwrite `timeout` via `kwargs`\\n            response = requests.get(url, **{**{\\'timeout\\': 30}, **kwargs})\\n            # for 4xx, return instantly, no hope of success\\n            if 400 <= response.status_code < 500:\\n                return None\\n            # successfully return 2XX and 3xx\\n            if 200 <= response.status_code < 400:\\n                return response\\n            # for 1xx and 5xx, retry\\n        except RequestException as e:\\n            if verbose:\\n                print(str(e))\\n\\n        time.sleep(sleep_seconds)\\n        sleep_seconds *= 2\\n    return None',\n",
       " 'def set_image(self):\\n        \"\"\"This code must be in its own method since the fetch functions need\\n        credits to be set. m2m fields are not yet set at the end of either the\\n        save method or post_save signal.\"\"\"\\n\\n        if not self.image:\\n            scrape_image(self)\\n\\n        # If still no image then use first contributor image\\n        if not self.image:\\n            contributors = self.get_primary_contributors()\\n            if contributors:\\n                self.image = contributors[0].image\\n                self.save(set_image=False)\\n\\n        # If still not image then default\\n        if not self.image:\\n            filename = settings.STATIC_ROOT + \\'music/images/default.png\\'\\n            if os.path.exists(filename):\\n                image = File(\\n                    open(filename, \\'rb\\')\\n                )\\n                image.name = \\'default.png\\'\\n                self.image = image\\n                self.save(set_image=False)',\n",
       " 'def configure_api(app):\\n    \"\"\"Configure API Endpoints.\\n    \"\"\"\\n    from heman.api.empowering import resources as empowering_resources\\n    from heman.api.cch import resources as cch_resources\\n    from heman.api.form import resources as form_resources\\n    from heman.api import ApiCatchall\\n\\n    # Add Empowering resources\\n    for resource in empowering_resources:\\n        api.add_resource(*resource)\\n\\n    # Add CCHFact resources\\n    for resource in cch_resources:\\n        api.add_resource(*resource)\\n\\n    # Add Form resources\\n    for resource in form_resources:\\n        api.add_resource(*resource)\\n\\n    api.add_resource(ApiCatchall, \\'/<path:path>\\')\\n    api.init_app(app)',\n",
       " 'def configure_login(app):\\n    \"\"\"Configure login authentification\\n\\n    Uses `Flask-Login <https://flask-login.readthedocs.org>`_\\n    \"\"\"\\n    from heman.auth import login_manager, login\\n    login_manager.init_app(app)\\n\\n    @app.teardown_request\\n    def force_logout(*args, **kwargs):\\n        login.logout_user()',\n",
       " 'def load_DragonDosBinary(self, data, strip_padding=True):\\n        \"\"\"\\n        Dragon DOS Binary Format\\n\\n        http://dragon32.info/info/binformt.html\\n\\n        Offset:  Type:   Value:\\n          0       byte    $55           Constant\\n          1       byte    Filetype\\n          2:3     word    Load Address\\n          4:5     word    Length\\n          6:7     word    Exec Address\\n          8       byte    $AA           Constant\\n          9-xxx   byte[]  Data\\n        \"\"\"\\n        data = bytearray(data)\\n\\n        log.debug(\"Load Dragon DOS Binary Format.\")\\n\\n        meta_data = struct.unpack(\">BBHHHB\", data[:9])\\n\\n        machine_type = meta_data[0]\\n        if machine_type != 0x55:\\n            log.error(\"ERROR: Machine type wrong: is $%02X but should be $55!\", machine_type)\\n\\n        self.file_type = meta_data[1]\\n        self.load_address = meta_data[2]\\n        self.length = meta_data[3]\\n        self.exec_address = meta_data[4]\\n        terminator = meta_data[5]\\n        if terminator != 0xAA:\\n            log.error(\"ERROR: Terminator byte is $%02X but should be $AA!\", terminator)\\n\\n        # print(\"before strip:\")\\n        # print(\"\\\\n\".join(bin2hexline(data, width=16)))\\n        if strip_padding:\\n            self.data = data[9:self.length + 9]\\n        else:\\n            self.data = data[9:]\\n        # print(\"after strip:\")\\n        # print(\"\\\\n\".join(bin2hexline(self.data, width=16)))\\n\\n        log.debug(\\n            \"File type: $%02X Load Address: $%04X Exec Address: $%04X Length: %iBytes\",\\n            self.file_type, self.load_address, self.exec_address, self.length\\n        )\\n        if self.length != len(self.data):\\n            log.error(\"ERROR: Wrong data size: should be: %i Bytes but is %i Bytes!\", self.length, len(self.data))\\n\\n        # log_bytes(self.data, \"data in hex: %s\", level=logging.DEBUG)\\n        self.debug2log(level=logging.DEBUG)',\n",
       " 'def rotatePoint(x, y, rotationDegrees, pivotx=0, pivoty=0):\\n    \"\"\"\\n    Rotates the point at `x` and `y` by `rotationDegrees`. The point is rotated\\n    around the origin by default, but can be rotated around another pivot point\\n    by specifying `pivotx` and `pivoty`.\\n\\n    The points are rotated counterclockwise.\\n\\n    Returns an x and y tuple.\\n\\n    Since the final result will be integers, there is a large amount of\\n    rounding error that can take place.\\n\\n    >>> rotatePoint(10, 0, 90)\\n    (0, 10)\\n    >>> rotatePoint(10, 0, 180)\\n    (-10, 0)\\n    >>> rotatePoint(10, 0, 45)\\n    (7, 7)\\n    \"\"\"\\n\\n    # Reuse the code in rotatePoints()\\n    return list(rotatePoints([(x, y)], rotationDegrees, pivotx, pivoty))[0]',\n",
       " 'def rotatePoints(points, rotationDegrees, pivotx=0, pivoty=0):\\n    \"\"\"\\n    Rotates each x and y tuple in `points`` by `rotationDegrees`. The points\\n    are rotated around the origin by default, but can be rotated around another\\n    pivot point by specifying `pivotx` and `pivoty`.\\n\\n    The points are rotated counterclockwise.\\n\\n    Returns a generator that produces an x and y tuple for each point in `points`.\\n\\n    >>> list(rotatePoints([(10, 0), (7, 7)], 45))\\n    [(7, 7), (0, 9)]\\n    \"\"\"\\n\\n    rotationRadians = math.radians(rotationDegrees % 360)\\n\\n    for x, y in points:\\n        _checkForIntOrFloat(x)\\n        _checkForIntOrFloat(y)\\n        x -= pivotx\\n        y -= pivoty\\n        x, y = x * math.cos(rotationRadians) - y * math.sin(rotationRadians), x * math.sin(rotationRadians) + y * math.cos(rotationRadians)\\n        x += pivotx\\n        y += pivoty\\n\\n        yield int(x), int(y)',\n",
       " 'def line(x1, y1, x2, y2, thickness=1, endcap=None, _skipFirst=False):\\n    \"\"\"\\n    Returns a generator that produces all of the points in a line between `x1`, `y1` and `x2`, `y2`.\\n\\n    (Note: The `thickness` and `endcap` parameters are not yet implemented.)\\n\\n    >>> list(line(0, 0, 10, 3))\\n    [(0, 0), (1, 0), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 2), (8, 2), (9, 3), (10, 3)]\\n    >>> drawPoints(line(0, 0, 20, 3))\\n    OOOO,,,,,,,,,,,,,,,,,\\n    ,,,,OOOOOOO,,,,,,,,,,\\n    ,,,,,,,,,,,OOOOOO,,,,\\n    ,,,,,,,,,,,,,,,,,OOOO\\n    \"\"\"\\n\\n    if (thickness != 1) or (endcap is not None):\\n        raise NotImplementedError(\\'The pybresenham module is under development and the filled and thickness parameters are not implemented. You can contribute at https://github.com/asweigart/pybresenham\\')\\n\\n    _checkForIntOrFloat(x1)\\n    _checkForIntOrFloat(y1)\\n    _checkForIntOrFloat(x2)\\n    _checkForIntOrFloat(y2)\\n    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # TODO - Do we want this line?\\n\\n    if not isinstance(_skipFirst, bool):\\n        raise PyBresenhamException(\\'_skipFirst argument must be a bool\\')\\n\\n    isSteep = abs(y2-y1) > abs(x2-x1)\\n    if isSteep:\\n        x1, y1 = y1, x1\\n        x2, y2 = y2, x2\\n    isReversed = x1 > x2\\n\\n    if isReversed:\\n        x1, x2 = x2, x1\\n        y1, y2 = y2, y1\\n\\n        deltax = x2 - x1\\n        deltay = abs(y2-y1)\\n        error = int(deltax / 2)\\n        y = y2\\n        ystep = None\\n        if y1 < y2:\\n            ystep = 1\\n        else:\\n            ystep = -1\\n        for x in range(x2, x1 - 1, -1):\\n            if isSteep:\\n                if not (_skipFirst and (x, y) == (x2, y2)):\\n                    yield (y, x)\\n            else:\\n                if not (_skipFirst and (x, y) == (x2, y2)):\\n                    yield (x, y)\\n            error -= deltay\\n            if error <= 0:\\n                y -= ystep\\n                error += deltax\\n    else:\\n        deltax = x2 - x1\\n        deltay = abs(y2-y1)\\n        error = int(deltax / 2)\\n        y = y1\\n        ystep = None\\n        if y1 < y2:\\n            ystep = 1\\n        else:\\n            ystep = -1\\n        for x in range(x1, x2 + 1):\\n            if isSteep:\\n                if not (_skipFirst and (x, y) == (x1, y1)):\\n                    yield (y, x)\\n            else:\\n                if not (_skipFirst and (x, y) == (x1, y1)):\\n                    yield (x, y)\\n            error -= deltay\\n            if error < 0:\\n                y += ystep\\n                error += deltax',\n",
       " 'def emit(self, record):\\n        \"\"\"Store the message, not only the record.\"\"\"\\n        self.records.append(Record(levelno=record.levelno, levelname=record.levelname,\\n                                   message=self.format(record)))\\n        return super(SetupLogChecker, self).emit(record)',\n",
       " 'def _check_generic_pos(self, *tokens):\\n        \"\"\"Check if the different tokens were logged in one record, any level.\"\"\"\\n        for record in self.records:\\n            if all(token in record.message for token in tokens):\\n                return\\n\\n        # didn\\'t exit, all tokens are not present in the same record\\n        msgs = [\"Tokens {} not found, all was logged is...\".format(tokens)]\\n        for record in self.records:\\n            msgs.append(\"    {:9s} {!r}\".format(record.levelname, record.message))\\n        self.test_instance.fail(\"\\\\n\".join(msgs))',\n",
       " 'def _check_pos(self, level, *tokens):\\n        \"\"\"Check if the different tokens were logged in one record, assert by level.\"\"\"\\n        for record in self.records:\\n            if all(record.levelno == level and token in record.message for token in tokens):\\n                return\\n\\n        # didn\\'t exit, all tokens are not present in the same record\\n        level_name = logging.getLevelName(level)\\n        msgs = [\"Tokens {} not found in {}, all was logged is...\".format(tokens, level_name)]\\n        for record in self.records:\\n            msgs.append(\"    {:9s} {!r}\".format(record.levelname, record.message))\\n        self.test_instance.fail(\"\\\\n\".join(msgs))',\n",
       " 'def _check_neg(self, level, *tokens):\\n        \"\"\"Check that the different tokens were NOT logged in one record, assert by level.\"\"\"\\n        for record in self.records:\\n            if level is not None and record.levelno != level:\\n                continue\\n            if all(token in record.message for token in tokens):\\n                break\\n        else:\\n            return\\n\\n        # didn\\'t exit, all tokens found in the same record\\n        msg = \"Tokens {} found in the following record:  {}  {!r}\".format(\\n            tokens, record.levelname, record.message)\\n        self.test_instance.fail(msg)',\n",
       " 'def get_consumers(self, _Consumer, channel):\\n        \"\"\"\\n        | ConsumerMixin requirement.\\n        | Get the consumers list.\\n\\n        :returns: All the consumers.\\n        :rtype: list.\\n        \"\"\"\\n        return [_Consumer(queues=[self.queue(channel)], callbacks=[self.main_callback], prefetch_count=self.prefetch_count)]',\n",
       " 'def start(self, *args, **kwargs):#pylint:disable=unused-argument\\n        \"\"\"\\n        | Launch the consumer.\\n        | It can listen forever for messages or just wait for one.\\n\\n        :param forever: If set, the consumer listens forever. Default to `True`.\\n        :type forever: bool\\n        :param timeout: If set, the consumer waits the specified seconds before quitting.\\n        :type timeout: None, int\\n        :rtype: None\\n        :raises socket.timeout: when no message has been received since `timeout`.\\n        \"\"\"\\n        forever = kwargs.get(\\'forever\\', True)\\n        timeout = kwargs.get(\\'timeout\\', None)\\n        if forever:\\n            return self.run(timeout=timeout)\\n        elif timeout:\\n            next((self.consume(timeout=timeout)), None)\\n        else:\\n            next((self.consume(limit=1, timeout=timeout)), None)',\n",
       " 'def modelserializer_factory(model, serializer=None, fields=None, exclude=None):\\n    \"\"\"\\n    Returns a ModelSerializer containing fields for the given model.\\n\\n    :param model: model class.\\n    :param fields: is an optional list of field names. If provided, only the named\\n    fields will be included in the returned fields. If omitted or \\'__all__\\', all\\n    fields will be used.\\n    :param exclude: is an optional list of field names. If provided, the named fields\\n    will be excluded from the returned fields, even if they are listed in the ``fields``\\n    argument.\\n    :return: ModelSerializer class\\n    \"\"\"\\n\\n    # default values\\n    serializer = serializer or serializers.ModelSerializer\\n\\n    attrs = {\\'model\\': model}\\n    if fields == \\'__all__\\':\\n        opts = model._meta.concrete_model._meta\\n        attrs[\\'fields\\'] = [field.name for field in opts.fields if field.serialize]\\n    elif fields is not None:\\n        attrs[\\'fields\\'] = fields\\n    if exclude is not None:\\n        attrs[\\'exclude\\'] = exclude\\n\\n    # create meta class\\n    parent = (object,)\\n    Meta = type(\\'Meta\\', parent, attrs)\\n\\n    # Give this new serializer class a reasonable name.\\n    class_name = model.__name__ + \\'Serializer\\'\\n\\n    # Class attributes for the new serializer class.\\n    serializer_class_attrs = {\\n        \\'Meta\\': Meta,\\n    }\\n    return type(serializer)(class_name, (serializer,), serializer_class_attrs)',\n",
       " 'def get_kube_path():\\n    \"\"\"Get the current config path. If the KUBECONFIG environment \\n    parameter is set, use it. If multiple paths are listed in \\n    KUBECONFIG, use the first path.\\n    \"\"\"\\n    try:\\n        path = pathlib.Path(os.environ[\"KUBECONFIG\"].split(\\':\\')[0])\\n    except KeyError:\\n        path = pathlib.Path.home().joinpath(\\'.kube\\', \\'config\\')\\n    return path',\n",
       " 'def open(self, create_if_not_found=True):\\n        \"\"\"Open a kube config file. If the file does not\\n        exist, it creates a new file.\\n        \"\"\"\\n        try:\\n            self.data = self._read()\\n        # If the file does\\n        except FileNotFoundError as e: \\n            if create_if_not_found is True:\\n                self.data = {}\\n            else: \\n                raise e\\n\\n        # Enforce the following keys exists in data.\\n        if \\'clusters\\' not in self.data:\\n            self.data[\\'clusters\\'] = []\\n        if \\'contexts\\' not in self.data:\\n            self.data[\\'clusters\\'] = []\\n        if \\'users\\' not in self.data:\\n            self.data[\\'users\\'] = []\\n        if \\'apiVersion\\' not in self.data:\\n            self.data[\\'apiVersion\\'] = \\'v1\\'\\n        if \\'kind\\' not in self.data:\\n            self.data[\\'kind\\'] = \\'Config\\'\\n        if \\'preferences\\' not in self.data:\\n            self.data[\\'preferences\\'] = {}\\n        if \\'current-context\\' not in self.data:\\n            self.data[\\'current-context\\'] = \\'\\'\\n\\n        return self',\n",
       " 'def _read(self):\\n        \"\"\"Read the kube config file. \\n        \"\"\"\\n        stream = self.path.read_text()\\n        data = yaml.load(stream)\\n        return data',\n",
       " 'def _write(self, data):\\n        \"\"\"Write data to config file.\"\"\"\\n        stream = yaml.dump(data, default_flow_style=False)\\n        self.path.write_text(stream)',\n",
       " 'def cluster_exists(self, name):\\n        \"\"\"Check if a given cluster exists.\"\"\"\\n        clusters = self.data[\\'clusters\\']\\n        for cluster in clusters:\\n            if cluster[\\'name\\'] == name:\\n                return True\\n        return False',\n",
       " 'def get_cluster(self, name):\\n        \"\"\"Get cluster from kubeconfig.\"\"\"\\n        clusters = self.data[\\'clusters\\']\\n        for cluster in clusters:\\n            if cluster[\\'name\\'] == name:\\n                return cluster\\n        raise KubeConfError(\"Cluster name not found.\")',\n",
       " 'def print_clusters(self, names=False):\\n        \"\"\"Print contexts.\"\"\"\\n        clusters = self.get_clusters()\\n        if names:\\n            clusters = [cluster[\\'name\\'] for cluster in clusters]\\n        pprint.pprint(clusters)',\n",
       " 'def add_cluster(\\n        self, \\n        name, \\n        server=None,\\n        certificate_authority_data=None,\\n        **attrs):\\n        \"\"\"Add a cluster to config.\"\"\"\\n        if self.cluster_exists(name):\\n            raise KubeConfError(\"Cluster with the given name already exists.\")\\n\\n        clusters = self.get_clusters()\\n        \\n        # Add parameters.\\n        new_cluster = {\\'name\\': name, \\'cluster\\':{}}\\n        attrs_ = new_cluster[\\'cluster\\']\\n        if server is not None:\\n            attrs_[\\'server\\'] = server\\n        if certificate_authority_data is not None:\\n            attrs_[\\'certificate-authority-data\\'] = certificate_authority_data\\n\\n        attrs_.update(attrs)\\n        clusters.append(new_cluster)',\n",
       " 'def add_to_cluster(self, name, **attrs):\\n        \"\"\"Add attributes to a cluster.\\n        \"\"\"\\n        cluster = self.get_cluster(name=name)\\n        attrs_ = cluster[\\'cluster\\']\\n        attrs_.update(**attrs)',\n",
       " 'def remove_from_cluster(self, name, *args):\\n        \"\"\"Remove attributes from a cluster.\\n        \"\"\"\\n        cluster = self.get_cluster(name=name)\\n        attrs_ = cluster[\\'cluster\\']\\n        for a in args:\\n            del attrs_[a]',\n",
       " 'def remove_cluster(self, name):\\n        \"\"\"Remove a cluster from kubeconfig.\\n        \"\"\"\\n        cluster = self.get_cluster(name)\\n        clusters = self.get_clusters()\\n        clusters.remove(cluster)',\n",
       " 'def user_exists(self, name):\\n        \"\"\"Check if a given user exists.\"\"\"\\n        users = self.data[\\'users\\']\\n        for user in users:\\n            if user[\\'name\\'] == name:\\n                return True\\n        return False',\n",
       " 'def get_user(self, name):\\n        \"\"\"Get user from kubeconfig.\"\"\"\\n        users = self.data[\\'users\\']\\n        for user in users:\\n            if user[\\'name\\'] == name:\\n                return user\\n        raise KubeConfError(\"user name not found.\")',\n",
       " 'def add_user(\\n        self,\\n        name, \\n        **attrs\\n        ):\\n        \"\"\"Add a user to config.\"\"\"\\n        if self.user_exists(name):\\n            raise KubeConfError(\"user with the given name already exists.\")\\n\\n        users = self.get_users()\\n        \\n        # Add parameters.\\n        new_user = {\\'name\\': name, \\'user\\':{}}\\n        attrs_ = new_user[\\'user\\']\\n        attrs_.update(attrs)\\n        users.append(new_user)',\n",
       " 'def add_to_user(self, name, **attrs):\\n        \"\"\"Add attributes to a user.\\n        \"\"\"\\n        user = self.get_user(name=name)\\n        attrs_ = user[\\'user\\']\\n        attrs_.update(**attrs)',\n",
       " 'def remove_from_user(self, name, *args):\\n        \"\"\"Remove attributes from a user.\\n        \"\"\"\\n        user = self.get_user(name=name)\\n        attrs_ = user[\\'user\\']\\n        for a in args:\\n            del attrs_[a]',\n",
       " 'def remove_user(self, name):\\n        \"\"\"Remove a user from kubeconfig.\\n        \"\"\"\\n        user = self.get_user(name)\\n        users = self.get_users()\\n        users.remove(user)',\n",
       " 'def add_exec_to_user(\\n        self, \\n        name,\\n        env,\\n        command,\\n        args,\\n        **attrs\\n        ):\\n        \"\"\"Add an exec option to your user.\"\"\"\\n        # Add exec option.\\n        exec_options = {\\n            \\'command\\': command,\\n            \\'env\\': env,\\n            \\'args\\': args,\\n        }\\n        exec_options.update(attrs)\\n        # Add exec to user.\\n        self.add_to_user(name=name, exec=exec_options)',\n",
       " 'def context_exists(self, name):\\n        \"\"\"Check if a given context exists.\"\"\"\\n        contexts = self.data[\\'contexts\\']\\n        for context in contexts:\\n            if context[\\'name\\'] == name:\\n                return True\\n        return False',\n",
       " 'def get_context(self, name):\\n        \"\"\"Get context from kubeconfig.\"\"\"\\n        contexts = self.data[\\'contexts\\']\\n        for context in contexts:\\n            if context[\\'name\\'] == name:\\n                return context\\n        raise KubeConfError(\"context name not found.\")',\n",
       " 'def add_context(\\n        self,\\n        name,\\n        cluster_name=None,\\n        user_name=None,\\n        namespace_name=None,\\n        **attrs\\n        ):\\n        \"\"\"Add a context to config.\"\"\"\\n        if self.context_exists(name):\\n            raise KubeConfError(\"context with the given name already exists.\")\\n\\n        contexts = self.get_contexts()\\n        \\n        # Add parameters.\\n        new_context = {\\'name\\': name, \\'context\\':{}}\\n        \\n        # Add attributes\\n        attrs_ = new_context[\\'context\\']\\n        if cluster_name is not None:\\n            attrs_[\\'cluster\\'] = cluster_name\\n        if user_name is not None:\\n            attrs_[\\'user\\'] = user_name\\n        if namespace_name is not None:\\n            attrs_[\\'namespace\\'] = namespace_name\\n        attrs_.update(attrs)\\n\\n        contexts.append(new_context)',\n",
       " 'def add_to_context(self, name, **attrs):\\n        \"\"\"Add attributes to a context.\\n        \"\"\"\\n        context = self.get_context(name=name)\\n        attrs_ = context[\\'context\\']\\n        attrs_.update(**attrs)',\n",
       " 'def remove_from_context(self, name, *args):\\n        \"\"\"Remove attributes from a context.\\n        \"\"\"\\n        context = self.get_context(name=name)\\n        attrs_ = context[\\'context\\']\\n        for a in args:\\n            del attrs_[a]',\n",
       " 'def remove_context(self, name):\\n        \"\"\"Remove a context from kubeconfig.\\n        \"\"\"\\n        context = self.get_context(name)\\n        contexts = self.get_contexts()\\n        contexts.remove(context)',\n",
       " 'def set_current_context(self, name):\\n        \"\"\"Set the current context in kubeconfig.\"\"\"\\n        if self.context_exists(name):\\n            self.data[\\'current-context\\'] = name\\n        else:\\n            raise KubeConfError(\"Context does not exist.\")',\n",
       " 'def configure_logging(self, verbosity_lvl=None, format=\\'%(message)s\\'):\\n        \"\"\"Switches on logging at a given level.\\n\\n        :param verbosity_lvl:\\n        :param format:\\n\\n        \"\"\"\\n        if not verbosity_lvl:\\n            verbosity_lvl = logging.INFO\\n        logging.basicConfig(format=format)\\n        self.logger.setLevel(verbosity_lvl)',\n",
       " 'def _run_shell_command(self, command, pipe_it=True):\\n        \"\"\"Runs the given shell command.\\n\\n        :param command:\\n        :return: bool Status\\n        \"\"\"\\n        stdout = None\\n        if pipe_it:\\n            stdout = PIPE\\n        self.logger.debug(\\'Executing shell command: %s\\' % command)\\n        return not bool(Popen(command, shell=True, stdout=stdout).wait())',\n",
       " 'def run_manage_command(self, command, venv_path, verbose=True):\\n        \"\"\"Runs a given Django manage command in a given virtual environment.\\n\\n        :param str command:\\n        :param str venv_path:\\n        :param bool verbose:\\n        \"\"\"\\n        self.logger.debug(\\'Running manage command `%s` for `%s` ...\\' % (command, venv_path))\\n        self._run_shell_command(\\n            \\'. %s/bin/activate && python %s %s\\' % (venv_path, self._get_manage_py_path(), command),\\n            pipe_it=(not verbose))',\n",
       " 'def venv_install(self, package_name, venv_path):\\n        \"\"\"Installs a given python package into a given virtual environment.\\n\\n        :param str package_name:\\n        :param str venv_path:\\n        \"\"\"\\n        self.logger.debug(\\'Installing `%s` into `%s` ...\\' % (package_name, venv_path))\\n        self._run_shell_command(\\'. %s/bin/activate && pip install -U %s\\' % (venv_path, package_name))',\n",
       " 'def make_venv(self, dj_version):\\n        \"\"\"Creates a virtual environment for a given Django version.\\n\\n        :param str dj_version:\\n        :rtype: str\\n        :return: path to created virtual env\\n        \"\"\"\\n        venv_path = self._get_venv_path(dj_version)\\n        self.logger.info(\\'Creating virtual environment for Django %s ...\\' % dj_version)\\n        try:\\n            create_venv(venv_path, **VENV_CREATE_KWARGS)\\n        except ValueError:\\n            self.logger.warning(\\'Virtual environment directory already exists. Skipped.\\')\\n        self.venv_install(\\'django==%s\\' % dj_version, venv_path)\\n        return venv_path',\n",
       " 'def make_apps_dir(self):\\n        \"\"\"Creates an empty directory for symlinks to Django applications.\\n\\n        :rtype: str\\n        :return: created directory path\\n        \"\"\"\\n        self.logger.info(\\'Creating a directory for symlinks to your Django applications `%s` ...\\' % self.apps_path)\\n        try:\\n            os.mkdir(self.apps_path)\\n        except OSError:\\n            pass  # Already exists.\\n        return self.apps_path',\n",
       " 'def dispatch_op(self, op_name, args_dict):\\n        \"\"\"Dispatches an operation requested.\\n\\n        :param str op_name:\\n        :param dict args_dict:\\n        \"\"\"\\n        self.logger.debug(\\'Requested `%s` command with `%s` args.\\' % (op_name, args_dict))\\n        method = getattr(self, \\'op_%s\\' % op_name, None)\\n        if method is None:\\n            error_str = \\'`%s` command is not supported.\\' % op_name\\n            self.logger.error(error_str)\\n            raise DjangoDevException(error_str)\\n        method(**args_dict)\\n        self.logger.info(\\'Done.\\')',\n",
       " 'def get_venvs(self):\\n        \"\"\"Returns a list of names of available virtual environments.\\n\\n        :raises: DjangoDevException on errors\\n        :rtype: list\\n        :return: list of names\\n        \"\"\"\\n\\n        def raise_():\\n            error_str = \\'Virtual environments are not created. Please run `bootstrap` command.\\'\\n            self.logger.error(error_str)\\n            raise DjangoDevException(error_str)\\n\\n        if not os.path.exists(self.venvs_path):\\n            raise_()\\n        venvs = os.listdir(self.venvs_path)\\n        if not venvs:\\n            raise_()\\n\\n        venvs.sort()\\n        return venvs',\n",
       " 'def get_apps(self, only=None):\\n        \"\"\"Returns a list of names of available Django applications,\\n        Optionally filters it using `only`.\\n\\n        :param list|None only: a list on apps names to to filter all available apps against\\n        :raises: DjangoDevException on errors\\n        :rtype: list\\n        :return: list of apps names\\n        \"\"\"\\n        if not os.path.exists(self.apps_path):\\n            error_str = \\'It seems that this directory does not contain django-dev project. \\' \\\\\\n                        \\'Use `bootstrap` command to create project in the current directory.\\'\\n            self.logger.error(error_str)\\n            raise DjangoDevException(error_str)\\n\\n        apps = os.listdir(self.apps_path)\\n\\n        if not apps:\\n            error_str = \\'Applications directory is empty. \\' \\\\\\n                        \\'Please symlink your apps (and other apps that you apps depend upon) into %s\\' % self.apps_path\\n            self.logger.error(error_str)\\n            raise DjangoDevException(error_str)\\n\\n        apps.sort()\\n        if only is None:\\n            self.create_manage_py(apps)\\n            return apps\\n\\n        diff = set(only).difference(apps)\\n        if diff:\\n            error_str = \\'The following apps are not found: `%s`.\\' % (\\'`, `\\'.join(diff))\\n            self.logger.error(error_str)\\n            raise DjangoDevException(error_str)\\n\\n        self.create_manage_py(apps)\\n\\n        return [name for name in apps if name in only]',\n",
       " 'def create_manage_py(self, apps):\\n        \"\"\"Creates manage.py file, with a given list of installed apps.\\n\\n        :param list apps:\\n        \"\"\"\\n        self.logger.debug(\\'Creating manage.py ...\\')\\n        with open(self._get_manage_py_path(), mode=\\'w\\') as f:\\n            south_migration_modules = []\\n            for app in apps:\\n                south_migration_modules.append(\"\\'%(app)s\\': \\'%(app)s.south_migrations\\'\" % {\\'app\\': app})\\n\\n            f.write(MANAGE_PY % {\\n                \\'apps_available\\': \"\\', \\'\".join(apps),\\n                \\'apps_path\\': self.apps_path,\\n                \\'south_migration_modules\\': \", \".join(south_migration_modules)\\n\\n\\n            })',\n",
       " 'def op_list_venvs(self):\\n        \"\"\"Prints out and returns a list of known virtual environments.\\n\\n        :rtype: list\\n        :return: list of virtual environments\\n        \"\"\"\\n        self.logger.info(\\'Listing known virtual environments ...\\')\\n        venvs = self.get_venvs()\\n        for venv in venvs:\\n            self.logger.info(\\'Found `%s`\\' % venv)\\n        else:\\n            self.logger.info(\\'No virtual environments found in `%s` directory.\\' % VENVS_DIRNAME)\\n        return venvs',\n",
       " 'def op_list_apps(self):\\n        \"\"\"Prints out and returns a list of known applications.\\n\\n        :rtype: list\\n        :return: list of applications\\n        \"\"\"\\n        self.logger.info(\\'Listing known applications ...\\')\\n        apps = self.get_apps()\\n        for app in apps:\\n            self.logger.info(\\'Found `%s`\\' % app)\\n        else:\\n            self.logger.info(\\'\\\\nDONE. No applications found in `%s` directory.\\\\n\\' % APPS_DIRNAME)\\n        return apps',\n",
       " 'def op_bootstrap(self):\\n        \"\"\"Bootstraps django-dev by creating required directory structure.\"\"\"\\n        self.logger.info(\\'Bootstrapping django-dev directory structure in current directory ...\\')\\n        self.make_venv(DJANGO_DEFAULT_VERSION)\\n        venv_path = self.make_venv(\\'1.6.5\\')\\n        self.venv_install(\\'south==1.0.1\\', venv_path)\\n        apps_dir = self.make_apps_dir()\\n        self.logger.info(\\'Now you may symlink (ln -s) your apps \\'\\n                         \\'(and other apps that you apps depend upon) into %s\\' % apps_dir)',\n",
       " 'def op_install_package(self, names):\\n        \"\"\"Install packages into virtual envs as to satisfy app requirements.\\n\\n        Exact version numbers could be given as in PIP: somedep==1.5\\n\\n        :param list names:\\n\\n        \"\"\"\\n        venvs = self.get_venvs()\\n        for venv in venvs:\\n            for name in names:\\n                self.venv_install(name, self._get_venv_path(venv))',\n",
       " 'def to_sint(self):\\n        \"\"\"Converts the word to a BinInt, treating it as a signed number.\"\"\"\\n        if self._width == 0:\\n            return BinInt(0)\\n        sbit = 1 << (self._width - 1)\\n        return BinInt((self._val - sbit) ^ -sbit)',\n",
       " 'def sar(self, count):\\n        \"\"\"Performs an arithmetic right-shift of a BinWord by the given number\\n        of bits.  Bits shifted out of the word are lost.  The word is\\n        filled on the left with copies of the top bit.\\n\\n        The shift count can be an arbitrary non-negative number, including\\n        counts larger than the word (a word filled with copies of the sign bit\\n        is returned in this case).\\n        \"\"\"\\n        count = operator.index(count)\\n        if count < 0:\\n            raise ValueError(\\'negative shift\\')\\n        if count > self._width:\\n            count = self._width\\n        return BinWord(self._width, self.to_sint() >> count, trunc=True)',\n",
       " 'def slt(self, other):\\n        \"\"\"Compares two equal-sized BinWords, treating them as signed\\n        integers, and returning True if the first is smaller.\\n        \"\"\"\\n        self._check_match(other)\\n        return self.to_sint() < other.to_sint()',\n",
       " 'def sle(self, other):\\n        \"\"\"Compares two equal-sized BinWords, treating them as signed\\n        integers, and returning True if the first is smaller or equal.\\n        \"\"\"\\n        self._check_match(other)\\n        return self.to_sint() <= other.to_sint()',\n",
       " 'def sgt(self, other):\\n        \"\"\"Compares two equal-sized BinWords, treating them as signed\\n        integers, and returning True if the first is bigger.\\n        \"\"\"\\n        self._check_match(other)\\n        return self.to_sint() > other.to_sint()',\n",
       " 'def sge(self, other):\\n        \"\"\"Compares two equal-sized BinWords, treating them as signed\\n        integers, and returning True if the first is bigger or equal.\\n        \"\"\"\\n        self._check_match(other)\\n        return self.to_sint() >= other.to_sint()',\n",
       " 'def concat(cls, *args):\\n        \"\"\"Returns a BinWord made from concatenating several BinWords,\\n        in LSB-first order.\\n        \"\"\"\\n        width = 0\\n        val = 0\\n        for arg in args:\\n            if not isinstance(arg, BinWord):\\n                raise TypeError(\\'need BinWord in concat\\')\\n            val |= arg._val << width\\n            width += arg._width\\n        return cls(width, val)',\n",
       " 'def get_sort_function(order):\\n    \"\"\"\\n    Returns a callable similar to the built-in `cmp`, to be used on objects.\\n\\n    Takes a list of dictionaries. In each, \\'key\\' must be a string that is\\n    used to get an attribute of the objects to compare, and \\'reverse\\' must\\n    be a boolean indicating whether the result should be reversed.\\n    \"\"\"\\n    stable = tuple((d[\\'key\\'], -1 if d[\\'reverse\\'] else 1) for d in order)\\n    def sort_function(a, b):\\n        for name, direction in stable:\\n            v = cmp(getattr(a, name) if a else a, getattr(b, name) if b else b)\\n            if v != 0:\\n                return v * direction\\n        return 0\\n    return sort_function',\n",
       " 'def get_order(self):\\n        \"\"\"\\n        Return a list of dicionaries. See `set_order`.\\n        \"\"\"\\n        return [dict(reverse=r[0], key=r[1]) for r in self.get_model()]',\n",
       " 'def allow_headers(self, domain, headers, secure=True):\\n        \"\"\"\\n        Allows ``domain`` to push data via the HTTP headers named in\\n        ``headers``.\\n\\n        As with ``allow_domain``, ``domain`` may be either a full\\n        domain name or a wildcard. Again, use of wildcards is\\n        discouraged for security reasons.\\n\\n        The value for ``headers`` should be a list of header names.\\n\\n        To disable Flash\\'s requirement of security matching (e.g.,\\n        retrieving a policy via HTTPS will require that SWFs also be\\n        retrieved via HTTPS), pass ``secure=False``. Due to security\\n        concerns, it is strongly recommended that you not disable\\n        this.\\n\\n        \"\"\"\\n        if self.site_control == SITE_CONTROL_NONE:\\n            raise TypeError(\\n                METAPOLICY_ERROR.format(\"allow headers from a domain\")\\n            )\\n        self.header_domains[domain] = {\\'headers\\': headers,\\n                                       \\'secure\\': secure}',\n",
       " 'def allow_identity(self, fingerprint):\\n        \"\"\"\\n        Allows access from documents digitally signed by the key with\\n        ``fingerprint``.\\n\\n        In theory, multiple algorithms can be added in the future for\\n        calculating ``fingerprint`` from the signing key, but at this\\n        time only one algorithm -- SHA-1 -- is supported by the\\n        cross-domain policy specification.\\n\\n        \"\"\"\\n        if self.site_control == SITE_CONTROL_NONE:\\n            raise TypeError(\\n                METAPOLICY_ERROR.format(\"allow access from signed documents\")\\n            )\\n        if fingerprint not in self.identities:\\n            self.identities.append(fingerprint)',\n",
       " 'def _add_domains_xml(self, document):\\n        \"\"\"\\n        Generates the XML elements for allowed domains.\\n\\n        \"\"\"\\n        for domain, attrs in self.domains.items():\\n            domain_element = document.createElement(\\'allow-access-from\\')\\n            domain_element.setAttribute(\\'domain\\', domain)\\n            if attrs[\\'to_ports\\'] is not None:\\n                domain_element.setAttribute(\\n                    \\'to-ports\\',\\n                    \\',\\'.join(attrs[\\'to_ports\\'])\\n                )\\n            if not attrs[\\'secure\\']:\\n                domain_element.setAttribute(\\'secure\\', \\'false\\')\\n            document.documentElement.appendChild(domain_element)',\n",
       " 'def _add_header_domains_xml(self, document):\\n        \"\"\"\\n        Generates the XML elements for allowed header domains.\\n\\n        \"\"\"\\n        for domain, attrs in self.header_domains.items():\\n            header_element = document.createElement(\\n                \\'allow-http-request-headers-from\\'\\n            )\\n            header_element.setAttribute(\\'domain\\', domain)\\n            header_element.setAttribute(\\'headers\\', \\',\\'.join(attrs[\\'headers\\']))\\n            if not attrs[\\'secure\\']:\\n                header_element.setAttribute(\\'secure\\', \\'false\\')\\n            document.documentElement.appendChild(header_element)',\n",
       " 'def _add_identities_xml(self, document):\\n        \"\"\"\\n        Generates the XML elements for allowed digital signatures.\\n\\n        \"\"\"\\n        for fingerprint in self.identities:\\n            identity_element = document.createElement(\\n                \\'allow-access-from-identity\\'\\n            )\\n            signatory_element = document.createElement(\\n                \\'signatory\\'\\n            )\\n            certificate_element = document.createElement(\\n                \\'certificate\\'\\n            )\\n            certificate_element.setAttribute(\\n                \\'fingerprint\\',\\n                fingerprint)\\n            certificate_element.setAttribute(\\n                \\'fingerprint-algorithm\\',\\n                \\'sha-1\\')\\n            signatory_element.appendChild(certificate_element)\\n            identity_element.appendChild(signatory_element)\\n            document.documentElement.appendChild(identity_element)',\n",
       " 'def _get_xml_dom(self):\\n        \"\"\"\\n        Collects all options set so far, and produce and return an\\n        ``xml.dom.minidom.Document`` representing the corresponding\\n        XML.\\n\\n        \"\"\"\\n        if self.site_control == SITE_CONTROL_NONE and \\\\\\n           any((self.domains, self.header_domains, self.identities)):\\n            raise TypeError(BAD_POLICY)\\n\\n        policy_type = minidom.createDocumentType(\\n            qualifiedName=\\'cross-domain-policy\\',\\n            publicId=None,\\n            systemId=\\'http://www.adobe.com/xml/dtds/cross-domain-policy.dtd\\'\\n        )\\n        policy = minidom.createDocument(\\n            None,\\n            \\'cross-domain-policy\\',\\n            policy_type\\n        )\\n\\n        if self.site_control is not None:\\n            control_element = policy.createElement(\\'site-control\\')\\n            control_element.setAttribute(\\n                \\'permitted-cross-domain-policies\\',\\n                self.site_control\\n            )\\n            policy.documentElement.appendChild(control_element)\\n\\n        for elem_type in (\\'domains\\', \\'header_domains\\', \\'identities\\'):\\n            getattr(self, \\'_add_{}_xml\\'.format(elem_type))(policy)\\n\\n        return policy',\n",
       " \"def build_callbacks(self):\\n        '''Eventually, this should be configured, rather than hardcoded'''\\n        # checkpoint\\n        filepath = os.path.join(CHECKPOINT_DIR, 'weights.best.hdf5')\\n        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\\n                                \\n                                \\n        self.callbacks = [checkpoint]\",\n",
       " 'def reverse_with_query(named_url,**kwargs):\\n    \"Reverse named URL with GET query\"\\n    q = QueryDict(\\'\\',mutable=True)\\n    q.update(kwargs)\\n    return \\'{}?{}\\'.format(reverse(named_url),q.urlencode())',\n",
       " 'def can_undo(self):\\n        \"\"\"\\n        Are there actions to undo?\\n        \"\"\"\\n        return bool(self._undo) or bool(self._open and self._open[0])',\n",
       " 'def end_grouping(self):\\n        \"\"\"\\n        Raises IndexError when no group is open.\\n        \"\"\"\\n        close = self._open.pop()\\n        if not close:\\n            return\\n        if self._open:\\n            self._open[-1].extend(close)\\n        elif self._undoing:\\n            self._redo.append(close)\\n        else:\\n            self._undo.append(close)\\n        self.notify()',\n",
       " 'def redo(self):\\n        \"\"\"\\n        Performs the top group on the redo stack, if present. Creates an undo\\n        group with the same name. Raises RuntimeError if called while undoing.\\n        \"\"\"\\n        if self._undoing or self._redoing:\\n            raise RuntimeError\\n        if not self._redo:\\n            return\\n        group = self._redo.pop()\\n\\n        self._redoing = True\\n\\n        self.begin_grouping()\\n        group.perform()\\n        self.set_action_name(group.name)\\n        self.end_grouping()\\n\\n        self._redoing = False\\n\\n        self.notify()',\n",
       " 'def register(self, func, *args, **kwargs):\\n        \"\"\"\\n        Record an undo operation. Also clears the redo stack. Raises IndexError\\n        when no group is open.\\n        \"\"\"\\n        self._open[-1].append(UndoOperation(func, *args, **kwargs))\\n        if not (self._undoing or self._redoing):\\n            self._redo = []\\n        self.notify()',\n",
       " 'def set_action_name(self, name):\\n        \"\"\"\\n        Set the name of the top group, if present.\\n        \"\"\"\\n        if self._open and name is not None:\\n            self._open[-1].name = name\\n            self.notify()',\n",
       " 'def undo(self):\\n        \"\"\"\\n        Raises IndexError if more than one group is open, otherwise closes it\\n        and invokes undo_nested_group.\\n        \"\"\"\\n        if self.grouping_level() == 1:\\n            self.end_grouping()\\n        if self._open:\\n            raise IndexError\\n        self.undo_nested_group()\\n        self.notify()',\n",
       " 'def undo_action_name(self):\\n        \"\"\"\\n        The name of the top group on the undo stack, or an empty string.\\n        \"\"\"\\n        if self._open:\\n            return self._open[-1].name\\n        elif self._undo:\\n            return self._undo[-1].name\\n        return \"\"',\n",
       " 'def undo_nested_group(self):\\n        \"\"\"\\n        Performs the last group opened, or the top group on the undo stack.\\n        Creates a redo group with the same name.\\n        \"\"\"\\n        if self._undoing or self._redoing:\\n            raise RuntimeError\\n        if self._open:\\n            group = self._open.pop()\\n        elif self._undo:\\n            group = self._undo.pop()\\n        else:\\n            return\\n\\n        self._undoing = True\\n\\n        self.begin_grouping()\\n        group.perform()\\n        self.set_action_name(group.name)\\n        self.end_grouping()\\n\\n        self._undoing = False\\n\\n        self.notify()',\n",
       " \"def dispatch(*funcs):\\n    '''Iterates through the functions\\n    and calls them with given the parameters\\n    and returns the first non-empty result\\n\\n    >>> f = dispatch(lambda: None, lambda: 1)\\n    >>> f()\\n    1\\n\\n    :param \\\\*funcs: funcs list of dispatched functions\\n    :returns: dispatch functoin\\n    '''\\n\\n    def _dispatch(*args, **kwargs):\\n        for f in funcs:\\n            result = f(*args, **kwargs)\\n            if result is not None:\\n                return result\\n        return None\\n\\n    return _dispatch\",\n",
       " 'def preproc_directive(self) -> bool:\\n    \"\"\"Consume a preproc directive.\"\"\"\\n    self._stream.save_context()\\n    if self.read_until(\"\\\\n\", \\'\\\\\\\\\\'):\\n        return self._stream.validate_context()\\n    return self._stream.restore_context()',\n",
       " 'def connect(workbench):\\n    \"\"\"Connection inititalization routine.\\n\\n    \"\"\"\\n    d = _getContextFactory(getDataPath(), workbench)\\n    d.addCallback(_connectWithContextFactory, workbench)\\n    return d',\n",
       " 'def _connectWithContextFactory(ctxFactory, workbench):\\n    \"\"\"Connect using the given context factory. Notifications go to the\\n    given workbench.\\n\\n    \"\"\"\\n    endpoint = SSL4ClientEndpoint(reactor, \"localhost\", 4430, ctxFactory)\\n\\n    splash = _Splash(u\"Connecting\", u\"Connecting...\")\\n    workbench.display(splash)\\n\\n    d = endpoint.connect(Factory(workbench))\\n\\n    @d.addBoth\\n    def closeSplash(returnValue):\\n        workbench.undisplay()\\n        return returnValue\\n\\n    @d.addErrback\\n    def notifyFailure(f):\\n        f.trap(ConnectError)\\n        d = alert(workbench, u\"Couldn\\'t connect\", u\"Connection failed! \"\\n                  \"Check internet connection, or try again later.\\\\n\"\\n                  \"Error: {!r}\".format(f.value))\\n        return d.addCallback(lambda _result: reactor.stop())\\n\\n    return d',\n",
       " 'def _getContextFactory(path, workbench):\\n    \"\"\"Get a context factory.\\n\\n    If the client already has a credentials at path, use them.\\n    Otherwise, generate them at path. Notifications are reported to\\n    the given workbench.\\n\\n    \"\"\"\\n    try:\\n        return succeed(getContextFactory(path))\\n    except IOError:\\n        d = prompt(workbench, u\"E-mail entry\", u\"Enter e-mail:\")\\n        d.addCallback(_makeCredentials, path, workbench)\\n        d.addCallback(lambda _result: getContextFactory(path))\\n        return d',\n",
       " 'def _makeCredentials(email, path, workbench):\\n    \"\"\"Makes client certs and writes them to disk at path.\\n\\n    This essentially defers to clarent\\'s ``makeCredentials`` function,\\n    except it also shows a nice splash screen.\\n\\n    \"\"\"\\n    splash = _Splash(u\"SSL credential generation\",\\n                     u\"Generating SSL credentials. (This can take a while.)\")\\n    workbench.display(splash)\\n\\n    makeCredentials(path, email)\\n\\n    workbench.undisplay()',\n",
       " 'def npm_install(package, flags=None):\\n    \"\"\"Install a package from NPM.\"\"\"\\n\\n    command = u\\'install %s %s\\' % (package, flags or u\\'\\') \\n    npm_command(command.strip())',\n",
       " 'def fasta_iter(handle, header=None):\\n    \"\"\"Iterate over FASTA file and return FASTA entries\\n\\n    Args:\\n        handle (file): FASTA file handle, can be any iterator so long as it\\n            it returns subsequent \"lines\" of a FASTA entry\\n\\n        header (str): Header line of next FASTA entry, if \\'handle\\' has been\\n            partially read and you want to start iterating at the next entry,\\n            read the next FASTA header and pass it to this variable when\\n            calling fasta_iter. See \\'Examples.\\'\\n\\n    Yields:\\n        FastaEntry: class containing all FASTA data\\n\\n    Raises:\\n        IOError: If FASTA entry doesn\\'t start with \\'>\\'\\n\\n    Examples:\\n        The following two examples demonstrate how to use fasta_iter.\\n        Note: These doctests will not pass, examples are only in doctest\\n        format as per convention. bio_utils uses pytests for testing.\\n\\n        >>> for entry in fasta_iter(open(\\'test.fasta\\')):\\n        ...     print(entry.id)  # Print FASTA id\\n        ...     print(entry.description)  # Print FASTA description\\n        ...     print(entry.sequence)  # Print FASTA sequence\\n        ...     print(entry.write())  # Print full FASTA entry\\n\\n        >>> fasta_handle = open(\\'test.fasta\\')\\n        >>> next(fasta_handle)  # Skip first entry header\\n        >>> next(fasta_handle)  # Skip first entry sequence\\n        >>> first_line = next(fasta_handle)  # Read second entry header\\n        >>> for entry in fasta_iter(fasta_handle, header=first_line):\\n        ...     print(entry.id)  # Print FASTA id\\n        ...     print(entry.description)  # Print FASTA description\\n        ...     print(entry.sequence)  # Print FASTA sequence\\n        ...     print(entry.write())  # Print full FASTA entry\\n    \"\"\"\\n\\n    # Speed tricks: reduces function calls\\n    append = list.append\\n    join = str.join\\n    strip = str.strip\\n\\n    next_line = next\\n\\n    if header is None:\\n        header = next(handle)  # Read first FASTQ entry header\\n\\n    # Check if input is text or bytestream\\n    if (isinstance(header, bytes)):\\n        def next_line(i):\\n            return next(i).decode(\\'utf-8\\')\\n\\n        header = strip(header.decode(\\'utf-8\\'))\\n    else:\\n        header = strip(header)\\n\\n    try:  # Manually construct a for loop to improve speed by using \\'next\\'\\n\\n        while True:  # Loop until StopIteration Exception raised\\n\\n            line = strip(next_line(handle))\\n\\n            data = FastaEntry()\\n\\n            try:\\n                if not header[0] == \\'>\\':\\n                    raise IOError(\\'Bad FASTA format: no \">\" at beginning of line\\')\\n            except IndexError:\\n                raise IOError(\\'Bad FASTA format: file contains blank lines\\')\\n\\n            try:\\n                data.id, data.description = header[1:].split(\\' \\', 1)\\n            except ValueError:  # No description\\n                data.id = header[1:]\\n                data.description = \\'\\'\\n\\n            # Obtain sequence\\n            sequence_list = []\\n            while line and not line[0] == \\'>\\':\\n                append(sequence_list, line)\\n                line = strip(next_line(handle))  # Raises StopIteration at EOF\\n            header = line  # Store current line so it\\'s not lost next iteration\\n            data.sequence = join(\\'\\', sequence_list)\\n\\n            yield data\\n\\n    except StopIteration:  # Yield last FASTA entry\\n        data.sequence = \\'\\'.join(sequence_list)\\n        yield data',\n",
       " \"def embedded_images(X, images, exclusion_radius=None, ax=None, cmap=None,\\n                    zoom=1, seed=None, frameon=False):\\n  '''Plots a subset of images on an axis. Useful for visualizing image\\n  embeddings, especially when plotted over a scatterplot. Selects random points\\n  to annotate with their corresponding image, respecting an exclusion_radius\\n  around each selected point.'''\\n  assert X.shape[0] == images.shape[0], 'Unequal number of points and images'\\n  assert X.shape[1] == 2, 'X must be 2d'\\n  if ax is None:\\n    ax = plt.gca()\\n  if exclusion_radius is None:\\n    # TODO: make a smarter default based on image size and axis limits\\n    exclusion_radius = 1.\\n  if seed is not None:\\n    np.random.seed(seed)\\n  while X.shape[0] > 0:\\n    i = np.random.choice(X.shape[0])\\n    im = OffsetImage(images[i], zoom=zoom, cmap=cmap)\\n    ab = AnnotationBbox(im, X[i], xycoords='data', frameon=frameon)\\n    ax.add_artist(ab)\\n    dist = np.sqrt(np.square(X[i] - X).sum(axis=1))\\n    mask = (dist > exclusion_radius).ravel()\\n    X = X[mask]\\n    images = images[mask]\\n  return plt.show\",\n",
       " \"def jitterplot(data, positions=None, ax=None, vert=True, scale=0.1,\\n               **scatter_kwargs):\\n  '''Plots jittered points as a distribution visualizer.\\n\\n  Scatter plot arguments default to: marker='.', c='k', alpha=0.75\\n  Also known as a stripplot.\\n  See also: boxplot, violinplot, beeswarm\\n  '''\\n  if ax is None:\\n    ax = plt.gca()\\n  if positions is None:\\n    positions = range(len(data))\\n\\n  kwargs = dict(marker='.', c='k', alpha=0.75)\\n  kwargs.update(scatter_kwargs)\\n\\n  for pos, y in zip(positions, data):\\n    if scale > 0:\\n      x = np.random.normal(loc=pos, scale=scale, size=len(y))\\n    else:\\n      x = np.zeros_like(y) + pos\\n    if not vert:\\n      x, y = y, x\\n    ax.scatter(x, y, **kwargs)\\n  return plt.show\",\n",
       " 'def get_type(name, library):\\n        \"\"\"\\n        Gets object type by its name and library where it is defined.\\n\\n        :param name: an object type name.\\n\\n        :param library: a library where the type is defined\\n\\n        :return: the object type or null is the type wasn\\'t found.\\n        \"\"\"\\n        if name == None:\\n            raise Exception(\"Class name cannot be null\")\\n        if library == None:\\n            raise Exception(\"Module name cannot be null\")\\n\\n        try:\\n            module = importlib.import_module(library)\\n            return getattr(module, name)\\n        except:\\n           return None',\n",
       " 'def get_type_by_descriptor(descriptor):\\n        \"\"\"\\n        Gets object type by type descriptor.\\n\\n        :param descriptor: a type descriptor that points to an object type\\n\\n        :return: the object type or null is the type wasn\\'t found.\\n        \"\"\"\\n        if descriptor == None:\\n            raise Exception(\"Type descriptor cannot be null\")\\n\\n        return TypeReflector.get_type(descriptor.get_name(), descriptor.get_library())',\n",
       " 'def create_instance(name, library, *args):\\n        \"\"\"\\n        Creates an instance of an object type specified by its name and library where it is defined.\\n\\n        :param name: an object type (factory function) to create.\\n\\n        :param library: a library (module) where object type is defined.\\n\\n        :param args: arguments for the object constructor.\\n\\n        :return: the created object instance.\\n        \"\"\"\\n        obj_type = TypeReflector.get_type(name, library)\\n        if obj_type == None:\\n            raise NotFoundException(\\n                None, \"TYPE_NOT_FOUND\", \"Type \" + name + \",\" + library + \" was not found\"\\n            ).with_details(\"type\", name).with_details(\"library\", library)\\n        \\n        return obj_type(*args)',\n",
       " 'def is_primitive(value):\\n        \"\"\"\\n        Checks if value has primitive type.\\n\\n        Primitive types are: numbers, strings, booleans, date and time.\\n        Complex (non-primitive types are): objects, maps and arrays\\n\\n        :param value: a value to check\\n\\n        :return: true if the value has primitive type and false if value type is complex.\\n        \"\"\"\\n        typeCode = TypeConverter.to_type_code(value)\\n        return typeCode == TypeCode.String or typeCode == TypeCode.Enum or typeCode == TypeCode.Boolean \\\\\\n               or typeCode == TypeCode.Integer or typeCode == TypeCode.Long \\\\\\n               or typeCode == TypeCode.Float or typeCode == TypeCode.Double \\\\\\n               or typeCode == TypeCode.DateTime or typeCode == TypeCode.Duration',\n",
       " 'def restart(self, timeout=None):\\n        \"\"\"Restarts this Splunk instance.\\n\\n        The service is unavailable until it has successfully restarted.\\n\\n        If a *timeout* value is specified, ``restart`` blocks until the service\\n        resumes or the timeout period has been exceeded. Otherwise, ``restart`` returns\\n        immediately.\\n\\n        :param timeout: A timeout period, in seconds.\\n        :type timeout: ``integer``\\n        \"\"\"\\n        msg = { \"value\": \"Restart requested by \" + self.username + \"via the Splunk SDK for Python\"}\\n        # This message will be deleted once the server actually restarts.\\n        self.messages.create(name=\"restart_required\", **msg)\\n        result = self.post(\"server/control/restart\")\\n        if timeout is None:\\n            return result\\n        start = datetime.now()\\n        diff = timedelta(seconds=timeout)\\n        while datetime.now() - start < diff:\\n            try:\\n                self.login()\\n                if not self.restart_required:\\n                    return result\\n            except Exception as e:\\n                sleep(1)\\n        raise Exception( \"Operation time out.\")',\n",
       " 'def read(self, response):\\n        \"\"\" Reads the current state of the entity from the server. \"\"\"\\n        results = self._load_state(response)\\n        # In lower layers of the SDK, we end up trying to URL encode\\n        # text to be dispatched via HTTP. However, these links are already\\n        # URL encoded when they arrive, and we need to mark them as such.\\n        unquoted_links = dict([(k, UrlEncoded(v, skip_encode=True))\\n                               for k,v in results[\\'links\\'].items()])\\n        results[\\'links\\'] = unquoted_links\\n        return results',\n",
       " 'def create(self, name, **params):\\n        \"\"\"Creates a new entity in this collection.\\n\\n        This function makes either one or two roundtrips to the\\n        server, depending on the type of entities in this\\n        collection, plus at most two more if\\n        the ``autologin`` field of :func:`connect` is set to ``True``.\\n\\n        :param name: The name of the entity to create.\\n        :type name: ``string``\\n        :param namespace: A namespace, as created by the :func:`splunklib.binding.namespace`\\n            function (optional).  You can also set ``owner``, ``app``, and\\n            ``sharing`` in ``params``.\\n        :type namespace: A :class:`splunklib.data.Record` object with keys ``owner``, ``app``,\\n            and ``sharing``.\\n        :param params: Additional entity-specific arguments (optional).\\n        :type params: ``dict``\\n        :return: The new entity.\\n        :rtype: A subclass of :class:`Entity`, chosen by :meth:`Collection.self.item`.\\n\\n        **Example**::\\n\\n            import splunklib.client as client\\n            s = client.connect(...)\\n            applications = s.apps\\n            new_app = applications.create(\"my_fake_app\")\\n        \"\"\"\\n        if not isinstance(name, basestring):\\n            raise InvalidNameException(\"%s is not a valid name for an entity.\" % name)\\n        if \\'namespace\\' in params:\\n            namespace = params.pop(\\'namespace\\')\\n            params[\\'owner\\'] = namespace.owner\\n            params[\\'app\\'] = namespace.app\\n            params[\\'sharing\\'] = namespace.sharing\\n        response = self.post(name=name, **params)\\n        atom = _load_atom(response, XNAME_ENTRY)\\n        if atom is None:\\n            # This endpoint doesn\\'t return the content of the new\\n            # item. We have to go fetch it ourselves.\\n            return self[name]\\n        else:\\n            entry = atom.entry\\n            state = _parse_atom_entry(entry)\\n            entity = self.item(\\n                self.service,\\n                self._entity_path(state),\\n                state=state)\\n            return entity',\n",
       " 'def create(self, password, username, realm=None):\\n        \"\"\" Creates a storage password.\\n\\n        A `StoragePassword` can be identified by <username>, or by <realm>:<username> if the\\n        optional realm parameter is also provided.\\n\\n        :param password: The password for the credentials - this is the only part of the credentials that will be stored securely.\\n        :type name: ``string``\\n        :param username: The username for the credentials.\\n        :type name: ``string``\\n        :param realm: The credential realm. (optional)\\n        :type name: ``string``\\n\\n        :return: The :class:`StoragePassword` object created.\\n        \"\"\"\\n        if not isinstance(username, basestring):\\n            raise ValueError(\"Invalid name: %s\" % repr(username))\\n\\n        if realm is None:\\n            response = self.post(password=password, name=username)\\n        else:\\n            response = self.post(password=password, realm=realm, name=username)\\n\\n        if response.status != 201:\\n            raise ValueError(\"Unexpected status code %s returned from creating a stanza\" % response.status)\\n\\n        entries = _load_atom_entries(response)\\n        state = _parse_atom_entry(entries[0])\\n        storage_password = StoragePassword(self.service, self._entity_path(state), state=state, skip_refresh=True)\\n\\n        return storage_password',\n",
       " 'def create(self, username, password, roles, **params):\\n        \"\"\"Creates a new user.\\n\\n        This function makes two roundtrips to the server, plus at most\\n        two more if\\n        the ``autologin`` field of :func:`connect` is set to ``True``.\\n\\n        :param username: The username.\\n        :type username: ``string``\\n        :param password: The password.\\n        :type password: ``string``\\n        :param roles: A single role or list of roles for the user.\\n        :type roles: ``string`` or  ``list``\\n        :param params: Additional arguments (optional). For a list of available\\n            parameters, see `User authentication parameters\\n            <http://dev.splunk.com/view/SP-CAAAEJ6#userauthparams>`_\\n            on Splunk Developer Portal.\\n        :type params: ``dict``\\n\\n        :return: The new user.\\n        :rtype: :class:`User`\\n\\n        **Example**::\\n\\n            import splunklib.client as client\\n            c = client.connect(...)\\n            users = c.users\\n            boris = users.create(\"boris\", \"securepassword\", roles=\"user\")\\n            hilda = users.create(\"hilda\", \"anotherpassword\", roles=[\"user\",\"power\"])\\n        \"\"\"\\n        if not isinstance(username, basestring):\\n            raise ValueError(\"Invalid username: %s\" % str(username))\\n        username = username.lower()\\n        self.post(name=username, password=password, roles=roles, **params)\\n        # splunkd doesn\\'t return the user in the POST response body,\\n        # so we have to make a second round trip to fetch it.\\n        response = self.get(username)\\n        entry = _load_atom(response, XNAME_ENTRY).entry\\n        state = _parse_atom_entry(entry)\\n        entity = self.item(\\n            self.service,\\n            urllib.parse.unquote(state.links.alternate),\\n            state=state)\\n        return entity',\n",
       " 'def _filter_attribute(mcs, attribute_name, attribute_value):\\n        \"\"\"\\n        decides whether the given attribute should be excluded from tracing or not\\n        \"\"\"\\n        if attribute_name == \\'__module__\\':\\n            return True\\n        elif hasattr(attribute_value, \\'_trace_disable\\'):\\n            return True\\n        return False',\n",
       " 'def setup_columns(self):\\n        \"\"\"Creates the treeview stuff\"\"\"\\n        tv = self.view[\\'tv_categories\\']\\n\\n        # sets the model\\n        tv.set_model(self.model)\\n        \\n        # creates the columns\\n        cell = gtk.CellRendererText()\\n        tvcol = gtk.TreeViewColumn(\\'Name\\', cell)\\n\\n        def cell_data_func(col, cell, mod, it):\\n            if mod[it][0]: cell.set_property(\\'text\\', mod[it][0].name)\\n            return\\n        tvcol.set_cell_data_func(cell, cell_data_func)\\n        \\n        tv.append_column(tvcol)                \\n        return',\n",
       " 'def show_curr_model_view(self, model, select):        \\n        \"\"\"A currency has been added, or an existing curreny has been\\n        selected, and needs to be shown on the right side of the\\n        dialog\"\"\"\\n        v = self.view.add_currency_view(select)\\n        self.curreny = CurrencyCtrl(model, v)\\n        return',\n",
       " 'def apply_modification(self):\\n        \"\"\"Modifications on the right side need to be committed\"\"\"\\n        self.__changing_model = True\\n\\n        if self.adding_model: self.model.add(self.adding_model)\\n        elif self.editing_model and self.editing_iter:\\n            # notifies the currencies model\\n            path = self.model.get_path(self.editing_iter)\\n            self.model.row_changed(path, self.editing_iter)            \\n            pass            \\n        \\n        self.view.remove_currency_view()\\n        self.adding_model = None\\n        self.editing_model = None\\n        self.editing_iter = None\\n        self.curreny = None\\n\\n        self.unselect()\\n        self.__changing_model = False\\n        return',\n",
       " 'def on_selection_changed(self, sel):\\n        \"\"\"The user changed selection\"\"\"\\n        m, self.editing_iter = sel.get_selected()\\n\\n        if self.editing_iter:\\n            self.editing_model = m[self.editing_iter][0]\\n            self.show_curr_model_view(self.editing_model, False)\\n            \\n        else: self.view.remove_currency_view()\\n            \\n        return',\n",
       " 'def plot_estimates(positions, estimates):\\n    \"\"\"\\n    Plots density, and probability estimates.\\n\\n    Parameters\\n    ----------\\n    positions : iterable of float\\n        Paragraph positions for which densities, and probabilities were estimated.\\n    estimates : six-tuple of (sequence of float)\\n        Estimates of P(relevant), p(position), p(position | relevant), P(position, relevant), and\\n        P(relevant | position).\\n\\n    Returns\\n    -------\\n    matplotlib.figure.Figure\\n        The plotted figure.\\n    \"\"\"\\n    x = list(positions)\\n    fig = plt.figure(figsize=(SUBPLOT_WIDTH * len(estimates), FIGURE_HEIGHT))\\n    for i, (title, y) in enumerate(zip(ESTIMATE_TITLES, estimates)):\\n        ax = fig.add_subplot(1, len(estimates), i + 1)\\n        ax.plot(x, y, linewidth=LINE_WIDTH, c=LINE_COLOR)\\n        ax.title.set_text(title)\\n        ax.set_xlim(0, 1)\\n        ax.set_xlabel(\"position\")\\n        ax.set_ylabel(\"$\\\\\\\\hat P$\")\\n        ax.grid()\\n    return fig',\n",
       " 'def configure(self, options, conf):\\n        \"\"\" Get filetype option to specify additional filetypes to watch. \"\"\"\\n        Plugin.configure(self, options, conf)\\n        if options.filetype:\\n            self.filetypes += options.filetype',\n",
       " 'def wrap_multipart_params(func):\\n    \"\"\"\\n    A middleware that parses the multipart request body and adds the\\n    parsed content to the `multipart_params` attribute.\\n\\n    This middleware also merges the parsed value with the existing\\n    `params` attribute in same way as `wrap_form_params` is doing.\\n    \"\"\"\\n\\n    def wrapper(request, *args, **kwargs):\\n        ctype, pdict = parse_header(request.headers.get(\\'Content-Type\\', \\'\\'))\\n        if ctype == \"multipart/form-data\":\\n\\n            if isinstance(pdict[\\'boundary\\'], str):\\n                pdict[\\'boundary\\'] = pdict[\\'boundary\\'].encode()\\n\\n            params = {}\\n            mp = MultipartParser(BytesIO(request.body), pdict[\\'boundary\\'])\\n            for part in mp:\\n                params[part.name] = {\\n                    \"filename\": part.filename,\\n                    \"file\": part.file,\\n                }\\n\\n            request.params = merge_dicts(getattr(request, \"params\", None), params)\\n            request.multipart_params = params\\n\\n        return func(request, *args, **kwargs)\\n    return wrapper',\n",
       " 'def append(self, code):\\n        \"\"\"Core API method for appending to the source code stream.\\n\\n        It can take the following as input.\\n\\n        *Strings*\\n            The processor is called if specified. String values from the \\n            processed stream are added after newlines are alided and indented. \\n            Other values are recursed on.\\n            \\n            Multiple adjacent newlines which straddle appends are alided to \\n            produce a single newline. To insert multiple newlines, they must\\n            be adjacent in the same string passed to append.\\n            \\n        *Callables*\\n            Callables taking no arguments are called and their return value\\n            recursed on if not ``None`` or ``self``.\\n            \\n            Callables taking one argument are called with ``self`` and their\\n            return value is recursed on if not ``None`` or ``self``.\\n\\n        *Iterables*\\n            The items recursed on.\\n\\n        *Expressions*\\n            If ``code._CG_expression`` is defined, that value is recursed on.\\n            \\n            If ``code._CG_context`` is defined, its value will be appended to\\n            the processor using ``append``, if possible, while recursing.\\n\\n        *Convertables*\\n            See :data:`convert`.\\n            \\n        \"\"\"\\n        # support one-shot push and pop of dictionaries using operators\\n        pop_next = self._pop_next\\n        if pop_next:\\n            self._pop_next = False\\n\\n        if isinstance(code, str):\\n            # Strings are processed, then indented appropriately\\n            for token in self._process(code):\\n                prev = self.last_string\\n                prev_ends_with_nl = prev is None or prev.endswith(\\'\\\\n\\')\\n                token_starts_with_nl = token.startswith(\"\\\\n\")\\n                indent_depth = self.indent_depth\\n                if prev_ends_with_nl:\\n                    if indent_depth > 0:\\n                        self.code_builder.append(self.indent_str)\\n                    if token_starts_with_nl:\\n                        token = token[1:]\\n\\n                if indent_depth > 0:\\n                    token = cypy.re_nonend_newline.sub(\\n                        \"\\\\n\" + self.indent_str, token)\\n\\n                if token != \"\":\\n                    self.code_builder.append(token)\\n        else: self._process_nonstrings(code)\\n\\n        if pop_next:\\n            self.pop_context()\\n        return self',\n",
       " 'def lines(self, code):\\n        \"\"\"Fixes indentation for multiline strings before appending.\"\"\"\\n        if isinstance(code, str):\\n            fix_indentation = self.fix_indentation\\n            if fix_indentation:\\n                code = fix_indentation(code)\\n            return self.append(code)\\n        else:\\n            return self.append(code)',\n",
       " 'def last_string(self):\\n        \"\"\"The last entry in code_builder, or ``None`` if none so far.\"\"\"\\n        cb = self.code_builder\\n        len_cb = len(cb)\\n        if len_cb > 0:\\n            return cb[len_cb - 1]\\n        else:\\n            return None',\n",
       " 'def pop_context(self):\\n        \"\"\"Pops the last set of keyword arguments provided to the processor.\"\"\"\\n        processor = getattr(self, \\'processor\\', None)\\n        if processor is not None:\\n            pop_context = getattr(processor, \\'pop_context\\', None)\\n            if pop_context is None:\\n                pop_context = getattr(processor, \\'pop\\', None)\\n            if pop_context is not None:\\n                return pop_context()\\n        if self._pop_next:\\n            self._pop_next = False',\n",
       " 'def unescape(inp, quote=\\'\"\\'):\\n    \"\"\"\\n    Unescape `quote` in string `inp`.\\n\\n    Example usage::\\n\\n        >> unescape(\\'hello \\\\\\\\\"\\')\\n        \\'hello \"\\'\\n\\n    Args:\\n        inp (str): String in which `quote` will be unescaped.\\n        quote (char, default \"): Specify which character will be unescaped.\\n\\n    Returns:\\n        str: Unescaped string.\\n    \"\"\"\\n    if len(inp) < 2:\\n        return inp\\n\\n    output = \"\"\\n    unesc = False\\n    for act in inp:\\n        if act == quote and unesc:\\n            output = output[:-1]\\n\\n        output += act\\n\\n        if act == \"\\\\\\\\\":\\n            unesc = not unesc\\n        else:\\n            unesc = False\\n\\n    return output',\n",
       " 'def escape(inp, quote=\\'\"\\'):\\n    \"\"\"\\n    Escape `quote` in string `inp`.\\n\\n    Example usage::\\n\\n        >>> escape(\\'hello \"\\')\\n        \\'hello \\\\\\\\\"\\'\\n        >>> escape(\\'hello \\\\\\\\\"\\')\\n        \\'hello \\\\\\\\\\\\\\\\\"\\'\\n\\n    Args:\\n        inp (str): String in which `quote` will be escaped.\\n        quote (char, default \"): Specify which character will be escaped.\\n\\n    Returns:\\n        str: Escaped string.\\n    \"\"\"\\n    output = \"\"\\n\\n    for c in inp:\\n        if c == quote:\\n            output += \\'\\\\\\\\\\'\\n\\n        output += c\\n\\n    return output',\n",
       " 'def create_marking_iobject(self,\\n                               uid=None,\\n                               timestamp=timezone.now(),\\n                               metadata_dict=None,\\n                               id_namespace_uri=DINGOS_DEFAULT_ID_NAMESPACE_URI,\\n                               iobject_family_name=DINGOS_IOBJECT_FAMILY_NAME,\\n                               iobject_family_revison_name=DINGOS_REVISION_NAME,\\n                               iobject_type_name=DINGOS_DEFAULT_IMPORT_MARKING_TYPE_NAME,\\n                               iobject_type_namespace_uri=DINGOS_NAMESPACE_URI,\\n                               iobject_type_revision_name=DINGOS_REVISION_NAME,\\n                               ):\\n        \"\"\"\\n        A specialized version of create_iobject with defaults set such that a default marking object is created.\\n        \"\"\"\\n        if not uid:\\n            uid = uuid.uuid1()\\n\\n        iobject, created = self.create_iobject(iobject_family_name=iobject_family_name,\\n                                                      iobject_family_revision_name=iobject_family_revison_name,\\n                                                      iobject_type_name=iobject_type_name,\\n                                                      iobject_type_namespace_uri=iobject_type_namespace_uri,\\n                                                      iobject_type_revision_name=iobject_type_revision_name,\\n                                                      iobject_data=metadata_dict,\\n                                                      uid=uid,\\n                                                      identifier_ns_uri=id_namespace_uri,\\n                                                      timestamp=timestamp,\\n                                                      )\\n\\n        return iobject',\n",
       " 'def get(self, channel):\\n        \"\"\"Read single ADC Channel\"\"\"\\n        checked_channel = self._check_channel_no(channel)\\n        self.i2c.write_raw8(checked_channel  | self._dac_enabled)\\n        reading = self.i2c.read_raw8() \\n        reading = self.i2c.read_raw8() \\n        return reading / 255.0',\n",
       " 'def set(self, channel, state):\\n        \"\"\"Set DAC value and enable output\"\"\"\\n        checked_val = self._check_dac_val(channel, state)\\n        self._dac_enabled = 0x40\\n        self.i2c.write8(self._dac_enabled, checked_val * 255)',\n",
       " 'def get_optional_env(key):\\n    \"\"\"\\n    Return the value of an optional environment variable, and use\\n    the provided default if it\\'s not set.\\n    \"\"\"\\n    environment_variable_value = os.environ.get(key)\\n    if environment_variable_value:\\n        return environment_variable_value\\n    elif key in CONSTANTS:\\n        return CONSTANTS[key]\\n    else:\\n        raise Exception(\"The variable {1} is not set\".format(key))',\n",
       " 'def to_datetime_with_default(value, default_value):\\n        \"\"\"\\n        Converts value into Date or returns default when conversion is not possible.\\n\\n        :param value: the value to convert.\\n\\n        :param default_value: the default value.\\n\\n        :return: Date value or default when conversion is not supported.\\n        \"\"\"\\n        result = DateTimeConverter.to_nullable_datetime(value)\\n        return result if result != None else DateTimeConverter.to_utc_datetime(default_value)',\n",
       " 'def close(self):\\n        \"\"\"Close the cursor\"\"\"\\n\\n        if self.closed or self.connection.closed:\\n            return\\n\\n        self._cursor.close()\\n        self.closed = True',\n",
       " 'def acquire(self, lock_transactions=None):\\n        \"\"\"\\n            Acquire the connection locks.\\n\\n            :param lock_transactions: `bool`, acquire the transaction lock\\n                                      (`self.lock_transactions` is the default value)\\n        \"\"\"\\n\\n        if not self.personal_lock.acquire(timeout=self.lock_timeout):\\n            raise LockTimeoutError(self)\\n\\n        self.with_count += 1\\n\\n        if lock_transactions is None:\\n            lock_transactions = self.lock_transactions\\n\\n        if lock_transactions and self.db_state.active_connection is not self:\\n            if not self.db_state.transaction_lock.acquire(timeout=self.lock_timeout):\\n                self.personal_lock.release()\\n                raise LockTimeoutError(self)\\n\\n            self.db_state.active_connection = self\\n\\n        if not self.db_state.lock.acquire(timeout=self.lock_timeout):\\n            self.personal_lock.release()\\n\\n            if lock_transactions:\\n                self.db_state.active_connection = None\\n                self.db_state.transaction_lock.release()\\n\\n            raise LockTimeoutError(self)\\n\\n        try:\\n            # If the connection is closed, an exception is thrown\\n            in_transaction = self.in_transaction\\n        except sqlite3.ProgrammingError:\\n            in_transaction = False\\n\\n        self.was_in_transaction = in_transaction',\n",
       " 'def release(self, lock_transactions=None):\\n        \"\"\"\\n            Release the connection locks.\\n\\n            :param lock_transactions: `bool`, release the transaction lock\\n                                      (`self.lock_transactions` is the default value)\\n        \"\"\"\\n\\n        self.personal_lock.release()\\n\\n        self.with_count -= 1\\n\\n        if lock_transactions is None:\\n            lock_transactions = self.lock_transactions\\n\\n        if not lock_transactions:\\n            self.db_state.lock.release()\\n            return\\n\\n        try:\\n            # If the connection is closed, an exception is thrown\\n            in_transaction = self.in_transaction\\n        except sqlite3.ProgrammingError:\\n            in_transaction = False\\n\\n        # The transaction lock should be released only if:\\n        # 1) the connection was previously in a transaction and now it isn\\'t\\n        # 2) the connection wasn\\'t previously in a transaction and still isn\\'t\\n        if (self.was_in_transaction and not in_transaction) or not in_transaction:\\n            if self.with_count == 0: # This is for nested with statements\\n                self.db_state.active_connection = None\\n                self.db_state.transaction_lock.release()\\n\\n        self.db_state.lock.release()',\n",
       " 'def to_type_code(value):\\n        \"\"\"\\n        Gets TypeCode for specific value.\\n\\n        :param value: value whose TypeCode is to be resolved.\\n\\n        :return: the TypeCode that corresponds to the passed object\\'s type.\\n        \"\"\"\\n        if value == None:\\n            return TypeCode.Unknown\\n\\n        if not isinstance(value, type):\\n            value = type(value)\\n\\n        if value is list:\\n            return TypeCode.Array\\n        elif value is tuple:\\n            return TypeCode.Array\\n        elif value is set:\\n            return TypeCode.Array\\n        elif value is bool:\\n            return TypeCode.Boolean\\n        elif value is int:\\n            return TypeCode.Integer\\n        # elif value is long:\\n        #     return TypeCode.Long\\n        elif value is float:\\n            return TypeCode.Float\\n        elif value is str:\\n            return TypeCode.String\\n        # elif value is unicode:\\n        #     return TypeCode.String\\n        elif value is datetime:\\n            return TypeCode.DateTime\\n        elif value is dict:\\n            return TypeCode.Map\\n            \\n        return TypeCode.Object',\n",
       " 'def to_type_with_default(value_type, value, default_value):\\n        \"\"\"\\n        Converts value into an object type specified by Type Code or returns default value when conversion is not possible.\\n\\n        :param value_type: the TypeCode for the data type into which \\'value\\' is to be converted.\\n\\n        :param value: the value to convert.\\n\\n        :param default_value: the default value to return if conversion is not possible (returns None).\\n\\n        :return: object value of type corresponding to TypeCode, or default value when conversion is not supported.\\n        \"\"\"\\n        result = TypeConverter.to_nullable_type(value_type, value)\\n        return result if result != None else default_value',\n",
       " 'def to_string(type):\\n        \"\"\"\\n        Converts a TypeCode into its string name.\\n\\n        :param type: the TypeCode to convert into a string.\\n\\n        :return: the name of the TypeCode passed as a string value.\\n        \"\"\"\\n        if type == None:\\n            return \"unknown\"\\n        elif type == TypeCode.Unknown:\\n            return \"unknown\"\\n        elif type == TypeCode.String:\\n            return \"string\"\\n        elif type == TypeCode.Integer:\\n            return \"integer\"\\n        elif type == TypeCode.Long:\\n            return \"long\"\\n        elif type == TypeCode.Float:\\n            return \"float\"\\n        elif type == TypeCode.Double:\\n            return \"double\"\\n        elif type == TypeCode.Duration:\\n            return \"duration\"\\n        elif type == TypeCode.DateTime:\\n            return \"datetime\"\\n        elif type == TypeCode.Object:\\n            return \"object\"\\n        elif type == TypeCode.Enum:\\n            return \"enum\"\\n        elif type == TypeCode.Array:\\n            return \"array\"\\n        elif type == TypeCode.Map:\\n            return \"map\"\\n        else:\\n            return \"unknown\"',\n",
       " 'def run_netsh_command(netsh_args):\\n    \"\"\"Execute a netsh command and return the output.\"\"\"\\n    devnull = open(os.devnull, \\'w\\')\\n    command_raw = \\'netsh interface ipv4 \\' + netsh_args\\n    return int(subprocess.call(command_raw, stdout=devnull))',\n",
       " 'def parse_array(raw_array):\\n    \"\"\"Parse a WMIC array.\"\"\"\\n    array_strip_brackets = raw_array.replace(\\'{\\', \\'\\').replace(\\'}\\', \\'\\')\\n    array_strip_spaces = array_strip_brackets.replace(\\'\"\\', \\'\\').replace(\\' \\', \\'\\')\\n    return array_strip_spaces.split(\\',\\')',\n",
       " \"def llcs(s1, s2):\\n    '''length of the longest common sequence\\n\\n    This implementation takes O(len(s1) * len(s2)) time and\\n    O(min(len(s1), len(s2))) space.\\n\\n    Use only with short strings.\\n\\n    >>> llcs('a.b.cd','!a!b!c!!!d!')\\n    4\\n    '''\\n    m, n = len(s1), len(s2)\\n    if m < n:  # ensure n <= m, to use O(min(n,m)) space\\n        m, n = n, m\\n        s1, s2 = s2, s1\\n    l = [0] * (n+1)\\n    for i in range(m):\\n        p = 0\\n        for j in range(n):\\n            t = 1 if s1[i] == s2[j] else 0\\n            p, l[j+1] = l[j+1], max(p+t, l[j], l[j+1])\\n    return l[n]\",\n",
       " \"def lcsr(s1, s2):\\n    '''longest common sequence ratio\\n\\n    >>> lcsr('ab', 'abcd')\\n    0.5\\n    '''\\n    if s1 == s2:\\n        return 1.0\\n    return llcs(s1, s2) / max(1, len(s1), len(s2))\",\n",
       " \"def lcp(s1, s2):\\n    '''longest common prefix\\n\\n    >>> lcp('abcdx', 'abcdy'), lcp('', 'a'), lcp('x', 'yz')\\n    (4, 0, 0)\\n    '''\\n    i = 0\\n    for i, (c1, c2) in enumerate(zip(s1, s2)):\\n        if c1 != c2:\\n            return i\\n    return min(len(s1), len(s2))\",\n",
       " 'def serialize(data, b64_encode=True, uri_encode=True):\\n    \"\"\"Serializes a python dictionary into a Gzip, Base64 encoded string\\n\\n    :param data: Python dictionary or list to serialize\\n    :param b64_encode: If True, the message will be compressed using Gzip and encoded using Base64\\n    :param uri_encode: If True, the message will be encoded with the urllib.parse.quote_plus to be used as a value of a URI parameter\\n    :return: Serialized data string, encoded if `encode` is `True`\\n\\n    >>> from jsonuri import jsonuri\\n    >>> data = {\"age\": 31, \"name\": \"John\", \"account\": {\"id\": 127, \"regions\": [\"US\", \"SG\"]}}\\n    >>> jsonuri.serialize(data, b64_encode=True, uri_encode=False)\\n    \\'H4sIANRnb1oC/6tWSkxPVbJSMDbUUVDKS8wFsZW88jPylID8xOTk/NK8EqBQtVJmCpAyNDIHChelpmfm5xUD+dFKocEghcHuSrG1tQCN2YKETAAAAA==\\'\\n    >>> jsonuri.serialize(data, b64_encode=True, uri_encode=True)\\n    \\'H4sIAOdnb1oC%2F6tWSkxPVbJSMDbUUVDKS8wFsZW88jPylID8xOTk%2FNK8EqBQtVJmCpAyNDIHChelpmfm5xUD%2BdFKocEghcHuSrG1tQCN2YKETAAAAA%3D%3D\\'\\n=\\n    \"\"\"\\n\\n    if not isinstance(data, dict):\\n        raise RuntimeError(\"Only dictionaries are supported. The following is not a dictionary:\\\\n %s\", data)\\n\\n    message = json.dumps(data)\\n\\n    if b64_encode:\\n        message = jsonuri.io.compress(message).decode(\\'utf-8\\')\\n\\n    if uri_encode:\\n        message = urllib.parse.quote_plus(message)\\n\\n    return message',\n",
       " 'def _init(self, width, len_):\\n        \"\"\"Initializes internal data representation of the BinArray to all-0.\\n        The internal data representation is simply tightly-packed bits of all\\n        words, starting from LSB, split into bytes and stored in a bytearray.\\n        The unused trailing padding bits in the last byte must always be set\\n        to 0.\\n        \"\"\"\\n        self._width = width\\n        self._len = len_\\n        bits = len_ * width\\n        self._data = bytearray(BinInt(bits).ceildiv(8))',\n",
       " 'def _locate(self, idx):\\n        \"\"\"Locates an element in the internal data representation.  Returns\\n        starting byte index, starting bit index in the starting byte, and\\n        one past the final byte index.\\n        \"\"\"\\n        start = idx * self._width\\n        end = (idx + 1) * self._width\\n        sbyte, sbit = divmod(start, 8)\\n        ebyte = BinInt(end).ceildiv(8)\\n        return sbyte, sbit, ebyte',\n",
       " 'def repack(self, to_width, *, msb_first, start=0, start_bit=0,\\n               length=None):\\n        \"\"\"Extracts a part of a BinArray\\'s data and converts it to a BinArray\\n        of a different width.\\n\\n        For the purposes of this conversion, words in this BinArray are joined\\n        side-by-side, starting from a given start index (defaulting to 0),\\n        skipping ``start_bit`` first bits of the first word, then the resulting\\n        stream is split into ``to_width``-sized words and ``length`` first\\n        such words are returned as a new BinArray.\\n\\n        If ``msb_first`` is False, everything proceeds with little endian\\n        ordering: the first word provides the least significant bits of the\\n        combined stream, ``start_bit`` skips bits starting from the LSB,\\n        and the first output word is made from the lowest bits of the combined\\n        stream.  Otherwise (``msb_first`` is True), everything proceeds\\n        with big endian ordering: the first word provides the most\\n        significant bits of the combined stream, ``start_bit`` skips bits\\n        starting from the MSB, and the first output word is made from the\\n        highest bits of the combined stream.\\n\\n        ``start_bits`` must be smaller than the width of the input word.\\n        It is an error to request a larger length than can be provided from\\n        the input array.  If ``length`` is not provided, this function\\n        returns as many words as can be extracted.\\n\\n        For example, consider a 10-to-3 repack with start_bit=2, length=4\\n        msb_first=True:\\n\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        |         | MSB ... LSB       |\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        |         | ...               |\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        | start   |X|X|a|b|c|d|e|f|g|h|\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        | start+1 |i|j|k|l|X|X|X|X|X|X|\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        |         | ...               |\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n\\n        is repacked to:\\n\\n        +-+-+-+-+\\n        |0|a|b|c|\\n        +-+-+-+-+\\n        |1|d|e|f|\\n        +-+-+-+-+\\n        |2|g|h|i|\\n        +-+-+-+-+\\n        |3|j|k|l|\\n        +-+-+-+-+\\n\\n        The same repack for msb_first=False is performed as follows:\\n\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        |         | MSB ... LSB       |\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        |         | ...               |\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        | start   |h|g|f|e|d|c|b|a|X|X|\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        | start+1 |X|X|X|X|X|X|l|k|j|i|\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n        |         | ...               |\\n        +---------+-+-+-+-+-+-+-+-+-+-+\\n\\n        into:\\n\\n        +-+-+-+-+\\n        |0|c|b|a|\\n        +-+-+-+-+\\n        |1|f|e|d|\\n        +-+-+-+-+\\n        |2|i|h|g|\\n        +-+-+-+-+\\n        |3|l|k|j|\\n        +-+-+-+-+\\n        \"\"\"\\n        to_width = operator.index(to_width)\\n        if not isinstance(msb_first, bool):\\n            raise TypeError(\\'msb_first must be a bool\\')\\n        available = self.repack_data_available(\\n                to_width, start=start, start_bit=start_bit)\\n        if length is None:\\n            length = available\\n        else:\\n            length = operator.index(length)\\n            if length > available:\\n                raise ValueError(\\'not enough data available\\')\\n            if length < 0:\\n                raise ValueError(\\'length cannot be negative\\')\\n        start = operator.index(start)\\n        start_bit = operator.index(start_bit)\\n        pos = start\\n        accum = BinWord(0, 0)\\n        if start_bit:\\n            accum = self[pos]\\n            pos += 1\\n            rest = accum.width - start_bit\\n            if msb_first:\\n                accum = accum.extract(0, rest)\\n            else:\\n                accum = accum.extract(start_bit, rest)\\n        res = BinArray(width=to_width, length=length)\\n        for idx in range(length):\\n            while len(accum) < to_width:\\n                cur = self[pos]\\n                pos += 1\\n                if msb_first:\\n                    accum = BinWord.concat(cur, accum)\\n                else:\\n                    accum = BinWord.concat(accum, cur)\\n            rest = accum.width - to_width\\n            if msb_first:\\n                cur = accum.extract(rest, to_width)\\n                accum = accum.extract(0, rest)\\n            else:\\n                cur = accum.extract(0, to_width)\\n                accum = accum.extract(to_width, rest)\\n            res[idx] = cur\\n        return res',\n",
       " 'def repack_data_available(src_width, to_width, *,  # noqa: N805\\n                              src_length=None, start=None, start_bit=0):\\n        \"\"\"Calculates the maximum number of words that can be requested\\n        from a repack invocation with the given settings.\\n\\n        This function can be called either on a BinArray instance (assuming\\n        its width as the source width), or on the BinArray class (passing\\n        the source width as an extra first argument).  If called in the\\n        second form, ``src_length`` must be provided.  Otherwise, it will\\n        default to the number of words in the source array from the given\\n        ``start`` index (defaulting to 0) until the end.\\n        \"\"\"\\n        start_bit = operator.index(start_bit)\\n        if isinstance(src_width, BinArray):\\n            self = src_width\\n            if src_length is None:\\n                if start is None:\\n                    start = 0\\n                else:\\n                    start = operator.index(start)\\n                    if start < 0:\\n                        raise ValueError(\\'start must not be negative\\')\\n                src_length = len(self) - start\\n                start = None\\n            src_width = self.width\\n        if src_length is None:\\n            raise TypeError(\\'no length given\\')\\n        if start is not None:\\n            raise TypeError(\\'start is redundant with explicit src_length\\')\\n        src_width = operator.index(src_width)\\n        to_width = operator.index(to_width)\\n        src_length = operator.index(src_length)\\n        start_bit = operator.index(start_bit)\\n        if src_width <= 0:\\n            raise ValueError(\\'source width must be positive\\')\\n        if to_width <= 0:\\n            raise ValueError(\\'destination width must be positive\\')\\n        if src_length < 0:\\n            raise ValueError(\\'src_length must not be negative\\')\\n        if start_bit not in range(src_width):\\n            raise ValueError(\\'start bit must be in [0, src_width)\\')\\n        if src_length == 0 and start_bit != 0:\\n            raise ValueError(\\n                    \\'src_length must be positive if start_bit is not zero\\')\\n        return (src_width * src_length - start_bit) // to_width',\n",
       " \"def bucket_to_dataframe(name, buckets, append_name=None):\\n    '''A function that turns elasticsearch aggregation buckets into dataframes\\n\\n        :param name: The name of the bucket (will be a column in the dataframe)\\n        :type name: str\\n        :param bucket: a bucket from elasticsearch results\\n        :type bucket: list[dict]\\n        :returns: pandas.DataFrame\\n    '''\\n    expanded_buckets = []\\n    for item in buckets:\\n        if type(item) is dict:\\n            single_dict = item\\n        else:\\n            single_dict = item.to_dict()\\n        single_dict[name] = single_dict.pop('doc_count')\\n        if append_name:\\n            persistance_dict = single_dict.copy()\\n            for key in persistance_dict.keys():\\n                single_dict[append_name + '.' + key] = single_dict.pop(key)\\n        expanded_buckets.append(single_dict)\\n    return pd.DataFrame(expanded_buckets)\",\n",
       " \"def agg_to_two_dim_dataframe(agg):\\n    '''A function that takes an elasticsearch response with aggregation and returns the names of all bucket value pairs\\n\\n        :param agg: an aggregation from elasticsearch results\\n        :type agg: elasticsearch response.aggregation.agg_name object\\n        :returns: pandas data frame of one or two dimetions depending on input data\\n    '''\\n    expanded_agg = []\\n    for bucket in agg.buckets:\\n        bucket_as_dict = bucket.to_dict()\\n        if dict not in [type(item) for item in bucket_as_dict.values()]:\\n            return bucket_to_dataframe('doc_count', agg.buckets)\\n        else:\\n            lower_level_dict = [item for item in bucket_as_dict.keys() if type(bucket_as_dict[item]) is dict]\\n            if len(lower_level_dict) > 1:\\n                raise ValueError('Two dimensional data can only convert a 2 level aggregation (with 1 aggregation at each level)')\\n            name_of_lower_level = lower_level_dict[0]\\n            single_level_dataframe = bucket_to_dataframe(bucket.key,\\n                                                         bucket[name_of_lower_level]['buckets'],\\n                                                         name_of_lower_level)\\n            expanded_agg.append(single_level_dataframe)\\n    merged_results = merge_dataframes(*expanded_agg)\\n    # rearrange to get key as first col\\n    cols = merged_results.columns.tolist()\\n    indices_of_keys = [i for i, s in enumerate(cols) if 'key' in s]\\n    all_other_cols = [i for i in range(0, len(cols)) if i not in indices_of_keys]\\n    new_col_order = indices_of_keys + all_other_cols\\n    return merged_results[new_col_order]\",\n",
       " \"def merge_dataframes(*dfs):\\n    '''A helper function for merging two dataframes that have the same indices, duplicate columns are removed\\n\\n        :param dfs: a list of dataframes to be merged (note: they must have the same indices)\\n        :type dfs: list[pandas.DataFrame]\\n        :returns: pandas.DataFrame -- a merged dataframe\\n    '''\\n    merged_dataframe = pd.concat(dfs, axis=1, join_axes=[dfs[0].index])\\n    return merged_dataframe.transpose().drop_duplicates().transpose()\",\n",
       " 'def decode(self):\\n        \"\"\"Decodes the mission files into dictionaries\"\"\"\\n\\n        LOGGER.debug(\\'decoding lua tables\\')\\n\\n        if not self.zip_content:\\n            self.unzip()\\n\\n        LOGGER.debug(\\'reading map resource file\\')\\n        with open(str(self.map_res_file), encoding=ENCODING) as stream:\\n            self._map_res, self._map_res_qual = SLTP().decode(stream.read())\\n\\n        LOGGER.debug(\\'reading l10n file\\')\\n        with open(str(self.dictionary_file), encoding=ENCODING) as stream:\\n            self._l10n, self._l10n_qual = SLTP().decode(stream.read())\\n\\n        LOGGER.debug(\\'reading mission file\\')\\n        with open(str(self.mission_file), encoding=ENCODING) as stream:\\n            mission_data, self._mission_qual = SLTP().decode(stream.read())\\n            self._mission = Mission(mission_data, self._l10n)\\n\\n        LOGGER.debug(\\'gathering resources\\')\\n        for file in Path(self.temp_dir, \\'l10n\\', \\'DEFAULT\\').iterdir():\\n            if file.name in (\\'dictionary\\', \\'mapResource\\'):\\n                continue\\n            LOGGER.debug(\\'found resource: %s\\', file.name)\\n            self._resources.add(file.name)\\n\\n        LOGGER.debug(\\'decoding done\\')',\n",
       " 'def unzip(self, overwrite: bool = False):\\n        \"\"\"\\n        Flattens a MIZ file into the temp dir\\n\\n        Args:\\n            overwrite: allow overwriting exiting files\\n\\n        \"\"\"\\n\\n        if self.zip_content and not overwrite:\\n            raise FileExistsError(str(self.temp_dir))\\n\\n        LOGGER.debug(\\'unzipping miz to temp dir\\')\\n\\n        try:\\n\\n            with ZipFile(str(self.miz_path)) as zip_file:\\n\\n                LOGGER.debug(\\'reading infolist\\')\\n\\n                self.zip_content = [f.filename for f in zip_file.infolist()]\\n\\n                self._extract_files_from_zip(zip_file)\\n\\n        except BadZipFile:\\n            raise BadZipFile(str(self.miz_path))\\n\\n        except:  # noqa: E722\\n            LOGGER.exception(\\'error while unzipping miz file: %s\\', self.miz_path)\\n            raise\\n\\n        LOGGER.debug(\\'checking miz content\\')\\n\\n        # noinspection PyTypeChecker\\n        for miz_item in [\\'mission\\', \\'options\\', \\'warehouses\\', \\'l10n/DEFAULT/dictionary\\', \\'l10n/DEFAULT/mapResource\\']:\\n            if not Path(self.temp_dir.joinpath(miz_item)).exists():\\n                LOGGER.error(\\'missing file in miz: %s\\', miz_item)\\n                raise FileNotFoundError(miz_item)\\n\\n        self._check_extracted_content()\\n\\n        LOGGER.debug(\\'all files have been found, miz successfully unzipped\\')',\n",
       " \"def lis(seq, indices=False):\\n    '''longest increasing subsequence\\n\\n    >>> lis([1, 2, 5, 3, 4])\\n    [1, 2, 3, 4]\\n    '''\\n    if not seq:\\n        return []\\n    # prevs[i] is the index of the previous element in the longest subsequence\\n    # containing element i\\n    prevs = [None] * len(seq)\\n    # tails[i] is the pair (elem, index) of the lowest element of any\\n    # subsequence with length i + 1\\n    tails = [(seq[0], 0)]\\n    for i, elem in enumerate(seq[1:], start=1):\\n        if elem > tails[-1][0]:\\n            prevs[i] = tails[-1][1]\\n            tails.append((elem, i))\\n            continue\\n        # let's find a tail that we can extend\\n        k = bisect(tails, (elem, -1))\\n        if tails[k][0] > elem:\\n            tails[k] = (elem, i)\\n            if k > 0:\\n                prevs[i] = tails[k - 1][1]\\n    _, i = tails[-1]\\n    subseq = []\\n    while i is not None:\\n        subseq.append(i if indices else seq[i])\\n        i = prevs[i]\\n    return subseq[::-1]\",\n",
       " 'def __fix_bases(base_classes, have_mt):\\n        \"\"\"This function check whether base_classes contains a Model\\n        instance. If not, choose the best fitting class for\\n        model. Furthermore, it makes the list in a cannonical\\n        ordering form in a way that ic can be used as memoization\\n        key\"\"\"\\n        fixed = list(base_classes)\\n        contains_model = False\\n        for b in fixed:\\n            if isinstance(fixed, Model): contains_model = True; break\\n            pass\\n\\n        # adds a model when user is lazy\\n        if not contains_model:\\n            if have_mt:\\n                from gtkmvc3.model_mt import ModelMT\\n                fixed.insert(0, ModelMT)\\n            else: fixed.insert(0, Model)\\n            pass\\n\\n        class ModelFactoryWrap (object):\\n            __metaclass__ = get_noconflict_metaclass(tuple(fixed), (), ())\\n            def __init__(self, *args, **kwargs): pass\\n            pass\\n\\n        fixed.append(ModelFactoryWrap)\\n        fixed.sort()\\n        return tuple(fixed)',\n",
       " 'def make(base_classes=(), have_mt=False):\\n        \"\"\"Use this static method to build a model class that\\n        possibly derives from other classes. If have_mt is True,\\n        then returned class will take into account multi-threading\\n        issues when dealing with observable properties.\"\"\"\\n\\n        good_bc = ModelFactory.__fix_bases(base_classes, have_mt)\\n        print \"Base classes are:\", good_bc\\n        key = \"\".join(map(str, good_bc))\\n        if key in ModelFactory.__memoized:\\n            return ModelFactory.__memoized[key]\\n\\n        cls = new.classobj(\\'\\', good_bc, {\\'__module__\\': \\'__main__\\', \\'__doc__\\': None})\\n        ModelFactory.__memoized[key] = cls\\n        return cls',\n",
       " 'def _authentication(request_fun):\\n    \"\"\"Decorator to handle autologin and authentication errors.\\n\\n    *request_fun* is a function taking no arguments that needs to\\n    be run with this ``Context`` logged into Splunk.\\n\\n    ``_authentication``\\'s behavior depends on whether the\\n    ``autologin`` field of ``Context`` is set to ``True`` or\\n    ``False``. If it\\'s ``False``, then ``_authentication``\\n    aborts if the ``Context`` is not logged in, and raises an\\n    ``AuthenticationError`` if an ``HTTPError`` of status 401 is\\n    raised in *request_fun*. If it\\'s ``True``, then\\n    ``_authentication`` will try at all sensible places to\\n    log in before issuing the request.\\n\\n    If ``autologin`` is ``False``, ``_authentication`` makes\\n    one roundtrip to the server if the ``Context`` is logged in,\\n    or zero if it is not. If ``autologin`` is ``True``, it\\'s less\\n    deterministic, and may make at most three roundtrips (though\\n    that would be a truly pathological case).\\n\\n    :param request_fun: A function of no arguments encapsulating\\n                        the request to make to the server.\\n\\n    **Example**::\\n\\n        import splunklib.binding as binding\\n        c = binding.connect(..., autologin=True)\\n        c.logout()\\n        def f():\\n            c.get(\"/services\")\\n            return 42\\n        print _authentication(f)\\n    \"\"\"\\n    @wraps(request_fun)\\n    def wrapper(self, *args, **kwargs):\\n        if self.token is _NoAuthenticationToken:\\n            # Not yet logged in.\\n            if self.autologin and self.username and self.password:\\n                # This will throw an uncaught\\n                # AuthenticationError if it fails.\\n                self.login()\\n            else:\\n                # Try the request anyway without authentication.\\n                # Most requests will fail. Some will succeed, such as\\n                # \\'GET server/info\\'.\\n                with _handle_auth_error(\"Request aborted: not logged in.\"):\\n                    return request_fun(self, *args, **kwargs)\\n        try:\\n            # Issue the request\\n            return request_fun(self, *args, **kwargs)\\n        except HTTPError as he:\\n            if he.status == 401 and self.autologin:\\n                # Authentication failed. Try logging in, and then\\n                # rerunning the request. If either step fails, throw\\n                # an AuthenticationError and give up.\\n                with _handle_auth_error(\"Autologin failed.\"):\\n                    self.login()\\n                with _handle_auth_error(\\n                        \"Autologin succeeded, but there was an auth error on \"\\n                        \"next request. Something is very wrong.\"):\\n                    return request_fun(self, *args, **kwargs)\\n            elif he.status == 401 and not self.autologin:\\n                raise AuthenticationError(\\n                    \"Request failed: Session is not logged in.\", he)\\n            else:\\n                raise\\n\\n    return wrapper',\n",
       " 'def get(self, path_segment, owner=None, app=None, sharing=None, **query):\\n        \"\"\"Performs a GET operation from the REST path segment with the given\\n        namespace and query.\\n\\n        This method is named to match the HTTP method. ``get`` makes at least\\n        one round trip to the server, one additional round trip for each 303\\n        status returned, and at most two additional round trips if\\n        the ``autologin`` field of :func:`connect` is set to ``True``.\\n\\n        If *owner*, *app*, and *sharing* are omitted, this method uses the\\n        default :class:`Context` namespace. All other keyword arguments are\\n        included in the URL as query parameters.\\n\\n        :raises AuthenticationError: Raised when the ``Context`` object is not\\n             logged in.\\n        :raises HTTPError: Raised when an error occurred in a GET operation from\\n             *path_segment*.\\n        :param path_segment: A REST path segment.\\n        :type path_segment: ``string``\\n        :param owner: The owner context of the namespace (optional).\\n        :type owner: ``string``\\n        :param app: The app context of the namespace (optional).\\n        :type app: ``string``\\n        :param sharing: The sharing mode of the namespace (optional).\\n        :type sharing: ``string``\\n        :param query: All other keyword arguments, which are used as query\\n            parameters.\\n        :type query: ``string``\\n        :return: The response from the server.\\n        :rtype: ``dict`` with keys ``body``, ``headers``, ``reason``,\\n                and ``status``\\n\\n        **Example**::\\n\\n            c = binding.connect(...)\\n            c.get(\\'apps/local\\') == \\\\\\\\\\n                {\\'body\\': ...a response reader object...,\\n                 \\'headers\\': [(\\'content-length\\', \\'26208\\'),\\n                             (\\'expires\\', \\'Fri, 30 Oct 1998 00:00:00 GMT\\'),\\n                             (\\'server\\', \\'Splunkd\\'),\\n                             (\\'connection\\', \\'close\\'),\\n                             (\\'cache-control\\', \\'no-store, max-age=0, must-revalidate, no-cache\\'),\\n                             (\\'date\\', \\'Fri, 11 May 2012 16:30:35 GMT\\'),\\n                             (\\'content-type\\', \\'text/xml; charset=utf-8\\')],\\n                 \\'reason\\': \\'OK\\',\\n                 \\'status\\': 200}\\n            c.get(\\'nonexistant/path\\') # raises HTTPError\\n            c.logout()\\n            c.get(\\'apps/local\\') # raises AuthenticationError\\n        \"\"\"\\n        path = self.authority + self._abspath(path_segment, owner=owner,\\n                                              app=app, sharing=sharing)\\n        logging.debug(\"GET request to %s (body: %s)\", path, repr(query))\\n        response = self.http.get(path, self._auth_headers, **query)\\n        return response',\n",
       " 'def post(self, url, headers=None, **kwargs):\\n        \"\"\"Sends a POST request to a URL.\\n\\n        :param url: The URL.\\n        :type url: ``string``\\n        :param headers: A list of pairs specifying the headers for the HTTP\\n            response (for example, ``[(\\'Content-Type\\': \\'text/cthulhu\\'), (\\'Token\\': \\'boris\\')]``).\\n        :type headers: ``list``\\n        :param kwargs: Additional keyword arguments (optional). If the argument\\n            is ``body``, the value is used as the body for the request, and the\\n            keywords and their arguments will be URL encoded. If there is no\\n            ``body`` keyword argument, all the keyword arguments are encoded\\n            into the body of the request in the format ``x-www-form-urlencoded``.\\n        :type kwargs: ``dict``\\n        :returns: A dictionary describing the response (see :class:`HttpLib` for\\n            its structure).\\n        :rtype: ``dict``\\n        \"\"\"\\n        if headers is None: headers = []\\n        headers.append((\"Content-Type\", \"application/x-www-form-urlencoded\")),\\n        # We handle GET-style arguments and an unstructured body. This is here\\n        # to support the receivers/stream endpoint.\\n        if \\'body\\' in kwargs:\\n            body = kwargs.pop(\\'body\\')\\n            if len(kwargs) > 0:\\n                url = url + UrlEncoded(\\'?\\' + _encode(**kwargs), skip_encode=True)\\n        else:\\n            body = _encode(**kwargs)\\n        message = {\\n            \\'method\\': \"POST\",\\n            \\'headers\\': headers,\\n            \\'body\\': body\\n        }\\n        return self.request(url, message)',\n",
       " 'def create_proxy_model(self, model):\\n        \"\"\"Create a sort filter proxy model for the given model\\n\\n        :param model: the model to wrap in a proxy\\n        :type model: :class:`QtGui.QAbstractItemModel`\\n        :returns: a new proxy model that can be used for sorting and filtering\\n        :rtype: :class:`QtGui.QAbstractItemModel`\\n        :raises: None\\n        \"\"\"\\n        proxy = ReftrackSortFilterModel(self)\\n        proxy.setSourceModel(model)\\n        model.rowsInserted.connect(self.sort_model)\\n        return proxy',\n",
       " 'def setup_filter(self, ):\\n        \"\"\"Create a checkbox for every reftrack type so one can filter them\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        types = self.refobjinter.types.keys()\\n        for i, t in enumerate(types):\\n            cb = QtGui.QCheckBox(\"%s\" % t)\\n            cb.setChecked(True)\\n            cb.toggled.connect(self.update_filter)\\n            self.typecbmap[t] = cb\\n            self.typefilter_grid.addWidget(cb, int(i / 4), i % 4)',\n",
       " 'def switch_showfilter_icon(self, toggled):\\n        \"\"\"Switch the icon on the showfilter_tb\\n\\n        :param toggled: the state of the button\\n        :type toggled: :class:`bool`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        at = QtCore.Qt.DownArrow if toggled else QtCore.Qt.RightArrow\\n        self.showfilter_tb.setArrowType(at)',\n",
       " 'def open_addnew_win(self, *args, **kwargs):\\n        \"\"\"Open a new window so the use can choose to add new reftracks\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: NotImplementedError\\n        \"\"\"\\n        if self.reftrackadderwin:\\n            self.reftrackadderwin.close()\\n        self.reftrackadderwin = ReftrackAdderWin(self.refobjinter, self.root, parent=self)\\n        self.reftrackadderwin.destroyed.connect(self.addnewwin_destroyed)\\n        self.reftrackadderwin.show()',\n",
       " 'def update_filter(self, *args, **kwargs):\\n        \"\"\"Update the filter\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: NotImplementedError\\n        \"\"\"\\n        forbidden_statuses = []\\n        if not self.loaded_checkb.isChecked():\\n            forbidden_statuses.append(reftrack.Reftrack.LOADED)\\n        if not self.unloaded_checkb.isChecked():\\n            forbidden_statuses.append(reftrack.Reftrack.UNLOADED)\\n        if not self.imported_checkb.isChecked():\\n            forbidden_statuses.append(reftrack.Reftrack.IMPORTED)\\n        if not self.empty_checkb.isChecked():\\n            forbidden_statuses.append(None)\\n        self.proxy.set_forbidden_statuses(forbidden_statuses)\\n\\n        forbidden_types = []\\n        for typ, cb in self.typecbmap.items():\\n            if not cb.isChecked():\\n                forbidden_types.append(typ)\\n        self.proxy.set_forbidden_types(forbidden_types)\\n\\n        forbidden_uptodate = []\\n        if not self.old_checkb.isChecked():\\n            forbidden_uptodate.append(False)\\n        if not self.newest_checkb.isChecked():\\n            forbidden_uptodate.append(True)\\n        self.proxy.set_forbidden_uptodate(forbidden_uptodate)\\n\\n        forbidden_alien = [] if self.alien_checkb.isChecked() else [True]\\n        self.proxy.set_forbidden_alien(forbidden_alien)\\n\\n        self.proxy.setFilterWildcard(self.search_le.text())',\n",
       " 'def sort_model(self, *args, **kwargs):\\n        \"\"\"Sort the proxy model\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self.proxy.sort(17)  # sort the identifier\\n        self.proxy.sort(2)  # sort the element\\n        self.proxy.sort(1)  # sort the elementgrp\\n        self.proxy.sort(0)',\n",
       " 'def add_selected(self, ):\\n        \"\"\"Create a new reftrack with the selected element and type and add it to the root.\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: NotImplementedError\\n        \"\"\"\\n        browser = self.shot_browser if self.browser_tabw.currentIndex() == 1 else self.asset_browser\\n        selelements = browser.selected_indexes(2)\\n        if not selelements:\\n            return\\n        seltypes = browser.selected_indexes(3)\\n        if not seltypes:\\n            return\\n        elementi = selelements[0]\\n        typi = seltypes[0]\\n        if not elementi.isValid() or not typi.isValid():\\n            return\\n        element = elementi.internalPointer().internal_data()\\n        typ = typi.internalPointer().internal_data()[0]\\n\\n        reftrack.Reftrack(self.root, self.refobjinter, typ=typ, element=element)',\n",
       " 'def write_ensemble(ensemble, options):\\n    \"\"\"\\n\\tPrints out the ensemble composition at each size\\n\\t\"\"\"\\n\\n    # set output file name\\n    size = len(ensemble)\\n    filename = \\'%s_%s_queries.csv\\' % (options.outname, size)\\n    file = os.path.join(os.getcwd(), filename)\\n\\n    f = open(file, \\'w\\')\\n\\n    out = \\', \\'.join(ensemble)\\n\\n    f.write(out)\\n\\n    f.close()',\n",
       " 'def lookup_blob(hash_value):\\n    \"\"\"\\n    Combines all given arguments to create clean title-tags values.\\n    All arguments are divided by a \" \" seperator and HTML tags\\n    are to be removed.\\n    \"\"\"\\n    try:\\n        blob = BlobStorage.objects.get(sha256=hash_value)\\n    except:\\n        return \"Blob not found\"\\n    return blob.content',\n",
       " 'def comet_view(self, request):\\n        \"\"\"\\n        This is dumb function, it just passes everything it gets into the\\n        message stream.  Something else in the stream should be responsible\\n        for asynchronously figuring out what to do with all these messages.\\n        \"\"\"\\n        request_id = self.id_for_request(request)\\n        if not request_id:\\n            request.write(HttpResponse(403).as_bytes())\\n            request.finish()\\n            return\\n        \\n        data = {\\n            \\'headers\\': request.headers,\\n            \\'arguments\\': request.arguments,\\n            \\'remote_ip\\': request.remote_ip,\\n            \\'request_id\\': request_id,\\n        }\\n        message_kind = \\'comet-%s\\' % (request.method,)\\n        if request.method == \\'POST\\':\\n            data[\\'body\\'] = simplejson.loads(request.body)\\n            request.write(HttpResponse(201).as_bytes())\\n            request.finish()\\n        else:\\n            self.pending_requests[request_id].append(request)\\n        self.publish(Message(message_kind, datetime.now(), data))',\n",
       " 'def sshagent_run(cmd):\\n    \"\"\"\\n    Helper function.\\n    Runs a command with SSH agent forwarding enabled.\\n\\n    Note:: Fabric (and paramiko) can\\'t forward your SSH agent.\\n    This helper uses your system\\'s ssh to do so.\\n    \"\"\"\\n    # Handle context manager modifications\\n    wrapped_cmd = _prefix_commands(_prefix_env_vars(cmd), \\'remote\\')\\n    try:\\n        host, port = env.host_string.split(\\':\\')\\n        return local(\\n            u\"ssh -p %s -A -o StrictHostKeyChecking=no %s@%s \\'%s\\'\" % (\\n                port, env.user, host, wrapped_cmd\\n            )\\n        )\\n    except ValueError:\\n        return local(\\n            u\"ssh -A -o StrictHostKeyChecking=no %s@%s \\'%s\\'\" % (\\n                env.user, env.host_string, wrapped_cmd\\n            )\\n        )',\n",
       " 'def as_object(obj):\\n    \"\"\"Return a JSON serializable type for ``o``.\\n\\n    Args:\\n        obj (:py:class:`object`): the object to be serialized.\\n\\n    Raises:\\n        :py:class:`AttributeError`:\\n            when ``o`` is not a Python object.\\n\\n    Returns:\\n        (dict): JSON serializable type for the given object.\\n    \"\"\"\\n    LOGGER.debug(\\'as_object(%s)\\', obj)\\n\\n    if isinstance(obj, datetime.date):\\n        return as_date(obj)\\n\\n    elif hasattr(obj, \\'__dict__\\'):\\n\\n        # populate dict with visible attributes\\n        out = {k: obj.__dict__[k] for k in obj.__dict__ if not k.startswith(\\'_\\')}\\n\\n        # populate dict with property names and values\\n        for k, v in (\\n                (p, getattr(obj, p))\\n                for p, _ in inspect.getmembers(\\n                    obj.__class__,\\n                    lambda x: isinstance(x, property))\\n        ):\\n            out[k] = v\\n\\n        return out',\n",
       " 'def as_date(dat):\\n    \"\"\"Return the RFC3339 UTC string representation of the given date and time.\\n\\n    Args:\\n        dat (:py:class:`datetime.date`): the object/type to be serialized.\\n\\n    Raises:\\n        TypeError:\\n            when ``o`` is not an instance of ``datetime.date``.\\n\\n    Returns:\\n        (str) JSON serializable type for the given object.\\n    \"\"\"\\n    LOGGER.debug(\\'as_date(%s)\\', dat)\\n\\n    return strict_rfc3339.timestamp_to_rfc3339_utcoffset(\\n        calendar.timegm(dat.timetuple()))',\n",
       " 'def chunks(iterable, chunk):\\n    \"\"\"Yield successive n-sized chunks from an iterable.\"\"\"\\n    for i in range(0, len(iterable), chunk):\\n        yield iterable[i:i + chunk]',\n",
       " 'def integrate(self, function, lower_bound, upper_bound):\\n        \"\"\"\\n        Calculates the integral of the given one dimensional function\\n        in the interval from lower_bound to upper_bound, with the simplex integration method.\\n        \"\"\"\\n        ret = 0.0\\n        n = self.nsteps\\n        xStep = (float(upper_bound) - float(lower_bound)) / float(n)\\n        self.log_info(\"xStep\" + str(xStep))\\n        x = lower_bound\\n        val1 = function(x)\\n        self.log_info(\"val1: \" + str(val1))\\n        for i in range(n):\\n            x = (i + 1) * xStep + lower_bound\\n            self.log_info(\"x: \" + str(x))\\n            val2 = function(x)\\n            self.log_info(\"val2: \" + str(val2))\\n            ret += 0.5 * xStep * (val1 + val2)\\n            val1 = val2\\n        return ret',\n",
       " 'def sam_iter(handle, start_line=None, headers=False):\\n    \"\"\"Iterate over SAM file and return SAM entries\\n\\n    Args:\\n        handle (file): SAM file handle, can be any iterator so long as it\\n            it returns subsequent \"lines\" of a SAM entry\\n\\n        start_line (str): Next SAM entry, if \\'handle\\' has been partially read\\n            and you want to start iterating at the next entry, read the next\\n            SAM entry and pass it to this variable when calling sam_iter.\\n            See \\'Examples.\\'\\n\\n        headers (bool): Yields headers if True, else skips lines starting with\\n            \"@\"\\n\\n    Yields:\\n        SamEntry: class containing all SAM data, yields str for headers if\\n            headers options is True then yields GamEntry for entries\\n\\n    Examples:\\n        The following two examples demonstrate how to use sam_iter.\\n        Note: These doctests will not pass, examples are only in doctest\\n        format as per convention. bio_utils uses pytests for testing.\\n\\n        >>> for entry in sam_iter(open(\\'test.sam\\')):\\n        ...     print(entry.qname)  # Print query sequence name\\n        ...     print(entry.flag)  # Print flag number of alignment\\n        ...     print(entry.rname)  # Print reference sequence name\\n        ...     print(entry.pos)  # Print starting position of alignment\\n        ...     print(entry.mapq)  # Print mapping confidence of alignment\\n        ...     print(entry.cigar)  # Print CIGAR string of alignment\\n        ...     print(entry.rnext)  # Print paired read name\\n        ...     print(entry.pnext)  # Print position of paired read\\n        ...     print(entry.tlen)  # Print alignment length of all paired reads\\n        ...     print(entry.seq)  # Print query sequence\\n        ...     print(entry.qual)  # Print query quality scores\\n        ...     print(entry.write())  # Print whole SAM entry\\n\\n        >>> sam_handle = open(\\'test.gff3\\')\\n        >>> next(sam_handle)  # Skip first line/entry\\n        >>> next_line = next(sam_handle)  # Store next entry\\n        >>> for entry in sam_iter(open(\\'test.sam\\')):\\n        ...     print(entry.qname)  # Print query sequence name\\n        ...     print(entry.flag)  # Print flag number of alignment\\n        ...     print(entry.rname)  # Print reference sequence name\\n        ...     print(entry.pos)  # Print starting position of alignment\\n        ...     print(entry.mapq)  # Print mapping confidence of alignment\\n        ...     print(entry.cigar)  # Print CIGAR string of alignment\\n        ...     print(entry.rnext)  # Print paired read name\\n        ...     print(entry.pnext)  # Print position of paired read\\n        ...     print(entry.tlen)  # Print alignment length of all paired reads\\n        ...     print(entry.seq)  # Print query sequence\\n        ...     print(entry.qual)  # Print query quality scores\\n        ...     print(entry.write())  # Print whole SAM entry\\n    \"\"\"\\n\\n    # Speed tricks: reduces function calls\\n    split = str.split\\n    strip = str.strip\\n\\n    next_line = next\\n\\n    if start_line is None:\\n        line = next_line(handle)  # Read first B6/M8 entry\\n    else:\\n        line = start_line  # Set header to given header\\n\\n    # Check if input is text or bytestream\\n    if (isinstance(line, bytes)):\\n        def next_line(i):\\n            return next(i).decode(\\'utf-8\\')\\n\\n        line = strip(line.decode(\\'utf-8\\'))\\n    else:\\n        line = strip(line)\\n\\n\\n    # A manual \\'for\\' loop isn\\'t needed to read the file properly and quickly,\\n    # unlike fasta_iter and fastq_iter, but it is necessary begin iterating\\n    # partway through a file when the user gives a starting line.\\n    try:  # Manually construct a for loop to improve speed by using \\'next\\'\\n\\n        while True:  # Loop until StopIteration Exception raised\\n\\n            split_line = split(line, \\'\\\\t\\')\\n\\n            if line.startswith(\\'@\\') and not headers:\\n                line = strip(next_line(handle))\\n                continue\\n            elif line.startswith(\\'@\\') and headers:\\n                yield line\\n                line = strip(next_line(handle))\\n                continue\\n\\n            data = SamEntry()\\n            data.qname = split_line[0]\\n            try:  # Differentiate between int and hex bit flags\\n                data.flag = int(split_line[1])\\n            except ValueError:\\n                data.flag = split_line[1]\\n            data.rname = split_line[2]\\n            data.pos = int(split_line[3])\\n            data.mapq = int(split_line[4])\\n            data.cigar = split_line[5]\\n            data.rnext = split_line[6]\\n            data.pnext = int(split_line[7])\\n            data.tlen = int(split_line[8])\\n            data.seq = split_line[9]\\n            data.qual = split_line[10]\\n\\n            line = strip(next_line(handle))  # Raises StopIteration at EOF\\n\\n            yield data\\n\\n    except StopIteration:  # Yield last SAM entry\\n        yield data',\n",
       " 'def write(self):\\n        \"\"\"Return SAM formatted string\\n\\n        Returns:\\n            str: SAM formatted string containing entire SAM entry\\n        \"\"\"\\n\\n        return \\'{0}\\\\t{1}\\\\t{2}\\\\t{3}\\\\t{4}\\\\t\\' \\\\\\n               \\'{5}\\\\t{6}\\\\t{7}\\\\t{8}\\\\t{9}\\\\t\\' \\\\\\n               \\'{10}{11}\\'.format(self.qname,\\n                                 str(self.flag),\\n                                 self.rname,\\n                                 str(self.pos),\\n                                 str(self.mapq),\\n                                 self.cigar,\\n                                 self.rnext,\\n                                 str(self.pnext),\\n                                 str(self.tlen),\\n                                 self.seq,\\n                                 self.qual,\\n                                 os.linesep)',\n",
       " 'def request(self, request_path, data=None, do_authentication=True, is_json=True):\\n        \"\"\"\\n        Core \"worker\" for making requests and parsing JSON responses.\\n\\n        If `is_json` is ``True``, `data` should be a dictionary which\\n        will be JSON-encoded.\\n        \"\"\"\\n        uri = self.api_uri % request_path\\n        request = urllib2.Request(uri)\\n\\n        # Build up the request\\n        if is_json:\\n            request.add_header(\"Content-Type\", \"application/json\")\\n            if data is not None:\\n                request.add_data(json.dumps(data))\\n        elif data is not None:\\n            request.add_data(data)\\n\\n        if do_authentication:\\n            if self.client_id is None or self.client_secret is None:\\n                raise Exception(u\"You need to supply a client_id and client_secret to perform an authenticated request\")\\n            basic_auth = base64.b64encode(\"%s:%s\" % (self.client_id, self.client_secret))\\n            request.add_header(\"Authorization\", \"Basic %s\" % basic_auth)\\n\\n        try:\\n            response = self._make_request(request)\\n        except Exception as inst:\\n            raise # automatically re-raises the exception\\n\\n        if \\'status\\' in response:\\n            # Grab the status info if it exists\\n            self._last_status_code = response[\\'status\\'][\\'code\\']\\n            if \\'message\\' in response[\\'status\\']:\\n                self._last_status_message = response[\\'status\\'][\\'message\\']\\n\\n            if \\'data\\' in response:\\n                return response[\\'data\\']\\n\\n        return response',\n",
       " 'def _make_request(self, request):\\n        \"\"\"\\n        Does the magic of actually sending the request and parsing the response\\n        \"\"\"\\n        # TODO: I\\'m sure all kinds of error checking needs to go here\\n        try:\\n            response_raw = urllib2.urlopen(request)\\n        except urllib2.HTTPError, e:\\n            print e.read()\\n            raise\\n\\n        response_str = response_raw.read()\\n        response = json.loads(response_str)\\n\\n        self._last_request = request\\n        self._last_response = response_raw\\n        self._last_response_str = response_str\\n        return response',\n",
       " 'def add_member(self, address, **kwargs):\\n        \"\"\"\\n        Add a member to a group.\\n\\n        All Fiesta membership options can be passed in as keyword\\n        arguments. Some valid options include:\\n\\n        - `group_name`: Since each member can access a group using\\n          their own name, you can override the `group_name` in this\\n          method. By default, the group will have the name specified\\n          on the class level `default_name` property.\\n\\n        - `display_name` is the full name of the user that they will\\n          see throughout the UI if this is a new account.\\n\\n        - `welcome_message` should be a dictionary specified according\\n          to the docs. If you set it to ``False``, no message will be\\n          sent. See\\n          http://docs.fiesta.cc/list-management-api.html#message for\\n          formatting details.\\n\\n        .. seealso:: `Fiesta API documentation <http://docs.fiesta.cc/list-management-api.html#adding-members>`_\\n        \"\"\"\\n        path = \\'membership/%s\\' % self.id\\n        kwargs[\"address\"] = address\\n\\n        if \"group_name\" not in kwargs and self.default_name:\\n            kwargs[\"group_name\"] = self.default_name\\n\\n        response_data = self.api.request(path, kwargs)\\n        if \\'user_id\\' in response_data:\\n            user_id = response_data[\\'user_id\\']\\n            return FiestaUser(user_id, address=address, groups=[self])\\n        return None',\n",
       " 'def send_message(self, subject=None, text=None, markdown=None, message_dict=None):\\n        \"\"\"\\n        Helper function to send a message to a group\\n        \"\"\"\\n        message = FiestaMessage(self.api, self, subject, text, markdown, message_dict)\\n        return message.send()',\n",
       " 'def add_application(self, application_id, **kwargs):\\n        \"\"\"\\n        Add an application to a group.\\n\\n        `application_id` is the name of the application to add. Any\\n        application options can be specified as kwargs.\\n        \"\"\"\\n        path = \\'group/%s/application\\' % self.id\\n\\n        data = {\\'application_id\\': application_id}\\n        if kwargs:\\n            data[\"options\"] = kwargs\\n\\n        self.api.request(path, data)',\n",
       " 'def send(self, group_id=None, message_dict=None):\\n        \"\"\"\\n        Send this current message to a group.\\n\\n        `message_dict` can be a dictionary formatted according to http://docs.fiesta.cc/list-management-api.html#messages\\n        If message is provided, this method will ignore object-level variables.\\n        \"\"\"\\n        if self.group is not None and self.group.id is not None:\\n            group_id = self.group.id\\n\\n        path = \\'message/%s\\' % group_id\\n\\n        if message_dict is not None:\\n            request_data = {\\n                \\'message\\': message_dict,\\n            }\\n        else:\\n            subject = self.subject\\n            text = self.text\\n            markdown = self.markdown\\n\\n            request_data = {\\n                \\'message\\': {},\\n            }\\n            if subject:\\n                request_data[\\'message\\'][\\'subject\\'] = subject\\n            if text:\\n                request_data[\\'message\\'][\\'text\\'] = text\\n            if markdown:\\n                request_data[\\'message\\'][\\'markdown\\'] = markdown\\n\\n        response_data = self.api.request(path, request_data)\\n\\n        self.id = response_data[\\'message_id\\']\\n        self.thread_id = response_data[\\'thread_id\\']\\n        self.sent_message = FiestaMessage(self.api, response_data[\\'message\\'])',\n",
       " 'def setup_ui(self, ):\\n        \"\"\"Setup the ui\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        labels = self.reftrack.get_option_labels()\\n        self.browser = ComboBoxBrowser(len(labels), headers=labels)\\n        self.browser_vbox.addWidget(self.browser)',\n",
       " 'def select(self, ):\\n        \"\"\"Store the selected taskfileinfo self.selected and accept the dialog\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        s = self.browser.selected_indexes(self.browser.get_depth()-1)\\n        if not s:\\n            return\\n        i = s[0].internalPointer()\\n        if i:\\n            tfi = i.internal_data()\\n            self.selected = tfi\\n            self.accept()',\n",
       " 'def setup_icons(self, ):\\n        \"\"\"Setup the icons of the ui\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        iconbtns = [(\"menu_border_24x24.png\", self.menu_tb),\\n                    (\"duplicate_border_24x24.png\", self.duplicate_tb),\\n                    (\"delete_border_24x24.png\", self.delete_tb),\\n                    (\"reference_border_24x24.png\", self.reference_tb),\\n                    (\"load_border_24x24.png\", self.load_tb),\\n                    (\"unload_border_24x24.png\", self.unload_tb),\\n                    (\"replace_border_24x24.png\", self.replace_tb),\\n                    (\"import_border_24x24.png\", self.importref_tb),\\n                    (\"import_border_24x24.png\", self.importtf_tb),\\n                    (\"alien.png\", self.alien_tb),\\n                    (\"imported.png\", self.imported_tb)]\\n        for iconname, btn in iconbtns:\\n            i = get_icon(iconname, asicon=True)\\n            btn.setIcon(i)',\n",
       " 'def set_maintext(self, index):\\n        \"\"\"Set the maintext_lb to display text information about the given reftrack\\n\\n        :param index: the index\\n        :type index: :class:`QtGui.QModelIndex`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        dr = QtCore.Qt.DisplayRole\\n        text = \"\"\\n        model = index.model()\\n        for i in (1, 2, 3, 5, 6):\\n            new = model.index(index.row(), i, index.parent()).data(dr)\\n            if new is not None:\\n                text = \" | \".join((text, new)) if text else new\\n\\n        self.maintext_lb.setText(text)',\n",
       " 'def set_identifiertext(self, index):\\n        \"\"\"Set the identifier text on the identifier_lb\\n\\n        :param index: the index\\n        :type index: :class:`QtGui.QModelIndex`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        dr = QtCore.Qt.DisplayRole\\n        t = index.model().index(index.row(), 17, index.parent()).data(dr)\\n        if t is None:\\n            t = -1\\n        else:\\n            t = t+1\\n        self.identifier_lb.setText(\"#%s\" % t)',\n",
       " 'def set_type_icon(self, index):\\n        \"\"\"Set the type icon on type_icon_lb\\n\\n        :param index: the index\\n        :type index: :class:`QtGui.QModelIndex`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        icon = index.model().index(index.row(), 0, index.parent()).data(QtCore.Qt.DecorationRole)\\n        if icon:\\n            pix = icon.pixmap(self.type_icon_lb.size())\\n            self.type_icon_lb.setPixmap(pix)\\n        else:\\n            self.type_icon_lb.setPixmap(None)',\n",
       " 'def disable_restricted(self, ):\\n        \"\"\"Disable the restricted buttons\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        todisable = [(self.reftrack.duplicate, self.duplicate_tb),\\n                     (self.reftrack.delete, self.delete_tb),\\n                     (self.reftrack.reference, self.reference_tb),\\n                     (self.reftrack.replace, self.replace_tb),]\\n        for action, btn in todisable:\\n            res = self.reftrack.is_restricted(action)\\n            btn.setDisabled(res)',\n",
       " 'def hide_restricted(self, ):\\n        \"\"\"Hide the restricted buttons\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        tohide = [((self.reftrack.unload, self.unload_tb),\\n                   (self.reftrack.load, self.load_tb)),\\n                  ((self.reftrack.import_file, self.importtf_tb),\\n                   (self.reftrack.import_reference, self.importref_tb))]\\n        for (action1, btn1), (action2, btn2) in tohide:\\n            res1 = self.reftrack.is_restricted(action1)\\n            res2 = self.reftrack.is_restricted(action2)\\n            if res1 != res2:\\n                btn1.setEnabled(True)\\n                btn1.setHidden(res1)\\n                btn2.setHidden(res2)\\n            else:  # both are restricted, then show one but disable it\\n                btn1.setDisabled(True)\\n                btn1.setVisible(True)\\n                btn2.setVisible(False)',\n",
       " 'def set_top_bar_color(self, index):\\n        \"\"\"Set the color of the upper frame to the background color of the reftrack status\\n\\n        :param index: the index\\n        :type index: :class:`QtGui.QModelIndex`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        dr = QtCore.Qt.ForegroundRole\\n        c = index.model().index(index.row(), 8, index.parent()).data(dr)\\n        if not c:\\n            c = self.upper_fr_default_bg_color\\n        self.upper_fr.setStyleSheet(\\'background-color: rgb(%s, %s, %s)\\' % (c.red(), c.green(), c.blue()))',\n",
       " 'def set_menu(self, ):\\n        \"\"\"Setup the menu that the menu_tb button uses\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self.menu = QtGui.QMenu(self)\\n        actions = self.reftrack.get_additional_actions()\\n        self.actions = []\\n        for a in actions:\\n            if a.icon:\\n                qaction = QtGui.QAction(a.icon, a.name, self)\\n            else:\\n                qaction = QtGui.QAction(a.name, self)\\n            qaction.setCheckable(a.checkable)\\n            qaction.setChecked(a.checked)\\n            qaction.setEnabled(a.enabled)\\n            qaction.triggered.connect(a.action)\\n            self.actions.append(qaction)\\n            self.menu.addAction(qaction)\\n        self.menu_tb.setMenu(self.menu)',\n",
       " 'def get_taskfileinfo_selection(self, ):\\n        \"\"\"Return a taskfileinfo that the user chose from the available options\\n\\n        :returns: the chosen taskfileinfo\\n        :rtype: :class:`jukeboxcore.filesys.TaskFileInfo`\\n        :raises: None\\n        \"\"\"\\n        sel = OptionSelector(self.reftrack)\\n        sel.exec_()\\n        return sel.selected',\n",
       " 'def reference(self, ):\\n        \"\"\"Reference a file\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        tfi = self.get_taskfileinfo_selection()\\n        if tfi:\\n            self.reftrack.reference(tfi)',\n",
       " 'def import_file(self, ):\\n        \"\"\"Import a file\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: NotImplementedError\\n        \"\"\"\\n        tfi = self.get_taskfileinfo_selection()\\n        if tfi:\\n            self.reftrack.import_file(tfi)',\n",
       " 'def replace(self, ):\\n        \"\"\"Replace the current reftrack\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        tfi = self.get_taskfileinfo_selection()\\n        if tfi:\\n            self.reftrack.replace(tfi)',\n",
       " \"def delete_renditions_if_master_has_changed(sender, instance, **kwargs):\\n    '''if master file as changed delete all renditions'''\\n    try:\\n        obj = sender.objects.get(pk=instance.pk)\\n    except sender.DoesNotExist:\\n        pass  # Object is new, so field hasn't technically changed.\\n    else:\\n        if not obj.master == instance.master:  # Field has changed\\n            obj.master.delete(save=False)\\n            instance.delete_all_renditions()\",\n",
       " \"def photo_post_delete_handler(sender, **kwargs):\\n    '''delete image when rows is gone from database'''\\n    instance = kwargs.get('instance')\\n    instance.master.delete(save=False)\\n    instance.delete_all_renditions()\",\n",
       " \"def get_rendition_size(self, width=0, height=0):\\n        '''returns real rendition URL'''\\n        if width == 0 and height == 0:\\n            return (self.master_width, self.master_height)\\n\\n        target_width = int(width)\\n        target_height = int(height)\\n\\n        ratio = self.master_width / float(self.master_height)\\n        if target_height == 0 and target_width != 0:\\n            target_height = int(target_width / ratio)\\n\\n        if target_height != 0 and target_width == 0:\\n            target_width = int(target_height * ratio)\\n\\n        return target_width, target_height\",\n",
       " \"def get_rendition_url(self, width=0, height=0):\\n        '''get the rendition URL for a specified size\\n\\n        if the renditions does not exists it will be created\\n        '''\\n        if width == 0 and height == 0:\\n            return self.get_master_url()\\n\\n        target_width, target_height = self.get_rendition_size(width, height)\\n\\n        key = '%sx%s' % (target_width, target_height)\\n        if not self.renditions:\\n            self.renditions = {}\\n        rendition_name = self.renditions.get(key, False)\\n        if not rendition_name:\\n            rendition_name = self.make_rendition(target_width, target_height)\\n        return default_storage.url(rendition_name)\",\n",
       " \"def delete_all_renditions(self):\\n        '''delete all renditions and rendition dict'''\\n        if self.renditions:\\n            for r in self.renditions.values():\\n                default_storage.delete(r)\\n            self.renditions = {}\",\n",
       " \"def make_rendition(self, width, height):\\n        '''build a rendition\\n\\n        0 x 0 -> will give master URL\\n        only width -> will make a renditions with master's aspect ratio\\n        width x height -> will make an image potentialy cropped\\n        '''\\n        image = Image.open(self.master)\\n        format = image.format\\n\\n        target_w = float(width)\\n        target_h = float(height)\\n\\n        if (target_w == 0):\\n            target_w = self.master_width\\n\\n        if (target_h == 0):\\n            target_h = self.master_height\\n\\n        rendition_key = '%dx%d' % (target_w, target_h)\\n\\n        if rendition_key in self.renditions:\\n            return self.renditions[rendition_key]\\n\\n        if (target_w != self.master_width or target_h != self.master_height):\\n            r = target_w / target_h\\n            R = float(self.master_width) / self.master_height\\n            if r != R:\\n                if r > R:\\n                    crop_w = self.master_width\\n                    crop_h = crop_w / r\\n                    x = 0\\n                    y = int(self.master_height - crop_h) >> 1\\n                else:\\n                    crop_h = self.master_height\\n                    crop_w = crop_h * r\\n                    x = int(self.master_width - crop_w) >> 1\\n                    y = 0\\n                image = image.crop((x, y, int(crop_w + x), int(crop_h + y)))\\n\\n            image.thumbnail((int(target_w), int(target_h)), Image.ANTIALIAS)\\n\\n            filename, ext = os.path.splitext(self.get_master_filename())\\n            rendition_name = '%s/%s_%s%s' % (\\n                IMAGE_DIRECTORY,\\n                filename,\\n                rendition_key,\\n                ext\\n            )\\n            fd = BytesIO()\\n            image.save(fd, format)\\n            default_storage.save(rendition_name, fd)\\n\\n            self.renditions[rendition_key] = rendition_name\\n            self.save()\\n\\n            return rendition_name\\n\\n        return self.master.name\",\n",
       " 'def execute_actioncollection(obj, actioncollection, confirm=True):\\n    \"\"\"Execute the given actioncollection with the given object\\n\\n    :param obj: the object to be processed\\n    :param actioncollection:\\n    :type actioncollection: :class:`ActionCollection`\\n    :param confirm: If True, ask the user to continue, if actions failed.\\n    :type confirm: :class:`bool`\\n    :returns: An action status. If the execution fails but the user confirms, the status will be successful.\\n    :rtype: :class:`ActionStatus`\\n    :raises: None\\n    \"\"\"\\n    actioncollection.execute(obj)\\n    status = actioncollection.status()\\n    if status.value == ActionStatus.SUCCESS or not confirm:\\n        return status\\n    ard = ActionReportDialog(actioncollection)\\n    confirmed = ard.exec_()\\n    if confirmed:\\n        msg = \"User confirmed to continue although the status was: %s\" % status.message,\\n        s = ActionStatus.SUCCESS\\n        tb = status.traceback\\n    else:\\n        s = status.value\\n        msg = \"User aborted the actions because the status was: %s\" % status.message,\\n        tb = status.traceback\\n    return ActionStatus(s, msg, tb)',\n",
       " 'def release(self):\\n        \"\"\"Create a release\\n\\n        1. Perform Sanity checks on work file.\\n        2. Copy work file to releasefile location.\\n        3. Perform cleanup actions on releasefile.\\n\\n        :returns: True if successfull, False if not.\\n        :rtype: bool\\n        :raises: None\\n        \"\"\"\\n        log.info(\"Releasing: %s\", self._workfile.get_fullpath())\\n        ac = self.build_actions()\\n        ac.execute(self)\\n        s = ac.status().value\\n        if not s == ActionStatus.SUCCESS:\\n            ard = ActionReportDialog(ac)\\n            ard.exec_()\\n            pass\\n        return s == ActionStatus.SUCCESS',\n",
       " 'def build_actions(self):\\n        \"\"\"Create an ActionCollection that will perform sanity checks, copy the file,\\n        create a database entry and perform cleanup actions and in case of a failure clean everything up.\\n\\n        :param work: the workfile\\n        :type work: :class:`JB_File`\\n        :param release: the releasefile\\n        :type release: :class:`JB_File`\\n        :param checks: the action collection object with sanity checks\\n                       It should accept a :class:`JB_File` as object for execute.\\n        :type checks: :class:`ActionCollection`\\n        :param cleanup: a action collection object that holds cleanup actions for the given file.\\n                        It should accept a :class:`JB_File` as object for execute.\\n        :type cleanup: :class:`ActionCollection`\\n        :param comment: comment for the release\\n        :type comment: :class:`str`\\n        :returns: An ActionCollection ready to execute.\\n        :rtype: :class:`ActionCollection`\\n        :raises: None\\n        \"\"\"\\n        checkau = ActionUnit(\"Sanity Checks\",\\n                             \"Check the workfile. If the file is not conform, ask the user to continue.\",\\n                             self.sanity_check)\\n        copyau = ActionUnit(\"Copy File\",\\n                            \"Copy the workfile to the releasefile location.\",\\n                            self.copy,\\n                            depsuccess=[checkau])\\n        dbau = ActionUnit(\"Create DB entry\",\\n                          \"Create an entry in the database for the releasefile\",\\n                          self.create_db_entry,\\n                          depsuccess=[copyau])\\n        cleanau = ActionUnit(\"Cleanup\",\\n                             \"Cleanup the releasefile. If something fails, ask the user to continue.\",\\n                             self.cleanup,\\n                             depsuccess=[dbau])\\n        deletefau1 = ActionUnit(\"Delete the releasefile.\",\\n                                \"In case the db entry creation fails, delete the releasefile.\",\\n                                self.delete_releasefile,\\n                                depfail=[dbau])\\n        deletefau2 = ActionUnit(\"Delete the releasefile.\",\\n                                \"In case the cleanup fails, delete the releasefile.\",\\n                                self.delete_releasefile,\\n                                depsuccess=[copyau],\\n                                depfail=[cleanau])\\n        deletedbau = ActionUnit(\"Delete the database entry.\",\\n                                \"In case the cleanup fails, delete the database entry\",\\n                                self.delete_db_entry,\\n                                depsuccess=[dbau],\\n                                depfail=[cleanau])\\n        return ActionCollection([checkau, copyau, dbau, cleanau, deletefau1, deletefau2, deletedbau])',\n",
       " 'def sanity_check(self, release):\\n        \"\"\"Perform sanity checks on the workfile of the given release\\n\\n        This is inteded to be used in a action unit.\\n\\n        :param release: the release with the workfile and sanity checks\\n        :type release: :class:`Release`\\n        :returns: the action status of the sanity checks\\n        :rtype: :class:`ActionStatus`\\n        :raises: None\\n        \"\"\"\\n        log.info(\"Performing sanity checks.\")\\n        return execute_actioncollection(release._workfile, actioncollection=release._checks, confirm=True)',\n",
       " 'def copy(self, release):\\n        \"\"\"Copy the workfile of the given release to the releasefile location\\n\\n        This is inteded to be used in a action unit.\\n\\n        :param release: the release with the release and workfile\\n        :type release: :class:`Release`\\n        :returns: an action status\\n        :rtype: :class:`ActionStatus`\\n        :raises: None\\n        \"\"\"\\n        workfp = release._workfile.get_fullpath()\\n        releasefp = release._releasefile.get_fullpath()\\n        copy_file(release._workfile, release._releasefile)\\n        return ActionStatus(ActionStatus.SUCCESS,\\n                            msg=\"Copied %s to %s location.\" % (workfp,\\n                                                               releasefp))',\n",
       " 'def create_db_entry(self, release):\\n        \"\"\"Create a db entry for releasefile of the given release\\n\\n        Set _releasedbentry and _commentdbentry of the given release file\\n\\n        This is inteded to be used in a action unit.\\n\\n        :param release: the release with the releasefile and comment\\n        :type release: :class:`Release`\\n        :returns: an action status\\n        :rtype: :class:`ActionStatus`\\n        :raises: ValidationError, If the comment could not be created, the TaskFile is deleted and the Exception is propagated.\\n        \"\"\"\\n        log.info(\"Create database entry with comment: %s\", release.comment)\\n        tfi = release._releasefile.get_obj()\\n        tf, note = tfi.create_db_entry(release.comment)\\n        release._releasedbentry = tf\\n        release._commentdbentry = note\\n        return ActionStatus(ActionStatus.SUCCESS,\\n                            msg=\"Created database entry for the release filw with comment: %s\" % release.comment)',\n",
       " 'def cleanup(self, release):\\n        \"\"\"Perform cleanup actions on the releasefile of the given release\\n\\n        This is inteded to be used in a action unit.\\n\\n        :param release: the release with the releasefile and cleanup actions\\n        :type release: :class:`Release`\\n        :returns: the action status of the cleanup actions\\n        :rtype: :class:`ActionStatus`\\n        :raises: None\\n        \"\"\"\\n        log.info(\"Performing cleanup.\")\\n        return execute_actioncollection(release._releasefile, actioncollection=release._cleanup, confirm=True)',\n",
       " 'def delete_releasefile(self, release):\\n        \"\"\"Delete the releasefile of the given release\\n\\n        This is inteded to be used in a action unit.\\n\\n        :param release: the release with the releasefile\\n        :type release: :class:`Release`\\n        :returns: an action status\\n        :rtype: :class:`ActionStatus`\\n        :raises: None\\n        \"\"\"\\n        fp = release._releasefile.get_fullpath()\\n        log.info(\"Deleting release file %s\", fp)\\n        delete_file(release._releasefile)\\n        return ActionStatus(ActionStatus.SUCCESS,\\n                            msg=\"Deleted %s\" % fp)',\n",
       " 'def delete_db_entry(self, release):\\n        \"\"\"Delete the db entries for releasefile and comment of the given release\\n\\n        :param release: the release with the releasefile and comment db entries\\n        :type release: :class:`Release`\\n        :returns: an action status\\n        :rtype: :class:`ActionStatus`\\n        :raises: None\\n        \"\"\"\\n        log.info(\"Delete database entry for file.\")\\n        release._releasedbentry.delete()\\n        log.info(\"Delete database entry for comment.\")\\n        release._commentdbentry.delete()\\n        return ActionStatus(ActionStatus.SUCCESS,\\n                            msg=\"Deleted database entries for releasefile and comment\")',\n",
       " 'def socket_reader(connection: socket, buffer_size: int = 1024):\\n    \"\"\" read data from adb socket \"\"\"\\n    while connection is not None:\\n        try:\\n            buffer = connection.recv(buffer_size)\\n            # no output\\n            if not len(buffer):\\n                raise ConnectionAbortedError\\n        except ConnectionAbortedError:\\n            # socket closed\\n            print(\\'connection aborted\\')\\n            connection.close()\\n            yield None\\n        except OSError:\\n            # still operate connection after it was closed\\n            print(\\'socket closed\\')\\n            connection.close()\\n            yield None\\n        else:\\n            yield buffer',\n",
       " 'def decode_response(content: bytes) -> set:\\n    \"\"\" adb response text -> device set \"\"\"\\n    content = content[4:].decode(config.ENCODING)\\n    if \\'\\\\t\\' not in content and \\'\\\\n\\' not in content:\\n        return set()\\n\\n    connected_devices = set()\\n    device_list = [i for i in content.split(\\'\\\\n\\') if i]\\n    for each_device in device_list:\\n        device_id, device_status = each_device.split(\\'\\\\t\\')\\n        if device_status == \\'device\\':\\n            connected_devices.add(device_id)\\n    return connected_devices',\n",
       " 'def main(requirements_file, skip_requirements_file, pipfile, skip_pipfile):\\n    # type: (str, bool, str, bool) -> None\\n    \"\"\"Update the requirements.txt file and reformat the Pipfile.\"\"\"\\n    pipfile_path = path.Path(pipfile)\\n    pf = load_pipfile(pipfile_path)\\n\\n    if not skip_requirements_file:\\n        requirements_file_path = path.Path(requirements_file)\\n        update_requirements(requirements_file_path, pf)\\n\\n    if not skip_pipfile:\\n        dump_pipfile(pipfile_path, pf)',\n",
       " 'def clean_file(self):\\n        \"\"\"Analyse the uploaded file, and return the parsed lines.\\n\\n        Returns:\\n            tuple of tuples of cells content (as text).\\n        \"\"\"\\n        data = self.cleaned_data[\\'file\\']\\n\\n        available_parsers = self.get_parsers()\\n\\n        for parser in available_parsers:\\n            try:\\n                return parser.parse_file(data)\\n            except parsers.ParserError:\\n                pass\\n\\n        raise forms.ValidationError(\\n            \"No parser could read the file. Tried with parsers %s.\" %\\n            (\", \" % (force_text(p) for p in available_parsers)))',\n",
       " 'def clean(self):\\n        \"\"\"Global cleanup.\"\"\"\\n        super(LineFormSet, self).clean()\\n\\n        if any(self.errors):\\n            # Already seen errors, let\\'s skip.\\n            return\\n\\n        self.clean_unique_fields()',\n",
       " 'def clean_unique_fields(self):\\n        \"\"\"Ensure \\'unique fields\\' are unique among entered data.\"\"\"\\n        if not self.unique_fields:\\n            return\\n\\n        keys = set()\\n        duplicates = []\\n\\n        for form in self.forms:\\n            key = tuple(form.cleaned_data[field] for field in self.unique_fields)\\n            if key in keys:\\n                duplicates.append(\",\".join(key))\\n            else:\\n                keys.add(key)\\n\\n        if duplicates:\\n            raise forms.ValidationError(\\n                \"Fields %s should be unique; found duplicates for %s\" % (\\n                    \\',\\'.join(self.unique_fields), duplicates))',\n",
       " 'def run(itf):\\n    \"\"\"\\n\\tRun optimize functions.\\n\\t\"\"\"\\n\\n    if not itf:\\n        return 1\\n\\n    # access user input\\n    options = SplitInput(itf)\\n\\n    # read input\\n    inputpath = os.path.abspath(options.inputpath)\\n    print(\" Reading input file ...\")\\n    molecules = csv_interface.read_csv(inputpath, options)\\n    if not molecules:\\n        print(\"\\\\n \\'{flag}\\' was unable to be parsed\\\\n\".format(flag=os.path.basename(options.inputpath)))\\n        sys.exit(1)\\n\\n    # determine the sort order & ensemble_size\\n    #sort_order = classification.get_sort_order(molecules)\\n    sort_order = \\'asc\\'\\n    ensemble_size = options.ensemble_size\\n\\n    # loop over all ensembles\\n    # temp 2/3/15 append to auc_list ef_list & write it out for later histogram construction\\n    auc_list = []\\n    ef_list = []\\n    for size in [x + 1 for x in range(ensemble_size)]:\\n        auc, ef = optimizor(molecules, sort_order, size, options)\\n        auc_list += auc\\n        ef_list += ef\\n    # temp 2/9/15 write auc_list & ef_list out to files for subsequent post-processing\\n    f = open(\\'auc_histogram.csv\\', \\'w\\')\\n    for value in auc_list:\\n        f.write(\\'%f\\\\n\\' % value)\\n        #f.write(\\'%f, %s\\\\n\\' % (value[0], value[1]))\\n    f.close()\\n    f = open(\\'ef_histogram.csv\\', \\'w\\')\\n    for value in ef_list:\\n        f.write(\\'%f\\\\n\\' % value)\\n    f.close()',\n",
       " 'def optimizor(molecules, sort_order, ensemble_size, options):\\n    \"\"\"\\n\\tEvaluate the performance of all ensembles of fixed size.\\n\\t\"\"\"\\n    # set variables\\n    ncpu = options.ncpu\\n    score_field = options.score_field\\n\\n    # generate an exhaustive list of all possible ensembles\\n    ensemble_list = make_ensemble_list(molecules, score_field, ensemble_size)\\n\\n    # set number of processors.\\n    if not ncpu:\\n        ncpu = multiprocessing.cpu_count()\\n\\n    if ncpu > 1:\\n        print(\"Determining the performance of {d} ensembles using {n} processors\".format(d=len(ensemble_list), n=ncpu))\\n\\n        if ncpu > len(ensemble_list):\\n            ncpu = len(ensemble_list)\\n\\n        jobs = []\\n        output_queue = multiprocessing.Queue()\\n\\n        for ensemble_chunk in chunker(ensemble_list, ncpu):\\n            p = multiprocessing.Process(target=evaluate,\\n                                        args=(molecules, ensemble_chunk, sort_order, options, output_queue))\\n            jobs.append(p)\\n            p.start()\\n\\n        # collect results into a dictionary\\n        results = {}\\n        for i in range(len(jobs)):\\n            results.update(output_queue.get())\\n\\n        # stop jobs\\n        for j in jobs:\\n            j.join()\\n\\n    else:\\n        print(\"Determining the performance of {d} ensembles using {n} processor\".format(d=len(ensemble_list), n=ncpu))\\n        results = evaluate(molecules, ensemble_list, sort_order, options)\\n\\n    # peel away the best performing ensemble\\n    ensemble = screener.find_best_ensemble(results, options)\\n\\n    # write out the best performing ensemble\\n    output.write_ensemble(list(ensemble), options)\\n\\n    # temp 2/9/15 generate and return a list of auc values and ef at fpf = 0.001 to build up a histogram\\n    nd = max([results[x].ef.keys() for x in results.keys()][0])\\n    n = int(round(0.001 * nd))\\n    ef_list = [results[x].get_prop(n, \\'ef\\') for x in results.keys()]\\n    auc_list = [results[x].get_prop(\\'auc\\') for x in results.keys()]\\n    # auc_list = [[results[x].get_prop(\\'auc\\'), results[x].get_prop(\\'ensemble\\')] for x in results.keys()]\\n    return auc_list, ef_list',\n",
       " 'def evaluate(molecules, ensemble_chunk, sort_order, options, output_queue=None):\\n    \"\"\"\\n\\tEvaluate VS performance of each ensemble in ensemble_chunk\\n\\t\"\"\"\\n\\n    results = {}    # {(\\'receptor_1\\', ..., \\'receptor_n\\') : ensemble storage object}\\n\\n    for ensemble in ensemble_chunk:\\n        results[ensemble] = calculate_performance(molecules, ensemble, sort_order, options)\\n\\n    if output_queue is not None:\\n        output_queue.put(results)\\n    else:\\n        return results',\n",
       " 'def make_ensemble_list(molecules, score_field, ensemble_size):\\n    \"\"\"\\n\\tConstruct ensemble list\\n\\t\"\"\"\\n\\n    # generate list of queries\\n    queryList = molecules[0].scores.keys()\\n\\n    # nchoosek\\n    ensemble_iterator = itertools.combinations(queryList, ensemble_size)\\n\\n    # list of tuples: [(query1, query2), ... (queryN-1, queryN)\\n    ensembleList = []\\n\\n    for ensemble in ensemble_iterator:\\n        ensembleList.append(ensemble)\\n\\n    return ensembleList',\n",
       " 'def chunker(ensemble_list, ncpu):\\n    \"\"\"\\n\\tGenerate successive chunks of ensemble_list.\\n\\t\"\"\"\\n\\n    # determine sublist lengths\\n    length = int(len(ensemble_list) / ncpu)\\n\\n    # generator\\n    for i in range(0, len(ensemble_list), length):\\n        yield ensemble_list[i:i + length]',\n",
       " 'def fasta_verifier(entries, ambiguous=False):\\n    \"\"\"Raises error if invalid FASTA format detected\\n\\n    Args:\\n        entries (list): A list of FastaEntry instances\\n\\n        ambiguous (bool): Permit ambiguous bases, i.e. permit non-ACGTU bases\\n\\n    Raises:\\n        FormatError: Error when FASTA format incorrect with descriptive message\\n\\n    Example:\\n        >>> from bio_utils.iterators import fasta_iter\\n        >>> import os\\n        >>> entries = r\\'>entry1{0}AAGGATTCG{0}\\' \\\\\\n        ...           r\\'>entry{0}AGGTCCCCCG{0}\\' \\\\\\n        ...           r\\'>entry3{0}GCCTAGC{0}\\'.format(os.linesep)\\n        >>> fasta_entries = fasta_iter(iter(entries.split(os.linesep)))\\n        >>> fasta_verifier(fasta_entries)\\n    \"\"\"\\n\\n    if ambiguous:\\n        regex = r\\'^>.+{0}[ACGTURYKMSWBDHVNX]+{0}$\\'.format(os.linesep)\\n    else:\\n        regex = r\\'^>.+{0}[ACGTU]+{0}$\\'.format(os.linesep)\\n    delimiter = r\\'{0}\\'.format(os.linesep)\\n\\n    for entry in entries:\\n        try:\\n            entry_verifier([entry.write()], regex, delimiter)\\n        except FormatError as error:\\n            if error.part == 0:\\n                msg = \\'Unknown Header Error with {0}\\'.format(entry.id)\\n                raise FormatError(message=msg)\\n            elif error.part == 1 and ambiguous:\\n                msg = \\'{0} contains a base not in \\' \\\\\\n                      \\'[ACGTURYKMSWBDHVNX]\\'.format(entry.id)\\n                raise FormatError(message=msg)\\n            elif error.part == 1 and not ambiguous:\\n                msg = \\'{0} contains a base not in \\' \\\\\\n                      \\'[ACGTU]\\'.format(entry.id)\\n                raise FormatError(message=msg)\\n            else:\\n                msg = \\'{0}: Unknown Error: Likely a Bug\\'.format(entry.id)\\n                raise FormatError(message=msg)',\n",
       " \"def guard(params, guardian, error_class=GuardError, message=''):\\n    '''\\n    A guard function - check parameters\\n    with guardian function on decorated function\\n\\n    :param tuple or string params: guarded function parameter/s\\n    :param function guardian: verifying the conditions for the selected parameter\\n    :param Exception error_class: raised class when guardian return false\\n    :param string message: error message\\n    '''\\n    params = [params] if isinstance(params, string_types) else params\\n\\n    def guard_decorate(f):\\n        @wraps(f)\\n        def _guard_decorate(*args, **kwargs):\\n            if guardian(**_params(f, args, kwargs, params)):\\n                return f(*args, **kwargs)\\n            else:\\n                raise error_class(message)\\n        return _guard_decorate\\n    return guard_decorate\",\n",
       " 'def main(dimension, iterations):\\n    \"\"\" Main function for PSO optimizer example.\\n\\n    Instantiate PSOOptimizer to optimize 30-dimensional spherical function.\\n    \"\"\"\\n    optimizer = PSOOptimizer()\\n    solution = optimizer.minimize(sphere, -5.12, 5.12, dimension,\\n                                  max_iterations(iterations))\\n    return solution, optimizer',\n",
       " 'def get_last_commit_message(self):\\n        \"\"\"\\n        Gets the last commit message on the active branch\\n\\n        Returns None if not in a git repo\\n        \"\"\"\\n        # Check if we are currently in a repo\\n        try:\\n            branch = self.active_branch\\n            return self.commit(branch).message\\n        except InvalidGitRepositoryError:\\n            print \"Not in a git repo\"\\n            return None',\n",
       " 'def get_last_modified_timestamp(self):\\n        \"\"\"\\n        Looks at the files in a git root directory and grabs the last modified timestamp\\n        \"\"\"\\n        cmd = \"find . -print0 | xargs -0 stat -f \\'%T@ %p\\' | sort -n | tail -1 | cut -f2- -d\\' \\'\"\\n        ps = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)\\n        output = ps.communicate()[0]\\n        print output',\n",
       " 'def find_config_root(path=sys.argv[0]):\\n    \"\"\"\\n    Finds config root relative to the given file path\\n    \"\"\"\\n    dirname = os.path.dirname(path)\\n    lastdirname = None\\n\\n    while dirname != lastdirname:\\n        config_root = os.path.join(dirname, \\'config\\')\\n        if os.path.exists(config_root):\\n            return config_root\\n\\n        lastdirname, dirname = dirname, os.path.dirname(dirname)',\n",
       " 'def restore_default(self, index):\\n        \"\"\"Set the value of the given index row to its default\\n\\n        :param index:\\n        :type index:\\n        :returns:\\n        :rtype:\\n        :raises:\\n        \"\"\"\\n        spec = self.get_configspec_str(index)\\n        if spec is None or isinstance(spec, Section):\\n            return\\n        try:\\n            default = self._vld.get_default_value(spec)\\n            defaultstr = self._val_to_str(default)\\n            self.setData(index, defaultstr)\\n        except KeyError:\\n            raise ConfigError(\"Missing Default Value in spec: \\\\\"%s\\\\\"\" % spec)',\n",
       " 'def get_value(self, index):\\n        \"\"\" Return the value of the given index\\n\\n        The index stores the section as internal pointer.\\n        The row of the index determines the key.\\n        The key is used on the section to return the value\\n\\n        :param index: The QModelIndex\\n        :type index: QModelIndex\\n        :returns: The value for the given index\\n        \"\"\"\\n        p = index.internalPointer()\\n        k = self.get_key(p, index.row())\\n        return p[k]',\n",
       " 'def get_configspec_str(self, index):\\n        \"\"\" Return the config spec string of the given index\\n\\n        The index stores the section as internal pointer.\\n        The row of the index determines the key.\\n        The section stores the spec in its configspec attribute\\n        The key is used on the configspec attribute to return the spec\\n\\n        :param index: The QModelIndex\\n        :type index: QModelIndex\\n        :returns: The spec for the given index or None\\n        \"\"\"\\n        p = index.internalPointer()\\n        if p is None:\\n            return\\n        spec = p.configspec\\n        if spec is None:\\n            return None\\n        k = self.get_key(p, index.row())\\n        try:\\n            return spec[k]\\n        except KeyError:\\n            return None',\n",
       " 'def _val_to_str(self, value):\\n        \"\"\"Converts the value to a string that will be handled correctly by the confobj\\n\\n        :param value: the value to parse\\n        :type value: something configobj supports\\n        :returns: str\\n        :rtype: str\\n        :raises: None\\n\\n        When the value is a list, it will be converted to a string that can be parsed to\\n        the same list again.\\n        \"\"\"\\n        # might be a list value\\n        # then represent it \\'nicer\\' so that when we edit it, the same value will return\\n        if isinstance(value, list):\\n            # so we have a list value. the default str(v) would produce something like: [\\'a\\', \\'b\\']\\n            # handling such a value is not possible. it should be: \\'a\\', \\'b\\'\\n            # so we have to convert it to a string but we have to make sure, we do not loose quotes\\n            # even when values are integers, they get quoted. thats alright. the config obj will parse them correctly\\n            return \\', \\'.join(\"\\'%s\\'\" % str(i) for i in value)\\n        return str(value)',\n",
       " 'def set_index_edited(self, index, edited):\\n        \"\"\"Set whether the conf was edited or not.\\n\\n        Edited files will be displayed with a \\\\\\'*\\\\\\'\\n\\n        :param index: the index that was edited\\n        :type index: QModelIndex\\n        :param edited: if the file was edited, set edited to True, else False\\n        :type edited: bool\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self.__edited[index.row()] = edited\\n        self.dataChanged.emit(index, index)',\n",
       " 'def get_edited(self, ):\\n        \"\"\"Return all indices that were modified\\n\\n        :returns: list of indices for modified confs\\n        :rtype: list of QModelIndex\\n        :raises: None\\n        \"\"\"\\n        modified = []\\n        for i in range(len(self.__edited)):\\n            if self.__edited[i]:\\n                modified.append(self.__configs[i])\\n        return modified',\n",
       " 'def validate(self, index):\\n        \"\"\"Validate the conf for the given index\\n\\n        :param index: the index of the model to validate\\n        :type index: QModelIndex\\n        :returns: True if passed and a False/True dict representing fail/pass. The structure follows the configobj. If the configobj does not have a configspec True is returned.\\n        :rtype: True|Dict\\n        :raises: None\\n        \"\"\"\\n        c = self.__configs[index.row()]\\n        if c.configspec is None:\\n            return True\\n        else:\\n            return c.validate(self.vld)',\n",
       " 'def metapolicy(request, permitted, domains=None):\\n    \"\"\"\\n    Serves a cross-domain policy which can allow other policies\\n    to exist on the same domain.\\n\\n    Note that this view, if used, must be the master policy for the\\n    domain, and so must be served from the URL ``/crossdomain.xml`` on\\n    the domain: setting metapolicy information in other policy files\\n    is forbidden by the cross-domain policy specification.\\n\\n    **Required arguments:**\\n\\n    ``permitted``\\n        A string indicating the extent to which other policies are\\n        permitted. A set of constants is available in\\n        ``flashpolicies.policies``, defining acceptable values for\\n        this argument.\\n\\n    **Optional arguments:**\\n\\n    ``domains``\\n        A list of domains from which to allow access. Each value may\\n        be either a domain name (e.g., ``example.com``) or a wildcard\\n        (e.g., ``*.example.com``). Due to serious potential security\\n        issues, it is strongly recommended that you not use wildcard\\n        domain values.\\n\\n    \"\"\"\\n    if domains is None:\\n        domains = []\\n    policy = policies.Policy(*domains)\\n    policy.metapolicy(permitted)\\n    return serve(request, policy)',\n",
       " 'def _run_popen(command, print_output=False):\\n    \"\"\"\\n    subprocess has the most terrible interface ever.\\n    Envoy is an option but too heavyweight for this.\\n    This is a convenience wrapper around subprocess.Popen.\\n\\n    Also, this merges STDOUT and STDERR together, since\\n    there isn\\'t a good way of interleaving them without\\n    threads.\\n    \"\"\"\\n    output = \\'\\'\\n    po = subprocess.Popen(\\n        command,\\n        stdout=subprocess.PIPE,\\n        stderr=subprocess.STDOUT,\\n    )\\n    fcntl.fcntl(\\n        po.stdout.fileno(),\\n        fcntl.F_SETFL,\\n        fcntl.fcntl(po.stdout.fileno(), fcntl.F_GETFL) | os.O_NONBLOCK,\\n    )\\n    while po.poll() is None:\\n        stream = po.stdout\\n        readx = select.select([stream.fileno()], [], [])[0]\\n        if readx:\\n            chunk = stream.read()\\n            output += chunk\\n            if print_output:\\n                print chunk\\n    return Result(output, po.returncode)',\n",
       " 'def perimeter(patch, world_size=(60, 60),\\n              neighbor_func=get_rook_neighbors_toroidal):\\n    \"\"\"\\n    Count cell faces in patch that do not connect to part of patch.\\n    This preserves various square geometry features that would not\\n    be preserved by merely counting the number of cells that touch\\n    an edge.\\n    \"\"\"\\n    edge = 0\\n    patch = set([tuple(i) for i in patch])\\n    for cell in patch:\\n        neighbors = neighbor_func(cell, world_size)\\n        neighbors = [n for n in neighbors if n not in patch]\\n        edge += len(neighbors)\\n\\n    return edge',\n",
       " 'def traverse_core(core_area, world_size=(60, 60),\\n                  neighbor_func=get_moore_neighbors_toroidal):\\n    \"\"\"\\n    Treat cells in core_area like a graph and traverse it to\\n    see how many connected components there are.\\n    \"\"\"\\n\\n    if not core_area:\\n        return []\\n    core_area = [tuple(i) for i in core_area]\\n    curr = core_area[0]\\n    core_area = set(core_area[1:])\\n    to_explore = []\\n    cores = [[curr]]\\n\\n    while core_area:\\n        neighbors = neighbor_func(curr, world_size)\\n\\n        for n in neighbors:\\n            if n in core_area:\\n                core_area.remove(n)\\n                to_explore.append(n)\\n                cores[-1].append(n)\\n\\n        if to_explore:\\n            curr = to_explore.pop()\\n        else:\\n            curr = core_area.pop()\\n            cores.append([curr])\\n\\n    return cores',\n",
       " 'def parse_command_line_args():\\n    \"\"\"parse command line args\"\"\"\\n    parser = argparse.ArgumentParser(description=\\'PipApp. {}\\'.format(DESCRIPTION))\\n    parser.add_argument(\\n        \\'-d\\', \\'--dir\\',\\n        metavar=\\'DIR\\',\\n        help=\\'Root directory where to create new project files and dirs. Default is current directory.\\'\\n    )\\n    parser.add_argument(\\n        \\'-v,\\', \\'--version\\',\\n        action=\\'version\\',\\n        version=\\'{} v{}\\'.format(PROGRAMNAME, VERSION)\\n    )\\n    parser.add_argument(\\n        \"project_name\",\\n        metavar=\\'PROJECTNAME\\',\\n        help=\"Name of the generated Project. Has to be a valid Python identifier.\"\\n    )\\n    return parser.parse_args()',\n",
       " 'def requirements(collector):\\n    \"\"\"Just print out the requirements\"\"\"\\n    out = sys.stdout\\n    artifact = collector.configuration[\\'dashmat\\'].artifact\\n    if artifact not in (None, \"\", NotSpecified):\\n        if isinstance(artifact, six.string_types):\\n            out = open(artifact, \\'w\\')\\n        else:\\n            out = artifact\\n\\n    for active in collector.configuration[\\'__imported__\\'].values():\\n        for requirement in active.requirements():\\n            out.write(\"{0}\\\\n\".format(requirement))',\n",
       " 'def run_checks(collector):\\n    \"\"\"Just run the checks for our modules\"\"\"\\n    artifact = collector.configuration[\"dashmat\"].artifact\\n    chosen = artifact\\n    if chosen in (None, \"\", NotSpecified):\\n        chosen = None\\n\\n    dashmat = collector.configuration[\"dashmat\"]\\n    modules = collector.configuration[\"__active_modules__\"]\\n    config_root = collector.configuration[\"config_root\"]\\n    module_options = collector.configuration[\"modules\"]\\n\\n    datastore = JsonDataStore(os.path.join(config_root, \"data.json\"))\\n    if dashmat.redis_host:\\n        datastore = RedisDataStore(redis.Redis(dashmat.redis_host))\\n\\n    scheduler = Scheduler(datastore)\\n\\n    for name, module in modules.items():\\n        if chosen is None or name == chosen:\\n            server = module.make_server(module_options[name].server_options)\\n            scheduler.register(module, server, name)\\n\\n    scheduler.twitch(force=True)',\n",
       " 'def list_npm_modules(collector, no_print=False):\\n    \"\"\"List the npm modules that get installed in a docker image for the react server\"\"\"\\n    default = ReactServer().default_npm_deps()\\n    for _, module in sorted(collector.configuration[\"__active_modules__\"].items()):\\n        default.update(module.npm_deps())\\n\\n    if not no_print:\\n        print(json.dumps(default, indent=4, sort_keys=True))\\n    return default',\n",
       " 'def collect_dashboard_js(collector):\\n    \"\"\"Generate dashboard javascript for each dashboard\"\"\"\\n    dashmat = collector.configuration[\"dashmat\"]\\n\\n    modules = collector.configuration[\"__active_modules__\"]\\n    compiled_static_prep = dashmat.compiled_static_prep\\n    compiled_static_folder = dashmat.compiled_static_folder\\n\\n    npm_deps = list_npm_modules(collector, no_print=True)\\n    react_server = ReactServer()\\n    react_server.prepare(npm_deps, compiled_static_folder)\\n\\n    for dashboard in collector.configuration[\"dashboards\"].values():\\n        log.info(\"Generating compiled javascript for dashboard:{0}\".format(dashboard.path))\\n        filename = dashboard.path.replace(\"_\", \"__\").replace(\"/\", \"_\")\\n        location = os.path.join(compiled_static_folder, \"dashboards\", \"{0}.js\".format(filename))\\n        if os.path.exists(location):\\n            os.remove(location)\\n        generate_dashboard_js(dashboard, react_server, compiled_static_folder, compiled_static_prep, modules)',\n",
       " 'def read_file(file, filename=\\'<input>\\'):\\n    \"\"\"This is a generator that yields all top-level S-expression nodes from\\n    a given file object.\"\"\"\\n    reader = Reader(filename)\\n    for line in file:\\n        yield from reader.feed_line(line)\\n    reader.finish()',\n",
       " 'def _feed_node(self, value, loc):\\n        \"\"\"A helper method called when an S-expression has been recognized.\\n        Like feed_line, this is a generator that yields newly recognized\\n        top-level expressions.  If the reader is currently at the top level,\\n        simply yields the passed expression.  Otherwise, it appends it\\n        to whatever is currently being parsed and yields nothing.\\n        \"\"\"\\n        node = GenericNode(value, loc)\\n        if not self.stack:\\n            yield node\\n        else:\\n            top = self.stack[-1]\\n            if isinstance(top, StackEntryList):\\n                top.items.append(node)\\n            elif isinstance(top, StackEntryComment):\\n                self.stack.pop()\\n            else:\\n                assert 0',\n",
       " 'def run_until_complete(self):\\n        \"\"\"Run loop until all futures are done.\\n\\n        Schedule futures for execution and wait until all are done.\\n        Return value from future, or list of values if multiple\\n        futures had been passed to constructor or gather method.\\n\\n        All results will be in the same order as order of futures passed to constructor.\\n\\n        :Example:\\n\\n        .. code-block:: python\\n\\n            >>> async def slow():\\n            ...     await ultra_slow_task()\\n            ...     return \\'ultra slow\\'\\n            ...\\n            >>> async def fast():\\n            ...     await the_fastest_task_on_earth()\\n            ...\\n            >>> with Loop(slow(), fast()) as loop:\\n            ...     result = loop.run_until_complete()\\n            ...\\n            >>> result\\n            [\\'ultra slow\\', None]\\n\\n\\n        :return: Value from future or list of values.\\n        :rtype: None, list, Any\\n        \"\"\"\\n        try:\\n            result = self.loop.run_until_complete(self.futures)\\n        except asyncio.futures.CancelledError:\\n            return None\\n        else:\\n            if self.ft_count == 1:\\n                return result[0]\\n            return result',\n",
       " 'def get_irregular_vertex(bgedge):\\n    \"\"\"\\n    This method is called only in irregular edges in current implementation, thus at least one edge will be irregular\\n    \"\"\"\\n    if not bgedge.is_irregular_edge:\\n        raise Exception(\"trying to retrieve an irregular vertex from regular edge\")\\n    return bgedge.vertex1 if bgedge.vertex1.is_irregular_vertex else bgedge.vertex2',\n",
       " \"def from_coordinates(cls,   ra=None, dec=None,\\n                                distance=None,\\n                                pm_ra_cosdec=None, pm_dec=None,\\n                                radial_velocity=None,\\n                                obstime=2000.0*u.year,\\n                                id=None, mag=None,\\n                                **kwargs):\\n        '''\\n        Iniitalize a constellation object.\\n\\n\\n        Parameters\\n        ----------\\n\\n        ra, dec, distance, pm_ra_cosdec, pm_dec, radial_velocity\\n            These must be able to initialize a SkyCoord.\\n        id : list, array\\n            Identifications for the entries.\\n        mag : list, array\\n            Magnitudes for the entries.\\n        **kwargs\\n            All arguments and keyword arguments are passed along\\n            to SkyCoord. They can be coordinates in the first place,\\n            or, for example, ra and dec with units, or any other\\n            inputs that can initialize a SkyCoord.\\n        '''\\n\\n        # make sure we can initialzie some coordinates\\n        # coordinates = coord.SkyCoord(ra=ra, dec=dec, distance=distance, pm_ra_cosdec=pm_ra_cosdec, pm_dec=pm_dec, radial_velocity=radial_velocity)\\n\\n\\n        N = len(np.atleast_1d(ra))\\n        if id is None:\\n            id = ['{}'.format(i) for i in range(N)]\\n        if mag is None:\\n            mag = np.zeros(N)\\n        standardized = Table(data=[id, mag], names=['object-id', 'filter-mag'])\\n\\n        for k in cls.coordinate_keys:\\n            if locals()[k] is not None:\\n                standardized[k] = locals()[k]\\n\\n        return cls(standardized)\",\n",
       " \"def to_text(self, filename=None, overwrite=True):\\n        '''\\n        Write this catalog out to a text file.\\n        '''\\n\\n        table = self.standardized\\n        #table = hstack([self.identifiers,\\n        #                self._coordinate_table(),\\n        #                self.magnitudes,\\n        #                self.errors])\\n\\n        if filename == None:\\n            filename = '{}.txt'.format(self.name)\\n        self.speak('saving to {}'.format(filename))\\n        table.write(filename, format='ascii.ecsv', overwrite=overwrite)\",\n",
       " \"def plot(self, sizescale=10, color=None, alpha=0.5, label=None, edgecolor='none', **kw):\\n        '''\\n        Plot the ra and dec of the coordinates,\\n        at a given epoch, scaled by their magnitude.\\n\\n        (This does *not* create a new empty figure.)\\n\\n        Parameters\\n        ----------\\n        sizescale : (optional) float\\n            The marker size for scatter for a star at the magnitudelimit.\\n        color : (optional) any valid color\\n            The color to plot (but there is a default for this catalog.)\\n        **kw : dict\\n            Additional keywords will be passed on to plt.scatter.\\n\\n        Returns\\n        -------\\n\\n        plotted : outputs from the plots\\n        '''\\n        # calculate the sizes of the stars (logarithmic with brightness?)\\n        size = np.maximum(sizescale*(1 + self.magnitudelimit - self.magnitude), 1)\\n\\n        # make a scatter plot of the RA + Dec\\n        scatter = plt.scatter(self.ra, self.dec,\\n                                    s=size,\\n                                    color=color or self.color,\\n                                    label=label or '{} ({:.1f})'.format(self.name, self.epoch),\\n                                    alpha=alpha,\\n                                    edgecolor=edgecolor,\\n                                    **kw)\\n\\n        return scatter\",\n",
       " \"def animate(self, filename='constellation.mp4', epochs=[1900,2100], dt=5, dpi=300, fps=10, **kw):\\n        '''\\n        Animate a finder chart.\\n        '''\\n\\n        scatter = self.finder(**kw)\\n        plt.tight_layout()\\n        figure = plt.gcf()\\n\\n        if '.gif' in filename:\\n            try:\\n                writer = ani.writers['pillow'](fps=fps)\\n            except (RuntimeError, KeyError):\\n                writer = ani.writers['imagemagick'](fps=fps)\\n            except:\\n                raise RuntimeError('This python seems unable to make an animated gif.')\\n        else:\\n            try:\\n                writer = ani.writers['ffmpeg'](fps=fps)\\n            except (RuntimeError,KeyError):\\n                raise RuntimeError('This computer seems unable to ffmpeg.')\\n\\n\\n        with writer.saving(figure, filename, dpi or figure.get_dpi()):\\n            for epoch in tqdm(np.arange(epochs[0], epochs[1]+dt, dt)):\\n\\n                # update the illustration to a new time\\n                coords = self.atEpoch(epoch)\\n                scatter.set_offsets(list(zip(coords.ra.value, coords.dec.value)))\\n                plt.title('{} in {:.1f}'.format(self.name, epoch))\\n\\n                writer.grab_frame()\",\n",
       " 'def get_gitdir(self):\\n        \"\"\"Determine the git repository for this request\"\"\"\\n        if self.gitlookup is None:\\n            raise tornado.web.HTTPError(500, \\'no git lookup configured\\')\\n\\n        gitdir = self.gitlookup(self.request)\\n        if gitdir is None:\\n            raise tornado.web.HTTPError(404, \\'unable to find repository\\')\\n        logger.debug(\"Accessing git at: %s\", gitdir)\\n\\n        return gitdir',\n",
       " 'def get_last_data(self, uuid, period=0, average_by=0):\\n        \"\"\"\\n        Get the data from one device for period till now.\\n\\n        :param uuid: Id of the device\\n        :type uuid: str\\n        :param period: Number of seconds between start time of search and now\\n        :type period: integer\\n        :param average_by: amount of seconds to average data over.\\n            0 or 300 for no average. Use 3600 (average hourly) or a multiple for\\n            long range requests (e.g. more than 1 day)\\n        :type average_by: integer\\n        :returns: list of datapoints\\n        :raises: ClientError, AuthFailure, BadFormat, ForbiddenAccess,\\n                 TooManyRequests, InternalError\\n\\n        .. note::\\n            Use period = 0 and averageBy = 0 to get the very last data point.\\n            If you only need one average for a period, the average_by needs to\\n            be bigger than the period (eg, for a 10 minutes average: period = 600,\\n            average_by = 601)\\n\\n        .. seealso:: :func:`parse_data` for return data syntax\\n        \"\"\"\\n        return self.parse_data((yield from self._get(\\n            LAST_DATA_URL.format(uuid= uuid,\\n                period= trunc(period),\\n                average_by= trunc(average_by)))))',\n",
       " 'def get_historical_data(self, uuid, start, end, average_by=0):\\n        \"\"\"\\n        Get the data from one device for a specified time range.\\n\\n        .. note::\\n            Can fetch a maximum of 42 days of data.\\n            To speed up query processing, you can use a combination of average factor\\n            multiple of 1H in seconds (e.g. 3600), and o\\'clock start and end times\\n\\n        :param uuid: Id of the device\\n        :type uuid: str\\n        :param start: start of the range\\n        :type start: datetime\\n        :param end: end of the range\\n        :type end: datetime\\n        :param average_by: amount of seconds to average data over.\\n            0 or 300 for no average. Use 3600 (average hourly) or a multiple for\\n            long range requests (e.g. more than 1 day)\\n        :type average_by: integer\\n        :returns: list of datapoints\\n        :raises: ClientError, AuthFailure, BadFormat, ForbiddenAccess,\\n                 TooManyRequests, InternalError\\n\\n        .. seealso:: :func:`parse_data` for return data syntax\\n        \"\"\"\\n        return self.parse_data((yield from self._get(\\n            HISTORICAL_DATA_URL.format(uuid= uuid,\\n                start = trunc(start.replace(tzinfo=timezone.utc).timestamp()),\\n                end = trunc(end.replace(tzinfo=timezone.utc).timestamp()),\\n                average_by= trunc(average_by)))))',\n",
       " 'def parse_data(self, response):\\n        \"\"\"\\n        Convert the weird list format used for datapoints to a more usable\\n        dictionnary one \\n\\n        :param response: dictionnary from API json response\\n        :type response: dict\\n        :returns: list of datapoints\\n\\n        .. note::\\n            Datapoint content:\\n                * time: UTC timestamp, unit: seconds\\n                * pm: Particulate Matter, unit: ugm3\\n                * tmp: temperature, unit: C\\n                * hum: humidity, unit: %\\n                * co2: Carbon Dioxide, unit: ppm\\n                * voc: Volatile Organic Compounds, unit: ppb\\n                * allpollu: `foobot index <https://help.foobot.io/hc/en-us/articles/204814371-What-does-central-number-mean->`_, unit: %\\n        \"\"\"\\n        parsed = []\\n        try:\\n            items = response[\\'sensors\\']\\n            for datapoint in response[\\'datapoints\\']:\\n                line = {}\\n                for index, data in enumerate(datapoint):\\n                    line[items[index]] = data\\n                parsed.append(line)\\n            return parsed\\n        except (KeyError, IndexError, TypeError):\\n            raise FoobotClient.InvalidData()',\n",
       " 'def metaclass(self):\\n        \"\"\"Get a metaclass configured to use this registry.\"\"\"\\n        if \\'_metaclass\\' not in self.__dict__:\\n            self._metaclass = type(\\'PermissionsMeta\\', (PermissionsMeta,), {\\'registry\\': self})\\n        return self._metaclass',\n",
       " 'def register(self, perm_func=None, model=None, allow_staff=None, allow_superuser=None,\\n                 allow_anonymous=None, unauthenticated_handler=None, request_types=None, name=None,\\n                 replace=False, _return_entry=False):\\n        \"\"\"Register permission function & return the original function.\\n\\n        This is typically used as a decorator::\\n\\n            permissions = PermissionsRegistry()\\n            @permissions.register\\n            def can_do_something(user):\\n                ...\\n\\n        For internal use only: you can pass ``_return_entry=True`` to\\n        have the registry :class:`.Entry` returned instead of\\n        ``perm_func``.\\n\\n        \"\"\"\\n        allow_staff = _default(allow_staff, self._allow_staff)\\n        allow_superuser = _default(allow_superuser, self._allow_superuser)\\n        allow_anonymous = _default(allow_anonymous, self._allow_anonymous)\\n        unauthenticated_handler = _default(unauthenticated_handler, self._unauthenticated_handler)\\n        request_types = _default(request_types, self._request_types)\\n\\n        if perm_func is None:\\n            return (\\n                lambda perm_func_:\\n                    self.register(\\n                        perm_func_, model, allow_staff, allow_superuser, allow_anonymous,\\n                        unauthenticated_handler, request_types, name, replace, _return_entry)\\n            )\\n\\n        name = _default(name, perm_func.__name__)\\n        if name == \\'register\\':\\n            raise PermissionsError(\\'register cannot be used as a permission name\\')\\n        elif name in self._registry and not replace:\\n            raise DuplicatePermissionError(name)\\n\\n        view_decorator = self._make_view_decorator(\\n            name, perm_func, model, allow_staff, allow_superuser, allow_anonymous,\\n            unauthenticated_handler, request_types)\\n        entry = Entry(\\n            name, perm_func, view_decorator, model, allow_staff, allow_superuser, allow_anonymous,\\n            unauthenticated_handler, request_types, set())\\n        self._registry[name] = entry\\n\\n        @wraps(perm_func)\\n        def wrapped_func(user, instance=NO_VALUE):\\n            if user is None:\\n                return False\\n            if not allow_anonymous and user.is_anonymous():\\n                return False\\n            test = lambda: perm_func(user) if instance is NO_VALUE else perm_func(user, instance)\\n            return (\\n                allow_staff and user.is_staff or\\n                allow_superuser and user.is_superuser or\\n                test()\\n            )\\n\\n        register.filter(name, wrapped_func)\\n\\n        log.debug(\\'Registered permission: {0}\\'.format(name))\\n        return entry if _return_entry else wrapped_func',\n",
       " 'def require(self, perm_name, **kwargs):\\n        \"\"\"Use as a decorator on a view to require a permission.\\n\\n        Optional args:\\n\\n            - ``field`` The name of the model field to use for lookup\\n              (this is only relevant when requiring a permission that\\n              was registered with ``model=SomeModelClass``)\\n\\n        Examples::\\n\\n            @registry.require(\\'can_do_stuff\\')\\n            def view(request):\\n                ...\\n\\n            @registry.require(\\'can_do_stuff_with_model\\', field=\\'alt_id\\')\\n            def view_model(request, model_id):\\n                ...\\n\\n        \"\"\"\\n        view_decorator = self._get_entry(perm_name).view_decorator\\n        return view_decorator(**kwargs) if kwargs else view_decorator',\n",
       " 'def entry_for_view(self, view, perm_name):\\n        \"\"\"Get registry entry for permission if ``view`` requires it.\\n\\n        In other words, if ``view`` requires the permission specified by\\n        ``perm_name``, return the :class:`Entry` associated with the\\n        permission. If ``view`` doesn\\'t require the permission, return\\n        ``None`` instead.\\n\\n        \"\"\"\\n        view_name = self._get_view_name(view)\\n        entry = self._get_entry(perm_name)\\n        if view_name in entry.views:\\n            return entry\\n        return None',\n",
       " 'def get_importer(self):\\n        \"\"\"\\n        Resolve importer from TRACK_IMPORTER_CLASS setting.\\n        \"\"\"\\n        try:\\n            importer_path = settings.TRACK_IMPORTER_CLASS\\n        except AttributeError:\\n            raise ImproperlyConfigured(\\'No TRACK_IMPORTER_CLASS setting found.\\')\\n        try:\\n            dot = importer_path.rindex(\\'.\\')\\n        except ValueError:\\n            raise ImproperlyConfigured(\\'%s isn\\\\\\'t a Track Importer module.\\' % importer_path)\\n        module, classname = importer_path[:dot], importer_path[dot+1:]\\n        try:\\n            mod = import_module(module)\\n        except ImportError, e:\\n            raise ImproperlyConfigured(\\'Could not import Track Importer %s: \"%s\".\\' % (module, e))\\n        try:\\n            importer_class = getattr(mod, classname)\\n        except AttributeError:\\n            raise ImproperlyConfigured(\\'Track Importer module \"%s\" does not define a \"%s\" class.\\' % (module, classname))\\n   \\n        importer_instance = importer_class()\\n        if not hasattr(importer_instance, \\'run\\'):\\n            raise ImproperlyConfigured(\\'Track Importer class \"%s\" does not define a run method. Implement the method to return a list of Track objects.\\' % classname)\\n        \\n        return importer_instance',\n",
       " 'def lookup_track(self, track):\\n        \"\"\"\\n        Looks up Django Track object for provided raw importing track object.\\n        \"\"\"\\n        tracks = Track.objects.filter(title__iexact=track.title)\\n        for track_obj in tracks:\\n            for contributor in track_obj.get_primary_contributors(permitted=False):\\n                if contributor.title == track.artist:\\n                    return track_obj\\n        return None',\n",
       " 'def run(self):\\n        \"\"\"\\n        Run import.\\n        \"\"\"\\n        latest_track = Track.objects.all().order_by(\\'-last_played\\')\\n        latest_track = latest_track[0] if latest_track else None\\n        \\n        importer = self.get_importer()\\n        tracks = importer.run()\\n\\n        # Create/update Django Track objects for importer tracks.\\n        for track in tracks:\\n            # Only create/update if tracks with start times greater than what already exists are imported. \\n            if not latest_track or not latest_track.last_played \\\\\\n                    or track.start_time > latest_track.last_played:\\n                obj = self.lookup_track(track)\\n                # Don\\'t update importing track that is regarded as the latest. This prevents start times from constantly incrementing.\\n                if latest_track and obj == latest_track:\\n                    print \"[%s-%s]: Start time not updated as it is the latest track.\" % (track.title, track.artist)\\n                    continue\\n\\n                # If no existing track object could be resolved, create it.\\n                if not obj:\\n                    print \"[%s-%s]: Created.\" % (track.title, track.artist)\\n                    obj = Track.objects.create(title=track.title)\\n                    obj.length = track.length\\n                    roles = MusicCreditOption.objects.all().order_by(\\'role_priority\\') \\n                    role = roles[0].role_priority if roles else 1\\n                    obj.create_credit(track.artist, role)\\n                else:\\n                    print \"[%s-%s]: Not created as it already exists.\" % (track.title, track.artist)\\n                \\n                # Update last played time to start time.\\n                obj.last_played = track.start_time\\n                obj.save()\\n                print \"[%s-%s]: Start time updated to %s.\" % (track.title, track.artist, track.start_time)\\n            else:\\n                print \"[%s-%s]: Not created as it has a past start time of %s (latest %s). \" % (track.title, track.artist, track.start_time, latest_track.last_played)',\n",
       " 'def match_value_by_name(expected_type, actual_value):\\n        \"\"\"\\n        Matches expected type to a type of a value.\\n\\n        :param expected_type: an expected type name to match.\\n\\n        :param actual_value: a value to match its type to the expected one.\\n\\n        :return: true if types are matching and false if they don\\'t.\\n        \"\"\"\\n        if expected_type == None:\\n            return True\\n        if actual_value == None:\\n            raise Exception(\"Actual value cannot be null\")\\n\\n        return TypeMatcher.match_type_by_name(expected_type, type(actual_value))',\n",
       " 'def match_type_by_name(expected_type, actual_type):\\n        \"\"\"\\n        Matches expected type to an actual type.\\n\\n        :param expected_type: an expected type name to match.\\n\\n        :param actual_type: an actual type to match defined by type code.\\n\\n        :return: true if types are matching and false if they don\\'t.\\n        \"\"\"\\n        if expected_type == None:\\n            return True\\n        if actual_type == None:\\n            raise Exception(\"Actual type cannot be null\")\\n        \\n        expected_type = expected_type.lower()\\n\\n        if actual_type.__name__.lower() == expected_type: \\n            return True\\n        elif expected_type == \"object\":\\n            return True\\n        elif expected_type == \"int\" or expected_type == \"integer\":\\n            return issubclass(actual_type, int) #or issubclass(actual_type, long)\\n        elif expected_type == \"long\":\\n            return issubclass(actual_type, int)\\n        elif expected_type == \"float\" or expected_type == \"double\":\\n            return issubclass(actual_type, float)\\n        elif expected_type == \"string\":\\n            return issubclass(actual_type, str) #or issubclass(actual_type, unicode)\\n        elif expected_type == \"bool\" or expected_type == \"boolean\":\\n            return issubclass(actual_type, bool)\\n        elif expected_type == \"date\" or expected_type == \"datetime\":\\n            return issubclass(actual_type, datetime.datetime) or issubclass(actual_type. datetime.date)\\n        elif expected_type == \"timespan\" or expected_type == \"duration\":\\n            return issubclass(actual_type, int) or issubclass(actual_type, float)\\n        elif expected_type == \"enum\":\\n            return issubclass(actual_type, str) or issubclass(actual_type, int)\\n        elif expected_type == \"map\" or expected_type == \"dict\" or expected_type == \"dictionary\":\\n            return issubclass(actual_type, dict)\\n        elif expected_type == \"array\" or expected_type == \"list\":\\n            return issubclass(actual_type, list) or issubclass(actual_type, tuple) or issubclass(actual_type, set)\\n        elif expected_type.endswith(\"[]\"):\\n            # Todo: Check subtype\\n            return issubclass(actual_type, list) or issubclass(actual_type, tuple) or issubclass(actual_type, set)\\n        else:\\n            return False',\n",
       " 'def blob(self, request, pk=None):\\n        \"\"\"\\n        fetch large object from pg and gives it back to user via HTTP 1.1\\n        request\\n\\n        :param request: django request instance\\n        :param pk: requested resource primary key\\n        :rtype: django.http.HttpResponse\\n        :rtype: HttpResponse\\n        :return: file with its filename stored in database\\n        \"\"\"\\n        obj = self.get_object_or_none()\\n        if obj:\\n            blob = obj.get_blob_data()\\n            content_type = \\'octet/stream\\'\\n            response = HttpResponse(blob, content_type=content_type,\\n                                    status=status.HTTP_200_OK)\\n            response[\\'Content-Disposition\\'] = (\\n                \\'attachment; filename=\"%s\"\\' % obj.name\\n            )\\n            return response\\n        return HttpResponse(\\'404\\', status=status.HTTP_404_NOT_FOUND,\\n                            content_type=\\'application/json\\')',\n",
       " 'def _get_github(self):\\n        \"\"\"Creates an instance of github.Github to interact with the repos via the \\n        API interface in pygithub.\\n        \"\"\"\\n        from github import Github\\n        vms(\"Querying github with user \\'{}\\'.\".format(self.username))\\n        g = Github(self.username, self.apikey)\\n        self._user = g.get_user()\\n        if self._user is None:\\n            raise ValueError(\"Can\\'t authenticate to github with \\'{}\\'.\".format(self.username))\\n        #The github user authenticating always has to be specified; however the user\\n        #may not be able to see the repo, even if it has access to it. We may need\\n        #to check the organization repos.\\n        if self.organization is not None:\\n            self._org = g.get_organization(self.organization)\\n            vms(\"Found github organization \\'{}\\'.\".format(self._org.name), 2)\\n\\n            #Next we need to find this repository in the lists available to both\\n            #the user *and* the organization. If they specified an organization, then we\\n            #should check that first/exclusively.\\n            for repo in self._org.get_repos():\\n                if repo.full_name.lower() == self.name.lower():\\n                    self._repo = repo\\n                    vms(\"Found organization repository \\'{}\\'.\".format(self._repo.full_name), 2)\\n                    break\\n        else:\\n            for repo in self._user.get_repos():\\n                if repo.full_name.lower() == self.name.lower():\\n                    self._repo = repo\\n                    vms(\"Found user repository \\'{}\\'.\".format(self._repo.full_name), 2)\\n                    break',\n",
       " 'def _parse_xml(self):\\n        \"\"\"Extracts the XML settings into class instances that can operate on\\n        the settings to perform the testing functions.\\n        \"\"\"\\n        import xml.etree.ElementTree as ET\\n        from os import path\\n        #This dict has the keys of XML tags that are required in order for the\\n        #CI server to run the repo. When each one is parsed, we change its value\\n        #to True and then check that they are all true at the end.\\n        required = {\"testing\": False, \"wiki\": False}\\n        #Make sure the file exists and then import it as XML and read the values out.\\n        if path.isfile(self.filepath):\\n            tree = ET.parse(self.filepath)\\n            vms(\"Parsing XML tree from {}.\".format(self.filepath), 2)\\n            root = tree.getroot()\\n            if root.tag != \"cirepo\":\\n                raise ValueError(\"The root tag in a continuous integration settings XML \"\\n                                 \"file should be a <cirepo> tag.\")\\n\\n            self._parse_repo(root)\\n            for child in root:\\n                if child.tag == \"cron\":\\n                    if self.server is not None:\\n                        self.server.cron.settings[self.name] = CronSettings(child)\\n                if child.tag == \"testing\":\\n                    self.testing = TestingSettings(child)\\n                if child.tag == \"static\":\\n                    self.static = StaticSettings(child)\\n                if child.tag == \"wiki\":\\n                    self.wiki[\"user\"] = get_attrib(child, \"user\", \"wiki\")\\n                    self.wiki[\"password\"] = get_attrib(child, \"password\", \"wiki\")\\n                    self.wiki[\"basepage\"] = get_attrib(child, \"basepage\", \"wiki\")\\n                if child.tag in required:\\n                    required[child.tag] = True\\n\\n            if not all(required.values()):\\n                tags = \\', \\'.join([\"<{}>\".format(t) for t in required])\\n                raise ValueError(\"{} are required tags in the repo\\'s XML settings file.\".format(tags))',\n",
       " 'def _parse_xml(self, xml):\\n        \"\"\"Extracts the attributes from the XMLElement instance.\"\"\"\\n        from re import split\\n        vms(\"Parsing <cron> XML child tag.\", 2)\\n        self.frequency = get_attrib(xml, \"frequency\", default=5, cast=int)\\n        self.emails = split(\",\\\\s*\", get_attrib(xml, \"emails\", default=\"\"))\\n        self.notify = split(\",\\\\s*\", get_attrib(xml, \"notify\", default=\"\"))',\n",
       " 'def _parse_xml(self, xml):\\n        \"\"\"Extracts objects representing and interacting with the settings in the\\n        xml tag.\\n        \"\"\"\\n        vms(\"Parsing <static> XML child tag.\", 2)\\n        for child in xml:\\n            if \"path\" in child.attrib and \"target\" in child.attrib:\\n                if child.tag == \"file\":\\n                    self.files.append({\"source\": child.attrib[\"path\"],\\n                                       \"target\": child.attrib[\"target\"]})\\n                elif child.tag == \"folder\":\\n                    self.folders.append({\"source\": child.attrib[\"path\"],\\n                                         \"target\": child.attrib[\"target\"]})',\n",
       " 'def copy(self, repodir):\\n        \"\"\"Copies the static files and folders specified in these settings into the\\n        locally-cloned repository directory.\\n\\n        :arg repodir: the full path to the directory with the locally-cloned version\\n          of the pull request being unit tested.\\n        \"\"\"\\n        #Instead of using the built-in shell copy, we make shell calls to rsync.\\n        #This allows us to copy only changes across between runs of pull-requests.\\n        from os import system, path\\n        vms(\"Running static file copy locally.\", 2)\\n        for file in self.files:\\n            fullpath = path.expanduser(file[\"source\"])\\n            if path.isfile(fullpath):\\n                vms(\"Running \\'rsync\\' for {}.\".format(fullpath), 3)\\n                system(\"rsync -t -u {} {}\".format(fullpath, get_repo_relpath(repodir, file[\"target\"])))\\n\\n        for folder in self.folders:\\n            fullpath = path.expanduser(folder[\"source\"])\\n            if path.isdir(fullpath):\\n                vms(\"Running \\'rsync\\' for {}.\".format(fullpath), 3)\\n                system(\"rsync -t -u -r {} {}\".format(path.join(fullpath, \"\"),\\n                                                     path.join(get_repo_relpath(repodir, folder[\"target\"]), \"\")))',\n",
       " 'def serial(self):\\n        \"\"\"Returns true if the CI server should run in serial mode.\\n        \"\"\"\\n        serial = self.property_get(\"SERIAL\", False)\\n        if isinstance(serial, str):\\n            return serial.lower() == \"true\"\\n        else:\\n            return serial',\n",
       " 'def var_replace(self, text):\\n        \"\"\"Replaces all instances of @VAR with their values in the specified text.\\n        \"\"\"\\n        result = text\\n        for var in self._vardict:\\n            result = result.replace(\"@{}\".format(var), self._vardict[var])\\n        return result',\n",
       " 'def get_or_create_iobject(identifier_uid,\\n                          identifier_namespace_uri,\\n                          iobject_type_name,\\n                          iobject_type_namespace_uri,\\n                          iobject_type_revision_name,\\n                          iobject_family_name,\\n                          iobject_family_revision_name=\"\",\\n                          identifier_namespace_name=\"\",\\n                          timestamp=None,\\n                          create_timestamp=None,\\n                          overwrite=False,\\n                          dingos_class_map=dingos_class_map):\\n    \"\"\"\\n    Get or create an information object.\\n    \"\"\"\\n\\n    # create or retrieve the iobject type and revision\\n\\n    # create or retrieve identifier\\n\\n    if not timestamp:\\n        raise StandardError(\"You must supply a timestamp.\")\\n\\n    id_namespace, created = dingos_class_map[\\'IdentifierNameSpace\\'].objects.get_or_create(uri=identifier_namespace_uri)\\n\\n    if created and identifier_namespace_name:\\n        id_namespace.name = identifier_namespace_name\\n        id_namespace.save()\\n\\n    identifier, created = dingos_class_map[\\'Identifier\\'].objects.get_or_create(uid=identifier_uid,\\n                                                                              namespace=id_namespace,\\n                                                                              defaults={\\'latest\\': None})\\n\\n    iobject_type_namespace, created = dingos_class_map[\\'DataTypeNameSpace\\'].objects.get_or_create(uri=iobject_type_namespace_uri)\\n\\n    iobject_family, created = dingos_class_map[\\'InfoObjectFamily\\'].objects.get_or_create(name=iobject_family_name)\\n    iobject_family_revision, created = dingos_class_map[\\'Revision\\'].objects.get_or_create(\\n        name=iobject_family_revision_name)\\n\\n    # create or retrieve the iobject type\\n    iobject_type, created = dingos_class_map[\\'InfoObjectType\\'].objects.get_or_create(name=iobject_type_name,\\n                                                                                    iobject_family=iobject_family,\\n                                                                                    namespace=iobject_type_namespace)\\n    iobject_type_revision, created = dingos_class_map[\\'Revision\\'].objects.get_or_create(name=iobject_type_revision_name)\\n\\n    if not create_timestamp:\\n        create_timestamp = timezone.now()\\n    #if not timestamp:\\n    #    timestamp = create_timestamp\\n    #    iobject = overwrite\\n    #    created = False\\n\\n\\n\\n    iobject, created = dingos_class_map[\"InfoObject\"].objects.get_or_create(identifier=identifier,\\n                                                                           timestamp=timestamp,\\n                                                                           defaults={\\'iobject_family\\': iobject_family,\\n                                                                                     \\'iobject_family_revision\\': iobject_family_revision,\\n                                                                                     \\'iobject_type\\': iobject_type,\\n                                                                                     \\'iobject_type_revision\\': iobject_type_revision,\\n                                                                                     \\'create_timestamp\\': create_timestamp})\\n    if created:\\n        iobject.set_name()\\n        iobject.save()\\n        identifier.latest = iobject\\n        identifier.save()\\n\\n\\n    elif overwrite:\\n        iobject.timestamp = timestamp\\n        iobject.create_timestamp = create_timestamp\\n        iobject.iobject_family = iobject_family\\n        iobject.iobject_family_revision = iobject_family_revision\\n        iobject.iobject_type = iobject_type\\n        iobject.iobject_type_revision = iobject_type_revision\\n        iobject.set_name()\\n        iobject.save()\\n\\n    logger.debug(\\n        \"Created iobject id with %s , ts %s (created was %s) and overwrite as %s\" % (iobject.identifier, timestamp, created, overwrite))\\n    return iobject, created',\n",
       " 'def get_or_create_fact(fact_term,\\n                       fact_dt_name=\\'String\\',\\n                       fact_dt_namespace_uri=DINGOS_NAMESPACE_URI,\\n                       values=None,\\n                       value_iobject_id=None,\\n                       value_iobject_ts=None,\\n                       ):\\n    \"\"\"\\n    Get or create a fact object.\\n    \"\"\"\\n\\n    if not values:\\n        values = []\\n\\n\\n    vocab_namespace, created = dingos_class_map[\\'DataTypeNameSpace\\'].objects.get_or_create(uri=fact_dt_namespace_uri)\\n\\n    fact_data_type, created = dingos_class_map[\\'FactDataType\\'].objects.get_or_create(name=fact_dt_name,\\n                                                                                    namespace=vocab_namespace)\\n\\n    # Maybe we already have a fact with exactly the same fact term and the same fact values?\\n    # We start by looking at the number of values\\n\\n    value_objects = []\\n\\n    for value in values:\\n        storage_location=dingos.DINGOS_VALUES_TABLE\\n        # collect (create or get) the required value objects\\n        if value == None:\\n            value = \\'\\'\\n        if isinstance(value,tuple):\\n            # If a value is wrapped in a tuple, the second component of the tuple\\n            # specifies the storage location of the value.\\n            value, storage_location = value\\n\\n        if storage_location == dingos.DINGOS_VALUES_TABLE:\\n            # If the value is larger than a given size, the value is written to disk, instead.\\n            # We use this to keep too large values out of the database. Depending on how the\\n            # database is set up, this may be necessary to allow indexing, which in turn is\\n            # required to check uniqueness on values.\\n\\n            if len(value) > dingos.DINGOS_MAX_VALUE_SIZE_WRITTEN_TO_VALUE_TABLE:\\n                (value_hash,storage_location) = write_large_value(value)\\n                value = value_hash\\n\\n\\n        fact_value, created = dingos_class_map[\\'FactValue\\'].objects.get_or_create(value=value,\\n                                                                                 fact_data_type=fact_data_type,\\n                                                                                 storage_location=storage_location)\\n        value_objects.append(fact_value)\\n\\n\\n\\n    # Do we already have a fact with given fact term and given values?\\n    #\\n    # For understanding the query below better, see https://groups.google.com/forum/#!topic/django-users/X9TCSrBn57Y.\\n    # The double query is necessary, because the first count counts the number of selected\\n    # fact_value objects, not the number of total objects for each fact.\\n\\n\\n    possibly_matching_facts = Fact.objects.filter(fact_values__in=value_objects,\\n                                                  value_iobject_id=value_iobject_id,\\n                                                  value_iobject_ts=value_iobject_ts,\\n                                                  fact_term=fact_term\\n    ).values_list(\\'pk\\',flat=True)\\n\\n    matching_facts = Fact.objects.filter(pk__in=list(possibly_matching_facts)). \\\\\\n        annotate(num_values=Count(\\'fact_values\\')). \\\\\\n        filter(num_values=len(value_objects)). \\\\\\n        exclude(id__in= \\\\\\n        Fact.objects.filter(pk__in=possibly_matching_facts).annotate(total_values=Count(\\'fact_values\\')). \\\\\\n            filter(total_values__gt=len(value_objects)))\\n\\n    # Below, for educational purposes, the original query until Dingos 0.2.0, which got *really*\\n    # slow with lot\\'s of objects in the system. The reason for this are the last three lines:\\n    # the exclude-statement required the database to count the the number of values for each\\n    # Fact in the system... but we are really only interested into facts with the same\\n    # fact_term, value_iobject_id and value_iobject_ts...\\n\\n    #matching_facts = Fact.objects.filter(fact_values__in=value_objects). \\\\\\n    #    annotate(num_values=Count(\\'fact_values\\')). \\\\\\n    #    filter(num_values=len(value_objects)). \\\\\\n    #    filter(value_iobject_id=value_iobject_id). \\\\\\n    #    filter(value_iobject_ts=value_iobject_ts). \\\\\\n    #    filter(fact_term=fact_term). \\\\\\n    #    exclude(id__in= \\\\\\n    #    Fact.objects.annotate(total_values=Count(\\'fact_values\\')). \\\\\\n    #        filter(total_values__gt=len(value_objects)))\\n\\n    created = True\\n    try:\\n        fact_obj = matching_facts[0]\\n        created = False\\n        logger.debug(\"FOUND MATCHING OBJECT with pk %s\" % fact_obj.pk)\\n    except:\\n        fact_obj = dingos_class_map[\\'Fact\\'].objects.create(fact_term=fact_term,\\n                                                          value_iobject_id=value_iobject_id,\\n                                                          value_iobject_ts=value_iobject_ts,\\n                                                           )\\n\\n        fact_obj.fact_values.add(*value_objects)\\n        fact_obj.save()\\n\\n\\n    return fact_obj, created',\n",
       " 'def get_or_create_fact_term(iobject_family_name,\\n                            fact_term_name,\\n                            fact_term_attribute,\\n                            iobject_type_name,\\n                            iobject_type_namespace_uri,\\n                            fact_dt_name=DINGOS_DEFAULT_FACT_DATATYPE,\\n                            fact_dt_namespace_name=None,\\n                            fact_dt_kind=FactDataType.UNKNOWN_KIND,\\n                            fact_dt_namespace_uri=DINGOS_NAMESPACE_URI,\\n                            dingos_class_map=dingos_class_map\\n):\\n    \"\"\"\\n    Get or create a fact term.\\n    \"\"\"\\n\\n    if not fact_term_attribute:\\n        fact_term_attribute = \\'\\'\\n\\n    # create or retrieve the enrichment type and revision\\n\\n    iobject_family, created = dingos_class_map[\\'InfoObjectFamily\\'].objects.get_or_create(name=iobject_family_name)\\n\\n    # create or retrieve namespace of data type\\n\\n    fact_dt_namespace, created = dingos_class_map[\\'DataTypeNameSpace\\'].objects.get_or_create(uri=fact_dt_namespace_uri)\\n\\n    # create or retrieve namespace of the infoobject type\\n\\n    iobject_type_namespace, created = dingos_class_map[\\'DataTypeNameSpace\\'].objects.get_or_create(uri=iobject_type_namespace_uri)\\n\\n    if created and fact_dt_namespace_name:\\n        fact_dt_namespace.name = fact_dt_namespace_name\\n        fact_dt_namespace.save()\\n\\n\\n    # create or retrieve the fact-value data type object\\n    fact_dt, created = dingos_class_map[\\'FactDataType\\'].objects.get_or_create(name=fact_dt_name,\\n                                                                              namespace=fact_dt_namespace)\\n\\n    if created:\\n        fact_dt.kind = fact_dt_kind\\n        fact_dt.save()\\n\\n    # create or retreive the iobject type\\n    iobject_type, created = dingos_class_map[\\'InfoObjectType\\'].objects.get_or_create(name=iobject_type_name,\\n                                                                                    iobject_family=iobject_family,\\n                                                                                    namespace=iobject_type_namespace)\\n\\n    fact_term, created = dingos_class_map[\\'FactTerm\\'].objects.get_or_create(term=fact_term_name,\\n                                                                           attribute=fact_term_attribute)\\n\\n    fact_term_2_type, dummy = dingos_class_map[\\'FactTerm2Type\\'].objects.get_or_create(fact_term=fact_term,\\n                                                                                     iobject_type=iobject_type,\\n                                                                                     )\\n\\n    fact_term_2_type.fact_data_types.add(fact_dt)\\n\\n    fact_term_2_type.save()\\n\\n    return fact_term, created',\n",
       " 'def marking_thru(self):\\n        \"\"\"\\n        Return the back-pointer to  markings that\\n        may have been attached via Django\\'s content type mechanism.\\n        \"\"\"\\n        self_django_type = ContentType.objects.get_for_model(self)\\n        return Marking2X.objects.filter(content_type__pk=self_django_type.id,\\n                                        object_id=self.id)',\n",
       " 'def embedded_in(self):\\n        \"\"\"\\n        Used in the view for the InfoObject (in order to be able to use the standard class-based object view.\\n        Should be removed from here and put into a proper custom view for the object.\\n\\n        This query only returns embedding objects of the latest revision: to change\\n        this, the filter \\'iobject__timestamp=F(\\'iobject__identifier__latest__timestamp\\' must\\n        be removed.\\n        \"\"\"\\n\\n        return self._DCM[\\'InfoObject2Fact\\']. \\\\\\n            objects. \\\\\\n            filter(fact__value_iobject_id=self.identifier). \\\\\\n            filter(iobject__timestamp=F(\\'iobject__identifier__latest__timestamp\\')). \\\\\\n            order_by(\\'-iobject__timestamp\\') \\\\\\n            .values_list(\\n            \\'iobject\\',\\n            \\'iobject__identifier__namespace__uri\\',\\n            \\'iobject__identifier__uid\\',\\n            \\'iobject__timestamp\\',\\n            \\'iobject__name\\',\\n            \\'fact__value_iobject_ts\\',\\n            \\'fact__fact_term__term\\', \\n            \\'node_id__name\\').distinct()',\n",
       " 'def set_name(self,name=None):\\n        \"\"\"\\n        Set the name of the object. If no name is given, the\\n        name is extracted via the extract_name method.\\n        \"\"\"\\n        if name:\\n            self.name = name[:254]\\n        else:\\n            self.name = self.extract_name()[:254]\\n\\n        self.save()\\n\\n        return self.name',\n",
       " 'def add_relation(self,\\n                     target_id=None,\\n                     relation_types=None,\\n                     fact_dt_namespace_name=None,\\n                     fact_dt_namespace_uri=DINGOS_NAMESPACE_URI,\\n                     fact_dt_kind=FactDataType.UNKNOWN_KIND,\\n                     fact_dt_name=\\'String\\',\\n                     metadata_dict=None,\\n                     markings=None\\n    ):\\n        \"\"\"\\n        Add a relationship between this object and another object.\\n        \"\"\"\\n        if not markings:\\n            markings = []\\n\\n        if relation_types == None:\\n            relation_types = []\\n\\n        # Create fact-term for relation types\\n        relation_type_ft, created = get_or_create_fact_term(iobject_family_name=self.iobject_family.name,\\n                                                            fact_term_name=DINGOS_RELATION_TYPE_FACTTERM_NAME,\\n                                                            iobject_type_name=self.iobject_type.name,\\n                                                            iobject_type_namespace_uri=self.iobject_type.namespace.uri,\\n                                                            fact_dt_name=fact_dt_name,\\n                                                            fact_dt_namespace_name=fact_dt_namespace_name,\\n                                                            fact_dt_kind=fact_dt_kind,\\n                                                            fact_dt_namespace_uri=fact_dt_namespace_uri)\\n\\n        # Create fact containing relation types\\n        relation_type_fact, created = get_or_create_fact(fact_term=relation_type_ft,\\n                                                         fact_dt_name=fact_dt_name,\\n                                                         fact_dt_namespace_uri=fact_dt_namespace_uri,\\n                                                         values=relation_types,\\n                                                         value_iobject_id=None,\\n                                                         value_iobject_ts=None,\\n                                                         )\\n\\n        rel_target_id = target_id\\n        rel_source_id = self.identifier\\n\\n        # Create relation object\\n        relation, created = self._DCM[\\'Relation\\'].objects.get_or_create(\\n            source_id=rel_source_id,\\n            target_id=rel_target_id,\\n            relation_type=relation_type_fact)\\n\\n        # Add markings\\n        for marking in markings:\\n            Marking2X.objects.create(marked=relation,\\n                                     marking=marking)\\n\\n        if metadata_dict:\\n            # If the relation already existed and had associated metadata,\\n            # we retrieve the identifier of that metadata object and\\n            # write the current metadata as new revision. Otherwise,\\n            # we create a new identifier.\\n\\n            if relation.metadata_id:\\n                rel_identifier_uid = relation.metadata_id.uid\\n                rel_identifier_namespace_uri = relation.metadata_id.namespace.uri\\n            else:\\n                rel_identifier_uid = None\\n                rel_identifier_namespace_uri = DINGOS_ID_NAMESPACE_URI\\n\\n            metadata_iobject, created = get_or_create_iobject(identifier_uid=rel_identifier_uid,\\n                                                              identifier_namespace_uri=rel_identifier_namespace_uri,\\n                                                              iobject_type_name=DINGOS_RELATION_METADATA_OBJECT_TYPE_NAME,\\n                                                              iobject_type_namespace_uri=DINGOS_NAMESPACE_URI,\\n                                                              iobject_type_revision_name=DINGOS_REVISION_NAME,\\n                                                              iobject_family_name=DINGOS_IOBJECT_FAMILY_NAME,\\n                                                              iobject_family_revision_name=DINGOS_REVISION_NAME,\\n                                                              timestamp=None,\\n                                                              overwrite=False)\\n            metadata_iobject.from_dict(metadata_dict)\\n\\n        return relation',\n",
       " 'def _load_data(self):\\n        \"\"\"\\n        Load data from raw_data or file_path\\n        \"\"\"\\n        if self.raw_data is None and self.data_format is not FormatType.PYTHON:\\n            if self.file_path is None:\\n                raise ArgumentInvalid(\\'One of \"raw_data\" or \"file_path\" should be set!\\')\\n            if not os.path.isfile(self.file_path) or not os.access(self.file_path, os.R_OK):\\n                raise ArgumentInvalid(\\'\"file_path\" should be a valid path to an exist file with read permission!\\')\\n            with open(self.file_path) as f:\\n                self.raw_data = f.read()',\n",
       " 'def _validate(self):\\n        \"\"\"\\n        Validate the input data.\\n        \"\"\"\\n        if self.data_format is FormatType.PYTHON:\\n            self.data = self.raw_data\\n        elif self.data_format is FormatType.JSON:\\n            self._validate_json()\\n        elif self.data_format is FormatType.YAML:\\n            self._validate_yaml()',\n",
       " 'def match(pattern, text, no_escape=False, path_name=True, wild_star=True, period=False,\\n          case_fold=False):\\n    u\"\"\"\\n    Matches text against the supplied wildmatch pattern.\\n\\n    To get git\\'s behavior, use the `wild_star` flag.\\n\\n    Note that the EXTMATCH (ksh extended glob patterns) option is not available\\n\\n    :type pattern: text_type\\n    :param pattern: A wildmatch pattern\\n    :type text: text_type\\n    :param text: The text to match\\n    :type no_escape: bool\\n    :param no_escape: Disable backslash escaping\\n    :type path_name: bool\\n    :param path_name: Separator (slash) in text cannot be matched by an asterisk, question-mark nor\\n                      bracket expression in pattern (only a literal).\\n    :type wild_star: bool\\n    :param wild_star: A True value forces the `path_name` flag to True. This allows the\\n                      double-asterisk `**` to match any (0 to many) number of directories\\n    :type period: bool\\n    :param period: A leading period in text cannot be matched by an asterisk, question-mark nor\\n                   bracket expression in pattern (only a literal). A period is \"leading\" if:\\n                   - it is the first character of `text`\\n                   OR\\n                   - path_name (or wild_star) is True and the previous character is a slash\\n    :type case_fold: bool\\n    :param case_fold: Perform a case insensitive match (GNU Extension)\\n    :rtype: bool\\n    :return: Result of the match\\n    \"\"\"\\n\\n    regex = translate(pattern, no_escape=no_escape, path_name=path_name, wild_star=wild_star,\\n                      period=period, case_fold=case_fold, closed_regex=True)\\n    return regex.match(text) is not None',\n",
       " 'def filter(self, texts):\\n        u\"\"\"\\n        Returns a generator yielding the elements of `texts` matching this pattern.\\n\\n        :type texts: typing.Iterable[text_type]\\n        :param texts: An iterable collection of texts to match\\n        :rtype: typing.Iterable[text_type]\\n        :return: A generator of filtered elements.\\n        \"\"\"\\n        return (text for text in texts if self.regex.match(text) is not None)',\n",
       " \"def imagesc(data, title=None, fig='current', ax=None):\\n  '''Simple alias for a Matlab-like imshow function.'''\\n  ax = _get_axis(fig, ax, False)\\n  ax.imshow(data, interpolation='nearest', aspect='auto')\\n  if title:\\n    ax.set_title(title)\\n  return plt.show\",\n",
       " \"def vector_field(points, directions, title=None, fig='current', ax=None,\\n                 edge_style='k-', vertex_style='o'):\\n  '''Plots vectors that start at 'points', and move along 'directions'.'''\\n  assert points.shape[1] in (2,3) and directions.shape == points.shape\\n  ax = _get_axis(fig, ax, points.shape[1] == 3)\\n  # Plot.\\n  if points.shape[1] == 2:\\n    x,y = points.T\\n    dx,dy = directions.T\\n    if hasattr(ax, 'zaxis'):  # Must be on a 3d plot axis, so supply zeros.\\n      _quiver3d(ax, x, y, 0, dx, dy, 0, arrow_length_ratio=0.1)\\n    else:\\n      args = (x, y, dx, dy)\\n      ax.quiver(*args, angles='xy', scale_units='xy', scale=1, headwidth=5)\\n    if vertex_style is not None:\\n      ax.scatter(x, y, marker=vertex_style, zorder=2, edgecolor='none')\\n  else:\\n    x,y,z = points.T\\n    dx,dy,dz = directions.T\\n    _quiver3d(ax, x, y, z, dx, dy, dz, arrow_length_ratio=0.1)\\n    if vertex_style is not None:\\n      ax.scatter(x, y, z, marker=vertex_style, zorder=2, edgecolor='none')\\n  if title:\\n    ax.set_title(title)\\n  return plt.show\",\n",
       " 'def read_passwd_file(pass_file):\\n    \"\"\"Read password from external file and retrun as string. The file should\\n    contain just single line. Prevents hard-coding password anywhere in this\\n    script. IMPORTANT! Password is stored as plain text! Do NOT use with your\\n    personal account!\"\\n\\n    Args:\\n        pass_file (str): /path/to/pass_file\\n    \"\"\"\\n    with open(pass_file) as fin:\\n        passwd = fin.read().strip()\\n    return passwd',\n",
       " 'def send_mail(to_addr,\\n              subj_msg,\\n              body_msg,\\n              attach_path,\\n              serv_addr,\\n              serv_port,\\n              from_addr,\\n              passwd):\\n    \"\"\"Send an e-mail message using smtplib and email standard python libraries.\\n    IMPORTANT! Password is stored as plain text! Do NOT use with your personal\\n    account!\\n\\n    Args:\\n        to_addr (str): Recipient address.\\n        subj_msg (str): Message subject.\\n        body_msg (str): Message body.\\n        serv_addr (str): Server\\'s address. Default: <smtp.gmail.com>.\\n        serv_port (int): Server\\'s port. Default: <587>.\\n        from_addr (str): Account address. Default: <headnode.notifiy@gmail.com>.\\n        passwd (str): Account password.\\n    \"\"\"\\n    msg = MIMEMultipart()\\n    if attach_path is not None:\\n        with open(attach_path, \"rb\") as fin:\\n            part = MIMEBase(\"application\", \"octet-stream\")\\n            part.set_payload(fin.read())\\n            encoders.encode_base64(part)\\n            part.add_header(\"Content-Disposition\",\\n                            \"attachment; filename={0}\".format(attach_path))\\n            msg.attach(part)\\n    else:\\n        pass\\n    msg[\"From\"] = from_addr\\n    msg[\"To\"] = to_addr\\n    msg[\"Subject\"] = subj_msg\\n    msg.attach(MIMEText(body_msg, \"plain\"))\\n    server = smtplib.SMTP(serv_addr, serv_port)\\n    server.starttls()\\n    server.login(from_addr, passwd)\\n    text_msg = msg.as_string()\\n    server.sendmail(from_addr, to_addr, text_msg)\\n    server.quit',\n",
       " 'def roc_calculator(screened_molecules, status_field, active_label, decoy_label):\\n    \"\"\"\\n    Calculates ROC curve\\n    \"\"\"\\n\\n    P = 0  # Total no. of actives\\n    N = 0  # Total no. of decoys\\n    tpf = [];\\n    tpf.append(0)  # true positive fraction list\\n    fpf = [];\\n    fpf.append(0)  # false positive fraction list\\n    fpindex = []  # indeces where decoys are found are labeled \\'1\\'\\n\\n    # Tally the # of positives & negatives at each threshold & in total\\n    for index in range(len(screened_molecules)):\\n        if screened_molecules[index].GetProp(status_field) == active_label and index == 0:\\n            tpf[index] = float(1)\\n            P = P + 1\\n            fpindex.append(0)\\n        elif screened_molecules[index].GetProp(status_field) == active_label and index > 0:\\n            tpf.append(float(tpf[index - 1] + 1))\\n            fpf.append(float(fpf[index - 1]))\\n            P = P + 1\\n            fpindex.append(0)\\n        elif screened_molecules[index].GetProp(status_field) == decoy_label and index == 0:\\n            fpf[index] = float(1)\\n            N = N + 1\\n            fpindex.append(1)\\n        elif screened_molecules[index].GetProp(status_field) == decoy_label and index > 0:\\n            fpf.append(float(fpf[index - 1] + 1))\\n            tpf.append(float(tpf[index - 1]))\\n            N = N + 1\\n            fpindex.append(1)\\n\\n    # calculate TPF & FPF\\n    for index in range(len(tpf)):\\n        tpf[index] = tpf[index] / P\\n        fpf[index] = fpf[index] / N\\n\\n    return tpf, fpf, P, N',\n",
       " 'def listen(identifier):\\n  \"\"\"\\n  Launch a listener and return the compactor context.\\n  \"\"\"\\n\\n  context = Context()\\n  process = WebProcess(identifier)\\n\\n  context.spawn(process)\\n\\n  log.info(\"Launching PID %s\", process.pid)\\n\\n  return process, context',\n",
       " 'def history(self):\\n        \"\"\"Get the latest 10 files uploaded to the account.\\n        Return a list of Puush File objects.\\n        \"\"\"\\n        res = self._api_request(\\'hist\\')\\n        if res[0][0] == \\'-1\\':\\n            raise PuushError(\"History retrieval failed.\")\\n        \\n        files = []\\n        for line in res[1:]:\\n            id, upload_time, url, filename, views, _ = line\\n            files.append(self._File(id, url, filename, upload_time, views))\\n        return files',\n",
       " 'def prepare_value(self, value):\\n        \"\"\"\\n        To avoid evaluating the lazysorted callable more than necessary to\\n        establish a potential initial value for the field, we do it here.\\n\\n        If there\\'s\\n        - only one template choice, and\\n        - the field is required, and\\n        - there\\'s no prior initial set (either by being bound or by being set\\n          higher up the stack\\n        then forcibly select the only \"good\" value as the default.\\n        \"\"\"\\n        if value is None and self.required:\\n            choices =list(self.choices)\\n            if len(choices) == 1:\\n                value = choices[0][0]\\n        return super(TemplateChoiceField, self).prepare_value(value)',\n",
       " 'def to_float_with_default(value, default_value):\\n        \"\"\"\\n        Converts value into float or returns default when conversion is not possible.\\n\\n        :param value: the value to convert.\\n\\n        :param default_value: the default value.\\n\\n        :return: float value or default value when conversion is not supported.\\n        \"\"\"\\n        result = FloatConverter.to_nullable_float(value)\\n        return result if result != None else default_value',\n",
       " 'def run(self):\\n        \"\"\"This method is run by a separated thread\"\"\"\\n        self.busy = True\\n\\n        for i in range(9):\\n            self.counter += 1\\n            time.sleep(0.5)\\n            pass\\n        self.counter += 1\\n        \\n        self.busy = False\\n        return',\n",
       " 'def get_info_field(prop):\\n        \"\"\"\\n        Return the info attribute of the given property\\n        \"\"\"\\n        if isinstance(prop, ColumnProperty):\\n            column = prop.columns[0]\\n\\n        elif isinstance(prop, RelationshipProperty):\\n            column = prop\\n\\n        return column.info',\n",
       " 'def add_item(self, sqla_col_type, item, key_specific=None):\\n        \"\"\"\\n        Add an item to the registry\\n        \"\"\"\\n        if key_specific is not None:\\n            self.setdefault(key_specific, {})[sqla_col_type] = item\\n        else:\\n            self[sqla_col_type] = item',\n",
       " 'def add_formatter(self, sqla_col_type, formatter, key_specific=None):\\n        \"\"\"\\n        Add a formatter to the registry\\n        if key_specific is provided, this formatter will only be used for some\\n        specific exports\\n        \"\"\"\\n        self.add_item(sqla_col_type, formatter, key_specific)',\n",
       " 'def setup_layout(self, orientation=None):\\n        \"\"\"Setup the layout for the tooltip in the given orientation\\n\\n        :param layout: the orentation of the layout\\n        :type layout: QtCore.Qt.Orientation | None\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if orientation == QtCore.Qt.Horizontal or orientation is None:\\n            layout = QtGui.QHBoxLayout()\\n        elif orientation == QtCore.Qt.Vertical:\\n            layout = QtGui.QVBoxLayout()\\n        else:\\n            raise TypeError(\\'Orientation is of wrong type! Allowed is QtCore.Qt.Horizontal and QtCore.Qt.Vertical. Given: %s\\' % orientation)\\n        layout.setContentsMargins(0, 0, 0, 0)\\n        layout.setSpacing(0)\\n        self.setLayout(layout)',\n",
       " 'def setup_size(self, width, height):\\n        \"\"\"Set the width and height for one cell in the tooltip\\n\\n        This is inderectly acomplished by setting the iconsizes for the buttons.\\n\\n        :param width: the width of one cell, min. is 7 -> icon width = 0\\n        :type width: int\\n        :param height: the height of one cell, min. is 6 -> icon height = 0\\n        :type height: int\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self._iconw = max(0, width - 7)\\n        self._iconh = max(0, height - 6)\\n        self.update_all_buttons()',\n",
       " 'def setup_cyatimer(self, interval):\\n        \"\"\"Setup the timer that will close the widget after the mouse left the widget for the time of interval\\n\\n        :param interval: the time that the tooltip waits before it dissapears in milliseconds\\n        :type interval: int\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self.cyatimer = QtCore.QTimer(self)\\n        self.cyatimer.setSingleShot(True)\\n        self.cyatimer.timeout.connect(self.hide)\\n        self._interval = interval',\n",
       " 'def event(self, event):\\n        \"\"\"Reimplementation of QWidget.event\\n\\n        The widget is closed, when the window is deactivated.\\n        The widget is closed after the set interval if the mouse leaves the widget.\\n        The timer is stops when the mouse enters the widget before the interval ends.\\n        On show, the added widgets are rendered for the tooltip into buttons. The buttons\\n        are used to set the widget in focus.\\n        \"\"\"\\n        if event.type() == QtCore.QEvent.WindowDeactivate:  # hide the tooltip\\n            self.cyatimer.stop()\\n            self.hide()\\n            return True\\n        if event.type() == QtCore.QEvent.Leave:  # start timer\\n            self.cyatimer.start(self._interval)\\n            return True\\n        if event.type() == QtCore.QEvent.Enter:  # reset/stop timer\\n            self.cyatimer.stop()\\n            return True\\n        if event.type() == QtCore.QEvent.Show:  # render the widgets\\n            self.cyatimer.stop()\\n            return True\\n        return super(WidgetToolTip, self).event(event)',\n",
       " 'def create_button(self, widget):\\n        \"\"\"Create a button that has the given widget rendered as an icon\\n\\n        :param widget: the widget to render as icon\\n        :type widget: QtGui.QWidget\\n        :returns: the created button\\n        :rtype: QtGui.QAbstractButton\\n        :raises: None\\n        \"\"\"\\n        btn = QtGui.QToolButton(self)\\n        btn.setIconSize(QtCore.QSize(self._iconw, self._iconh))\\n        self.update_button(btn, widget)\\n        return btn',\n",
       " 'def update_button(self, button, widget):\\n        \"\"\"Update the icon of the button with the given widget\\n\\n        if the widget does not is invalid, it is deleted from the tooltip automatically.\\n\\n        :param button: the button to update\\n        :type button: QtGui.QAbstractButton\\n        :param widget: the widget to render as icon\\n        :type widget: QtGui.QWidget\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if not shiboken.isValid(widget):\\n            self.remove_widget(widget)\\n            return\\n        button.setIconSize(QtCore.QSize(self._iconw, self._iconh))\\n        pix = QtGui.QPixmap(widget.size())\\n        widget.render(pix)\\n        icon = QtGui.QIcon(pix)\\n        button.setIcon(icon)',\n",
       " 'def update_all_buttons(self, ):\\n        \"\"\"Update all buttons\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        for widget, button in self._buttons.items():\\n            self.update_button(button, widget)\\n        self.adjustSize()',\n",
       " 'def focus_widget(self, checked=None, w=None):\\n        \"\"\"Focus the given widget. Checked is ignored and only used as a slot for QAbstractButton.clicked.\\n\\n        :param checked: The checked state of the button that was clicked\\n        :type checked: bool\\n        :param w: the widget to focus\\n        :type w: QtGui.QWidget\\n        :returns: None\\n        :raises: None\\n        \"\"\"\\n        if w is None:\\n            return\\n        if w.isMinimized():\\n            w.showNormal()\\n        else:\\n            w.show()\\n        w.activateWindow()\\n        w.setFocus()',\n",
       " 'def add_widget(self, widget):\\n        \"\"\"Add the given widget to the tooltip\\n\\n        :param widget: the widget to add\\n        :type widget: QtGui.QWidget\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if self._buttons.get(widget):\\n            return\\n        btn = self.create_button(widget)\\n        cb = partial(self.focus_widget, w=widget)\\n        btn.clicked.connect(cb)\\n        self.layout().addWidget(btn)\\n        self._buttons[widget] = btn',\n",
       " 'def remove_widget(self, widget):\\n        \"\"\"Remove the given widget from the tooltip\\n\\n        :param widget: the widget to remove\\n        :type widget: QtGui.QWidget\\n        :returns: None\\n        :rtype: None\\n        :raises: KeyError\\n        \"\"\"\\n        button = self._buttons.pop(widget)\\n        self.layout().removeWidget(button)\\n        button.deleteLater()',\n",
       " 'def eventFilter(self, watched, event):\\n        \"\"\"Filter ToolTip events and display this tooltip widget, if watched requests a tooltip.\\n\\n        :param watched: The watched object\\n        :type watched: QtCore.QObject\\n        :param event: The event sent by watched\\n        :type event: QtCore.QEvent\\n        :returns: True if the event was processed. False if the event should be passed on.\\n        :rtype: bool\\n        :raises: None\\n        \"\"\"\\n        if event.type() == self._triggerevent:\\n            self.show()\\n            return True\\n        else:\\n            return False',\n",
       " 'def get_position(self, ):\\n        \"\"\"Return a recommended position for this widget to appear\\n\\n        This implemenation returns a position so that the widget is vertically centerd on the mouse\\n        and 10 pixels left of the mouse\\n\\n        :returns: the position\\n        :rtype: QPoint\\n        :raises: None\\n        \"\"\"\\n        pos = QtGui.QCursor.pos()\\n        if self._alignment & QtCore.Qt.AlignLeft == QtCore.Qt.AlignLeft:\\n            pos.setX(pos.x() - self._offset)\\n        elif self._alignment & QtCore.Qt.AlignRight == QtCore.Qt.AlignRight:\\n            pos.setX(pos.x() - self.frameGeometry().width() + self._offset)\\n        elif self._alignment & QtCore.Qt.AlignHCenter == QtCore.Qt.AlignHCenter:\\n            pos.setX(pos.x() - self.frameGeometry().width()/2)\\n        if self._alignment & QtCore.Qt.AlignTop == QtCore.Qt.AlignTop:\\n            pos.setY(pos.y() - self._offset)\\n        elif self._alignment & QtCore.Qt.AlignBottom == QtCore.Qt.AlignBottom:\\n            pos.setY(pos.y() - self.frameGeometry().height() + self._offset)\\n        elif self._alignment & QtCore.Qt.AlignVCenter == QtCore.Qt.AlignVCenter:\\n            pos.setY(pos.y() - self.frameGeometry().height()/2)\\n        return pos',\n",
       " 'def show(self, ):\\n        \"\"\"Reimplementation that moves the tooltip and updates the buttons\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self.update_all_buttons()\\n        pos = self.get_position()\\n        self.move(pos)\\n        super(WidgetToolTip, self).show()',\n",
       " 'def show(self, ):\\n        \"\"\"Reimplementation of show to update all currently available JB_MainWindows\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        wins = set(JB_MainWindow.instances())\\n        widgets = set(self.get_widgets())\\n        for w in wins - widgets:\\n            self.add_widget(w)\\n        super(JB_WindowToolTip, self).show()',\n",
       " 'def get_issue(self, branch):\\n        \"\"\"\\n        Gets the JIRA issue associated with the branch name.\\n\\n        Returns None if no issue with this branch name.\\n        \"\"\"\\n        if branch:\\n            try:\\n                issue = self.issue(branch, expand=\\'changelog\\')\\n                return issue\\n            except jira.exceptions.JIRAError as ex:\\n                if ex.status_code == 404:\\n                    print \"No JIRA issue found for branch %s\" % branch\\n                else:\\n                    print str(ex)',\n",
       " 'def workflow_transition(self, issue, status_name):\\n        \"\"\"\\n        Change the status of a JIRA issue to a named status.  Will only be updated\\n        if this transition is available from the current status.\\n        \"\"\"\\n        transitions = self.transitions(issue)\\n        for transition in transitions:\\n            if transition[\\'to\\'][\\'name\\'] == status_name:\\n                transition_id = transition[\\'id\\']\\n                self.transition_issue(issue, transition_id)\\n                print \"Changed status of issue %s to %s\" % (issue.key, status_name)\\n                return True\\n\\n        print \"Unable to change status of issue %s to %s\" % (issue.key, status_name)',\n",
       " 'def get_datetime_issue_in_progress(self, issue):\\n        \"\"\"\\n        If the issue is in progress, gets that most recent time that the issue became \\'In Progress\\'\\n        \"\"\"\\n        histories = issue.changelog.histories\\n        for history in reversed(histories):\\n            history_items = history.items\\n            for item in history_items:\\n                if item.field == \\'status\\' and item.toString == \"In Progress\":\\n                    return dateutil.parser.parse(history.created)',\n",
       " 'def get_cycle_time(self, issue_or_start_or_key):\\n        \"\"\"\\n        Provided an issue or a start datetime, will return the cycle time since the start or progress\\n        \"\"\"\\n        if isinstance(issue_or_start_or_key, basestring):\\n            issue_or_start_or_key = self.get_issue(issue_or_start_or_key)\\n\\n        if isinstance(issue_or_start_or_key, jira.resources.Issue):\\n            progress_started = self.get_datetime_issue_in_progress(issue_or_start_or_key)\\n        elif isinstance(issue_or_start_or_key, datetime.datetime):\\n            progress_started = issue_or_start_or_key\\n\\n        curr_time = datetime.datetime.now(dateutil.tz.tzlocal())\\n        return utils.working_cycletime(progress_started, curr_time)',\n",
       " 'def get_week_avg_cycletime(self):\\n        \"\"\"\\n        Gets the average cycletime of the current user for the past week.\\n        This includes any ticket that was marked \"In Progress\" but not reopened.\\n        \"\"\"\\n        def moving_average(new_val, old_avg, prev_n):\\n            return (new_val + old_avg) / (prev_n + 1)\\n\\n        active_tickets_jql = \\'assignee=currentUser() and status was \"In Progress\" DURING (startOfWeek(), endofweek()) and status not in (Backlog, Open) ORDER BY updated DESC\\'\\n\\n        week_active_tickets = self.search_issues(active_tickets_jql)\\n\\n        avg_cycletime = 0\\n        n_issues = 0\\n        for issue in week_active_tickets:\\n            cycle_time = self.get_cycle_time(self.get_issue(issue.key))\\n            avg_cycletime = moving_average(cycle_time, avg_cycletime, n_issues)\\n            n_issues = n_issues + 1\\n\\n        return avg_cycletime',\n",
       " 'def b6_evalue_filter(handle, e_value, *args, **kwargs):\\n    \"\"\"Yields lines from handle with E-value less than or equal to e_value\\n\\n    Args:\\n        handle (file): B6/M8 file handle, can be any iterator so long as it\\n            it returns subsequent \"lines\" of a B6/M8 entry\\n\\n        e_value (float): max E-value to return\\n\\n        *args: Variable length argument list for b6_iter\\n\\n        **kwargs: Arbitrary keyword arguments for b6_iter\\n\\n    Yields:\\n        B6Entry: class containing all B6/M8 data\\n\\n    Example:\\n        Note: These doctests will not pass, examples are only in doctest\\n        format as per convention. bio_utils uses pytests for testing.\\n\\n        >>> b6_handle = open(\\'test.b6\\')\\n        >>> for entry in b6_evalue_filter(b6_handle, 1e5)\\n        ...     print(entry.evalue)  # Print E-value of filtered entry\\n    \"\"\"\\n\\n    for entry in b6_iter(handle, *args, **kwargs):\\n        if entry.evalue <= e_value:\\n            yield entry',\n",
       " 'def value(self):\\n        \"\"\"\\n        Return the current evaluation of a condition statement\\n        \"\"\"\\n        return \\'\\'.join(map(str, self.evaluate(self.trigger.user)))',\n",
       " 'def get_judged_identifiers(input_file):\\n    \"\"\"\\n    Extracts the paragraph identifiers, and the scores of the judged paragraphs from relevance\\n    judgements in the NTCIR-11 Math-2, and NTCIR-12 MathIR format.\\n\\n    Parameters\\n    ----------\\n    input_file : file\\n        The input file containing relevance judgements in the NTCIR-11 Math-2, and NTCIR-12 MathIR\\n        format.\\n\\n    Yields\\n    ------\\n    (str, float)\\n        The judged paragraph identifiers, and scores.\\n    \"\"\"\\n    for line in tqdm(list(input_file)):\\n        _, __, identifier, score = line.split(\\' \\')\\n        yield (identifier, float(score))',\n",
       " 'def get_all_identifiers(dataset):\\n    \"\"\"\\n    Extracts paragraph identifiers from a dataset in the NTCIR-11 Math-2, and NTCIR-12 MathIR XHTML5\\n    format.\\n\\n    Parameters\\n    ----------\\n    dataset : Path\\n        A path to a dataset.\\n\\n    Yields\\n    -------\\n    (Path, str)\\n        A parent directory of a paragraph, and the identifier of the paragraph.\\n    \"\"\"\\n    for document in tqdm(\\n            dataset.glob(\"**/*.xhtml.zip\"), desc=\"get_all_identifiers(%s)\" % dataset.name):\\n        identifier = get_identifier(document)\\n        directory = document.parents[0]\\n        yield (directory, identifier)',\n",
       " 'def get_position(directory, identifier):\\n    \"\"\"\\n    Extracts the position of a paragraph from the identifier, and the parent directory of the\\n    paragraph.\\n\\n    Parameters\\n    ----------\\n    directory : Path\\n        A parent directory of a paragraph.\\n    identifier : str\\n        An identifier of a paragraph.\\n\\n    Returns\\n    -------\\n    float\\n        The estimated position of the paragraph in the range [0; 1).\\n    \"\"\"\\n    paragraph_number = get_paragraph_number(identifier)\\n    paragraph_total = max(  # Not all paragraphs are stored, e.g. because of processing errors.\\n        get_paragraph_number(get_identifier(document)) + 1\\n        for document in directory.iterdir())\\n    assert paragraph_total > paragraph_number and paragraph_total > 0\\n    position = paragraph_number / paragraph_total\\n    return position',\n",
       " 'def get_all_positions(dataset, num_workers=1):\\n    \"\"\"\\n    Extracts paragraph identifiers, and positions from a dataset in the NTCIR-11 Math-2, and\\n    NTCIR-12 MathIR XHTML5 format.\\n\\n    Parameters\\n    ----------\\n    dataset : Path\\n        A path to a dataset.\\n    num_workers : int, optional\\n        The number of processes that will extract paragraph positions from the dataset.\\n\\n    Yields\\n    -------\\n    (Path, str, float)\\n        A parent directory of a paragraph, the identifier of the paragraph, and an estimate of the\\n        position of the paragraph in its parent document. The position is in the range [0; 1).\\n    \"\"\"\\n    positions = []\\n    identifiers = tqdm(\\n        list(get_all_identifiers(dataset)), desc=\"get_all_positions(%s)\" % dataset.name)\\n    with Pool(num_workers) as pool:\\n        for directory, identifier, position in pool.map(_get_position_worker, identifiers):\\n            positions.append((directory, identifier, position))\\n    for directory, identifier, position in positions:\\n        yield (directory, identifier, position)',\n",
       " 'def get_estimators(positions_all, positions_relevant):\\n    \"\"\"\\n    Extracts density estimators from a judged sample of paragraph positions.\\n\\n    Parameters\\n    ----------\\n    positions_all : dict of (Path, float)\\n        A sample of paragraph positions from various datasets in the NTCIR-11\\n        Math-2, and NTCIR-12 MathIR format.\\n    positions_relevant : dict of (Path, float)\\n        A sample of relevant paragraph positions from various datasets in the\\n        NTCIR-11 A subsample of relevant paragraph positions.\\n\\n    Returns\\n    -------\\n    (float, KernelDensity, KernelDensity)\\n        An estimate of P(relevant), and estimators of p(position), and p(position | relevant).\\n    \"\"\"\\n    samples_all = [\\n        (position,) for _, positions in positions_all.items() for position in positions]\\n    samples_relevant = [\\n        (position,) for _, positions in positions_relevant.items() for position in positions]\\n    estimators = dict()\\n    estimators[\"P(relevant)\"] = len(samples_relevant) / len(samples_all)\\n    LOGGER.info(\"Fitting prior p(position) density estimator\")\\n    estimators[\"p(position)\"] = KernelDensity(**KERNEL).fit(samples_all)\\n    LOGGER.info(\"Fitting conditional p(position | relevant) density estimator\")\\n    estimators[\"p(position|relevant)\"] = KernelDensity(**KERNEL).fit(samples_relevant)\\n    return (\\n        estimators[\"P(relevant)\"], estimators[\"p(position)\"], estimators[\"p(position|relevant)\"])',\n",
       " 'def get_estimates(estimators_tuple, positions, num_workers=1):\\n    \"\"\"\\n    Estimates densities, and probabilities for paragraph positions.\\n\\n    Parameters\\n    ----------\\n    estimators_tuple : (float, KernelDensity, KernelDensity)\\n        An estimate of the prior probability P(relevant), an estimator of the prior density\\n        p(position), and an estimator of the conditional density p(position | relevant).\\n    positions : iterable of float\\n        Paragraph positions for which densities, and probabilities will be estimated.\\n    num_workers : int, optional\\n        The number of processes that will compute the estimates.\\n\\n    Returns\\n    -------\\n    five-tuple of (sequence of float)\\n        Estimates of P(relevant), p(position), p(position | relevant), P(position, relevant), and\\n        P(relevant | position) in the form of histograms.\\n    \"\"\"\\n    estimators = dict()\\n    estimators[\"P(relevant)\"], estimators[\"p(position)\"], \\\\\\n        estimators[\"p(position|relevant)\"] = estimators_tuple\\n\\n    log_estimates = dict()\\n    log_estimates[\"P(relevant)\"] = log(estimators[\"P(relevant)\"])\\n    X = [(position,) for position in positions]\\n    with Pool(num_workers) as pool:\\n        first_job = pool.map_async(estimators[\"p(position)\"].score_samples, tqdm(\\n            array_split(X, num_workers), desc=\"p(position)\"))\\n        second_job = pool.map_async(estimators[\"p(position|relevant)\"].score_samples, tqdm(\\n            array_split(X, num_workers), desc=\"p(position | relevant)\"))\\n        log_estimates[\"p(position)\"] = concatenate(first_job.get())\\n        log_estimates[\"p(position|relevant)\"] = concatenate(second_job.get())\\n    log_estimates[\"P(position,relevant)\"] = \\\\\\n        log_estimates[\"p(position|relevant)\"] + log_estimates[\"P(relevant)\"]\\n    log_estimates[\"P(relevant|position)\"] = \\\\\\n        log_estimates[\"P(position,relevant)\"] - log_estimates[\"p(position)\"]\\n    return (\\n        [estimators[\"P(relevant)\"]] * len(X), exp(log_estimates[\"p(position)\"]),\\n        exp(log_estimates[\"p(position|relevant)\"]), exp(log_estimates[\"P(position,relevant)\"]),\\n        exp(log_estimates[\"P(relevant|position)\"]))',\n",
       " 'def _get_build_command(self, mkdocs_site_path: Path) -> str:\\n        \\'\\'\\'Generate ``mkdocs build`` command to build the site.\\n\\n        :param mkdocs_site_path: Path to the output directory for the site\\n        \\'\\'\\'\\n\\n        components = [self._mkdocs_config.get(\\'mkdocs_path\\', \\'mkdocs\\')]\\n        components.append(\\'build\\')\\n        components.append(f\\'-d \"{self._escape_control_characters(str(mkdocs_site_path))}\"\\')\\n\\n        command = \\' \\'.join(components)\\n\\n        self.logger.debug(f\\'Build command: {command}\\')\\n\\n        return command',\n",
       " \"def _get_ghp_command(self) -> str:\\n        '''Generate ``mkdocs gh-deploy`` command to deploy the site to GitHub Pages.'''\\n\\n        components = [self._mkdocs_config.get('mkdocs_path', 'mkdocs')]\\n        components.append('gh-deploy')\\n\\n        command = ' '.join(components)\\n\\n        self.logger.debug(f'GHP upload command: {command}')\\n\\n        return command\",\n",
       " \"def _get_page_with_optional_heading(self, page_file_path: str) -> str or Dict:\\n        '''Get the content of first heading of source Markdown file, if the file\\n        contains any headings. Return a data element of ``pages`` section\\n        of ``mkdocs.yml`` file.\\n\\n        :param page_file_path: path to source Markdown file\\n\\n        :returns: Unchanged file path or a dictionary: content of first heading, file path\\n        '''\\n\\n        self.logger.debug(f'Looking for the first heading in {page_file_path}')\\n\\n        if page_file_path.endswith('.md'):\\n            page_file_full_path = self.project_path / self.config['src_dir'] / page_file_path\\n\\n            with open(page_file_full_path, encoding='utf8') as page_file:\\n                content = page_file.read()\\n                headings_found = search(\\n                    r'^\\\\s*#{1,6}[ \\\\t]+([^\\\\r\\\\n]+?)(?:[ \\\\t]+\\\\{#\\\\S+\\\\})?\\\\s*[\\\\r\\\\n]+',\\n                    content\\n                )\\n\\n                if headings_found:\\n                    first_heading = headings_found.group(1)\\n                    self.logger.debug(f'Heading found: {first_heading}')\\n                    return {first_heading: page_file_path}\\n\\n        self.logger.debug(f'No heading found, returning original file path.')\\n\\n        return page_file_path\",\n",
       " 'def wrap_json(func=None, *, encoder=json.JSONEncoder, preserve_raw_body=False):\\n    \"\"\"\\n    A middleware that parses the body of json requests and\\n    encodes the json responses.\\n\\n    NOTE: this middleware exists just for backward compatibility,\\n    but it has some limitations in terms of response body encoding\\n    because it only accept list or dictionary outputs and json\\n    specification allows store other values also.\\n\\n    It is recommended use the `wrap_json_body` and wrap_json_response`\\n    instead of this.\\n    \"\"\"\\n\\n    if func is None:\\n        return functools.partial(\\n            wrap_json,\\n            encoder=encoder,\\n            preserve_raw_body=preserve_raw_body\\n        )\\n\\n    wrapped_func = wrap_json_body(func, preserve_raw_body=preserve_raw_body)\\n    wrapped_func = wrap_json_response(wrapped_func, encoder=encoder)\\n    return wrapped_func',\n",
       " 'def wrap_json_params(func):\\n    \"\"\"\\n    A middleware that parses the body of json requests and\\n    add it to the request under the `params` key.\\n    \"\"\"\\n\\n    @functools.wraps(func)\\n    def wrapper(request, *args, **kwargs):\\n        ctype, pdict = parse_header(request.headers.get(\\'Content-Type\\', \\'\\'))\\n        if ctype == \"application/json\":\\n            request.params = json.loads(request.body.decode(\"utf-8\")) if request.body else None\\n        return func(request, *args, **kwargs)\\n    return wrapper',\n",
       " 'def run(itf):\\n    \"\"\"\\n\\tRun preprocess functions\\n\\t\"\"\"\\n\\n    if not itf:\\n        return 1\\n\\n    # access command-line arguments\\n    options = SplitInput(itf)\\n\\n    # read input\\n    infile = os.path.abspath(options.input)\\n    molList = read_csv(infile, options)\\n\\n    # split molList into actives and decoys\\n    activeList, decoyList = partition(molList, options)\\n\\n    # split actives and decoys into training and validation sets\\n    trainset, valset = split(activeList, decoyList, options)\\n\\n    # write csv files formatted for ensemble builder\\n    csv_writer(trainset, options, \\'training_set\\')\\n    csv_writer(valset, options, \\'test_set\\')',\n",
       " 'def write_csv_header(mol, csv_writer):\\n    \"\"\"\\n\\tWrite the csv header\\n\\t\"\"\"\\n\\n    # create line list where line elements for writing will be stored\\n    line = []\\n\\n    # ID\\n    line.append(\\'id\\')\\n\\n    # status\\n    line.append(\\'status\\')\\n\\n    # query labels\\n    queryList = mol.properties.keys()\\n    for queryLabel in queryList:\\n        line.append(queryLabel)\\n\\n    # write line\\n    csv_writer.writerow(line)',\n",
       " 'def write_csv_line(mol, csv_writer, options):\\n    \"\"\"\\n\\tParse mol object and write a line to the csv file\\n\\t\"\"\"\\n\\n    # set variables\\n    status_field = options.status_field\\n\\n    # elements for writing will be stored in the line list\\n    line = []\\n\\n    # ID\\n    id = mol.GetProp(\\'id\\')\\n    if id is not None:\\n        line.append(id)\\n    else:\\n        line.append(\\'n/a\\')\\n\\n    # status\\n    line.append(mol.GetProp(status_field))\\n\\n    # query labels\\n    queryList = mol.properties.keys()\\n    for queryLabel in queryList:\\n        line.append(mol.properties[queryLabel])\\n\\n    # write line\\n    csv_writer.writerow(line)',\n",
       " 'def csv_writer(molecules, options, prefix):\\n    \"\"\"\\n\\tWrite a csv file.\\n\\t\"\"\"\\n\\n    # output file\\n    outdir = os.getcwd()\\n    filename = prefix + \\'.csv\\'\\n    outfile = os.path.join(outdir, filename)\\n\\n    # initiate csv writer object\\n    f = open(outfile, \\'w\\')\\n    csv_writer = csv.writer(f)\\n\\n    # write csv header\\n    mol = molecules[0]\\n    write_csv_header(mol, csv_writer)\\n\\n    # write csv lines\\n    for mol in molecules:\\n        write_csv_line(mol, csv_writer, options)\\n\\n    # close file\\n    f.close()',\n",
       " 'def split(activeList, decoyList, options):\\n    \"\"\"\\n\\tCreate training and validation sets\\n\\t\"\"\"\\n\\n    # set input variables\\n    training_fraction = options.training_fraction\\n    decoy_to_active = options.decoy_to_active\\n\\n    # take care of default decoy_to_active ratio\\n    if decoy_to_active is None:\\n        decoy_to_active = len(decoyList) / len(activeList)\\n\\n    # verify that there are enough molecules to satisfy the ratio\\n    if len(decoyList) < (len(activeList) * decoy_to_active):\\n        max = len(decoyList) / len(activeList)\\n        print(\"\\\\n The maximum decoy to active ratio the input file will support is {f} \\\\n\".format(f=max))\\n        sys.exit(1)\\n\\n    # randomly split the actives\\n    trainsize = int(round(training_fraction * len(activeList)))\\n\\n    trainIndex = []\\n    valIndex = []\\n    trainIndex = random.sample(range(len(activeList)), trainsize)\\n    valIndex = [x for x in range(len(activeList)) if x not in trainIndex]\\n\\n    trainactives = [activeList[index] for index in trainIndex]\\n    valactives = [activeList[index] for index in valIndex]\\n\\n    # match up decoys\\n    trainsize = len(trainactives) * decoy_to_active\\n    valsize = len(valactives) * decoy_to_active\\n\\n    trainIndex = []\\n    valIndex = []\\n    trainIndex = random.sample(range(len(decoyList)), int(trainsize))\\n    valIndex = [x for x in range(len(decoyList)) if x not in trainIndex][0:int(valsize)]\\n\\n    traindecoys = [decoyList[index] for index in trainIndex]\\n    valdecoys = [decoyList[index] for index in valIndex]\\n\\n    # merge actives and decoys for each set\\n    trainset = trainactives + traindecoys\\n    valset = valactives + valdecoys\\n\\n    # return sets\\n    return trainset, valset',\n",
       " 'def partition(molList, options):\\n    \"\"\"\\n\\tPartition molList into activeList and decoyList\\n\\t\"\"\"\\n    # set input variables\\n    status_field = options.status_field\\n    active_label = options.active_label\\n    decoy_label = options.decoy_label\\n\\n    # initiate lists\\n    activeList = []\\n    decoyList = []\\n\\n    # partition moList\\n    for mol in molList:\\n        if mol.GetProp(status_field) == active_label:\\n            activeList.append(mol)\\n        elif mol.GetProp(status_field) == decoy_label:\\n            decoyList.append(mol)\\n\\n    # return partitions\\n    return activeList, decoyList',\n",
       " 'def read_csv(csvfile, options):\\n    \"\"\"\\n\\tRead csv and return molList, a list of mol objects\\n\\t\"\"\"\\n\\n    # open file or exit\\n    name, ext = os.path.splitext(csvfile)\\n    try:\\n        if ext == \\'.gz\\':\\n            f = gzip.open(csvfile, \\'rb\\')\\n        else:\\n            f = open(csvfile, \\'rU\\')\\n    except IOError:\\n        print(\" \\\\n \\'{f}\\' could not be opened\\\\n\".format(f=os.path.basename(csvfile)))\\n        sys.exit(1)\\n\\n    # read file\\n    csv_reader = csv.reader(f)\\n    molList = []\\n    linenumber = 1\\n\\n    for line in csv_reader:\\n        # get column labels from the first line\\n        if linenumber == 1:\\n            prop_indices = read_header(line, options)\\n\\n        # otherwise read line & append to MolList\\n        else:\\n            mol = Molecule()\\n            mol = read_line(line, options, prop_indices, mol)\\n            # if the line\\'s junk, skip it\\n            if mol == 1:\\n                print(\" skipping molecule \\'m\\'\\\\n\".format(m=(linenumber - 1)))\\n            else:\\n                molList.append(mol)\\n\\n        linenumber += 1\\n\\n    # return molList\\n\\n    return molList',\n",
       " 'def read(self, input_file):\\n        \"\"\" Reads an InputHeader from `input_file`.\\n\\n        The input header is read as a sequence of *<key>***:***<value>* pairs\\n        separated by a newline. The end of the input header is signalled by an\\n        empty line or an end-of-file.\\n\\n        :param input_file: File-like object that supports iteration over lines\\n\\n        \"\"\"\\n        key, value = None, None\\n        import sys\\n        for line in input_file:\\n            if line == \\'\\\\n\\':\\n                break\\n            if line[-1:] == \\'\\\\n\\':\\n                line = line[:-1]\\n            item = line.split(\\':\\', 1)\\n            if len(item) == 2:\\n                # start of a new item\\n                self._update(key, value)\\n                key, value = item[0], urllib.unquote(item[1])\\n            elif key is not None:\\n                # continuation of the current item\\n                value = \\'\\\\n\\'.join([value, urllib.unquote(line)])\\n\\n        self._update(key, value)\\n        return',\n",
       " 'def write(self, output_file):\\n        \"\"\" Writes this MessageHeader to an output stream.\\n\\n        Messages are written as a sequence of *<message_text-message_level>***=**\\n        *<message_text-text>* pairs separated by \\'\\\\r\\\\n\\'. The sequence is\\n        terminated by a pair of \\'\\\\r\\\\n\\' sequences.\\n\\n        \"\"\"\\n        for message_level, message_text in self:\\n            output_file.write(\\'%s=%s\\\\r\\\\n\\' % (message_level, message_text))\\n        output_file.write(\\'\\\\r\\\\n\\')',\n",
       " 'def callback(self, event):\\n        \"\"\"\\n        Selects cells on click.\\n        \"\"\"\\n        self.init_width()\\n\\n        if len(self.initial) > 0:\\n            for cell in self.initial:\\n                self.color_square(cell[0], cell[1], True)\\n            self.initial = []\\n        self.begin_drag = event\\n        self.color_square(event.x, event.y)',\n",
       " 'def init_width(self):\\n        \"\"\"\\n        Get rectangle diameters\\n        \"\"\"\\n        self.col_width = self.c.winfo_width()/self.cols\\n        self.row_height = self.c.winfo_height()/self.rows',\n",
       " 'def color_square(self, x, y, unit_coords=False):\\n        \"\"\"\\n        Handles actually coloring the squares\\n        \"\"\"\\n        # Calculate column and row number\\n        if unit_coords:\\n            col = x\\n            row = y\\n        else:\\n            col = x//self.col_width\\n            row = y//self.row_height\\n\\n        # If the tile is not filled, create a rectangle\\n        if not self.tiles[row][col]:\\n            self.tiles[row][col] = \\\\\\n                self.c.create_rectangle(col*self.col_width,\\n                                        row*self.row_height,\\n                                        (col+1)*self.col_width,\\n                                        (row+1)*self.row_height,\\n                                        fill=\"black\")\\n            self.cells.append(row*self.cols + col)\\n\\n        # If the tile is filled, delete the rectangle and clear the reference\\n        else:\\n            self.c.delete(self.tiles[row][col])\\n            self.tiles[row][col] = None\\n            self.cells.remove(row*self.cols + col)',\n",
       " 'def dragend(self, event):\\n        \"\"\"\\n        Handles the end of a drag action.\\n        \"\"\"\\n        x_range = [self.begin_drag.x//self.col_width, event.x//self.col_width]\\n        y_range = [self.begin_drag.y//self.row_height,\\n                   event.y//self.row_height]\\n\\n        # Check bounds\\n        for i in range(2):\\n            for ls in [x_range, y_range]:\\n                if ls[i] < 0:\\n                    ls[i] = 0\\n                if ls[i] >= self.rows:\\n                    ls[i] = self.rows-1\\n\\n        for x in range(min(x_range), max(x_range)+1):\\n            for y in range(min(y_range), max(y_range)+1):\\n                if x == self.begin_drag.x//self.col_width and \\\\\\n                   y == self.begin_drag.y//self.row_height:\\n                    continue\\n                self.color_square(x*self.col_width, y*self.row_height)\\n        self.begin_drag = None\\n\\n        print(len(self.cells), \"cells selected\")',\n",
       " 'def _lower_if_str(item):\\n    \"\"\"\\n    Try to convert item to lowercase, if it is string.\\n\\n    Args:\\n        item (obj): Str, unicode or any other object.\\n\\n    Returns:\\n        obj: ``item.lower()`` if `item` is ``str`` or ``unicode``, else just \\\\\\n             `item` itself.\\n    \"\"\"\\n    # python 2 / 3 shill\\n    try:\\n        string_type = basestring\\n    except NameError:\\n        string_type = str\\n\\n    if isinstance(item, string_type):\\n        return item.lower()\\n\\n    return item',\n",
       " 'def get_repo_relpath(repo, relpath):\\n    \"\"\"Returns the absolute path to the \\'relpath\\' taken relative to the base\\n    directory of the repository.\\n    \"\"\"\\n    from os import path\\n    if relpath[0:2] == \"./\":\\n        return path.join(repo, relpath[2::])\\n    else:\\n        from os import chdir, getcwd\\n        cd = getcwd()\\n        chdir(path.expanduser(repo))\\n        result = path.abspath(relpath)\\n        chdir(cd)\\n        return result',\n",
       " 'def load_with_datetime(pairs):\\n    \"\"\"Deserialize JSON into python datetime objects.\"\"\"\\n    d = {}\\n    for k, v in pairs:\\n        if isinstance(v, basestring):\\n            try:\\n                d[k] = dateutil.parser.parse(v)\\n            except ValueError:\\n                d[k] = v\\n        else:\\n            d[k] = v             \\n    return d',\n",
       " 'def get_json(jsonpath, default):\\n    \"\"\"Returns the JSON serialized object at the specified path, or the default\\n    if it doesn\\'t exist or can\\'t be deserialized.\\n    \"\"\"\\n    from os import path\\n    import json\\n    result = default\\n    \\n    if path.isfile(jsonpath):\\n        try:\\n            with open(jsonpath) as f:\\n                result = json.load(f, object_pairs_hook=load_with_datetime)\\n        except(IOError):\\n            err(\"Unable to deserialize JSON at {}\".format(jsonpath))\\n            pass\\n\\n    return result',\n",
       " 'def run_exec(repodir, command, output, index):\\n    \"\"\"Runs the specified command in the repo directory.\\n\\n    :arg repodir: the absolute path of the repo directory to run \\'command\\' in.\\n    :arg command: what to run in the \\'repodir\\'. Should be valid in the context\\n      of the $PATH variable.\\n    :arg output: the multiprocessing queue to push the results to.\\n    :arg index: the index of this test in the master list.\\n    \"\"\"\\n    from os import path\\n    from subprocess import Popen, PIPE\\n    from datetime import datetime\\n    \\n    child = Popen(\"cd {}; {} > {}.cidat\".format(repodir, command, index),\\n                  shell=True, executable=\"/bin/bash\")\\n    # Need to do this so that we are sure the process is done before moving on\\n    child.wait()\\n    output.put({\"index\": index, \"end\": datetime.now(), \"code\": child.returncode,\\n                \"output\": path.join(repodir, \"{}.cidat\".format(index))})',\n",
       " 'def load_class(location: str) -> type:\\n    \"\"\" Loads a class from a string and returns it.\\n\\n    >>> from arca.utils import load_class\\n    >>> load_class(\"arca.backend.BaseBackend\")\\n    <class \\'arca.backend.base.BaseBackend\\'>\\n\\n    :raise ArcaMisconfigured: If the class can\\'t be loaded.\\n    \"\"\"\\n    module_name, _, class_name = location.rpartition(\".\")\\n\\n    if not module_name:\\n        raise ArcaMisconfigured(f\"The module is not specified, can\\'t load class from \\'{location}\\'\")\\n\\n    try:\\n        imported_module = importlib.import_module(module_name)\\n        return getattr(imported_module, class_name)\\n    except ModuleNotFoundError:\\n        raise ArcaMisconfigured(f\"{module_name} does not exist.\")\\n    except AttributeError:\\n        raise ArcaMisconfigured(f\"{module_name} does not have a {class_name} class\")',\n",
       " 'def get_hash_for_file(repo: Repo, path: Union[str, Path]) -> str:\\n    \"\"\" Returns the hash for the specified path.\\n\\n    Equivalent to ``git rev-parse HEAD:X``\\n\\n    :param repo: The repo to check in\\n    :param path: The path to a file or folder to get hash for\\n    :return: The hash\\n    \"\"\"\\n    return repo.git.rev_parse(f\"HEAD:{str(path)}\")',\n",
       " 'def get(self, *keys: str, default: Any = NOT_SET) -> Any:\\n        \"\"\" Returns values from the settings in the order of keys, the first value encountered is used.\\n\\n        Example:\\n\\n        >>> settings = Settings({\"ARCA_ONE\": 1, \"ARCA_TWO\": 2})\\n        >>> settings.get(\"one\")\\n        1\\n        >>> settings.get(\"one\", \"two\")\\n        1\\n        >>> settings.get(\"two\", \"one\")\\n        2\\n        >>> settings.get(\"three\", \"one\")\\n        1\\n        >>> settings.get(\"three\", default=3)\\n        3\\n        >>> settings.get(\"three\")\\n        Traceback (most recent call last):\\n        ...\\n        KeyError:\\n\\n        :param keys: One or more keys to get from settings. If multiple keys are provided, the value of the first key\\n            that has a value is returned.\\n        :param default: If none of the ``options`` aren\\'t set, return this value.\\n        :return: A value from the settings or the default.\\n\\n        :raise ValueError: If no keys are provided.\\n        :raise KeyError: If none of the keys are set and no default is provided.\\n\\n        \"\"\"\\n        if not len(keys):\\n            raise ValueError(\"At least one key must be provided.\")\\n\\n        for option in keys:\\n            key = f\"{self.PREFIX}_{option.upper()}\"\\n            if key in self._data:\\n                return self._data[key]\\n\\n        if default is NOT_SET:\\n            raise KeyError(\"None of the following key is present in settings and no default is set: {}\".format(\\n                \", \".join(keys)\\n            ))\\n\\n        return default',\n",
       " 'def batch(items, size):\\n    \"\"\"Batches a list into a list of lists, with sub-lists sized by a specified\\n    batch size.\"\"\"\\n    return [items[x:x + size] for x in xrange(0, len(items), size)]',\n",
       " 'def get_storage(key, username):\\n    \"\"\"Returns the Storage class compatible with the current environment.\"\"\"\\n    if IS_APPENGINE and appengine:\\n        return appengine.StorageByKeyName(\\n            appengine.CredentialsModel, username, \\'credentials\\')\\n    file_name = os.path.expanduser(\\'~/.config/webreview/{}_{}\\'.format(key, username))\\n    dir_name = os.path.dirname(file_name)\\n    if not os.path.exists(dir_name):\\n        os.makedirs(dir_name)\\n    return oauth_file.Storage(file_name)',\n",
       " 'def _clean_record(self, record):\\n        \"\"\"Remove all fields with `None` values\"\"\"\\n        for k, v in dict(record).items():\\n            if isinstance(v, dict):\\n                v = self._clean_record(v)\\n            if v is None:\\n                record.pop(k)\\n        return record',\n",
       " 'def serialize(self, root, records):\\n        \"\"\"Serialize the payload into JSON\"\"\"\\n        logging.info(\"Serializing record\")\\n        logging.debug(\"Root: {}\".format(root))\\n        logging.debug(\"Records: {}\".format(records))\\n        if records == {}:\\n            return \\'{}\\'\\n        if isinstance(records, dict):\\n            if list(records.keys())[0] == \\'errors\\':\\n                logging.warning(\"Found errors. Moving on\".format(records))\\n                root = None\\n            elif \\'_id\\' in records:\\n                records[\\'id\\'] = records.pop(\\'_id\\')\\n        else:\\n            records = list(records)\\n\\n            # rename _id to id\\n            for r in records:\\n                if \\'_id\\' in r:\\n                    r[\\'id\\'] = r.pop(\\'_id\\')\\n\\n        if root is not None:\\n            records = {root: records}\\n        return json.dumps(records, cls=JSONEncoder)',\n",
       " 'def rule(ctxt, name):\\n    \"\"\"\\n    Allows evaluation of another rule while evaluating a rule.\\n\\n    :param ctxt: The evaluation context for the rule.\\n    :param name: The name of the rule to evaluate.\\n    \"\"\"\\n\\n    # If the result of evaluation is in the rule cache, bypass\\n    # evaluation\\n    if name in ctxt.rule_cache:\\n        ctxt.stack.append(ctxt.rule_cache[name])\\n        return\\n\\n    # Obtain the rule we\\'re to evaluate\\n    try:\\n        rule = ctxt.policy[name]\\n    except KeyError:\\n        # Rule doesn\\'t exist; log a message and assume False\\n        log = logging.getLogger(\\'policies\\')\\n        log.warn(\"Request to evaluate non-existant rule %r \"\\n                 \"while evaluating rule %r\" % (name, ctxt.name))\\n        ctxt.stack.append(False)\\n        ctxt.rule_cache[name] = False\\n        return\\n\\n    # Evaluate the rule, stopping at the set_authz instruction\\n    with ctxt.push_rule(name):\\n        rule.instructions(ctxt, True)\\n\\n    # Cache the result\\n    ctxt.rule_cache[name] = ctxt.stack[-1]',\n",
       " 'def resolve(self, symbol):\\n        \"\"\"\\n        Resolve a symbol encountered during a rule evaluation into the\\n        actual value for that symbol.\\n\\n        :param symbol: The symbol being resolved.\\n\\n        :returns: The value of that symbol.  If the symbol was not\\n                  declared in the ``variables`` parameter of the\\n                  constructor, a call will be made to the ``Policy``\\'s\\n                  ``resolve()`` method.\\n        \"\"\"\\n\\n        # Try the variables first\\n        if symbol in self.variables:\\n            return self.variables[symbol]\\n\\n        return self.policy.resolve(symbol)',\n",
       " 'def push_rule(self, name):\\n        \"\"\"\\n        Allow one rule to be evaluated in the context of another.\\n        This allows keeping track of the rule names during nested rule\\n        evaluation.\\n\\n        :param name: The name of the nested rule to be evaluated.\\n\\n        :returns: A context manager, suitable for use with the\\n                  ``with`` statement.  No value is generated.\\n        \"\"\"\\n\\n        # Verify that we haven\\'t been evaluating the rule already;\\n        # this is to prohibit recursive rules from locking us up...\\n        if name in self._name:\\n            raise PolicyException(\\n                \"Rule recursion detected; invocation chain: %s -> %s\" %\\n                (\\' -> \\'.join(self._name), name))\\n\\n        # Save the name temporarily, and set up the program counter\\n        # and step\\n        self._name.append(name)\\n        self._pc.append(0)\\n        self._step.append(1)\\n        try:\\n            yield\\n        except Exception as exc:\\n            exc_info = sys.exc_info()\\n\\n            # Report only if we haven\\'t reported it yet\\n            if not self.reported:\\n                # Get the logger and emit a log message\\n                log = logging.getLogger(\\'policies\\')\\n                log.warn(\"Exception raised while evaluating rule %r: %s\" %\\n                         (name, exc))\\n                self.reported = True\\n\\n            six.reraise(*exc_info)\\n        finally:\\n            # Pop the name off the stack of names and restore program\\n            # counter and step\\n            self._name.pop()\\n            self._pc.pop()\\n            self._step.pop()',\n",
       " 'def declare(self, name, text=\\'\\', doc=None, attrs=None, attr_docs=None):\\n        \"\"\"\\n        Declare a rule.  This allows a default for a given rule to be\\n        set, along with default values for the authorization\\n        attributes.  This function can also include documentation for\\n        the rule and the authorization attributes, allowing a sample\\n        policy configuration file to be generated.\\n\\n        :param name: The name of the rule.\\n        :param text: The text of the rule.  Defaults to the empty\\n                     string.\\n        :param doc: A string documenting the purpose of the rule.\\n        :param attrs: A dictionary of default values for the\\n                      authorization attributes.  Note that\\n                      authorization attributes cannot have names\\n                      beginning with an underscore (\"_\").\\n        :param attr_docs: A dictionary of strings for documenting the\\n                          purpose of the authorization attributes.\\n        \"\"\"\\n\\n        self._defaults[name] = rules.Rule(name, text, attrs)\\n        self._docs[name] = rules.RuleDoc(name, doc, attr_docs)\\n\\n        return self._defaults[name]',\n",
       " 'def get_doc(self, name):\\n        \"\"\"\\n        Retrieve a ``RuleDoc`` object from the ``Policy`` with the\\n        given name.  The ``RuleDoc`` object contains all documentation\\n        for the named rule.\\n\\n        :param name: The name of the rule to retrieve the\\n                     documentation for.\\n\\n        :returns: A ``RuleDoc`` object containing the documentation\\n                  for the rule.\\n        \"\"\"\\n\\n        # Create one if there isn\\'t one already\\n        if name not in self._docs:\\n            self._docs[name] = rules.RuleDoc(name)\\n\\n        return self._docs[name]',\n",
       " 'def resolve(self, symbol):\\n        \"\"\"\\n        Resolve a symbol using the entrypoint group.\\n\\n        :param symbol: The symbol being resolved.\\n\\n        :returns: The value of that symbol.  If the symbol cannot be\\n                  found, or if no entrypoint group was passed to the\\n                  constructor, will return ``None``.\\n        \"\"\"\\n\\n        # Search for a corresponding symbol\\n        if symbol not in self._resolve_cache:\\n            result = None\\n\\n            # Search through entrypoints only if we have a group\\n            if self._group is not None:\\n                for ep in pkg_resources.iter_entry_points(self._group, symbol):\\n                    try:\\n                        result = ep.load()\\n                    except (ImportError, AttributeError,\\n                            pkg_resources.UnknownExtra):\\n                        continue\\n\\n                    # We found the result we were looking for\\n                    break\\n\\n            # Cache the result\\n            self._resolve_cache[symbol] = result\\n\\n        return self._resolve_cache[symbol]',\n",
       " 'def evaluate(self, name, variables=None):\\n        \"\"\"\\n        Evaluate a named rule.\\n\\n        :param name: The name of the rule to evaluate.\\n        :param variables: An optional dictionary of variables to make\\n                          available during evaluation of the rule.\\n\\n        :returns: An instance of\\n                  ``policies.authorization.Authorization`` with the\\n                  result of the rule evaluation.  This will include\\n                  any authorization attributes.\\n        \"\"\"\\n\\n        # Get the rule and predeclaration\\n        rule = self._rules.get(name)\\n        default = self._defaults.get(name)\\n\\n        # Short-circuit if we don\\'t have either\\n        if rule is None and default is None:\\n            return authorization.Authorization(False)\\n\\n        # Marry the attribute defaults\\n        attrs = {}\\n        if default:\\n            attrs.update(default.attrs)\\n        if rule:\\n            attrs.update(rule.attrs)\\n\\n        # Select the rule we\\'ll actually use\\n        if rule is None:\\n            rule = default\\n\\n        # Construct the context\\n        ctxt = self.context_class(self, attrs, variables or {})\\n\\n        # Execute the rule\\n        try:\\n            with ctxt.push_rule(name):\\n                rule.instructions(ctxt)\\n        except Exception as exc:\\n            # Fail closed\\n            return authorization.Authorization(False, attrs)\\n\\n        # Return the authorization result\\n        return ctxt.authz',\n",
       " 'def from_string(cls, pid):\\n    \"\"\"Parse a PID from its string representation.\\n\\n    PIDs may be represented as name@ip:port, e.g.\\n\\n    .. code-block:: python\\n\\n        pid = PID.from_string(\\'master(1)@192.168.33.2:5051\\')\\n\\n    :param pid: A string representation of a pid.\\n    :type pid: ``str``\\n    :return: The parsed pid.\\n    :rtype: :class:`PID`\\n    :raises: ``ValueError`` should the string not be of the correct syntax.\\n    \"\"\"\\n    try:\\n      id_, ip_port = pid.split(\\'@\\')\\n      ip, port = ip_port.split(\\':\\')\\n      port = int(port)\\n    except ValueError:\\n      raise ValueError(\\'Invalid PID: %s\\' % pid)\\n    return cls(ip, port, id_)',\n",
       " 'def set_as_object(self, index = None, value= None):\\n        \"\"\"\\n        Sets a new value to array element specified by its index.\\n        When the index is not defined, it resets the entire array value.\\n        This method has double purpose because method overrides are not supported in JavaScript.\\n\\n        :param index: (optional) an index of the element to set\\n\\n        :param value: a new element or array value.\\n        \"\"\"\\n        if index == None and value != None:\\n            self.set_as_array(value)\\n        else:\\n            self[index] = value',\n",
       " 'def get_as_array(self, index):\\n        \"\"\"\\n        Converts array element into an AnyValueArray or returns empty AnyValueArray if conversion is not possible.\\n\\n        :param index: an index of element to get.\\n\\n        :return: AnyValueArray value of the element or empty AnyValueArray if conversion is not supported.\\n        \"\"\"\\n        if index == None:\\n            array = []\\n            for value in self:\\n                array.append(value)\\n            return array\\n        else:\\n            value = self[index]\\n            return AnyValueArray.from_value(value)',\n",
       " 'def get_as_string_with_default(self, index, default_value):\\n        \"\"\"\\n        Converts array element into a string or returns default value if conversion is not possible.\\n\\n        :param index: an index of element to get.\\n\\n        :param default_value: the default value\\n\\n        :return: string value ot the element or default value if conversion is not supported.\\n        \"\"\"\\n        value = self[index]\\n        return StringConverter.to_string_with_default(value, default_value)',\n",
       " 'def get_as_boolean_with_default(self, index, default_value):\\n        \"\"\"\\n        Converts array element into a boolean or returns default value if conversion is not possible.\\n\\n        :param index: an index of element to get.\\n\\n        :param default_value: the default value\\n\\n        :return: boolean value ot the element or default value if conversion is not supported.\\n        \"\"\"\\n        value = self[index]\\n        return BooleanConverter.to_boolean_with_default(value, default_value)',\n",
       " 'def get_as_integer_with_default(self, index, default_value):\\n        \"\"\"\\n        Converts array element into an integer or returns default value if conversion is not possible.\\n\\n        :param index: an index of element to get.\\n\\n        :param default_value: the default value\\n\\n        :return: integer value ot the element or default value if conversion is not supported.\\n        \"\"\"\\n        value = self[index]\\n        return IntegerConverter.to_integer_with_default(value, default_value)',\n",
       " 'def get_as_float_with_default(self, index, default_value):\\n        \"\"\"\\n        Converts array element into a float or returns default value if conversion is not possible.\\n\\n        :param index: an index of element to get.\\n\\n        :param default_value: the default value\\n\\n        :return: float value ot the element or default value if conversion is not supported.\\n        \"\"\"\\n        value = self[index]\\n        return FloatConverter.to_float_with_default(value, default_value)',\n",
       " 'def get_as_datetime_with_default(self, index, default_value):\\n        \"\"\"\\n        Converts array element into a Date or returns default value if conversion is not possible.\\n\\n        :param index: an index of element to get.\\n\\n        :param default_value: the default value\\n\\n        :return: Date value ot the element or default value if conversion is not supported.\\n        \"\"\"\\n        value = self[index]\\n        return DateTimeConverter.to_datetime_with_default(value, default_value)',\n",
       " 'def get_as_nullable_type(self, index, value_type):\\n        \"\"\"\\n        Converts array element into a value defined by specied typecode.\\n        If conversion is not possible it returns None.\\n\\n        :param index: an index of element to get.\\n\\n        :param value_type: the TypeCode that defined the type of the result\\n\\n        :return: element value defined by the typecode or None if conversion is not supported.\\n        \"\"\"\\n        value = self[index]\\n        return TypeConverter.to_nullable_type(value_type, value)',\n",
       " 'def get_as_type(self, index, value_type):\\n        \"\"\"\\n        Converts array element into a value defined by specied typecode.\\n        If conversion is not possible it returns default value for the specified type.\\n\\n        :param index: an index of element to get.\\n\\n        :param value_type: the TypeCode that defined the type of the result\\n\\n        :return: element value defined by the typecode or default if conversion is not supported.\\n        \"\"\"\\n        value = self[index]\\n        return TypeConverter.to_type(value_type, value)',\n",
       " 'def get_as_type_with_default(self, index, value_type, default_value):\\n        \"\"\"\\n        Converts array element into a value defined by specied typecode.\\n        If conversion is not possible it returns default value.\\n\\n        :param index: an index of element to get.\\n\\n        :param value_type: the TypeCode that defined the type of the result\\n\\n        :param default_value: the default value\\n\\n        :return: element value defined by the typecode or default value if conversion is not supported.\\n        \"\"\"\\n        value = self[index]\\n        return TypeConverter.to_type_with_default(value_type, value, default_value)',\n",
       " 'def contains(self, value):\\n        \"\"\"\\n        Checks if this array contains a value.\\n        The check uses direct comparison between elements and the specified value.\\n\\n        :param value: a value to be checked\\n\\n        :return: true if this array contains the value or false otherwise.\\n        \"\"\"\\n        str_value = StringConverter.to_nullable_string(value)\\n\\n        for element in self:\\n            str_element = StringConverter.to_string(element)\\n\\n            if str_value == None and str_element == None:\\n                return True\\n            if str_value == None or str_element == None:\\n                continue\\n            \\n            if str_value == str_element:\\n                return True\\n\\n        return False',\n",
       " 'def contains_as_type(self, value_type, value):\\n        \"\"\"\\n        Checks if this array contains a value.\\n        The check before comparison converts elements and the value to type specified by type code.\\n\\n        :param value_type: a type code that defines a type to convert values before comparison\\n\\n        :param value: a value to be checked\\n\\n        :return: true if this array contains the value or false otherwise.\\n        \"\"\"\\n        typed_value = TypeConverter.to_nullable_type(value_type, value)\\n\\n        for element in self:\\n            typed_element = TypeConverter.to_type(value_type, element)\\n\\n            if typed_value == None and typed_element == None:\\n                return True\\n            if typed_value == None or typed_element == None:\\n                continue\\n            \\n            if typed_value == typed_element:\\n                return True\\n\\n        return False',\n",
       " 'def from_value(value):\\n        \"\"\"\\n        Converts specified value into AnyValueArray.\\n\\n        :param value: value to be converted\\n\\n        :return: a newly created AnyValueArray.\\n        \"\"\"\\n        value = ArrayConverter.to_nullable_array(value)\\n        if value != None:\\n            return AnyValueArray(value)\\n        return AnyValueArray()',\n",
       " 'def from_string(values, separator, remove_duplicates = False):\\n        \"\"\"\\n        Splits specified string into elements using a separator and assigns\\n        the elements to a newly created AnyValueArray.\\n\\n        :param values: a string value to be split and assigned to AnyValueArray\\n\\n        :param separator: a separator to split the string\\n\\n        :param remove_duplicates: (optional) true to remove duplicated elements\\n\\n        :return: a newly created AnyValueArray.\\n        \"\"\"\\n        result = AnyValueArray()\\n\\n        if values == None or len(values) == 0:\\n            return result\\n\\n        items = str(values).split(separator)\\n        for item in items:\\n            if (item != None and len(item) > 0) or remove_duplicates == False:\\n                result.append(item)\\n\\n        return result',\n",
       " 'def paint(self, painter, option, index):\\n        \"\"\"Use the painter and style option to render the item specified by the item index.\\n\\n        :param painter: the painter to paint\\n        :type painter: :class:`QtGui.QPainter`\\n        :param option: the options for painting\\n        :type option: :class:`QtGui.QStyleOptionViewItem`\\n        :param index: the index to paint\\n        :type index: :class:`QtCore.QModelIndex`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if self._widget is None:\\n            return super(WidgetDelegate, self).paint(painter, option, index)\\n\\n        self.set_widget_index(index)\\n        painter.save()\\n        painter.translate(option.rect.topLeft())\\n        self._widget.resize(option.rect.size())\\n        self._widget.render(painter, QtCore.QPoint())\\n        painter.restore()',\n",
       " 'def sizeHint(self, option, index):\\n        \"\"\"Return the appropriate amount for the size of the widget\\n\\n        The widget will always be expanded to at least the size of the viewport.\\n\\n        :param option: the options for painting\\n        :type option: :class:`QtGui.QStyleOptionViewItem`\\n        :param index: the index to paint\\n        :type index: :class:`QtCore.QModelIndex`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if self._widget is None:\\n            return super(WidgetDelegate, self).sizeHint(option, index)\\n\\n        self.set_widget_index(index)\\n        self._widget.resize(option.rect.size())\\n        sh = self._widget.sizeHint()\\n        return sh',\n",
       " 'def close_editors(self, ):\\n        \"\"\"Close all current editors\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        for k in reversed(self._edit_widgets.keys()):\\n            self.commit_close_editor(k)',\n",
       " 'def createEditor(self, parent, option, index):\\n        \"\"\"Return the editor to be used for editing the data item with the given index.\\n\\n        Note that the index contains information about the model being used.\\n        The editor\\'s parent widget is specified by parent, and the item options by option.\\n\\n        This will set auto fill background to True on the editor, because else, you would see\\n        The rendered delegate below.\\n\\n        :param parent: the parent widget\\n        :type parent: QtGui.QWidget\\n        :param option: the options for painting\\n        :type option: QtGui.QStyleOptionViewItem\\n        :param index: the index to paint\\n        :type index: QtCore.QModelIndex\\n        :returns: The created widget | None\\n        :rtype: :class:`QtGui.QWidget` | None\\n        :raises: None\\n        \"\"\"\\n        # close all editors\\n        self.close_editors()\\n        e = self.create_editor_widget(parent, option, index)\\n        if e:\\n            self._edit_widgets[index] = e\\n            e.setAutoFillBackground(True)\\n            e.destroyed.connect(partial(self.editor_destroyed, index=index))\\n        return e',\n",
       " 'def commit_close_editor(self, index, endedithint=QtGui.QAbstractItemDelegate.NoHint):\\n        \"\"\"Commit and close the editor\\n\\n        Call this method whenever the user finished editing.\\n\\n        :param index: The index of the editor\\n        :type index: :class:`QtCore.QModelIndex`\\n        :param endedithint: Hints that the delegate can give the model\\n                            and view to make editing data comfortable for the user\\n        :type endedithint: :data:`QtGui.QAbstractItemDelegate.EndEditHint`\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        editor = self._edit_widgets[index]\\n        self.commitData.emit(editor)\\n        self.closeEditor.emit(editor, endedithint)\\n        del self._edit_widgets[index]',\n",
       " 'def updateEditorGeometry(self, editor, option, index):\\n        \"\"\"Make sure the editor is the same size as the widget\\n\\n        By default it can get smaller because does not expand over viewport size.\\n        This will make sure it will resize to the same size as the widget.\\n\\n        :param editor: the editor to update\\n        :type editor: :class:`QtGui.QWidget`\\n        :param option: the options for painting\\n        :type option: QtGui.QStyleOptionViewItem\\n        :param index: the index to paint\\n        :type index: QtCore.QModelIndex\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        super(WidgetDelegate, self).updateEditorGeometry(editor, option, index)\\n        editor.setGeometry(option.rect)\\n        if self.keep_editor_size:\\n            esh = editor.sizeHint()\\n            osh = option.rect.size()\\n            w = osh.width() if osh.width() > esh.width() else esh.width()\\n            h = osh.height() if osh.height() > esh.height() else esh.height()\\n            editor.resize(w, h)',\n",
       " 'def get_pos_in_delegate(self, index, globalpos):\\n        \"\"\"Map the global position to the position relative to the\\n        given index\\n\\n        :param index: the index to map to\\n        :type index: :class:`QtCore.QModelIndex`\\n        :param globalpos: the global position\\n        :type globalpos: :class:`QtCore.QPoint`\\n        :returns: The position relative to the given index\\n        :rtype: :class:`QtCore.QPoint`\\n        :raises: None\\n        \"\"\"\\n        rect = self.visualRect(index)  # rect of the index\\n        p = self.viewport().mapToGlobal(rect.topLeft())\\n        return globalpos - p',\n",
       " 'def propagate_event_to_delegate(self, event, eventhandler):\\n        \"\"\"Propagate the given Mouse event to the widgetdelegate\\n\\n        Enter edit mode, get the editor widget and issue an event on that widget.\\n\\n        :param event: the mouse event\\n        :type event: :class:`QtGui.QMouseEvent`\\n        :param eventhandler: the eventhandler to use. E.g. ``\"mousePressEvent\"``\\n        :type eventhandler: str\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        # if we are recursing because we sent a click event, and it got propagated to the parents\\n        # and we recieve it again, terminate\\n        if self.__recursing:\\n            return\\n        # find index at mouse position\\n        i = self.index_at_event(event)\\n\\n        # if the index is not valid, we don\\'t care\\n        # handle it the default way\\n        if not i.isValid():\\n            return getattr(super(WidgetDelegateViewMixin, self), eventhandler)(event)\\n        # get the widget delegate. if there is None, handle it the default way\\n        delegate = self.itemDelegate(i)\\n        if not isinstance(delegate, WidgetDelegate):\\n            return getattr(super(WidgetDelegateViewMixin, self), eventhandler)(event)\\n\\n        # see if there is already a editor\\n        widget = delegate.edit_widget(i)\\n        if not widget:\\n            # close all editors, then start editing\\n            delegate.close_editors()\\n            # Force editing. If in editing state, view will refuse editing.\\n            if self.state() == self.EditingState:\\n                self.setState(self.NoState)\\n            self.edit(i)\\n            # get the editor widget. if there is None, there is nothing to do so return\\n            widget = delegate.edit_widget(i)\\n        if not widget:\\n            return getattr(super(WidgetDelegateViewMixin, self), eventhandler)(event)\\n\\n        # try to find the relative position to the widget\\n        pid = self.get_pos_in_delegate(i, event.globalPos())\\n        widgetatpos = widget.childAt(pid)\\n        if widgetatpos:\\n            widgettoclick = widgetatpos\\n            g = widget.mapToGlobal(pid)\\n            clickpos = widgettoclick.mapFromGlobal(g)\\n        else:\\n            widgettoclick = widget\\n            clickpos = pid\\n\\n        # create a new event for the editor widget.\\n        e = QtGui.QMouseEvent(event.type(),\\n                              clickpos,\\n                              event.button(),\\n                              event.buttons(),\\n                              event.modifiers())\\n        # before we send, make sure, we cannot recurse\\n        self.__recursing = True\\n        try:\\n            r = QtGui.QApplication.sendEvent(widgettoclick, e)\\n        finally:\\n            self.__recursing = False  # out of the recursion. now we can accept click events again\\n        return r',\n",
       " 'def get_total_indentation(self, index):\\n        \"\"\"Get the indentation for the given index\\n\\n        :param index: the index to query\\n        :type index: :class:`QtCore.ModelIndex`\\n        :returns: the number of parents\\n        :rtype: int\\n        :raises: None\\n        \"\"\"\\n        n = 0\\n        while index.isValid():\\n            n += 1\\n            index = index.parent()\\n        return n * self.indentation()',\n",
       " 'def render(self, f_buf=None):\\n        \"\"\"\\n        Write to the dest buffer\\n\\n        :param obj f_buf: A file buffer supporting the write and seek\\n        methods\\n        \"\"\"\\n        if f_buf is None:\\n            f_buf = StringIO.StringIO()\\n\\n        headers = getattr(self, \\'headers\\', ())\\n\\n        keys = [\\n            force_encoding(header[\\'label\\'], self.encoding)\\n            for header in headers\\n        ]\\n\\n        extra_headers = getattr(self, \\'extra_headers\\', ())\\n        keys.extend([\\n            force_encoding(header[\\'label\\'], self.encoding)\\n            for header in extra_headers\\n        ])\\n\\n        outfile = csv.DictWriter(\\n            f_buf,\\n            keys,\\n            extrasaction=\\'ignore\\',\\n            delimiter=self.delimiter,\\n            quotechar=self.quotechar,\\n            quoting=csv.QUOTE_ALL,\\n        )\\n        outfile.writeheader()\\n        _datas = getattr(self, \\'_datas\\', ())\\n        outfile.writerows(_datas)\\n        f_buf.seek(0)\\n        return f_buf',\n",
       " 'def format_row(self, row):\\n        \"\"\"\\n        Format the row to fit our export switch the key used to store it in the\\n        dict\\n\\n        since csv writer is expecting dict with keys matching the headers\\' names\\n        we switch the name the attributes fo the row are stored using labels\\n        instead of names\\n        \"\"\"\\n        res_dict = {}\\n        headers = getattr(self, \\'headers\\', [])\\n        extra_headers = getattr(self, \\'extra_headers\\', [])\\n        for header in tuple(headers) + tuple(extra_headers):\\n            name, label = header[\\'name\\'], header[\\'label\\']\\n            val = row.get(name)\\n            if val is None:\\n                continue\\n            label = force_encoding(label, self.encoding)\\n            if hasattr(self, \"format_%s\" % name):\\n                val = getattr(self, \"format_%s\" % name)(val)\\n\\n            res_dict[label] = force_encoding(val, self.encoding)\\n        return res_dict',\n",
       " 'def set_headers(self, headers):\\n        \"\"\"\\n        Set the headers of our csv writer\\n\\n        :param list headers: list of dict with label and name key (label is\\n        mandatory : used for the export)\\n        \"\"\"\\n        self.headers = []\\n        if \\'order\\' in self.options:\\n            for element in self.options[\\'order\\']:\\n                for header in headers:\\n                    if header[\\'key\\'] == element:\\n                        self.headers.append(header)\\n                        break\\n        else:\\n            self.headers = headers',\n",
       " 'def set_style(primary=None, secondary=None):\\n    \"\"\" Sets primary and secondary component styles.\\n    \"\"\"\\n    global _primary_style, _secondary_style\\n    if primary:\\n        _primary_style = primary\\n    if secondary:\\n        _secondary_style = secondary',\n",
       " 'def set_char(key, value):\\n    \"\"\" Updates charters used to render components.\\n    \"\"\"\\n    global _chars\\n    category = _get_char_category(key)\\n    if not category:\\n        raise KeyError\\n    _chars[category][key] = value',\n",
       " 'def ascii_mode(enabled=True):\\n    \"\"\" Disables color and switches to an ASCII character set if True.\\n    \"\"\"\\n    global _backups, _chars, _primary_style, _secondary_style, _ascii_mode\\n    if not (enabled or _backups) or (enabled and _ascii_mode):\\n        return\\n    if enabled:\\n        _backups = _chars.copy(), _primary_style, _secondary_style\\n        _chars = {\\n            \"primary\": {\"selected\": \"*\", \"block\": \"#\"},\\n            \"secondary\": {\"arrow\": \">\", \"left-edge\": \"|\", \"right-edge\": \"|\"},\\n            \"plain\": {\"unselected\": \".\"},\\n        }\\n        _primary_style = ()\\n        _secondary_style = ()\\n    else:\\n        _chars, _primary_style, _secondary_style = _backups\\n    _ascii_mode = enabled',\n",
       " 'def sam_verifier(entries, line=None):\\n    \"\"\"Raises error if invalid SAM format detected\\n\\n    Args:\\n        entries (list): A list of SamEntry instances\\n\\n        line (int): Line number of first entry\\n\\n    Raises:\\n        FormatError: Error when SAM format incorrect with descriptive message\\n    \"\"\"\\n\\n    regex = r\\'^[!-?A-~]{1,255}\\\\t\\' \\\\\\n            + r\\'([0-9]{1,4}|[0-5][0-9]{4}|\\' \\\\\\n            + r\\'[0-9]{1,4}|[1-5][0-9]{4}|\\' \\\\\\n            + r\\'6[0-4][0-9]{3}|65[0-4][0-9]{2}|\\' \\\\\\n            + r\\'655[0-2][0-9]|6553[0-7])\\\\t\\' \\\\\\n            + r\\'\\\\*|[!-()+-<>-~][!-~]*\\\\t\\' \\\\\\n            + r\\'([0-9]{1,9}|1[0-9]{9}|2(0[0-9]{8}|\\' \\\\\\n            + r\\'1([0-3][0-9]{7}|4([0-6][0-9]{6}|\\' \\\\\\n            + r\\'7([0-3][0-9]{5}|4([0-7][0-9]{4}|\\' \\\\\\n            + r\\'8([0-2][0-9]{3}|3([0-5][0-9]{2}|\\' \\\\\\n            + r\\'6([0-3][0-9]|4[0-7])))))))))\\\\t\\' \\\\\\n            + r\\'([0-9]{1,2}|1[0-9]{2}|\\' \\\\\\n            + r\\'2[0-4][0-9]|25[0-5])\\\\t\\' \\\\\\n            + r\\'\\\\*|([0-9]+[MIDNSHPX=])+\\\\t\\' \\\\\\n            + r\\'\\\\*|=|[!-()+-<>-~][!-~]*\\\\t\\' \\\\\\n            + r\\'([0-9]{1,9}|1[0-9]{9}|2(0[0-9]{8}|\\' \\\\\\n            + r\\'1([0-3][0-9]{7}|4([0-6][0-9]{6}|\\' \\\\\\n            + r\\'7([0-3][0-9]{5}|4([0-7][0-9]{4}|\\' \\\\\\n            + r\\'8([0-2][0-9]{3}|3([0-5][0-9]{2}|\\' \\\\\\n            + r\\'6([0-3][0-9]|4[0-7])))))))))\\\\t\\' \\\\\\n            + r\\'-?([0-9]{1,9}|1[0-9]{9}|2(0[0-9]{8}|\\' \\\\\\n            + r\\'1([0-3][0-9]{7}|4([0-6][0-9]{6}|\\' \\\\\\n            + r\\'7([0-3][0-9]{5}|4([0-7][0-9]{4}|\\' \\\\\\n            + r\\'8([0-2][0-9]{3}|3([0-5][0-9]{2}|\\' \\\\\\n            + r\\'6([0-3][0-9]|4[0-7])))))))))\\\\t\\' \\\\\\n            + r\\'\\\\*|[A-Za-z=.]+\\\\t\\' \\\\\\n            + r\\'[!-~]+{0}$\\'.format(os.linesep)\\n    delimiter = r\\'\\\\t\\'\\n\\n    for entry in entries:\\n        try:\\n            entry_verifier([entry.write()], regex, delimiter)\\n        except FormatError as error:\\n            # Format info on what entry error came from\\n            if line:\\n                intro = \\'Line {0}\\'.format(str(line))\\n            elif error.part == 0:\\n                intro = \\'An entry with reference {0}\\'.format(entry.rname)\\n            else:\\n                intro = \\'An entry with query {0}\\'.format(entry.qname)\\n\\n            # Generate error\\n            if error.part == 0:\\n                if len(entry.qname) == 0:\\n                    msg = \\'{0} has no query name\\'.format(intro)\\n                elif len(entry.qname) > 255:\\n                    msg = \\'{0} query name must be less than 255 \\' \\\\\\n                          \\'characters\\'.format(intro)\\n                else:\\n                    msg = \\'{0} query name contains characters not in \\' \\\\\\n                          \\'[!-?A-~]\\'.format(intro)\\n            elif error.part == 1:\\n                msg = \\'{0} flag not in range [0-(2^31-1)]\\'.format(intro)\\n            elif error.part == 2:\\n                if len(entry.rname) == 0:\\n                    msg = \\'{0} has no reference name\\'.format(intro)\\n                else:\\n                    msg = \\'{0} reference name has characters not in \\' \\\\\\n                          \\'[!-()+-<>-~][!-~]\\'.format(intro)\\n            elif error.part == 3:\\n                msg = \\'{0} leftmost position not in range \\' \\\\\\n                      \\'[0-(2^31-1)]\\'.format(intro)\\n            elif error.part == 4:\\n                msg = \\'{0} mapping quality not in range \\' \\\\\\n                      \\'[0-(2^8-1)]\\'.format(intro)\\n            elif error.part == 5:\\n                msg = \\'{0} CIGAR string has characters not in \\' \\\\\\n                      \\'[0-9MIDNSHPX=]\\'.format(intro)\\n            elif error.part == 6:\\n                msg = \\'{0} mate read name has characters not in \\' \\\\\\n                      \\'[!-()+-<>-~][!-~]\\'.format(intro)\\n            elif error.part == 7:\\n                msg = \\'{0} mate read position not in range \\' \\\\\\n                      \\'[0-(2^31-1)]\\'.format(intro)\\n            elif error.part == 8:\\n                msg = \\'{0} template length not in range \\' \\\\\\n                      \\'[(-2^31+1)-(2^31-1)]\\'.format(intro)\\n            elif error.part == 9:\\n                msg = \\'{0} sequence has characters not in \\' \\\\\\n                      \\'[A-Za-z=.]\\'.format(intro)\\n            elif error.part == 10:\\n                msg = \\'{0} quality scores has characters not in \\' \\\\\\n                      \\'[!-~]\\'.format(intro)\\n            else:\\n                msg = \\'{0}: Unknown Error: Likely a Bug\\'.format(intro)\\n            raise FormatError(message=msg)\\n\\n        if line:\\n            line += 1',\n",
       " 'def send(self, message, *args, **kwargs):\\n        \"\"\"\\n        Send the the `message` to the broker.\\n\\n        :param message: The message to send. Its type depends on the serializer used.\\n        :type message: object\\n        :rtype: None\\n        \"\"\"\\n        routing_keys = kwargs.get(\\'routing_key\\') or self.routing_key\\n        routing_keys = [routing_keys] if isinstance(routing_keys, basestring) else routing_keys\\n        correlation_id = kwargs.get(\\'correlation_id\\', None)\\n        reply_to = kwargs.get(\\'reply_to\\', None)\\n        declare=[self.exchange] + kwargs.get(\\'declare\\', [])\\n        conn = self.get_connection()\\n        with connections[conn].acquire(block=True) as connection:\\n            self.exchange.maybe_bind(connection)\\n            #reply_to.maybe_bind(connection)\\n            #reply_to.declare(True)\\n            with producers[connection].acquire(block=True) as producer:\\n                for routing_key in routing_keys:\\n                    LOGGER.info(\\'Send message %s to exchange %s with routing_key %s reply_to %s correlation_id %s\\',\\n                                message, self.exchange.name, routing_key, reply_to, correlation_id)\\n                    producer.publish(\\n                        message,\\n                        exchange=self.exchange,\\n                        declare=declare,\\n                        serializer=self.settings[\\'serializer\\'],\\n                        routing_key=routing_key,\\n                        correlation_id=correlation_id,\\n                        retry=self.settings[\\'retry\\'],\\n                        delivery_mode=self.settings[\\'delivery_mode\\'],\\n                        reply_to=reply_to,\\n                        retry_policy=self.settings[\\'retry_policy\\'])',\n",
       " 'def exit_with_error(message):\\n    \"\"\" Display formatted error message and exit call \"\"\"\\n    click.secho(message, err=True, bg=\\'red\\', fg=\\'white\\')\\n    sys.exit(0)',\n",
       " 'def main(search_engine, search_option, list_engines, query):\\n    \"\"\"Quick search command tool for your terminal\"\"\"\\n\\n    engine_data = {}\\n    if list_engines:\\n        for name in engines:\\n            conf = get_config(name)\\n            optionals = filter(lambda e: e != \\'default\\', conf.keys())\\n            if optionals:\\n                click.echo(\\'{command} -o {options}\\'.format(\\n                    command=name.replace(\\'.json\\', \\'\\'),\\n                    options=\\', \\'.join(optionals)))\\n            else:\\n                click.echo(name.replace(\\'.json\\', \\'\\'))\\n        sys.exit(0)\\n\\n    for name in engines:\\n        if name.find(search_engine) == 0:\\n            engine_data = get_config(name)\\n            break\\n\\n    # read from standard input if available\\n    if not sys.stdin.isatty():\\n        query = sys.stdin.read()\\n\\n    if not query:\\n        exit_with_error(\\'Query parameter is missing.\\')\\n\\n    if not engine_data:\\n        exit_with_error(\\'Engine ``{0}`` not found\\'.format(search_engine))\\n\\n    if search_option not in engine_data:\\n        exit_with_error(\\'Option ``{0}`` not available for engine ``{1}``\\'.\\\\\\n                        format(search_option, search_engine))\\n\\n    query = u\\' \\'.join(query) if isinstance(query, tuple) else query\\n    engine_url = engine_data.get(search_option)\\n    url = engine_url.format(query).encode(\\'utf-8\\')\\n    launch.open(url)',\n",
       " 'def _load_db():\\n    \"\"\"Deserializes the script database from JSON.\"\"\"\\n    from os import path\\n    from pyci.utility import get_json\\n    global datapath, db\\n    datapath = path.abspath(path.expanduser(settings.datafile))\\n    vms(\"Deserializing DB from {}\".format(datapath))\\n    db = get_json(datapath, {\"installed\": [], \"enabled\": True, \"cron\": False})',\n",
       " 'def _save_db():\\n    \"\"\"Serializes the contents of the script db to JSON.\"\"\"\\n    from pyci.utility import json_serial\\n    import json\\n    vms(\"Serializing DB to JSON in {}\".format(datapath))\\n    with open(datapath, \\'w\\') as f:\\n        json.dump(db, f, default=json_serial)',\n",
       " 'def _check_virtualenv():\\n    \"\"\"Makes sure that the virtualenv specified in the global settings file\\n    actually exists.\\n    \"\"\"\\n    from os import waitpid\\n    from subprocess import Popen, PIPE\\n    penvs = Popen(\"source /usr/local/bin/virtualenvwrapper.sh; workon\",\\n                 shell=True, executable=\"/bin/bash\", stdout=PIPE, stderr=PIPE)\\n    waitpid(penvs.pid, 0)\\n    envs = penvs.stdout.readlines()\\n    enverr = penvs.stderr.readlines()\\n    result = (settings.venv + \\'\\\\n\\') in envs and len(enverr) == 0\\n\\n    vms(\"Find virtualenv: {}\".format(\\' \\'.join(envs).replace(\\'\\\\n\\', \\'\\')))\\n    vms(\"Find virtualenv | stderr: {}\".format(\\' \\'.join(enverr)))\\n    \\n    if not result:\\n        info(envs)\\n        err(\"The virtualenv \\'{}\\' does not exist; can\\'t use CI server.\".format(settings.venv))\\n        if len(enverr) > 0:\\n            map(err, enverr)\\n    return result',\n",
       " 'def _check_global_settings():\\n    \"\"\"Makes sure that the global settings environment variable and file\\n    exist for configuration.\\n    \"\"\"\\n    global settings\\n    if settings is not None:\\n        #We must have already loaded this and everything was okay!\\n        return True\\n    \\n    from os import getenv\\n    result = False\\n    \\n    if getenv(\"PYCI_XML\") is None:\\n        err(\"The environment variable PYCI_XML for the global configuration \"\\n            \"has not been set.\")\\n    else:\\n        from os import path\\n        fullpath = path.abspath(path.expanduser(getenv(\"PYCI_XML\")))\\n        if not path.isfile(fullpath):\\n            err(\"The file {} for global configuration does not exist.\".format(fullpath))\\n        else:\\n            from pyci.config import GlobalSettings\\n            settings = GlobalSettings()\\n            result = True\\n\\n    return result',\n",
       " 'def _setup_crontab():\\n    \"\"\"Sets up the crontab if it hasn\\'t already been setup.\"\"\"\\n    from crontab import CronTab\\n    #Since CI works out of a virtualenv anyway, the `ci.py` script will be\\n    #installed in the bin already, so we can call it explicitly.\\n    command = \\'/bin/bash -c \"source ~/.cron_profile; workon {}; ci.py -cron\"\\'.format(settings.venv)\\n    user = _get_real_user()\\n    if args[\"nolive\"]:\\n        vms(\"Skipping cron tab configuration because \\'nolive\\' enabled.\")\\n        return\\n    cron = CronTab(user=user)\\n    \\n    #We need to see if the cron has already been created for this command.\\n    existing = False\\n    possible = cron.find_comment(\"pyci_cron\")\\n    if len(list(possible)) > 0:\\n        if args[\"rollback\"]:\\n            vms(\"Removing {} from cron tab.\".format(command))\\n            cron.remove_all(command)\\n            cron.write()\\n            db[\"cron\"] = False\\n            _save_db()\\n        else:\\n            existing = True\\n    \\n    if not existing and not args[\"rollback\"]:\\n        job = cron.new(command=command, comment=\"pyci_cron\")\\n        #Run the cron every minute of every hour every day.\\n        if args[\"cronfreq\"] == 1:\\n            vms(\"New cron tab configured *minutely* for {}\".format(command))\\n            job.setall(\"* * * * *\")\\n        else:\\n            vms(\"New cron tab configured every {} minutes for {}.\".format(args[\"cronfreq\"], command))\\n            job.setall(\"*/{} * * * *\".format(args[\"cronfreq\"]))\\n        cron.write()\\n        db[\"cron\"] = True\\n        _save_db()',\n",
       " 'def _cron_profile():\\n    \"\"\"Sets up the .cron_profile file if it does not already exist.\\n    \"\"\"\\n    #The main ingredients of the file are the import of the virtualenvwrapper\\n    #and the setting of the PYCI_XML variable for global configuration.\\n    from os import path\\n    cronpath = path.expanduser(\"~/.cron_profile\")\\n    if not path.isfile(cronpath):\\n        from os import getenv\\n        xmlpath = getenv(\"PYCI_XML\")    \\n        contents = [\\'source /usr/local/bin/virtualenvwrapper.sh\\',\\n                    \\'export PYCI_XML=\"{}\"\\'.format(xmlpath)]\\n        with open(cronpath, \\'w\\') as f:\\n            f.write(\\'\\\\n\\'.join(contents))',\n",
       " 'def _setup_server():\\n    \"\"\"Checks whether the server needs to be setup if a repo is being installed.\\n    If it does, checks whether anything needs to be done.\\n    \"\"\"\\n    if args[\"setup\"] or args[\"install\"]:\\n        #If the cron has been configured, it means that the server has been\\n        #setup. We also perform some checks of the configuration file and the\\n        #existence of the virtualenv.\\n        if not _check_global_settings() or not _check_virtualenv():\\n            return False\\n\\n        _cron_profile()\\n        if \"cron\" in db and not db[\"cron\"]:\\n            _setup_crontab()\\n\\n    if args[\"rollback\"]:\\n        _setup_crontab()',\n",
       " 'def _server_rollback():\\n    \"\"\"Removes script database and archive files to rollback the CI server\\n    installation.\\n    \"\"\"\\n    #Remove the data and archive files specified in settings. The cron\\n    #gets remove by the _setup_server() script if -rollback is specified.\\n    from os import path, remove\\n    archpath = path.abspath(path.expanduser(settings.archfile))\\n    if path.isfile(archpath) and not args[\"nolive\"]:\\n        vms(\"Removing archive JSON file at {}.\".format(archpath))\\n        remove(archpath)\\n    datapath = path.abspath(path.expanduser(settings.datafile))\\n    if path.isfile(datapath) and not args[\"nolive\"]:\\n        vms(\"Removing script database JSON file at {}\".format(datapath))\\n        remove(datapath)',\n",
       " 'def _list_repos():\\n    \"\"\"Lists all the installed repos as well as their last start and finish\\n    times from the cron\\'s perspective.\\n    \"\"\"\\n    if not args[\"list\"]:\\n        return\\n    \\n    #Just loop over the list of repos we have in a server instance. See if\\n    #they also exist in the db\\'s status; if they do, include the start/end\\n    #times we have saved.\\n    from pyci.server import Server\\n    server = Server(testmode=args[\"nolive\"])\\n    output = [\"Repository           |      Started     |      Finished    | XML File Path\",\\n              \"--------------------------------------------------------------------------\"]\\n\\n    dbs = {} if \"status\" not in db else db[\"status\"]\\n    fullfmt = \"{0:<20} | {1:^16} | {2:^16} | {3}\"\\n    for reponame, repo in server.repositories.items():\\n        if reponame in dbs:\\n            start = _fmt_time(dbs[reponame][\"start\"])\\n            end = _fmt_time(dbs[reponame][\"end\"])\\n        else:\\n            start = \"Never\"\\n            end = \"Never\"\\n        output.append(fullfmt.format(reponame, start, end, repo.filepath))\\n\\n    info(\\'\\\\n\\'.join(output))',\n",
       " 'def run():\\n    \"\"\"Main script entry to handle the arguments given to the script.\"\"\"\\n    _parser_options()\\n    set_verbose(args[\"verbose\"])\\n    \\n    if _check_global_settings():\\n        _load_db()\\n    else:\\n        exit(-1)\\n\\n    #Check the server configuration against the script arguments passed in.\\n    _setup_server()\\n\\n    if args[\"rollback\"]:\\n        _server_rollback()\\n        okay(\"The server rollback appears to have been successful.\")\\n        exit(0)\\n\\n    _server_enable()    \\n    _list_repos()\\n    _handle_install()\\n    \\n    #This is the workhorse once a successful installation has happened.\\n    _do_cron()',\n",
       " 'def _idle_register_view(self, view):\\n        \"\"\"Internal method that calls register_view\"\"\"\\n        assert(self.view is None)\\n        self.view = view\\n\\n        if self.handlers == \"class\":\\n            for name in dir(self):\\n                when, _, what = partition(name, \\'_\\')\\n                widget, _, signal = partition(what, \\'__\\')\\n                if when == \"on\":\\n                    try:\\n                        view[widget].connect(signal, getattr(self, name))\\n                    except IndexError:\\n                        # Not a handler\\n                        pass\\n                    except KeyError:\\n                        logger.warn(\"Widget not found for handler: %s\", name)\\n        elif self.handlers == \"glade\":\\n            self.__autoconnect_signals()\\n        else:\\n            raise NotImplementedError(\"%s is not a valid source of signal \"\\n                \"connections\" % self.handlers)\\n\\n        self.register_view(view)\\n        self.register_adapters()\\n        if self.__auto_adapt: self.adapt()\\n        return False',\n",
       " 'def __autoconnect_signals(self):\\n        \"\"\"This is called during view registration, to autoconnect\\n        signals in glade file with methods within the controller\"\"\"\\n        dic = {}\\n        for name in dir(self):\\n            method = getattr(self, name)\\n            if (not isinstance(method, collections.Callable)):\\n                continue\\n            assert(name not in dic) # not already connected!\\n            dic[name] = method\\n\\n        # autoconnects glade in the view (if available any)\\n        for xml in self.view.glade_xmlWidgets:\\n            xml.signal_autoconnect(dic)\\n\\n        # autoconnects builder if available\\n        if self.view._builder is not None:\\n            self.view._builder_connect_signals(dic)',\n",
       " 'def parseExtensionArgs(self, args):\\n        \"\"\"Parse the unqualified teams extension request\\n        parameters and add them to this object.\\n\\n        This method is essentially the inverse of\\n        C{L{getExtensionArgs}}. This method restores the serialized teams\\n        extension team names.\\n\\n        If you are extracting arguments from a standard OpenID\\n        checkid_* request, you probably want to use C{L{fromOpenIDRequest}},\\n        which will extract the teams extension namespace and arguments from the\\n        OpenID request. This method is intended for cases where the\\n        OpenID server needs more control over how the arguments are\\n        parsed than that method provides.\\n\\n        >>> args = message.getArgs(teams_uri)\\n        >>> request.parseExtensionArgs(args)\\n\\n        @param args: The unqualified teams extension arguments\\n        @type args: {str:str}\\n\\n        @returns: None; updates this object\\n        \"\"\"\\n        items = args.get(\\'query_membership\\')\\n        if items:\\n            for team_name in items.split(\\',\\'):\\n                self.requestTeam(team_name)',\n",
       " 'def requestTeam(self, team_name):\\n        \"\"\"Request the specified team membership from the OpenID user\\n\\n        @param team_name: the unqualified team name\\n        @type team_name: str\\n        \"\"\"\\n        if not team_name in self.requested:\\n            self.requested.append(team_name)',\n",
       " 'def requestTeams(self, team_names):\\n        \"\"\"Add the given list of team names to the request.\\n\\n        @param team_names: The team names to request\\n        @type team_names: [str]\\n        \"\"\"\\n        if isinstance(team_names, six.string_types):\\n            raise TypeError(\\'Teams should be passed as a list of \\'\\n                            \\'strings (not %r)\\' % (type(field_names),))\\n\\n        for team_name in team_names:\\n            self.requestTeam(team_name)',\n",
       " 'def has_property(obj, name):\\n        \"\"\"\\n        Checks recursively if object or its subobjects has a property with specified name.\\n\\n        The object can be a user defined object, map or array.\\n        The property name correspondently must be object property, map key or array index.\\n\\n        :param obj: an object to introspect.\\n\\n        :param name: a name of the property to check.\\n\\n        :return: true if the object has the property and false if it doesn\\'t.\\n        \"\"\"\\n        if obj == None or name == None:\\n            return False\\n\\n        names = name.split(\".\")\\n        if names == None or len(names) == 0: \\n            return False\\n\\n        return RecursiveObjectReader._perform_has_property(obj, names, 0)',\n",
       " 'def get_property(obj, name):\\n        \"\"\"\\n        Recursively gets value of object or its subobjects property specified by its name.\\n\\n        The object can be a user defined object, map or array.\\n        The property name correspondently must be object property, map key or array index.\\n\\n        :param obj: an object to read property from.\\n\\n        :param name: a name of the property to get.\\n\\n        :return: the property value or null if property doesn\\'t exist or introspection failed.\\n        \"\"\"\\n        if obj == None or name == None:\\n            return None\\n\\n        names = name.split(\".\")\\n        if names == None or len(names) == 0:\\n            return None\\n\\n        return RecursiveObjectReader._perform_get_property(obj, names, 0)',\n",
       " 'def get_property_names(obj):\\n        \"\"\"\\n        Recursively gets names of all properties implemented in specified object and its subobjects.\\n\\n        The object can be a user defined object, map or array.\\n        Returned property name correspondently are object properties, map keys or array indexes.\\n\\n        :param obj: an object to introspect.\\n\\n        :return: a list with property names.\\n        \"\"\"\\n        property_names = []\\n        \\n        if obj != None:\\n            cycle_detect = []\\n            RecursiveObjectReader._perform_get_property_names(obj, None, property_names, cycle_detect)\\n\\n        return property_names',\n",
       " 'def get_properties(obj):\\n        \"\"\"\\n        Get values of all properties in specified object and its subobjects and returns them as a map.\\n\\n        The object can be a user defined object, map or array.\\n        Returned properties correspondently are object properties, map key-pairs or array elements with their indexes.\\n\\n        :param obj: an object to get properties from.\\n\\n        :return: a map, containing the names of the object\\'s properties and their values.\\n        \"\"\"\\n        properties = {}\\n        \\n        if obj != None:\\n            cycle_detect = []\\n            RecursiveObjectReader._perform_get_properties(obj, None, properties, cycle_detect)\\n\\n        return properties',\n",
       " 'def hookable(cls):\\n    \"\"\"\\n    Initialise hookery in a class that declares hooks by decorating it with this decorator.\\n\\n    This replaces the class with another one which has the same name, but also inherits Hookable\\n    which has HookableMeta set as metaclass so that sub-classes of cls will have hook descriptors\\n    initialised properly.\\n\\n    When you say:\\n        @hookable\\n        class My:\\n            before = Hook()\\n\\n    then @hookable changes My.before to be a HookDescriptor which is then\\n    changed into Hook if anyone accesses it.\\n\\n    There is no need to decorate sub-classes of cls with @hookable.\\n    \"\"\"\\n    assert isinstance(cls, type)\\n\\n    # For classes that won\\'t have descriptors initialised by metaclass, need to do it here.\\n    hook_definitions = []\\n    if not issubclass(cls, Hookable):\\n        for k, v in list(cls.__dict__.items()):\\n            if isinstance(v, (ClassHook, InstanceHook)):\\n                delattr(cls, k)\\n                if v.name is None:\\n                    v.name = k\\n                hook_definitions.append((k, v))\\n\\n    hookable_cls = type(cls.__name__, (cls, Hookable), {})\\n\\n    for k, v in hook_definitions:\\n        setattr(hookable_cls, k, HookDescriptor(defining_hook=v, defining_class=hookable_cls))\\n\\n    return hookable_cls',\n",
       " 'def _triggering_ctx(self):\\n        \"\"\"\\n        Context manager that ensures that a hook is not re-triggered by one of its handlers.\\n        \"\"\"\\n        if self._is_triggering:\\n            raise RuntimeError(\\'{} cannot be triggered while it is being handled\\'.format(self))\\n        self._is_triggering = True\\n        try:\\n            yield self\\n        finally:\\n            self._is_triggering = False',\n",
       " 'def unregister_handler(self, handler_or_func):\\n        \"\"\"\\n        Remove the handler from this hook\\'s list of handlers.\\n        This does not give up until the handler is found in the class hierarchy.\\n        \"\"\"\\n        index = -1\\n        for i, handler in enumerate(self._direct_handlers):\\n            if handler is handler_or_func or handler._original_func is handler_or_func:\\n                index = i\\n                break\\n        if index >= 0:\\n            self._direct_handlers.pop(index)\\n            self._cached_handlers = None\\n\\n        elif self.parent_class_hook is not None and self.parent_class_hook.has_handler(handler_or_func):\\n            self.parent_class_hook.unregister_handler(handler_or_func)\\n            self._cached_handlers = None\\n\\n        elif self.instance_class_hook is not None and self.instance_class_hook.has_handler(handler_or_func):\\n            self.instance_class_hook.unregister_handler(handler_or_func)\\n            self._cached_handlers = None\\n\\n        else:\\n            raise ValueError(\\'{} is not a registered handler of {}\\'.format(handler_or_func, self))',\n",
       " 'def notifySolved(self, identifier, title):\\n        \"\"\"Notifies the user that a particular exercise has been solved.\\n\\n        \"\"\"\\n        notify(self.workbench, u\"Congratulations\", u\"Congratulations! You \"\\n               \"have completed the \\'{title}\\' exercise.\".format(title=title))\\n        return {}',\n",
       " 'def prepend_urls(self):\\n        \"\"\" Add the following array of urls to the Tileset base urls \"\"\"\\n        return [\\n            url(r\"^(?P<resource_name>%s)/(?P<pk>\\\\w[\\\\w/-]*)/generate%s$\" %\\n                (self._meta.resource_name, trailing_slash()),\\n                self.wrap_view(\\'generate\\'), name=\"api_tileset_generate\"),\\n            url(r\"^(?P<resource_name>%s)/(?P<pk>\\\\w[\\\\w/-]*)/download%s$\" %\\n                (self._meta.resource_name, trailing_slash()),\\n                self.wrap_view(\\'download\\'), name=\"api_tileset_download\"),\\n            url(r\"^(?P<resource_name>%s)/(?P<pk>\\\\w[\\\\w/-]*)/status%s$\" %\\n                (self._meta.resource_name, trailing_slash()),\\n                self.wrap_view(\\'status\\'), name=\"api_tileset_status\"),\\n            url(r\"^(?P<resource_name>%s)/(?P<pk>\\\\w[\\\\w/-]*)/stop%s$\" %\\n                (self._meta.resource_name, trailing_slash()),\\n                self.wrap_view(\\'stop\\'), name=\"api_tileset_stop\"),\\n        ]',\n",
       " 'def generate(self, request, **kwargs):\\n        \"\"\" proxy for the tileset.generate method \"\"\"\\n\\n        # method check to avoid bad requests\\n        self.method_check(request, allowed=[\\'get\\'])\\n\\n        # create a basic bundle object for self.get_cached_obj_get.\\n        basic_bundle = self.build_bundle(request=request)\\n\\n        # using the primary key defined in the url, obtain the tileset\\n        tileset = self.cached_obj_get(\\n            bundle=basic_bundle,\\n            **self.remove_api_resource_names(kwargs))\\n\\n        # Return what the method output, tastypie will handle the serialization\\n        return self.create_response(request, tileset.generate())',\n",
       " 'def download(self, request, **kwargs):\\n        \"\"\" proxy for the helpers.tileset_download method \"\"\"\\n\\n        # method check to avoid bad requests\\n        self.method_check(request, allowed=[\\'get\\'])\\n\\n        # create a basic bundle object for self.get_cached_obj_get.\\n        basic_bundle = self.build_bundle(request=request)\\n\\n        # using the primary key defined in the url, obtain the tileset\\n        tileset = self.cached_obj_get(\\n            bundle=basic_bundle,\\n            **self.remove_api_resource_names(kwargs))\\n\\n        filename = helpers.get_tileset_filename(tileset)\\n        filename = os.path.abspath(filename)\\n        if os.path.isfile(filename):\\n            response = serve(request, os.path.basename(filename), os.path.dirname(filename))\\n            response[\\'Content-Disposition\\'] = \\'attachment; filename=\"{}\"\\'.format(os.path.basename(filename))\\n        else:\\n            response = self.create_response(request, {\\'status\\': \\'not generated\\'})\\n        return response',\n",
       " 'def configure(self, config):\\n        \"\"\"\\n        Configures the component with specified parameters.\\n\\n        :param config: configuration parameters to set.\\n        \"\"\"\\n        dependencies = config.get_section(\"dependencies\")\\n        names = dependencies.get_key_names()\\n        for name in names:\\n            locator = dependencies.get(name)\\n            if locator == None:\\n                continue\\n            \\n            try:\\n                descriptor = Descriptor.from_string(locator)\\n                if descriptor != None:\\n                    self._dependencies[name] = descriptor\\n                else:\\n                    self._dependencies[name] = locator\\n            except Exception as ex:\\n                self._dependencies[name] = locator',\n",
       " 'def _locate(self, name):\\n        \"\"\"\\n        Gets a dependency locator by its name.\\n\\n        :param name: the name of the dependency to locate.\\n        :return: the dependency locator or null if locator was not configured.\\n        \"\"\"\\n        if name == None:\\n            raise Exception(\"Dependency name cannot be null\")\\n        if self._references == None:\\n            raise Exception(\"References shall be set\")\\n        \\n        return self._dependencies.get(name)',\n",
       " 'def get_optional(self, name):\\n        \"\"\"\\n        Gets all optional dependencies by their name.\\n\\n        :param name: the dependency name to locate.\\n\\n        :return: a list with found dependencies or empty list of no dependencies was found.\\n        \"\"\"\\n        locator = self._locate(name)\\n        return self._references.get_optional(locator) if locator != None else None',\n",
       " 'def get_one_optional(self, name):\\n        \"\"\"\\n        Gets one optional dependency by its name.\\n\\n        :param name: the dependency name to locate.\\n\\n        :return: a dependency reference or null of the dependency was not found\\n        \"\"\"\\n        locator = self._locate(name)\\n        return self._references.get_one_optional(locator) if locator != None else None',\n",
       " 'def find(self, name, required):\\n        \"\"\"\\n        Finds all matching dependencies by their name.\\n\\n        :param name: the dependency name to locate.\\n\\n        :param required: true to raise an exception when no dependencies are found.\\n\\n        :return: a list of found dependencies\\n        \"\"\"\\n        if name == None:\\n            raise Exception(\"Name cannot be null\")\\n        \\n        locator = self._locate(name)\\n        if locator == None:\\n            if required:\\n                raise ReferenceException(None, name)\\n            return None\\n        \\n        return self._references.find(locator, required)',\n",
       " 'def obtain_to(filename):\\n    \"\"\"\\n    Return the digital elevation map projected to the lat lon matrix coordenates.\\n\\n    Keyword arguments:\\n    filename -- the name of a netcdf file.\\n    \"\"\"\\n    root, _ = nc.open(filename)\\n    lat, lon = nc.getvar(root, \\'lat\\')[0,:], nc.getvar(root, \\'lon\\')[0,:]\\n    nc.close(root)\\n    return obtain(lat, lon)',\n",
       " 'def resolve(config, config_as_default = False):\\n        \"\"\"\\n        Resolves an \"options\" configuration section from component configuration parameters.\\n\\n        :param config: configuration parameters\\n\\n        :param config_as_default: (optional) When set true the method returns the entire parameter\\n                                  set when \"options\" section is not found. Default: false\\n\\n        :return: configuration parameters from \"options\" section\\n        \"\"\"\\n        options = config.get_section(\"options\")\\n\\n        if len(options) == 0 and config_as_default:\\n            options = config\\n\\n        return options',\n",
       " 'def init_form_view(self, view, opts):\\n        \"\"\"Checks if the form referenced in the view exists or attempts to\\n        create it by parsing the template\\n        \"\"\"\\n        name = opts.get(\"name\", opts.get(\"form\"))\\n        if isinstance(name, Form):\\n            return\\n\\n        template = opts.get(\"template\", getattr(view, \"template\", None))\\n        if not template:\\n            if not name:\\n                raise NoFormError(\"No form name specified in the form action and no template\")\\n            return\\n\\n        try:\\n            as_ = opts.get(\"var_name\", getattr(self.form, \"as_\", \"form\"))\\n            form_class = create_from_template(current_app, template, var_name=as_)\\n        except NoFormError:\\n            if not name:\\n                raise\\n            return\\n\\n        if not name:\\n            name = view.name\\n\\n        self.forms[name] = form_class\\n        self.form_created_from_view_signal.send(self, view=view, form_class=form_class)\\n        return form_class',\n",
       " 'def populate_obj(self, obj=None, form=None):\\n        \"\"\"Populates an object with the form\\'s data\\n        \"\"\"\\n        if not form:\\n            form = current_context.data.form\\n        if obj is None:\\n            obj = AttrDict()\\n        form.populate_obj(obj)\\n        return obj',\n",
       " 'def overlap(self, feature, stranded: bool=False):\\n        \"\"\"Determine if a feature\\'s position overlaps with the entry\\n\\n        Args:\\n            feature (class): GFF3Entry object\\n\\n            stranded (bool): allow features to overlap on different strands\\n                if True [default: False]\\n\\n        Returns:\\n            bool: True if features overlap, else False\\n        \"\"\"\\n\\n        # Allow features to overlap on different strands\\n        feature_strand = feature.strand\\n        strand = self.strand\\n\\n        if stranded and ((strand == \\'.\\') or (strand == \\'+\\' and \\\\\\n            feature_strand in [\\'-\\', \\'.\\']) or (strand == \\'-\\' and \\\\\\n            feature_strand in [\\'+\\', \\'.\\'])):\\n            return False\\n\\n        iv_1 = set(range(feature.start, feature.end + 1))\\n        iv_2 = set(range(self.start, self.end + 1))\\n\\n        if len(iv_1.intersection(iv_2)) > 0:\\n            return True\\n        else:\\n            return False',\n",
       " 'def write(self):\\n        \"\"\"Restore GFF3 entry to original format\\n\\n        Returns:\\n            str: properly formatted string containing the GFF3 entry\\n        \"\"\"\\n\\n        none_type = type(None)\\n\\n        # Format attributes for writing\\n        attrs = self.attribute_string()\\n\\n        # Place holder if field value is NoneType\\n        for attr in self.__dict__.keys():\\n            if type(attr) == none_type:\\n                setattr(self, attr, \\'.\\')\\n\\n        # Format entry for writing\\n        fstr = \\'{0}\\\\t{1}\\\\t{2}\\\\t{3}\\\\t{4}\\\\t{5}\\\\t{6}\\\\t{7}\\\\t{8}{9}\\'\\\\\\n               .format(self.seqid, self.source, self.type, str(self.start),\\n                       str(self.end), self._score_str, self.strand, \\n                       self.phase, attrs, os.linesep)\\n\\n        return fstr',\n",
       " 'def attribute_string(self):\\n        \"\"\"Restore an entries attributes in original format, escaping reserved\\n        characters when necessary\\n\\n        Returns:\\n            str: escaped attributes as tag=value pairs, separated by semi-colon\\n        \"\"\"\\n        escape_map = {ord(\\'=\\'): \\'%3D\\',\\n                      ord(\\',\\'): \\'%2C\\',\\n                      ord(\\';\\'): \\'%3B\\',\\n                      ord(\\'&\\'): \\'%26\\',\\n                      ord(\\'\\\\t\\'): \\'%09\\',\\n                     }\\n\\n        list_type = type(list())\\n\\n        attrs = self.attributes\\n        if type(attrs) is OrderedDict:\\n            reserved_attrs = []\\n            other_attrs = []\\n\\n            for name, value in attrs.items():\\n                # Escape reserved characters\\n                name = name.translate(escape_map)\\n\\n                if type(value) == list_type:\\n                    value = \\',\\'.join([i.translate(escape_map) for i in value])\\n                else:\\n                    value = value.translate(escape_map)\\n\\n                # Regain original formatting of attribute column\\n                out_attr = \\'{0}={1}\\'.format(name, value)\\n\\n                # Order attributes so that reserved tags are output first\\n                if name[0].isupper():\\n                    reserved_attrs.append(out_attr)\\n                else:\\n                    other_attrs.append(out_attr)\\n\\n            out_attrs = \\';\\'.join(reserved_attrs + other_attrs)\\n\\n        else:\\n            out_attrs = attrs\\n\\n        return out_attrs',\n",
       " 'def iterate(self, start_line=None, parse_attr=True, headers=False, \\n        comments=False):\\n        \"\"\"Iterate over GFF3 file, returning GFF3 entries\\n\\n        Args:\\n            start_line (str): Next GFF3 entry. If \\'handle\\' has been partially\\n                read and you want to start iterating at the next entry, read \\n                the next GFF3 entry and pass it to this variable when calling \\n                gff3_iter. See \\'Examples\\' for proper usage.\\n\\n            parse_attr (bool): Parse attributes column into a dictionary such \\n                that the string \"tag1=value1;tag2=value2\" becomes:\\n\\n                tag1: value1\\n                tag2: value2\\n\\n            headers (bool): Yields headers if True, else skips lines starting \\n                with \"##\"\\n\\n            comments (bool): Yields comments if True, else skips lines starting\\n                with \"#\"\\n\\n        Yields:\\n            GFF3Entry: class containing all GFF3 data, yields str for headers \\n                if headers options is True then yields GFF3Entry for entries\\n\\n        Examples:\\n            The following three examples demonstrate how to use gff3_iter.\\n            Note: These doctests will not pass, examples are only in doctest\\n            format as per convention. bio_utils uses pytests for testing.\\n\\n            >>> for entry in gff3_iter(open(\\'test.gff3\\')):\\n            ...     print(entry.seqid)  # Sequence ID\\n            ...     print(entry.source)  # Software that performed annotation\\n            ...     print(entry.type)  # Type of annotation\\n            ...     print(entry.start)  # Start position of annotation\\n            ...     print(entry.end)  # End position of annotation\\n            ...     print(entry.score)  # Confidence score of annotation\\n            ...     print(entry.strand)  # Strand annotation is on\\n            ...     print(entry.phase)  # Bases until next codon\\n            ...     print(entry.attributes)  # Attributes of annotation\\n            ...     print(entry.write())  # Reconstituted GFF3 entry\\n\\n            >>> gff3_handle = open(\\'test.gff3\\')\\n            >>> next(gff3_handle)  # Skip first line/entry\\n            >>> next_line = next(gff3_handle)  # Store next entry\\n            >>> for entry in gff3_iter(gff3_handle, start_line=next_line):\\n            ...     print(entry.seqid)  # Sequence ID\\n            ...     print(entry.source)  # Software that performed annotation\\n            ...     print(entry.type)  # Type of annotation\\n            ...     print(entry.start)  # Start position of annotation\\n            ...     print(entry.end)  # End position of annotation\\n            ...     print(entry.score)  # Confidence score of annotation\\n            ...     print(entry.strand)  # Strand annotation is on\\n            ...     print(entry.phase)  # Bases until next codon\\n            ...     print(entry.attributes)  # Attributes of annotation\\n            ...     print(entry.write())  # Reconstituted GFF3 entry\\n\\n            >>> for entry in gff3_iter(open(\\'test.gff3\\'), parse_attr=True):\\n            ...     print(entry.seqid)  # Sequence ID\\n            ...     print(entry.source)  # Software that performed annotation\\n            ...     print(entry.type)  # Type of annotation\\n            ...     print(entry.start)  # Start position of annotation\\n            ...     print(entry.end)  # End position of annotation\\n            ...     print(entry.score)  # Confidence score of annotation\\n            ...     print(entry.strand)  # Strand annotation is on\\n            ...     print(entry.phase)  # Bases until next codon\\n            ...     print(entry.attributes[\\'attr1\\'])  # Print attribute \\'attr1\\'\\n            ...     print(entry.attributes[\\'attr2\\'])  # Print attribute \\'attr2\\'\\n            ...     print(entry.write())  # Reconstituted GFF3 entry\\n        \"\"\"\\n\\n        handle = self.handle\\n\\n        # Speed tricks: reduces function calls\\n        split = str.split\\n        strip = str.strip\\n\\n        if start_line is None:\\n            line = next(handle)  # Read first GFF3\\n        else:\\n            line = start_line  # Set header to given header\\n\\n        # Check if input is text or bytestream\\n        if (isinstance(line, bytes)):\\n            def next_line(i):\\n                return next(i).decode(\\'utf-8\\')\\n\\n            line = strip(line.decode(\\'utf-8\\'))\\n        else:\\n            next_line = next\\n            line = strip(line)\\n\\n        # Manual \\'for\\' loop isn\\'t needed to read the file properly and quickly,\\n        # unlike fasta_iter and fastq_iter, but it is necessary begin iterating\\n        # partway through a file when the user gives a starting line.\\n        try:  # Manually construct a for loop to improve speed by using \\'next\\'\\n\\n            while True:  # Loop until StopIteration Exception raised\\n\\n                self.current_line += 1\\n\\n                data = GFF3Entry()  # Initialize early to prevent access error\\n\\n                if line.startswith(\\'##FASTA\\'):  # Skip FASTA entries\\n                    raise FastaFound\\n\\n                if line.startswith(\\'##\\') and not headers:\\n                    line = strip(next_line(handle))\\n                    continue\\n                elif line.startswith(\\'##\\') and headers:\\n                    yield line\\n                    line = strip(next_line(handle))\\n                    continue\\n\\n                if line.startswith(\\'#\\') and not comments:\\n                    line = strip(next_line(handle))\\n                    continue\\n                elif line.startswith(\\'#\\') and comments:\\n                    yield line\\n                    line = strip(next_line(handle))\\n                    continue\\n\\n                split_line = split(line, \\'\\\\t\\')\\n\\n                data.origline = line\\n                data.seqid = split_line[0]\\n                data.source = split_line[1]\\n                data.type = split_line[2]\\n                data.start = int(split_line[3])\\n                data.end = int(split_line[4])\\n                try:  # Make float unless dot\\n                    data.score = float(split_line[5])\\n                except ValueError:\\n                    data.score = split_line[5]\\n                data._score_str = split_line[5]\\n                data.strand = split_line[6]\\n                try:  # Get phase as int unless phase not given\\n                    data.phase = int(split_line[7])\\n                except ValueError:\\n                    data.phase = split_line[7]\\n                data.attributes = split_line[8]\\n\\n                if parse_attr:\\n                    attributes = split(data.attributes, \\';\\')\\n                    data.attributes = OrderedDict()\\n                    for attribute in attributes:\\n                        split_attribute = attribute.split(\\'=\\')\\n                        key = split_attribute[0]\\n                        value = split_attribute[-1].split(\\',\\') if \\',\\' in \\\\\\n                                split_attribute[-1] else split_attribute[-1]\\n                        if not key == \\'\\':  # Avoid semicolon split at end\\n                            data.attributes[key] = value\\n\\n                line = strip(next_line(handle))  # Raises StopIteration at EOF\\n\\n                yield data\\n\\n        except StopIteration:  # Yield last GFF3 entry\\n            if data.origline:\\n                yield data\\n            else:  #handle case where GFF ends in comment\\n                pass\\n        except FastaFound:  # When FASTA found, last entry is repeat so pass\\n            pass',\n",
       " 'def put(self, locator = None, component = None):\\n        \"\"\"\\n        Puts a new reference into this reference map.\\n\\n        :param locator: a component reference to be added.\\n\\n        :param component: a locator to find the reference by.\\n        \"\"\"\\n        if component == None:\\n            raise Exception(\"Component cannot be null\")\\n\\n        self._lock.acquire()\\n        try:\\n            self._references.append(Reference(locator, component))\\n        finally:\\n            self._lock.release()',\n",
       " 'def remove_all(self, locator):\\n        \"\"\"\\n        Removes all component references that match the specified locator.\\n\\n        :param locator: a locator to remove reference by.\\n\\n        :return: a list, containing all removed references.\\n        \"\"\"\\n        components = []\\n\\n        if locator == None:\\n            return components\\n\\n        self._lock.acquire()\\n        try:\\n            for reference in reversed(self._references):\\n                if reference.match(locator):\\n                    self._references.remove(reference)\\n                    components.append(reference.get_component())\\n        finally:\\n            self._lock.release()\\n        \\n        return components',\n",
       " 'def get_all_locators(self):\\n        \"\"\"\\n        Gets locators for all registered component references in this reference map.\\n\\n        :return: a list with component locators.\\n        \"\"\"\\n        locators = []\\n\\n        self._lock.acquire()\\n        try:\\n            for reference in self._references:\\n                locators.append(reference.get_locator())\\n        finally:\\n            self._lock.release()\\n\\n        return locators',\n",
       " 'def get_all(self):\\n        \"\"\"\\n        Gets all component references registered in this reference map.\\n\\n        :return: a list with component references.\\n        \"\"\"\\n        components = []\\n        \\n        self._lock.acquire()\\n        try:\\n            for reference in self._references:\\n                components.append(reference.get_component())\\n        finally:\\n            self._lock.release()\\n\\n        return components',\n",
       " 'def get_one_optional(self, locator):\\n        \"\"\"\\n        Gets an optional component reference that matches specified locator.\\n\\n        :param locator: the locator to find references by.\\n\\n        :return: a matching component reference or null if nothing was found.\\n        \"\"\"\\n        try:\\n            components = self.find(locator, False)\\n            return components[0] if len(components) > 0 else None\\n        except Exception as ex:\\n            return None',\n",
       " 'def get_one_required(self, locator):\\n        \"\"\"\\n         Gets a required component reference that matches specified locator.\\n\\n         :param locator: the locator to find a reference by.\\n\\n         :return: a matching component reference.\\n\\n         :raises: a [[ReferenceException]] when no references found.\\n         \"\"\"\\n        components = self.find(locator, True)\\n        return components[0] if len(components) > 0 else None',\n",
       " 'def initialize(**kwargs):\\n    \"\"\"\\n    Loads the globally shared YAML configuration\\n    \"\"\"\\n    global config\\n    config_opts = kwargs.setdefault(\\'config\\',{})\\n\\n    if isinstance(config_opts,basestring):\\n        config_opts = {\\'config_filename\\':config_opts}\\n        kwargs[\\'config\\'] = config_opts\\n\\n    if \\'environment\\' in kwargs:\\n        config_opts[\\'environment\\'] = kwargs[\\'environment\\']\\n\\n    config.load_config(**config_opts)\\n\\n    # Overlay the subconfig\\n    if kwargs.get(\\'name\\'):\\n        subconfig = config.get(kwargs.get(\\'name\\'),{})\\n        config.overlay_add(subconfig)\\n\\n    config.overlay_add(app_config)',\n",
       " 'def config_amend_key_(self,key,value):\\n        \"\"\" This will take a stringified key representation and value and\\n        load it into the configuration file for furthur usage. The good\\n        part about this method is that it doesn\\'t clobber, only appends\\n        when keys are missing.\\n        \"\"\"\\n        cfg_i = self._cfg\\n        keys = key.split(\\'.\\')\\n        last_key = keys.pop()\\n        trail = []\\n        for e in keys:\\n            cfg_i.setdefault(e,{})\\n            cfg_i = cfg_i[e]\\n            trail.append(e)\\n            if not isinstance(cfg_i,dict):\\n                raise Exception(\\'.\\'.join(trail) + \\' has conflicting dict/scalar types!\\')\\n        cfg_i.setdefault(last_key,value)',\n",
       " 'def config_amend_(self,config_amend):\\n        \"\"\" This will take a YAML or dict configuration and load it into\\n            the configuration file for furthur usage. The good part\\n            about this method is that it doesn\\'t clobber, only appends\\n            when keys are missing.\\n\\n            This should provide a value in dictionary format like:\\n\\n            {\\n              \\'default\\': {\\n                \\'togglsync\\': {\\n                  \\'dsn\\': \\'sqlite:///zerp-toggl.db\\',\\n                  \\'default\\': {\\n                    \\'username\\': \\'abced\\',\\n                    \\'toggl_api_key\\': \\'arfarfarf\\',\\n                  },\\n                  \\'dev\\': {\\n                    \\'cache\\': False\\n                  }\\n               }\\n            }\\n\\n            OR at user\\'s preference can also use yaml format:\\n\\n            default:\\n              togglsync:\\n                  dsn: \\'sqlite:///zerp-toggl.db\\'\\n                  default:\\n                    username: \\'abced\\'\\n                    toggl_api_key: \\'arfarfarf\\'\\n                  dev:\\n                    cache: False\\n\\n            Then the code will append the key/values where they may be\\n            missing.\\n\\n            If there is a conflict between a dict key and a value, this\\n            function will throw an exception.\\n\\n            IMPORTANT: after making the change to the configuration, \\n                       remember to save the changes with cfg.save_()\\n\\n        \"\"\"\\n        if not isinstance(config_amend,dict):\\n            config_amend = yaml.load(config_amend)\\n\\n        def merge_dicts(source,target,breadcrumbs=None):\\n            \"\"\"\\n            Function to update the configuration if required. Returns\\n            True if a change was made.\\n            \"\"\"\\n\\n            changed = False\\n\\n            if breadcrumbs is None:\\n                breadcrumbs = []\\n\\n            # Don\\'t descend if we\\'re not a dict\\n            if not isinstance(source,dict):\\n              return source\\n\\n            # Let\\'s start iterating over things\\n            for k,v in source.items():\\n\\n                # New key, simply add.\\n                if k not in target:\\n                    target[k] = v\\n                    changed = True\\n                    continue\\n\\n                # Not new key.... so is it a dict?\\n                elif isinstance(target[k],dict):\\n                    trail = breadcrumbs+[k]\\n                    if isinstance(v,dict):\\n                        if merge_dicts(v,target[k],trail):\\n                            changed = True\\n                    else:\\n                        raise Exception(\\'.\\'.join(trail) + \\' has conflicting dict/scalar types!\\')\\n\\n                else:\\n                    trail = breadcrumbs+[k]\\n                    if isinstance(v,dict):\\n                        raise Exception(\\'.\\'.join(trail) + \\' has conflicting dict/scalar types!\\')\\n\\n            return changed\\n\\n        if merge_dicts(config_amend,self._cfg):\\n            self.overlay_load()\\n\\n        return self._cfg',\n",
       " 'def get_string(self, input_string):\\n        \"\"\"\\n\\t\\tReturn string type user input\\n\\t\\t\"\"\"\\n\\n        if input_string in (\\'--input\\', \\'--outname\\', \\'--framework\\'):\\n\\n            # was the flag set?\\n            try:\\n                index = self.args.index(input_string) + 1\\n            except ValueError:\\n                # it wasn\\'t, so if it\\'s required, exit\\n                if input_string in self.required:\\n                    print(\"\\\\n {flag} is required\".format(input_string))\\n                    print_short_help()\\n                    sys.exit(1)\\n                # it wasn\\'t, if its optional, return the default\\n                else:\\n                    return None\\n\\n                    # the flag was set, so check if a value was set, otherwise exit\\n            try:\\n                if self.args[index] in self.flags:\\n                    print(\"\\\\n {flag} was set but a value was not specified\".format(flag=input_string))\\n                    print_short_help()\\n                    sys.exit(1)\\n            except IndexError:\\n                print(\"\\\\n {flag} was set but a value was not specified\".format(input_string))\\n                print_short_help()\\n                sys.exit(1)\\n\\n            # a value was set, so check and assign the appropriate value or exit\\n            if input_string == \\'--input\\':\\n                return os.path.abspath(self.args[index])\\n            elif input_string == \\'--outname\\':\\n                return format(self.args[index])',\n",
       " 'def select_executor(elem, doc):\\n    \"\"\"Determines the executor for the code in `elem.text`.\\n\\n    The elem attributes and classes select the executor in this order (highest\\n    to lowest):\\n        - custom commands (cmd=...)\\n        - runas (runas=...) takes a key for the executors\\n        - first element class (.class) determines language and thus executor\\n\\n    Args:\\n        elem The AST element.\\n        doc  The document.\\n\\n    Returns:\\n        The command to execute code.\\n    \"\"\"\\n    executor = EXECUTORS[\\'default\\']\\n\\n    if \\'cmd\\' in elem.attributes.keys():\\n        executor = elem.attributes[\\'cmd\\']\\n    elif \\'runas\\' in elem.attributes.keys():\\n        executor = EXECUTORS[elem.attributes[\\'runas\\']]\\n    elif elem.classes[0] != \\'exec\\':\\n        executor = EXECUTORS[elem.classes[0]]\\n\\n    return executor',\n",
       " 'def execute_code_block(elem, doc):\\n    \"\"\"Executes a code block by passing it to the executor.\\n\\n    Args:\\n        elem The AST element.\\n        doc  The document.\\n\\n    Returns:\\n        The output of the command.\\n    \"\"\"\\n    command = select_executor(elem, doc).split(\\' \\')\\n    code = elem.text\\n    if \\'plt\\' in elem.attributes or \\'plt\\' in elem.classes:\\n        code = save_plot(code, elem)\\n    command.append(code)\\n    if \\'args\\' in elem.attributes:\\n        for arg in elem.attributes[\\'args\\'].split():\\n            command.append(arg)\\n\\n    cwd = elem.attributes[\\'wd\\'] if \\'wd\\' in elem.attributes else None\\n\\n    return subprocess.run(command,\\n                          encoding=\\'utf8\\',\\n                          stdout=subprocess.PIPE,\\n                          stderr=subprocess.STDOUT,\\n                          cwd=cwd).stdout',\n",
       " 'def execute_interactive_code(elem, doc):\\n    \"\"\"Executes code blocks for a python shell.\\n\\n    Parses the code in `elem.text` into blocks and\\n    executes them.\\n\\n    Args:\\n        elem The AST element.\\n        doc  The document.\\n\\n    Return:\\n        The code with inline results.\\n    \"\"\"\\n    code_lines = [l[4:] for l in elem.text.split(\\'\\\\n\\')]\\n\\n    code_blocks = [[code_lines[0]]]\\n    for line in code_lines[1:]:\\n        if line.startswith(\\' \\') or line == \\'\\':\\n            code_blocks[-1].append(line)\\n        else:\\n            code_blocks.append([line])\\n\\n    final_code = []\\n    try:\\n        child = replwrap.REPLWrapper(\"python\", \">>> \", None)\\n    except NameError:\\n        pf.debug(\\'Can not run interactive session. No output produced \\' +\\n                 \\'(Code was:\\\\n{!s}\\\\n)\\'\\n                 .format(elem))\\n        pf.debug(\\'Please pip install pexpect.\\')\\n        return \\'\\'\\n    for code_block in code_blocks:\\n        result = child.run_command(\\'\\\\n\\'.join(code_block) + \\'\\\\n\\').rstrip(\\'\\\\r\\\\n\\')\\n        final_code += [(\\'>>> \\' if i == 0 else \\'... \\') + l for i, l in\\n                       enumerate(code_block)]\\n        if result:\\n            final_code += [r for r in result.split(\\'\\\\n\\')\\n                           if r.strip() not in code_block]\\n    return \\'\\\\n\\'.join(final_code)',\n",
       " 'def read_file(filename):\\n    \"\"\"Reads a file which matches the pattern `filename`.\\n\\n    Args:\\n        filename The filename pattern\\n\\n    Returns:\\n        The file content or the empty string, if the file is not found.\\n    \"\"\"\\n    hits = glob.glob(\\'**/{}\\'.format(filename), recursive=True)\\n    if not len(hits):\\n        pf.debug(\\'No file \"{}\" found.\\'.format(filename))\\n        return \\'\\'\\n    elif len(hits) > 1:\\n        pf.debug(\\'File pattern \"{}\" ambiguous. Using first.\\'.format(filename))\\n\\n    with open(hits[0], \\'r\\') as f:\\n        return f.read()',\n",
       " 'def filter_lines(code, line_spec):\\n    \"\"\"Removes all lines not matching the line_spec.\\n\\n    Args:\\n        code The code to filter\\n        line_spec The line specification. This should be a comma-separated\\n                  string of lines or line ranges, e.g. 1,2,5-12,15\\n                  If a line range starts with -, all lines up to this line are\\n                  included.\\n                  If a line range ends with -, all lines from this line on are\\n                  included.\\n                  All lines mentioned (ranges are inclusive) are used.\\n    Returns:\\n        Only the specified lines.\\n    \"\"\"\\n    code_lines = code.splitlines()\\n\\n    line_specs = [line_denom.strip() for line_denom in line_spec.split(\\',\\')]\\n\\n    single_lines = set(map(int, filter(lambda line: \\'-\\' not in line, line_specs)))\\n    line_ranges = set(filter(lambda line: \\'-\\' in line, line_specs))\\n\\n    for line_range in line_ranges:\\n        begin, end = line_range.split(\\'-\\')\\n        if not begin:\\n            begin = 1\\n        if not end:\\n            end = len(code_lines)\\n        single_lines.update(range(int(begin), int(end) + 1))\\n\\n    keep_lines = []\\n    for line_number, line in enumerate(code_lines, 1):\\n        if line_number in single_lines:\\n            keep_lines.append(line)\\n\\n    return \\'\\\\n\\'.join(keep_lines)',\n",
       " 'def remove_import_statements(code):\\n    \"\"\"Removes lines with import statements from the code.\\n\\n    Args:\\n        code: The code to be stripped.\\n\\n    Returns:\\n        The code without import statements.\\n    \"\"\"\\n    new_code = []\\n    for line in code.splitlines():\\n        if not line.lstrip().startswith(\\'import \\') and \\\\\\n           not line.lstrip().startswith(\\'from \\'):\\n            new_code.append(line)\\n\\n    while new_code and new_code[0] == \\'\\':\\n        new_code.pop(0)\\n    while new_code and new_code[-1] == \\'\\':\\n        new_code.pop()\\n\\n    return \\'\\\\n\\'.join(new_code)',\n",
       " 'def save_plot(code, elem):\\n    \"\"\"Converts matplotlib plots to tikz code.\\n\\n    If elem has either the plt attribute (format: plt=width,height) or the\\n    attributes width=width and/or height=height, the figurewidth and -height\\n    are set accordingly. If none are given, a height of 4cm and a width of 6cm\\n    is used as default.\\n\\n    Args:\\n        code: The matplotlib code.\\n        elem: The element.\\n\\n    Returns:\\n        The code and some code to invoke matplotlib2tikz.\\n    \"\"\"\\n    if \\'plt\\' in elem.attributes:\\n        figurewidth, figureheight = elem.attributes[\\'plt\\'].split(\\',\\')\\n    else:\\n        try:\\n            figureheight = elem.attributes[\\'height\\']\\n        except KeyError:\\n            figureheight = \\'4cm\\'\\n\\n        try:\\n            figurewidth = elem.attributes[\\'width\\']\\n        except KeyError:\\n            figurewidth = \\'6cm\\'\\n\\n    return f\"\"\"import matplotlib\\nmatplotlib.use(\\'TkAgg\\')\\n{code}\\nfrom matplotlib2tikz import get_tikz_code\\ntikz = get_tikz_code(figureheight=\\'{figureheight}\\', figurewidth=\\'{figurewidth}\\')  # noqa\\nprint(tikz)\"\"\"',\n",
       " 'def trimpath(attributes):\\n    \"\"\"Simplifies the given path.\\n\\n    If pathdepth is in attributes, the last pathdepth elements will be\\n    returned. If pathdepth is \"full\", the full path will be returned.\\n    Otherwise the filename only will be returned.\\n\\n    Args:\\n        attributes: The element attributes.\\n\\n    Returns:\\n        The trimmed path.\\n    \"\"\"\\n    if \\'pathdepth\\' in attributes:\\n        if attributes[\\'pathdepth\\'] != \\'full\\':\\n            pathelements = []\\n            remainder = attributes[\\'file\\']\\n            limit = int(attributes[\\'pathdepth\\'])\\n            while len(pathelements) < limit and remainder:\\n                remainder, pe = os.path.split(remainder)\\n                pathelements.insert(0, pe)\\n            return os.path.join(*pathelements)\\n        return attributes[\\'file\\']\\n    return os.path.basename(attributes[\\'file\\'])',\n",
       " 'def prepare(doc):\\n    \"\"\"Sets the caption_found and plot_found variables to False.\"\"\"\\n    doc.caption_found = False\\n    doc.plot_found = False\\n    doc.listings_counter = 0',\n",
       " 'def maybe_center_plot(result):\\n    \"\"\"Embeds a possible tikz image inside a center environment.\\n\\n    Searches for matplotlib2tikz last commend line to detect tikz images.\\n\\n    Args:\\n        result: The code execution result\\n\\n    Returns:\\n        The input result if no tikzpicture was found, otherwise a centered\\n        version.\\n    \"\"\"\\n    begin = re.search(\\'(% .* matplotlib2tikz v.*)\\', result)\\n    if begin:\\n        result = (\\'\\\\\\\\begin{center}\\\\n\\' + result[begin.end():] +\\n                  \\'\\\\n\\\\\\\\end{center}\\')\\n    return result',\n",
       " 'def action(elem, doc):  # noqa\\n    \"\"\"Processes pf.CodeBlocks.\\n\\n    For details and a specification of how each command should behave,\\n    check the example files (especially the md and pdf)!\\n\\n    Args:\\n        elem: The element to process.\\n        doc:  The document.\\n\\n    Returns:\\n        A changed element or None.\\n    \"\"\"\\n    if isinstance(elem, pf.CodeBlock):\\n        doc.listings_counter += 1\\n        elems = [elem] if \\'hide\\' not in elem.classes else []\\n\\n        if \\'file\\' in elem.attributes:\\n            elem.text = read_file(elem.attributes[\\'file\\'])\\n            filename = trimpath(elem.attributes)\\n            prefix = pf.Emph(pf.Str(\\'File:\\'))\\n\\n        if \\'exec\\' in elem.classes:\\n            if \\'interactive\\' in elem.classes or elem.text[:4] == \\'>>> \\':\\n                elem.text = execute_interactive_code(elem, doc)\\n            else:\\n                result = execute_code_block(elem, doc)\\n\\n                if \\'hideimports\\' in elem.classes:\\n                    elem.text = remove_import_statements(elem.text)\\n\\n                if \\'plt\\' in elem.attributes or \\'plt\\' in elem.classes:\\n                    doc.plot_found = True\\n                    result = maybe_center_plot(result)\\n                    block = pf.RawBlock(result, format=\\'latex\\')\\n                else:\\n                    block = pf.CodeBlock(result, classes=[\\'changelog\\'])\\n\\n                elems += [pf.Para(pf.Emph(pf.Str(\\'Output:\\'))), block]\\n\\n        if \\'lines\\' in elem.attributes:\\n            elem.text = filter_lines(elem.text, elem.attributes[\\'lines\\'])\\n\\n        label = elem.attributes.get(\\'label\\', f\\'cl:{doc.listings_counter}\\')\\n\\n        if \\'caption\\' in elem.attributes.keys():\\n            doc.caption_found = True\\n            cap = pf.convert_text(elem.attributes[\\'caption\\'], output_format=\\'latex\\')  # noqa\\n            if \\'shortcaption\\' in elem.attributes.keys():\\n                shortcap = pf.convert_text(elem.attributes[\\'shortcaption\\'], output_format=\\'latex\\')  # noqa\\n            else:\\n                shortcap = cap\\n            if \\'file\\' in elem.attributes.keys():\\n                cap += pf.convert_text(f\\'&nbsp;(`{filename}`)\\', output_format=\\'latex\\')  # noqa\\n\\n            elems = make_codelisting(elems, cap, label, shortcaption=shortcap,\\n                                     above=\\'capbelow\\' not in elem.classes)\\n        elif \\'caption\\' in elem.classes:\\n            doc.caption_found = True\\n            cap = \\'\\'\\n            if \\'file\\' in elem.attributes.keys():\\n                cap = pf.convert_text(f\\'`{filename}`\\', output_format=\\'latex\\')\\n            elems = make_codelisting(elems, cap, label,\\n                                     above=\\'capbelow\\' not in elem.classes)\\n        else:\\n            if \\'file\\' in elem.attributes.keys():\\n                elems.insert(0, pf.Para(prefix, pf.Space,\\n                                        pf.Code(filename)))\\n\\n        return elems',\n",
       " 'def finalize(doc):\\n    \"\"\"Adds the pgfplots and caption packages to the header-includes if needed.\\n    \"\"\"\\n    if doc.plot_found:\\n        pgfplots_inline = pf.MetaInlines(pf.RawInline(\\n            r\\'\\'\\'%\\n\\\\makeatletter\\n\\\\@ifpackageloaded{pgfplots}{}{\\\\usepackage{pgfplots}}\\n\\\\makeatother\\n\\\\usepgfplotslibrary{groupplots}\\n\\'\\'\\', format=\\'tex\\'))\\n        try:\\n            doc.metadata[\\'header-includes\\'].append(pgfplots_inline)\\n        except KeyError:\\n            doc.metadata[\\'header-includes\\'] = pf.MetaList(pgfplots_inline)\\n\\n    if doc.caption_found:\\n        caption_inline = pf.MetaInlines(pf.RawInline(\\n            r\\'\\'\\'%\\n\\\\makeatletter\\n\\\\@ifpackageloaded{caption}{}{\\\\usepackage{caption}}\\n\\\\@ifpackageloaded{cleveref}{}{\\\\usepackage{cleveref}}\\n\\\\@ifundefined{codelisting}{%\\n    \\\\DeclareCaptionType{codelisting}[Code Listing][List of Code Listings]\\n    \\\\crefname{codelisting}{code listing}{code listings}\\n    \\\\Crefname{codelisting}{Code Listing}{Code Listings}\\n    \\\\captionsetup[codelisting]{position=bottom}\\n}{}\\n\\\\makeatother\\n\\'\\'\\', format=\\'tex\\'))\\n        try:\\n            doc.metadata[\\'header-includes\\'].append(caption_inline)\\n        except KeyError:\\n            doc.metadata[\\'header-includes\\'] = pf.MetaList(caption_inline)',\n",
       " \"def rescue(f, on_success, on_error=reraise, on_complete=nop):\\n    '''\\n    Functional try-except-finally\\n\\n    :param function f: guarded function\\n    :param function on_succes: called when f is executed without error\\n    :param function on_error: called with `error` parameter when f failed\\n    :param function on_complete: called as finally block\\n    :returns function: call signature is equal f signature\\n    '''\\n    def _rescue(*args, **kwargs):\\n        try:\\n            return on_success(f(*args, **kwargs))\\n        except Exception as e:\\n            return on_error(e)\\n        finally:\\n            on_complete()\\n\\n    return _rescue\",\n",
       " 'def read_file(self, location):\\n        \"\"\"Read in a yaml file and return as a python object\"\"\"\\n        try:\\n            return yaml.load(open(location))\\n        except (yaml.parser.ParserError, yaml.scanner.ScannerError) as error:\\n            raise self.BadFileErrorKls(\"Failed to read yaml\", location=location, error_type=error.__class__.__name__, error=\"{0}{1}\".format(error.problem, error.problem_mark))',\n",
       " 'def _trigger_job(job):\\n    \"\"\" trigger a job \"\"\"\\n    if job.api_instance().is_running():\\n        return \"{0}, {1} is already running\".format(job.host, job.name)\\n    else:\\n        requests.get(job.api_instance().get_build_triggerurl())\\n        return \"triggering {0}, {1}...\".format(job.host, job.name)',\n",
       " 'def observed(cls, _func):\\n        \"\"\"\\n        Decorate methods to be observable. If they are called on an instance\\n        stored in a property, the model will emit before and after\\n        notifications.\\n        \"\"\"\\n\\n        def wrapper(*args, **kwargs):\\n            self = args[0]\\n            assert(isinstance(self, Observable))\\n\\n            self._notify_method_before(self, _func.__name__, args, kwargs)\\n            res = _func(*args, **kwargs)\\n            self._notify_method_after(self, _func.__name__, res, args, kwargs)\\n            return res\\n\\n        return wrapper',\n",
       " 'def emit(self, arg=None):\\n        \"\"\"Emits the signal, passing the optional argument\"\"\"\\n        for model,name in self.__get_models__():\\n            model.notify_signal_emit(name, arg)',\n",
       " 'def _linearize(cls, inst_list):\\n        \"\"\"\\n        A generator function which performs linearization of the list\\n        of instructions; that is, each instruction which should be\\n        executed will be yielded in turn, recursing into\\n        ``Instructions`` instances that appear in the list.\\n\\n        :param inst_list: A list (or other sequence) of instructions.\\n\\n        :returns: An iterator which returns all instructions.\\n        \"\"\"\\n\\n        for inst in inst_list:\\n            # Check if we need to recurse\\n            if isinstance(inst, Instructions):\\n                for sub_inst in cls._linearize(inst.instructions):\\n                    yield sub_inst\\n            else:\\n                yield inst',\n",
       " 'def add_to_known_hosts(self, hosts, known_hosts=DEFAULT_KNOWN_HOSTS, dry=False):\\n        \"\"\"\\n        Add the remote host SSH public key to the `known_hosts` file.\\n\\n        :param hosts: the list of the remote `Host` objects.\\n        :param known_hosts: the `known_hosts` file to store the SSH public keys.\\n        :param dry: perform a dry run.\\n        \"\"\"\\n        to_add = []\\n        with open(known_hosts) as fh:\\n            known_hosts_set = set(line.strip() for line in fh.readlines())\\n\\n        cmd = [\\'ssh-keyscan\\'] + [host.hostname for host in hosts]\\n        logger.debug(\\'Call: %s\\',  \\' \\'.join(cmd))\\n        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\\n        stdout, stderr = p.communicate()\\n        for line in stdout.splitlines():\\n            line = line.strip()\\n            logger.info(\\'[%s] Add the remote host SSH public key to [%s]...\\', line.split(\\' \\', 1)[0], known_hosts)\\n            if line not in known_hosts_set:\\n                known_hosts_set.add(line)\\n                to_add.append(\\'{0}\\\\n\\'.format(line))\\n\\n        if not dry:\\n            with open(known_hosts, \\'a\\') as fh:\\n                fh.writelines(to_add)',\n",
       " 'def remove_from_known_hosts(self, hosts, known_hosts=DEFAULT_KNOWN_HOSTS, dry=False):\\n        \"\"\"\\n        Remove the remote host SSH public key to the `known_hosts` file.\\n\\n        :param hosts: the list of the remote `Host` objects.\\n        :param known_hosts: the `known_hosts` file to store the SSH public keys.\\n        :param dry: perform a dry run.\\n        \"\"\"\\n        for host in hosts:\\n            logger.info(\\'[%s] Removing the remote host SSH public key from [%s]...\\', host.hostname, known_hosts)\\n            cmd = [\\'ssh-keygen\\', \\'-f\\', known_hosts, \\'-R\\', host.hostname]\\n            logger.debug(\\'Call: %s\\', \\' \\'.join(cmd))\\n            if not dry:\\n                try:\\n                    subprocess.check_call(cmd)\\n                except subprocess.CalledProcessError as ex:\\n                    logger.error(format_error(format_exception(ex)))',\n",
       " 'def process_requests(self):\\n        \"\"\"\\n        Loop that runs in a thread to process requests synchronously.\\n        \"\"\"\\n        while True:\\n            id, args, kwargs = self.request_queue.get()\\n            try:\\n                response = self._make_request(*args, **kwargs)\\n            except Exception as e:\\n                response = e\\n            self.results[id] = response',\n",
       " 'def default_from_address(self):\\n        \"\"\"\\n        Cache the coinbase address so that we don\\'t make two requests for every\\n        single transaction.\\n        \"\"\"\\n        if self._coinbase_cache_til is not None:\\n            if time.time - self._coinbase_cache_til > 30:\\n                self._coinbase_cache_til = None\\n                self._coinbase_cache = None\\n\\n        if self._coinbase_cache is None:\\n            self._coinbase_cache = self.get_coinbase()\\n\\n        return self._coinbase_cache',\n",
       " 'def find_pulls(self, testpulls=None):\\n        \"\"\"Finds a list of new pull requests that need to be processed.\\n\\n        :arg testpulls: a list of tserver.FakePull instances so we can test the code\\n          functionality without making live requests to github.\\n        \"\"\"\\n        #We check all the repositories installed for new (open) pull requests.\\n        #If any exist, we check the pull request number against our archive to\\n        #see if we have to do anything for it.\\n        result = {}\\n        for lname, repo in self.repositories.items():\\n            if lname not in self.archive:\\n                raise ValueError(\"Trying to find pull requests for a repository \"\\n                                 \"that hasn\\'t been installed. Use server.install().\")\\n            if self.runnable is not None and lname not in self.runnable:\\n                #We just ignore this repository completely and don\\'t even bother\\n                #performing a live check on github.\\n                continue\\n            \\n            pulls = testpulls if testpulls is not None else repo.repo.get_pulls(\"open\")\\n            result[lname] = []\\n            for pull in pulls:\\n                newpull = True\\n                if pull.snumber in self.archive[lname]:\\n                    #Check the status of that pull request processing. If it was\\n                    #successful, we just ignore this open pull request; it is\\n                    #obviously waiting to be merged in.\\n                    if self.archive[lname][pull.snumber][\"completed\"] == True:\\n                        newpull = False\\n\\n                if newpull:\\n                    #Add the pull request to the list that needs to be processed.\\n                    #We don\\'t add the request to the archive yet because the\\n                    #processing step hasn\\'t happened yet.\\n                    result[lname].append(PullRequest(self, repo, pull, testpulls is not None))\\n\\n        return result',\n",
       " 'def _save_archive(self):\\n        \"\"\"Saves the JSON archive of processed pull requests.\\n        \"\"\"\\n        import json\\n        from utility import json_serial\\n        with open(self.archpath, \\'w\\') as f:\\n            json.dump(self.archive, f, default=json_serial)',\n",
       " 'def _get_repos(self):\\n        \"\"\"Gets a list of all the installed repositories in this server.\\n        \"\"\"\\n        result = {}\\n        for xmlpath in self.installed:\\n            repo = RepositorySettings(self, xmlpath)\\n            result[repo.name.lower()] = repo\\n\\n        return result',\n",
       " 'def _get_installed(self):\\n        \"\"\"Gets a list of the file paths to repo settings files that are\\n        being monitored by the CI server.\\n        \"\"\"\\n        from utility import get_json\\n        #This is a little tricky because the data file doesn\\'t just have a list\\n        #of installed servers. It also manages the script\\'s database that tracks\\n        #the user\\'s interactions with it.\\n        fulldata = get_json(self.instpath, {})\\n        if \"installed\" in fulldata:\\n            return fulldata[\"installed\"]\\n        else:\\n            return []',\n",
       " 'def uninstall(self, xmlpath):\\n        \"\"\"Uninstalls the repository with the specified XML path from the server.\\n        \"\"\"\\n        from os import path\\n        fullpath = path.abspath(path.expanduser(xmlpath))\\n        if fullpath in self.installed:\\n            repo = RepositorySettings(self, fullpath)\\n            if repo.name.lower() in self.repositories:\\n                del self.repositories[repo.name.lower()]\\n            if repo.name.lower() in self.archive:\\n                del self.archive[repo.name.lower()]\\n                self._save_archive()\\n            self.installed.remove(fullpath)\\n            self._save_installed()\\n        else:\\n            warn(\"The repository at {} was not installed to begin with.\".format(fullpath))',\n",
       " 'def install(self, xmlpath):\\n        \"\"\"Installs the repository at the specified XML path as an additional\\n        repo to monitor pull requests for.\\n        \"\"\"\\n        #Before we can install it, we need to make sure that none of the existing\\n        #installed paths point to the same repo.\\n        from os import path\\n        fullpath = path.abspath(path.expanduser(xmlpath))\\n        if path.isfile(fullpath):\\n            repo = RepositorySettings(self, fullpath)\\n            if repo.name.lower() not in self.repositories:\\n                self.installed.append(fullpath)\\n                self._save_installed()\\n                self.archive[repo.name.lower()] = {}\\n                self._save_archive()\\n                \\n                self.repositories[repo.name.lower()] = repo\\n        else:\\n            warn(\"The file {} does not exist; install aborted.\".format(fullpath))',\n",
       " 'def _save_installed(self):\\n        \"\"\"Saves the list of installed repo XML settings files.\"\"\"\\n        import json\\n        from utility import json_serial, get_json\\n        #This is a little tricky because the data file doesn\\'t just have a list\\n        #of installed servers. It also manages the script\\'s database that tracks\\n        #the user\\'s interactions with it.\\n        fulldata = get_json(self.instpath, {})\\n        fulldata[\"installed\"] = self.installed\\n        with open(self.instpath, \\'w\\') as f:\\n            json.dump(fulldata, f, default=json_serial)',\n",
       " 'def init(self, archive):\\n        \"\"\"Creates the repo folder locally, copies the static files and \\n        folders available locally, initalizes the repo with git so it\\n        has the correct remote origin and is ready to sync.\\n\\n        :arg staging: the full path to the directory to stage the unit tests in.\\n        \"\"\"\\n        from os import makedirs, path, chdir, system, getcwd\\n        self.repodir = path.abspath(path.expanduser(self.repo.staging))\\n\\n        if (\"stage\" in archive and path.isdir(archive[\"stage\"]) and\\n            self.repodir != archive[\"stage\"] and archive[\"stage\"] is not None):\\n            #We have a previous attempt in a different staging directory to clean.\\n            from shutil import rmtree\\n            rmtree(archive[\"stage\"])\\n\\n        if not path.isdir(self.repodir):\\n            makedirs(self.repodir)\\n            \\n        #Copy across all the static files so that we don\\'t have to download them\\n        #again and chew up the bandwidth. We don\\'t have to copy files that already\\n        #exist in the local repo.\\n        self.repo.static.copy(self.repodir)\\n        cwd = getcwd()\\n        chdir(self.repodir)\\n        \\n        if not self._is_gitted():\\n            #Next we need to initialize the git repo, then add all the static files\\n            #and folders to be tracked so that when we pull from origin master they\\n            #can be merged into the repo without re-downloading them.\\n            system(\"git init\")\\n            if not self.testmode:\\n                system(\"git remote add origin {}.git\".format(self.repo.repo.html_url))\\n\\n            for file in self.repo.static.files:\\n                #Here the 2:: removes the ./ specifying the path relative to the git\\n                #repository root. It is added by convention in the config files.\\n                system(\"git add {}\".format(file[\"target\"][2::]))\\n            for folder in self.repo.static.folders:\\n                system(\"git add {}\".format(file[\"target\"][2::]))\\n\\n            #Now sync with the master branch so that we get everything else that isn\\'t\\n            #static. Also, fetch the changes from the pull request head so that we\\n            #can merge them into a new branch for unit testing.\\n            if not self.testmode:\\n                system(\"git pull origin master\")\\n\\n        #Even though we have initialized the repo before, we still need to fetch the\\n        #pull request we are wanting to merge in.\\n        if not self.testmode:\\n            system(\"git fetch origin pull/{0}/head:testing_{0}\".format(self.pull.number))\\n            system(\"git checkout testing_{}\".format(pull.number))\\n\\n        #The local repo now has the pull request\\'s proposed changes and is ready\\n        #to be unit tested.\\n        chdir(cwd)',\n",
       " 'def _fields_common(self):\\n        \"\"\"Returns a dictionary of fields and values that are common to all events\\n        for which fields dictionaries are created.\\n        \"\"\"\\n        result = {}\\n        if not self.testmode:\\n            result[\"__reponame__\"] = self.repo.repo.full_name\\n            result[\"__repodesc__\"] = self.repo.repo.description\\n            result[\"__repourl__\"] = self.repo.repo.html_url\\n            result[\"__repodir__\"] = self.repodir\\n\\n            if self.organization is not None:\\n                owner = self.repo.organization\\n            else:\\n                owner = self.repo.user\\n                \\n            result[\"__username__\"] = owner.name\\n            result[\"__userurl__\"] = owner.html_url\\n            result[\"__useravatar__\"] = owner.avatar_url\\n            result[\"__useremail__\"] = owner.email\\n\\n        return result',\n",
       " 'def wiki(self):\\n        \"\"\"Returns the wiki markup describing the details of the github pull request\\n        as well as a link to the details on github.\\n        \"\"\"\\n        date = self.pull.created_at.strftime(\"%m/%d/%Y %H:%M\")\\n        return \"{} {} ({} [{} github])\\\\n\".format(self.pull.avatar_url, self.pull.body, date,\\n                                                 self.pull.html_url)',\n",
       " 'def fields_general(self, event):\\n        \"\"\"Appends any additional fields to the common ones and returns the fields\\n        dictionary.\\n        \"\"\"\\n        result = self._fields_common()\\n        basic = {\\n            \"__test_html__\": self.repo.testing.html(False),\\n            \"__test_text__\": self.repo.testing.text(False)}\\n        full = {\\n            \"__test_html__\": self.repo.testing.html(),\\n            \"__test_text__\": self.repo.testing.text()}\\n        \\n        if event in [\"finish\", \"success\"]:\\n            full[\"__percent__\"] = \"{0:.2%}\".format(self.percent)\\n            full[\"__status__\"] = self.message\\n        \\n        extra = {\\n            \"start\": basic,\\n            \"error\": basic,\\n            \"finish\": full,\\n            \"success\": full,\\n            \"timeout\": basic\\n        }\\n        if event in extra:\\n            result.update(extra[event])\\n        return result',\n",
       " 'def _get_site(self):\\n        \"\"\"Returns the mwclient.Site for accessing and editing the wiki pages.\\n        \"\"\"\\n        import mwclient\\n        parts = self.server.settings.wiki.replace(\"http\", \"\").replace(\"://\", \"\").split(\"/\")\\n        self.url = parts[0]\\n        if len(parts) > 1 and parts[1].strip() != \"\":\\n            self.relpath = \\'/\\' + \\'/\\'.join(parts[1:len(parts)])\\n            #The API expects us to have a trailing forward-slash.\\n            if self.relpath[-1] != \"/\":\\n                self.relpath += \"/\"\\n            if not self.testmode:\\n                self.site = mwclient.Site(self.url, path=self.relpath)\\n        else:\\n            if not self.testmode:\\n                self.site = mwclient.Site(self.url)',\n",
       " 'def _site_login(self, repo):\\n        \"\"\"Logs the user specified in the repo into the wiki.\\n\\n        :arg repo: an instance of config.RepositorySettings with wiki credentials.\\n        \"\"\"\\n        try:\\n            if not self.testmode:\\n                self.site.login(repo.wiki[\"user\"], repo.wiki[\"password\"])\\n        except LoginError as e:\\n            print(e[1][\\'result\\'])\\n        self.basepage = repo.wiki[\"basepage\"]',\n",
       " 'def create(self, request):\\n        \"\"\"Creates a new wiki page for the specified PullRequest instance. The page\\n        gets initialized with basic information about the pull request, the tests\\n        that will be run, etc. Returns the URL on the wiki.\\n\\n        :arg request: the PullRequest instance with testing information.\\n        \"\"\"\\n        self._site_login(request.repo)\\n        self.prefix = \"{}_Pull_Request_{}\".format(request.repo.name, request.pull.number)\\n        \\n        #We add the link to the main repo page during this creation; we also create\\n        #the full unit test report page here.\\n        self._edit_main(request)\\n        return self._create_new(request)',\n",
       " 'def update(self, request):\\n        \"\"\"Updates the wiki page with the results of the unit tests run for the \\n        pull request.\\n\\n        :arg percent: the percent success rate of the unit tests.\\n        :arg ttotal: the total time elapsed in running *all* the unit tests.\\n        \"\"\"\\n        from os import path\\n        self._site_login(request.repo)\\n        self.prefix = \"{}_Pull_Request_{}\".format(request.repo.name, request.pull.number)\\n                \\n        #Before we can update the results from stdout, we first need to upload them to the\\n        #server. The files can be quite big sometimes; if a file is larger than 1MB, we ...\\n        for i, test in enumerate(request.repo.testing.tests):\\n            test[\"remote_file\"] = \"{}_{}.txt\".format(self.prefix, i)\\n            if test[\"result\"] is not None and path.isfile(test[\"result\"]):\\n                #Over here, we might consider doing something different if the wiki server\\n                #is the same physical machine as the CI server; we needn\\'t use the network\\n                #protocols for the copy then. However, the machine knows already if an address\\n                #it is accessing is its own; the copy, at worst, would be through the named\\n                #pipes over TCP. It is wasteful compared to a HDD copy, but simplifies the\\n                #uploading (which must also make an entry in the wiki database).\\n                if not self.testmode:\\n                    self.site.upload(open(test[\"result\"]), test[\"remote_file\"],\\n                                     \\'`stdout` from `{}`\\'.format(test[\"command\"]))\\n\\n        #Now we can just overwrite the page with the additional test results, including the\\n        #links to the stdout files we uploaded.\\n        head = list(self._newpage_head)\\n        #Add a link to the details page that points back to the github pull request URL.\\n        head.append(\"==Github Pull Request Info==\\\\n\")\\n        head.append(request.wiki())\\n        head.append(\"==Commands Run for Unit Testing==\\\\n\")\\n        head.append(request.repo.testing.wiki())\\n        if not self.testmode:\\n            page = self.site.Pages[self.newpage]\\n            result = page.save(\\'\\\\n\\'.join(head), summary=\\'Edited by CI bot with uploaded unit test details.\\',\\n                               minor=True, bot=True)\\n            return result[u\\'result\\'] == u\\'Success\\'\\n        else:\\n            return \\'\\\\n\\'.join(head)',\n",
       " 'def _create_new(self, request):\\n        \"\"\"Creates the new wiki page that houses the details of the unit testing runs.\\n        \"\"\"\\n        self.prefix = \"{}_Pull_Request_{}\".format(request.repo.name, request.pull.number)\\n        head = list(self._newpage_head)\\n        head.append(request.repo.testing.wiki(False))\\n        if not self.testmode:\\n            page = self.site.Pages[self.newpage]\\n            result = page.save(\\'\\\\n\\'.join(head), summary=\\'Created by CI bot for unit test details.\\', bot=True)\\n            return result[u\\'result\\'] == u\\'Success\\'\\n        else:\\n            return \\'\\\\n\\'.join(head)',\n",
       " 'def _edit_main(self, request):\\n        \"\"\"Adds the link to the new unit testing results on the repo\\'s main wiki page.\\n        \"\"\"\\n        self.prefix = \"{}_Pull_Request_{}\".format(request.repo.name, request.pull.number)\\n        if not self.testmode:\\n            page = site.pages[self.basepage]\\n            text = page.text()\\n        else:\\n            text = \"This is a fake wiki page.\\\\n\\\\n<!--@CI:Placeholder-->\"\\n            \\n        self.newpage = self.prefix\\n        link = \"Pull Request #{}\".format(request.pull.number)\\n        text = text.replace(\"<!--@CI:Placeholder-->\",\\n                            \"* [[{}|{}]]\\\\n<!--@CI:Placeholder-->\".format(self.newpage, link))\\n        if not self.testmode:\\n            result = page.save(text, summary=\"Added {} unit test link.\".format(link), minor=True, bot=True)\\n            return result[u\\'result\\'] == u\\'Success\\'\\n        else:\\n            return text',\n",
       " 'def email(self, repo, event, fields, dryrun=False):\\n        \"\"\"Sends an email to the configured recipients for the specified event.\\n\\n        :arg repo: the name of the repository to include in the email subject.\\n        :arg event: one of [\"start\", \"success\", \"failure\", \"timeout\", \"error\"].\\n        :arg fields: a dictionary of field values to replace into the email template\\n          contents to specialize them.\\n        :arg dryrun: when true, the email object and contents are initialized, but\\n          the request is never sent to the SMTP server.\\n        \"\"\"\\n        tcontents = self._get_template(event, \"txt\", fields)\\n        hcontents = self._get_template(event, \"html\", fields)\\n        if tcontents is not None and hcontents is not None:\\n            return Email(self.server, repo, self.settings[repo], tcontents, hcontents, dryrun)',\n",
       " 'def detect_sys():\\n    \"\"\"Tries to identify your python platform\\n\\n    :returns: a dict with the gathered information\\n    :rtype: dict\\n    :raises: None\\n\\n    the returned dict has these keys: \\'system\\', \\'bit\\', \\'compiler\\', \\'python_version_tuple\\'\\n\\n    eg.::\\n\\n      {\\'system\\':\\'Windows\\', \\'bit\\':\\'32bit\\', \\'compiler\\':\\'MSC v.1500 32bit (Intel)\\', \\'python_version_tuple\\':(\\'2\\', \\'7\\', \\'6\\')}\\n\\n    \"\"\"\\n    system = platform.system()\\n    bit = platform.architecture()[0]\\n    compiler = platform.python_compiler()\\n    ver = platform.python_version_tuple()\\n    return {\\'system\\': system, \\'bit\\': bit, \\'compiler\\': compiler, \\'python_version_tuple\\': ver}',\n",
       " 'def get_maya_location(self, ):\\n        \"\"\" Return the installation path to maya\\n\\n        :returns: path to maya\\n        :rtype: str\\n        :raises: errors.SoftwareNotFoundError\\n        \"\"\"\\n        import _winreg\\n        # query winreg entry\\n        # the last flag is needed, if we want to test with 32 bit python!\\n        # Because Maya is an 64 bit key!\\n        for ver in MAYA_VERSIONS:\\n            try:\\n                key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\\n                                      MAYA_REG_KEY.format(mayaversion=ver), 0,\\n                                      _winreg.KEY_READ | _winreg.KEY_WOW64_64KEY)\\n                value = _winreg.QueryValueEx(key, \"MAYA_INSTALL_LOCATION\")[0]\\n            except WindowsError:\\n                log.debug(\\'Maya %s installation not found in registry!\\' % ver)\\n        if not value:\\n            raise errors.SoftwareNotFoundError(\\'Maya %s installation not found in registry!\\' % MAYA_VERSIONS)\\n        return value',\n",
       " 'def get_maya_envpath(self):\\n        \"\"\"Return the PYTHONPATH neccessary for running mayapy\\n\\n        If you start native mayapy, it will setup these paths.\\n        You might want to prepend this to your path if running from\\n        an external intepreter.\\n\\n        :returns: the PYTHONPATH that is used for running mayapy\\n        :rtype: str\\n        :raises: None\\n        \"\"\"\\n        opj = os.path.join\\n        ml = self.get_maya_location()\\n        mb = self.get_maya_bin()\\n        msp = self.get_maya_sitepackage_dir()\\n        pyzip = opj(mb, \"python27.zip\")\\n        pydir = opj(ml, \"Python\")\\n        pydll = opj(pydir, \"DLLs\")\\n        pylib = opj(pydir, \"lib\")\\n        pyplat = opj(pylib, \"plat-win\")\\n        pytk = opj(pylib, \"lib-tk\")\\n        path = os.pathsep.join((pyzip, pydll, pylib, pyplat, pytk, mb, pydir, msp))\\n        return path',\n",
       " 'def _sort(self):\\n        \"\"\"\\n        Sort the response dictionaries priority levels for ordered iteration\\n        \"\"\"\\n        self._log.debug(\\'Sorting responses by priority\\')\\n        self._responses = OrderedDict(sorted(list(self._responses.items()), reverse=True))\\n        self.sorted = True',\n",
       " 'def register_blueprints(app, application_package_name=None, blueprint_directory=None):\\n    \"\"\"Register Flask blueprints on app object\"\"\"\\n    if not application_package_name:\\n        application_package_name = \\'app\\'\\n\\n    if not blueprint_directory:\\n        blueprint_directory = os.path.join(os.getcwd(), application_package_name)\\n\\n    blueprint_directories = get_child_directories(blueprint_directory)\\n\\n    for directory in blueprint_directories:\\n        abs_package = \\'{}.{}\\'.format(application_package_name, directory)\\n\\n        service = importlib.import_module(abs_package)\\n        app.register_blueprint(service.blueprint_api, url_prefix=\\'\\')',\n",
       " 'def get_child_directories(path):\\n    \"\"\"Return names of immediate child directories\"\"\"\\n    if not _is_valid_directory(path):\\n        raise exceptions.InvalidDirectory\\n\\n    entries = os.listdir(path)\\n    directory_names = []\\n\\n    for entry in entries:\\n        abs_entry_path = os.path.join(path, entry)\\n        if _is_valid_directory(abs_entry_path):\\n            directory_names.append(entry)\\n\\n    return directory_names',\n",
       " 'def delete(self):\\n        \"\"\"\\n        Deletes all the keys from redis along with emptying the objects\\n        internal `_data` dict, then deleting itself at the end of it all.\\n        \"\"\"\\n        redis_search_key = \":\".join([self.namespace, self.key, \"*\"])\\n        keys = self.conn.keys(redis_search_key)\\n        if keys:\\n            for key in keys:\\n                part = key.split(\":\")[-1]\\n                self._data.pop(part)\\n                self.conn.delete(part)\\n\\n        del self',\n",
       " 'def get(self, part):\\n        \"\"\"\\n        Retrieves a part of the model from redis and stores it.\\n\\n        :param part: The part of the model to retrieve.\\n        :raises RedisORMException: If the redis type is different from string\\n            or list (the only two supported types at this time.)\\n        \"\"\"\\n        redis_key = \\':\\'.join([self.namespace, self.key, part])\\n\\n        objectType = self.conn.type(redis_key)\\n        if objectType == \"string\":\\n            self._data[part] = self.conn.get(redis_key)\\n\\n        elif objectType == \"list\":\\n            self._data[part] = RedisList(redis_key, self.conn)\\n\\n        else:\\n            raise RedisORMException(\"Other types besides string and list are unsupported at this time.\")',\n",
       " 'def upload(client, source_dir):\\n    \"\"\"Upload inappproducts to play store.\"\"\"\\n    print(\\'\\')\\n    print(\\'upload inappproducs\\')\\n    print(\\'---------------------\\')\\n\\n    products_folder = os.path.join(source_dir, \\'products\\')\\n    product_files = filter(os.path.isfile, list_dir_abspath(products_folder))\\n\\n    current_product_skus = map(lambda product: product[\\'sku\\'], client.list_inappproducts())\\n    print(current_product_skus)\\n    for product_file in product_files:\\n        with open(product_file) as product_file:\\n            product = json.load(product_file)\\n        #check if the product is new\\n        sku = product[\\'sku\\']\\n        product[\\'packageName\\'] = client.package_name\\n        print(sku)\\n        if sku in current_product_skus:\\n            print(\"update product {0}\".format(sku))\\n            client.update_inappproduct(product, sku)\\n        else:\\n            print(\"create product {0}\".format(sku))\\n            client.insert_inappproduct(product)',\n",
       " 'def download(client, target_dir):\\n    \"\"\"Download inappproducts from play store.\"\"\"\\n    print(\\'\\')\\n    print(\"download inappproducts\")\\n    print(\\'---------------------\\')\\n    products = client.list_inappproducts()\\n\\n    for product in products:\\n        path = os.path.join(target_dir, \\'products\\')\\n        del product[\\'packageName\\']\\n        mkdir_p(path)\\n        with open(os.path.join(path, product[\\'sku\\'] + \\'.json\\'), \\'w\\') as outfile:\\n            print(\"save product for {0}\".format(product[\\'sku\\']))\\n            json.dump(\\n                product, outfile, sort_keys=True,\\n                indent=4, separators=(\\',\\', \\': \\'))',\n",
       " \"def dataset_exists(dataset_name):\\n    '''If a dataset with the given name exists, return its absolute path; otherwise return None'''\\n    dataset_dir = os.path.join(LIB_DIR, 'datasets')\\n    dataset_path = os.path.join(dataset_dir, dataset_name)\\n    \\n    return dataset_path if os.path.isdir(dataset_path) else None\",\n",
       " 'def run_script(self, args, event_writer, input_stream):\\n        \"\"\"Handles all the specifics of running a modular input\\n\\n        :param args: List of command line arguments passed to this script.\\n        :param event_writer: An ``EventWriter`` object for writing events.\\n        :param input_stream: An input stream for reading inputs.\\n        :returns: An integer to be used as the exit value of this program.\\n        \"\"\"\\n\\n        try:\\n            if len(args) == 1:\\n                # This script is running as an input. Input definitions will be\\n                # passed on stdin as XML, and the script will write events on\\n                # stdout and log entries on stderr.\\n                self._input_definition = InputDefinition.parse(input_stream)\\n                self.stream_events(self._input_definition, event_writer)\\n                event_writer.close()\\n                return 0\\n\\n            elif str(args[1]).lower() == \"--scheme\":\\n                # Splunk has requested XML specifying the scheme for this\\n                # modular input Return it and exit.\\n                scheme = self.get_scheme()\\n                if scheme is None:\\n                    event_writer.log(\\n                        EventWriter.FATAL,\\n                        \"Modular input script returned a null scheme.\")\\n                    return 1\\n                else:\\n                    event_writer.write_xml_document(scheme.to_xml())\\n                    return 0\\n\\n            elif args[1].lower() == \"--validate-arguments\":\\n                validation_definition = ValidationDefinition.parse(input_stream)\\n                try:\\n                    self.validate_input(validation_definition)\\n                    return 0\\n                except Exception as e:\\n                    root = ET.Element(\"error\")\\n                    ET.SubElement(root, \"message\").text = e.message\\n                    event_writer.write_xml_document(root)\\n\\n                    return 1\\n            else:\\n                err_string = \"ERROR Invalid arguments to modular input script:\" + \\' \\'.join(\\n                    args)\\n                event_writer._err.write(err_string)\\n\\n        except Exception as e:\\n            err_string = EventWriter.ERROR + e.message\\n            event_writer._err.write(err_string)\\n            return 1',\n",
       " 'def money(s, thousand_sep=\".\", decimal_sep=\",\"):\\n        \"\"\"Converts money amount in string to a Decimal object.\\n\\n        With the default arguments, the format is expected to be\\n        ``-38.500,00``, where dots separate thousands and comma the decimals.\\n\\n        Args:\\n            thousand_sep: Separator for thousands.\\n            decimal_sep: Separator for decimals.\\n\\n        Returns:\\n            A ``Decimal`` object of the string encoded money amount.\\n        \"\"\"\\n        s = s.replace(thousand_sep, \"\")\\n        s = s.replace(decimal_sep, \".\")\\n        return Decimal(s)',\n",
       " 'def csv_row_to_transaction(index, row, source_encoding=\"latin1\",\\n            date_format=\"%d-%m-%Y\", thousand_sep=\".\", decimal_sep=\",\"):\\n        \"\"\"\\n        Parses a row of strings to a ``Transaction`` object.\\n\\n        Args:\\n            index: The index of this row in the original CSV file. Used for\\n            sorting ``Transaction``s by their order of appearance.\\n\\n            row: The row containing strings for [transfer_date, posted_date,\\n            message, money_amount, money_total].\\n\\n            source_encoding: The encoding that will be used to decode strings\\n            to UTF-8.\\n\\n            date_format: The format of dates in this row.\\n\\n            thousand_sep: The thousand separator in money amounts.\\n\\n            decimal_sep: The decimal separator in money amounts.\\n\\n        Returns:\\n            A ``Transaction`` object.\\n\\n        \"\"\"\\n        xfer, posted, message, amount, total = row\\n        xfer = Parse.date(xfer)\\n        posted = Parse.date(posted)\\n        message = Parse.to_utf8(message, source_encoding)\\n        amount = Parse.money(amount)\\n        total = Parse.money(total)\\n        return Transaction(index, xfer, posted, message, amount, total)',\n",
       " 'def csv_to_transactions(handle, source_encoding=\"latin1\",\\n            date_format=\"%d-%m-%Y\", thousand_sep=\".\", decimal_sep=\",\"):\\n        \"\"\"\\n        Parses CSV data from stream and returns ``Transactions``.\\n\\n        Args:\\n            index: The index of this row in the original CSV file. Used for\\n            sorting ``Transaction``s by their order of appearance.\\n\\n            row: The row containing strings for [transfer_date, posted_date,\\n            message, money_amount, money_total].\\n\\n            source_encoding: The encoding that will be used to decode strings\\n            to UTF-8.\\n\\n            date_format: The format of dates in this row.\\n\\n            thousand_sep: The thousand separator in money amounts.\\n\\n            decimal_sep: The decimal separator in money amounts.\\n\\n        Returns:\\n            A ``Transactions`` object.\\n        \"\"\"\\n        trans = Transactions()\\n        rows = csv.reader(handle, delimiter=\";\", quotechar=\"\\\\\"\")\\n\\n        for index, row in enumerate(rows):\\n            trans.append(Parse.csv_row_to_transaction(index, row))\\n\\n        return trans',\n",
       " 'def to_sqlite3(self, location=\":memory:\"):\\n        \"\"\"Returns an SQLITE3 connection to a database containing the\\n        transactions.\"\"\"\\n\\n        def decimal_to_sqlite3(n):\\n            return int(100*n)\\n\\n        def sqlite3_to_decimal(s):\\n            return Decimal(s)/100\\n\\n        sqlite3.register_adapter(Decimal, decimal_to_sqlite3)\\n        sqlite3.register_converter(\"decimal\", sqlite3_to_decimal)\\n\\n        con = sqlite3.connect(location, detect_types=sqlite3.PARSE_COLNAMES |\\n                sqlite3.PARSE_DECLTYPES)\\n        cur = con.cursor()\\n        cur.execute(\"\"\"create table transactions(\\n                           id primary key,\\n                           xfer date,\\n                           posted date,\\n                           message text,\\n                           amount decimal,\\n                           total decimal)\"\"\")\\n        for t in self:\\n            cur.execute(\"INSERT INTO transactions values(?,?,?,?,?,?)\",\\n                (t.index, t.xfer, t.posted, t.message, t.amount, t.total))\\n        return con',\n",
       " 'def group_by(self, key, field=lambda x: x.xfer):\\n        \"\"\"Returns all transactions whose given ``field`` matches ``key``.\\n\\n        Returns:\\n            A ``Transactions`` object.\\n        \"\"\"\\n        return Transactions([t for t in self.trans if field(t) == key])',\n",
       " 'def range(self, start_date=None, stop_date=None, field=lambda x: x.xfer):\\n        \"\"\"Return a ``Transactions`` object in an inclusive date range.\\n\\n        Args:\\n            start_date: A ``datetime.Date`` object that marks the inclusive\\n            start date for the range.\\n\\n            stop_date: A ``datetime.Date`` object that marks the inclusive end\\n            date for the range.\\n\\n            field: The field to compare start and end dates to. Default is the\\n            ``xfer`` field.\\n\\n        Returns:\\n            A ``Transactions`` object.\\n        \"\"\"\\n        assert start_date <= stop_date, \\\\\\n            \"Start date must be earlier than end date.\"\\n\\n        out = Transactions()\\n\\n        for t in self.trans:\\n            date = field(t)\\n            if (start_date is not None) and not (date >= start_date):\\n                continue\\n            if (stop_date is not None) and not (date <= stop_date):\\n                continue\\n            out.append(t)\\n\\n        return out',\n",
       " 'def agg_grid(grid, agg=None):\\n    \"\"\"\\n    Many functions return a 2d list with a complex data type in each cell.\\n    For instance, grids representing environments have a set of resources,\\n    while reading in multiple data files at once will yield a list\\n    containing the values for that cell from each file. In order to visualize\\n    these data types it is helpful to summarize the more complex data types\\n    with a single number. For instance, you might want to take the length\\n    of a resource set to see how many resource types are present. Alternately,\\n    you might want to take the mode of a list to see the most common phenotype\\n    in a cell.\\n\\n    This function facilitates this analysis by calling the given aggregation\\n    function (agg) on each cell of the given grid and returning the result.\\n\\n    agg - A function indicating how to summarize grid contents. Default: len.\\n    \"\"\"\\n    grid = deepcopy(grid)\\n\\n    if agg is None:\\n        if type(grid[0][0]) is list and type(grid[0][0][0]) is str:\\n            agg = string_avg\\n        else:\\n            agg = mode\\n\\n    for i in range(len(grid)):\\n        for j in range(len(grid[i])):\\n            grid[i][j] = agg(grid[i][j])\\n\\n    return grid',\n",
       " 'def flatten_array(grid):\\n    \"\"\"\\n    Takes a multi-dimensional array and returns a 1 dimensional array with the\\n    same contents.\\n    \"\"\"\\n    grid = [grid[i][j] for i in range(len(grid)) for j in range(len(grid[i]))]\\n    while type(grid[0]) is list:\\n        grid = flatten_array(grid)\\n    return grid',\n",
       " 'def prepend_zeros_to_lists(ls):\\n    \"\"\"\\n    Takes a list of lists and appends 0s to the beggining of each sub_list\\n    until they are all the same length. Used for sign-extending binary numbers.\\n    \"\"\"\\n    longest = max([len(l) for l in ls])\\n\\n    for i in range(len(ls)):\\n        while len(ls[i]) < longest:\\n            ls[i].insert(0, \"0\")',\n",
       " 'def squared_toroidal_dist(p1, p2, world_size=(60, 60)):\\n    \"\"\"\\n    Separated out because sqrt has a lot of overhead\\n    \"\"\"\\n    halfx = world_size[0]/2.0\\n    if world_size[0] == world_size[1]:\\n        halfy = halfx\\n    else:\\n        halfy = world_size[1]/2.0\\n\\n    deltax = p1[0] - p2[0]\\n    if deltax < -halfx:\\n        deltax += world_size[0]\\n    elif deltax > halfx:\\n        deltax -= world_size[0]\\n\\n    deltay = p1[1] - p2[1]\\n    if deltay < -halfy:\\n        deltay += world_size[1]\\n    elif deltay > halfy:\\n        deltay -= world_size[1]\\n\\n    return deltax*deltax + deltay*deltay',\n",
       " 'def phenotype_to_res_set(phenotype, resources):\\n    \"\"\"\\n    Converts a binary string to a set containing the resources indicated by\\n    the bits in the string.\\n\\n    Inputs: phenotype - a binary string\\n            resources - a list of string indicating which resources correspond\\n                        to which indices of the phenotype\\n\\n    returns: A set of strings indicating resources\\n    \"\"\"\\n    assert(phenotype[0:2] == \"0b\")\\n    phenotype = phenotype[2:]\\n    # Fill in leading zeroes\\n    while len(phenotype) < len(resources):\\n        phenotype = \"0\" + phenotype\\n\\n    res_set = set()\\n\\n    for i in range(len(phenotype)):\\n        if phenotype[i] == \"1\":\\n            res_set.add(resources[i])\\n\\n    assert(phenotype.count(\"1\") == len(res_set))\\n    return res_set',\n",
       " 'def res_set_to_phenotype(res_set, full_list):\\n    \"\"\"\\n    Converts a set of strings indicating resources to a binary string where\\n    the positions of 1s indicate which resources are present.\\n\\n    Inputs: res_set - a set of strings indicating which resources are present\\n            full_list - a list of strings indicating all resources which could\\n                        could be present, and the order in which they should\\n                        map to bits in the phenotype\\n    returns: A binary string\\n    \"\"\"\\n\\n    full_list = list(full_list)\\n    phenotype = len(full_list) * [\"0\"]\\n\\n    for i in range(len(full_list)):\\n        if full_list[i] in res_set:\\n            phenotype[i] = \"1\"\\n\\n    assert(phenotype.count(\"1\") == len(res_set))\\n\\n    # Remove uneceesary leading 0s\\n    while phenotype[0] == \"0\" and len(phenotype) > 1:\\n        phenotype = phenotype[1:]\\n\\n    return \"0b\"+\"\".join(phenotype)',\n",
       " 'def weighted_hamming(b1, b2):\\n    \"\"\"\\n    Hamming distance that emphasizes differences earlier in strings.\\n    \"\"\"\\n    assert(len(b1) == len(b2))\\n    hamming = 0\\n    for i in range(len(b1)):\\n        if b1[i] != b2[i]:\\n            # differences at more significant (leftward) bits\\n            # are more important\\n            if i > 0:\\n                hamming += 1 + 1.0/i\\n                # This weighting is completely arbitrary\\n    return hamming',\n",
       " 'def n_tasks(dec_num):\\n    \"\"\"\\n    Takes a decimal number as input and returns the number of ones in the\\n    binary representation.\\n    This translates to the number of tasks being done by an organism with a\\n    phenotype represented as a decimal number.\\n    \"\"\"\\n    bitstring = \"\"\\n    try:\\n        bitstring = dec_num[2:]\\n    except:\\n        bitstring = bin(int(dec_num))[2:]  # cut off 0b\\n    # print bin(int(dec_num)), bitstring\\n    return bitstring.count(\"1\")',\n",
       " 'def convert_to_pysal(data):\\n    \"\"\"\\n    Pysal expects a distance matrix, and data formatted in a numpy array.\\n    This functions takes a data grid and returns those things.\\n    \"\"\"\\n    w = pysal.lat2W(len(data[0]), len(data))\\n    data = np.array(data)\\n    data = np.reshape(data, (len(data)*len(data[0]), 1))\\n    return w, data',\n",
       " 'def median(ls):\\n    \"\"\"\\n    Takes a list and returns the median.\\n    \"\"\"\\n    ls = sorted(ls)\\n    return ls[int(floor(len(ls)/2.0))]',\n",
       " 'def string_avg(strings, binary=True):\\n    \"\"\"\\n    Takes a list of strings of equal length and returns a string containing\\n    the most common value from each index in the string.\\n\\n    Optional argument: binary - a boolean indicating whether or not to treat\\n    strings as binary numbers (fill in leading zeros if lengths differ).\\n    \"\"\"\\n\\n    if binary:  # Assume this is a binary number and fill leading zeros\\n        strings = deepcopy(strings)\\n        longest = len(max(strings, key=len))\\n\\n        for i in range(len(strings)):\\n            while len(strings[i]) < longest:\\n                split_string = strings[i].split(\"b\")\\n                strings[i] = \"0b0\" + split_string[1]\\n\\n    avg = \"\"\\n    for i in (range(len(strings[0]))):\\n        opts = []\\n        for s in strings:\\n            opts.append(s[i])\\n        avg += max(set(opts), key=opts.count)\\n\\n    return avg',\n",
       " 'def get_world_dimensions(gridfile, delim=\" \"):\\n    \"\"\"\\n    This function takes the name of a file in grid_task format and returns\\n    the dimensions of the world it represents.\\n    \"\"\"\\n    infile = open(gridfile)\\n    lines = infile.readlines()\\n    infile.close()\\n    world_x = len(lines[0].strip().split(delim))\\n    world_y = len(lines)\\n    return (world_x, world_y)',\n",
       " 'def modify_config(path):\\n    \"\"\"\\n    Context manager to modify a flit config file.\\n\\n    Will read the config file, validate the config, yield the config object,\\n    validate and write back the config to the file on exit\\n    \"\"\"\\n    if isinstance(path, str):\\n        path = Path(path)\\n    config = _read_pkg_ini(path)\\n    _validate_config(config, path)\\n\\n    # don\\'t catch exception, we won\\'t write the new config.\\n    yield config\\n\\n    _validate_config(config, path)\\n    with path.open(\\'w\\') as f:\\n        config.write(f)',\n",
       " 'def pformat(self):\\n        \\'\\'\\'\\n        Manually pformat to force using \"\"\"...\"\"\" and supress escaping apostrophe\\n        \\'\\'\\'\\n        result = \"{\\\\n\"\\n        indent1 = \" \" * 4\\n        indent2 = \" \" * 8\\n        for line_no, code_objects in sorted(self.items()):\\n            result += \\'%s%i: [\\\\n\\' % (indent1, line_no)\\n            for code_object in code_objects:\\n                result += \\'%s\"\"\"<%s:%s>\"\"\",\\\\n\\' % (\\n                    indent2, code_object.PART_TYPE, code_object.content\\n                )\\n            result += \\'%s],\\\\n\\' % indent1\\n        result += \"}\"\\n\\n        return result',\n",
       " 'def _parse_string(self, line):\\n        \"\"\"\\n        Consume the complete string until next \" or \\\\n\\n        \"\"\"\\n        log.debug(\"*** parse STRING: >>>%r<<<\", line)\\n        parts = self.regex_split_string.split(line, maxsplit=1)\\n        if len(parts) == 1:  # end\\n            return parts[0], None\\n\\n        pre, match, post = parts\\n        log.debug(\"\\\\tpre: >>>%r<<<\", pre)\\n        log.debug(\"\\\\tmatch: >>>%r<<<\", match)\\n        log.debug(\"\\\\tpost: >>>%r<<<\", post)\\n        pre = pre + match\\n        log.debug(\"Parse string result: %r,%r\", pre, post)\\n        return pre, post',\n",
       " 'def _parse_code(self, line):\\n        \"\"\"\\n        parse the given BASIC line and branch into DATA, String and\\n        consume a complete Comment\\n        \"\"\"\\n        log.debug(\"*** parse CODE: >>>%r<<<\", line)\\n        parts = self.regex_split_all.split(line, maxsplit=1)\\n        if len(parts) == 1:  # end\\n            self.line_data.append(BASIC_Code(parts[0]))\\n            return\\n        pre, match, post = parts\\n        log.debug(\"\\\\tpre: >>>%r<<<\", pre)\\n        log.debug(\"\\\\tmatch: >>>%r<<<\", match)\\n        log.debug(\"\\\\tpost: >>>%r<<<\", post)\\n\\n        if match == \\'\"\\':\\n            log.debug(\"%r --> parse STRING\", match)\\n            self.line_data.append(BASIC_Code(pre))\\n            string_part, rest = self._parse_string(post)\\n            self.line_data.append(BASIC_String(match + string_part))\\n            if rest:\\n                self._parse_code(rest)\\n            return\\n\\n        self.line_data.append(BASIC_Code(pre + match))\\n\\n        if match == \"DATA\":\\n            log.debug(\"%r --> parse DATA\", match)\\n            data_part, rest = self._parse_data(post)\\n            self.line_data.append(BASIC_Data(data_part))\\n            if rest:\\n                self._parse_code(rest)\\n            return\\n        elif match in (\"\\'\", \"REM\"):\\n            log.debug(\"%r --> consume rest of the line as COMMENT\", match)\\n            if post:\\n                self.line_data.append(BASIC_Comment(post))\\n            return\\n\\n        raise RuntimeError(\"Wrong Reg.Exp.? match is: %r\" % match)',\n",
       " 'def close(correlation_id, components):\\n        \"\"\"\\n        Closes multiple components.\\n\\n        To be closed components must implement [[ICloseable]] interface.\\n        If they don\\'t the call to this method has no effect.\\n\\n        :param correlation_id: (optional) transaction id to trace execution through call chain.\\n\\n        :param components: the list of components that are to be closed.\\n        \"\"\"\\n        if components == None:\\n            return\\n\\n        for component in components:\\n            Closer.close_one(correlation_id, component)',\n",
       " 'def add(app, url = None, path = None, endpoint=None, decorate=None, index=\\'index.html\\', **options):\\n    \"\"\"Adds static files endpoint with optional directory index.\"\"\"\\n\\n    url = url or app.static_url_path or \\'\\'\\n    path = os.path.abspath(path or app.static_folder or \\'.\\')\\n    endpoint = endpoint or \\'static_\\' + os.path.basename(path)\\n    decorate = decorate or (lambda f: f)\\n    endpoints = {}\\n\\n    if path == app.static_folder:\\n        raise ValueError(\\'Files in `{}` path are already automatically served on `{}` URL by Flask.\\'\\n            \\' Set Flask app static_folder to None, if you want to serve them using Flask Ecstatic at `{}` URL\\'\\n            .format(path, app.static_url_path, url))\\n\\n    @app.route(url + \\'/<path:filename>\\', endpoint = endpoint)\\n    @handle404\\n    @decorate\\n    def static_files(filename):\\n        if index:\\n            filename = safe_join(path, filename)\\n            if os.path.isdir(filename):\\n                filename = os.path.join(filename, index)\\n            return send_file(filename, **options)\\n        else:\\n            return send_from_directory(path, filename, **options)\\n\\n    endpoints[endpoint] = static_files\\n\\n    if index:\\n         @app.route(url + \\'/\\', endpoint = endpoint + \\'_index\\')\\n         @handle404\\n         @decorate\\n         def static_index():\\n             return send_from_directory(path, index, **options)\\n\\n         endpoints[endpoint + \\'_index\\'] = static_index\\n\\n         if url:\\n             @app.route(url, endpoint = endpoint + \\'_index_bare\\')\\n             @handle404\\n             @decorate\\n             def static_index_bare():\\n                 return send_from_directory(path, index, **options)\\n\\n             endpoints[endpoint + \\'_index_bare\\'] = static_index_bare\\n\\n    return endpoints',\n",
       " 'def program_dump2ascii_lines(self, dump, program_start=None):\\n        \"\"\"\\n        convert a memory dump of a tokensized BASIC listing into\\n        ASCII listing list.\\n        \"\"\"\\n        dump = bytearray(dump)\\n        # assert isinstance(dump, bytearray)\\n\\n        if program_start is None:\\n            program_start = self.DEFAULT_PROGRAM_START\\n        return self.listing.program_dump2ascii_lines(dump, program_start)',\n",
       " 'def ascii_listing2program_dump(self, basic_program_ascii, program_start=None):\\n        \"\"\"\\n        convert a ASCII BASIC program listing into tokens.\\n        This tokens list can be used to insert it into the\\n        Emulator RAM.\\n        \"\"\"\\n        if program_start is None:\\n            program_start = self.DEFAULT_PROGRAM_START\\n\\n        basic_lines = self.ascii_listing2basic_lines(basic_program_ascii, program_start)\\n\\n        program_dump=self.listing.basic_lines2program_dump(basic_lines, program_start)\\n        assert isinstance(program_dump, bytearray), (\\n            \"is type: %s and not bytearray: %s\" % (type(program_dump), repr(program_dump))\\n        )\\n        return program_dump',\n",
       " 'def get_gaf_format(self):\\n        \"\"\"Return a GAF 2.0-compatible string representation of the annotation.\\n\\n        Parameters\\n        ----------\\n\\n        Returns\\n        -------\\n        str\\n            The formatted string.\\n        \"\"\"\\n        sep = \\'\\\\t\\'\\n        return sep.join(\\n            [self.gene, self.db_ref, self.term.id, self.evidence,\\n             \\'|\\'.join(self.db_ref), \\'|\\'.join(self.with_)])',\n",
       " \"def ahead(self, i, j=None):\\n        '''Raising stopiteration with end the parse.\\n        '''\\n        if j is None:\\n            return self._stream[self.i + i]\\n        else:\\n            return self._stream[self.i + i: self.i + j]\",\n",
       " 'def method_name(func):\\n    \"\"\"Method wrapper that adds the name of the method being called to its arguments list in Pascal case\\n\\n    \"\"\"\\n    @wraps(func)\\n    def _method_name(*args, **kwargs):\\n        name = to_pascal_case(func.__name__)\\n        return func(name=name, *args, **kwargs)\\n    return _method_name',\n",
       " 'def to_pascal_case(s):\\n    \"\"\"Transform underscore separated string to pascal case\\n\\n    \"\"\"\\n    return re.sub(r\\'(?!^)_([a-zA-Z])\\', lambda m: m.group(1).upper(), s.capitalize())',\n",
       " 'def to_underscore(s):\\n    \"\"\"Transform camel or pascal case to underscore separated string\\n\\n    \"\"\"\\n    return re.sub(\\n            r\\'(?!^)([A-Z]+)\\',\\n            lambda m: \"_{0}\".format(m.group(1).lower()),\\n            re.sub(r\\'(?!^)([A-Z]{1}[a-z]{1})\\', lambda m: \"_{0}\".format(m.group(1).lower()), s)\\n        ).lower()',\n",
       " 'def notify(self, correlation_id, args):\\n        \"\"\"\\n        Fires this event and notifies all registred listeners.\\n\\n        :param correlation_id: (optional) transaction id to trace execution through call chain.\\n\\n        :param args: the parameters to raise this event with.\\n        \"\"\"\\n        for listener in self._listeners:\\n            try:\\n                listener.on_event(correlation_id, self, args)\\n            except Exception as ex:\\n                raise InvocationException(\\n                    correlation_id,\\n                    \"EXEC_FAILED\",\\n                    \"Raising event \" + self._name + \" failed: \" + str(ex)\\n                ).with_details(\"event\", self._name).wrap(ex)',\n",
       " 'def _parseIsTag(self):\\n        \"\"\"\\n        Detect whether the element is HTML tag or not.\\n\\n        Result is saved to the :attr:`_istag` property.\\n        \"\"\"\\n        el = self._element\\n        self._istag = el and el[0] == \"<\" and el[-1] == \">\"',\n",
       " 'def _parseIsComment(self):\\n        \"\"\"\\n        Detect whether the element is HTML comment or not.\\n\\n        Result is saved to the :attr:`_iscomment` property.\\n        \"\"\"\\n        self._iscomment = (\\n            self._element.startswith(\"<!--\") and self._element.endswith(\"-->\")\\n        )',\n",
       " 'def _parseTagName(self):\\n        \"\"\"\\n        Parse name of the tag.\\n\\n        Result is saved to the :attr:`_tagname` property.\\n        \"\"\"\\n        for el in self._element.split():\\n            el = el.replace(\"/\", \"\").replace(\"<\", \"\").replace(\">\", \"\")\\n\\n            if el.strip():\\n                self._tagname = el.rstrip()\\n                return',\n",
       " 'def _parseParams(self):\\n        \"\"\"\\n        Parse parameters from their string HTML representation to dictionary.\\n\\n        Result is saved to the :attr:`params` property.\\n        \"\"\"\\n        # check if there are any parameters\\n        if \" \" not in self._element or \"=\" not in self._element:\\n            return\\n\\n        # remove \\'<\\' & \\'>\\'\\n        params = self._element.strip()[1:-1].strip()\\n\\n        # remove tagname\\n        offset = params.find(self.getTagName()) + len(self.getTagName())\\n        params = params[offset:].strip()\\n\\n        # parser machine\\n        next_state = 0\\n        key = \"\"\\n        value = \"\"\\n        end_quote = \"\"\\n        buff = [\"\", \"\"]\\n        for c in params:\\n            if next_state == 0:      # key\\n                if c.strip() != \"\":  # safer than list space, tab and all\\n                    if c == \"=\":     # possible whitespaces in UTF\\n                        next_state = 1\\n                    else:\\n                        key += c\\n\\n            elif next_state == 1:    # value decisioner\\n                if c.strip() != \"\":  # skip whitespaces\\n                    if c == \"\\'\" or c == \\'\"\\':\\n                        next_state = 3\\n                        end_quote = c\\n                    else:\\n                        next_state = 2\\n                        value += c\\n\\n            elif next_state == 2:    # one word parameter without quotes\\n                if c.strip() == \"\":\\n                    next_state = 0\\n                    self.params[key] = value\\n                    key = \"\"\\n                    value = \"\"\\n                else:\\n                    value += c\\n\\n            elif next_state == 3:    # quoted string\\n                if c == end_quote and (buff[0] != \"\\\\\\\\\" or (buff[0]) == \"\\\\\\\\\" and buff[1] == \"\\\\\\\\\"):\\n                    next_state = 0\\n                    self.params[key] = unescape(value, end_quote)\\n                    key = \"\"\\n                    value = \"\"\\n                    end_quote = \"\"\\n                else:\\n                    value += c\\n\\n            buff = _rotate_buff(buff)\\n            buff[0] = c\\n\\n        if key:\\n            if end_quote and value.strip():\\n                self.params[key] = unescape(value, end_quote)\\n            else:\\n                self.params[key] = value\\n\\n        if \"/\" in self.params.keys():\\n            del self.params[\"/\"]\\n            self._isnonpairtag = True',\n",
       " 'def isOpeningTag(self):\\n        \"\"\"\\n        Detect whether this tag is opening or not.\\n\\n        Returns:\\n            bool: True if it is opening.\\n        \"\"\"\\n        if self.isTag() and \\\\\\n           not self.isComment() and \\\\\\n           not self.isEndTag() and \\\\\\n           not self.isNonPairTag():\\n            return True\\n\\n        return False',\n",
       " 'def entropy(dictionary):\\n    \"\"\"\\n    Helper function for entropy calculations.\\n    Takes a frequency dictionary and calculates entropy of the keys.\\n    \"\"\"\\n    total = 0.0\\n    entropy = 0\\n    for key in dictionary.keys():\\n        total += dictionary[key]\\n\\n    for key in dictionary.keys():\\n        entropy += dictionary[key]/total * log(1.0/(dictionary[key]/total), 2)\\n    return entropy',\n",
       " 'def sqrt_shannon_entropy(filename):\\n    \"\"\"\\n    Calculates Shannon entropy based on square root of phenotype count.\\n    This might account for relationship between population size and\\n    evolvability.\\n    \"\"\"\\n    data = load_grid_data(filename, \"int\")\\n    data = agg_grid(data, mode)\\n    phenotypes = {}\\n    for r in data:\\n        for c in r:\\n            if c in phenotypes:\\n                phenotypes[c] += 1\\n            else:\\n                phenotypes[c] = 1\\n\\n    for key in phenotypes.keys():\\n        phenotypes[key] = sqrt(phenotypes[key])\\n\\n    return entropy(phenotypes)',\n",
       " 'def _composed_doc(fs):\\n    \"\"\"\\n    Generate a docstring for the composition of fs.\\n    \"\"\"\\n    if not fs:\\n        # Argument name for the docstring.\\n        return \\'n\\'\\n\\n    return \\'{f}({g})\\'.format(f=fs[0].__name__, g=_composed_doc(fs[1:]))',\n",
       " 'def update_model(self, idx=None):\\n        \"\"\"Updates the value of property at given index. If idx is\\n        None, all controlled indices will be updated. This method\\n        should be called directly by the user in very unusual\\n        conditions.\"\"\"\\n        if idx is None:\\n            for w in self._widgets:\\n                idx = self._get_idx_from_widget(w)\\n                try: val = self._read_widget(idx)\\n                except ValueError: pass\\n                else: self._write_property(val, idx)\\n                pass\\n            pass\\n        else:\\n            try: val = self._read_widget(idx)\\n            except ValueError: pass\\n            else: self._write_property(val, idx)\\n        return',\n",
       " 'def update_widget(self, idx=None):\\n        \"\"\"Forces the widget at given index to be updated from the\\n        property value. If index is not given, all controlled\\n        widgets will be updated. This method should be called\\n        directly by the user when the property is not observable, or\\n        in very unusual conditions.\"\"\"\\n        if idx is None:\\n            for w in self._widgets:\\n                idx = self._get_idx_from_widget(w)\\n                self._write_widget(self._read_property(idx), idx)\\n            pass\\n        else: self._write_widget(self._read_property(idx), idx)\\n        return',\n",
       " 'def _on_wid_changed(self, wid):\\n        \"\"\"Called when the widget is changed\"\"\"\\n        if self._itsme: return\\n        self.update_model(self._get_idx_from_widget(wid))\\n        return',\n",
       " 'def fetch_url(url):\\n    \"\"\"\\n    Fetch the given url, strip formfeeds and decode\\n    it into the defined encoding\\n    \"\"\"\\n\\n    with closing(urllib.urlopen(url)) as f:\\n        if f.code is 200:\\n            response = f.read()\\n            return strip_formfeeds(response).decode(ENCODING)',\n",
       " 'def match_entry_line(str_to_match, regex_obj=MAIN_REGEX_OBJ):\\n    \"\"\"Does a regex match of the mount entry string\"\"\"\\n    match_obj = regex_obj.match(str_to_match)\\n    if not match_obj:\\n        error_message = (\\'Line \"%s\" is unrecognized by overlay4u. \\'\\n                \\'This is only meant for use with Ubuntu Linux.\\')\\n        raise UnrecognizedMountEntry(error_message % str_to_match)\\n    return match_obj.groupdict()',\n",
       " 'def as_list(self, fs_type=None):\\n        \"\"\"List mount entries\"\"\"\\n        entries = self._entries\\n        if fs_type:\\n            entries = filter(lambda a: a.fs_type == fs_type, entries)\\n        return entries',\n",
       " 'def render(self, f_buf=None):\\n        \"\"\"\\n        Definitely render the workbook\\n\\n        :param obj f_buf: A file buffer supporting the write and seek\\n        methods\\n        \"\"\"\\n        if f_buf is None:\\n            f_buf = StringIO.StringIO()\\n        with odswriter.writer(f_buf) as writer:\\n            default_sheet = writer.new_sheet(self.title)\\n            self._render_headers(default_sheet)\\n            self._render_rows(default_sheet)\\n\\n            # abstract_sheet require the same attributes as our current writer\\n            for abstract_sheet in self.sheets:\\n                sheet = writer.new_sheet(name=abstract_sheet.title)\\n                abstract_sheet._render_headers(sheet)\\n                abstract_sheet._render_rows(sheet)\\n        f_buf.seek(0)\\n        return f_buf',\n",
       " 'def _get_related_exporter(self, related_obj, column):\\n        \"\"\"\\n        returns an SqlaOdsExporter for the given related object and stores it in\\n        the column object as a cache\\n        \"\"\"\\n        result = column.get(\\'sqla_ods_exporter\\')\\n        if result is None:\\n            result = column[\\'sqla_ods_exporter\\'] = SqlaOdsExporter(\\n                related_obj.__class__,\\n                is_root=False,\\n                title=column.get(\\'label\\', column[\\'key\\']),\\n            )\\n            self.add_sheet(result)\\n        return result',\n",
       " 'def _get_relationship_cell_val(self, obj, column):\\n        \"\"\"\\n        Return the value to insert in a relationship cell\\n        Handle the case of complex related datas we want to handle\\n        \"\"\"\\n        val = SqlaExporter._get_relationship_cell_val(self, obj, column)\\n        if val == \"\":\\n            related_key = column.get(\\'related_key\\', None)\\n\\n            if column[\\'__col__\\'].uselist and related_key is None and \\\\\\n                    self.is_root:\\n\\n                # on rcupre les objets lis\\n                key = column[\\'key\\']\\n                related_objects = getattr(obj, key, None)\\n                if not related_objects:\\n                    return \"\"\\n                else:\\n                    exporter = self._get_related_exporter(\\n                        related_objects[0],\\n                        column,\\n                    )\\n                    for rel_obj in related_objects:\\n                        exporter.add_row(rel_obj)\\n\\n        return val',\n",
       " 'def raster(times, indices, max_time=None, max_index=None, \\n           x_label=\"Timestep\", y_label=\"Index\", **kwargs):\\n    \"\"\"Plots a raster plot given times and indices of events.\"\"\"\\n    # set default size to 1\\n    if \\'s\\' not in kwargs:\\n        kwargs[\\'s\\'] = 1\\n    scatter(times, indices, **kwargs)\\n    \\n    if max_time is None:\\n        max_time = max(times)\\n    if max_index is None:\\n        max_index = max(indices)\\n    axis((0, max_time, 0, max_index))\\n    if x_label is not None: xlabel(x_label)\\n    if y_label is not None: ylabel(y_label)',\n",
       " 'def query(query):\\n    \\'\\'\\'\\n    Send an ADQL query to the Gaia archive,\\n    wait for a response,\\n    and hang on to the results.\\n    \\'\\'\\'\\n\\n    # send the query to the Gaia archive\\n    with warnings.catch_warnings() :\\n        warnings.filterwarnings(\"ignore\")\\n\\n        _gaia_job = astroquery.gaia.Gaia.launch_job(query)\\n\\n        # return the table of results\\n        return _gaia_job.get_results()',\n",
       " 'def connectionMade(self):\\n        \"\"\"\\n        Initializes the protocol.\\n        \"\"\"\\n        self._buffer = b\\'\\'\\n        self._queue = {}\\n        self._stopped = None\\n        self._tag = 0',\n",
       " 'def dataReceived(self, data):\\n        \"\"\"\\n        Parses chunks of bytes into responses.\\n\\n        Whenever a complete response is received, this method extracts its\\n        payload and calls L{responseReceived} to process it.\\n\\n        @param data: A chunk of data representing a (possibly partial) response\\n        @type data: C{bytes}\\n        \"\"\"\\n        size = len(self._buffer) + len(data)\\n        if size > self.MAX_LENGTH:\\n            self.lengthLimitExceeded(size)\\n        self._buffer += data\\n\\n        start = 0\\n        for match in self._pattern.finditer(self._buffer):\\n            # The start of the sentinel marks the end of the response.\\n            end = match.start()\\n            tag = int(match.group(1))\\n            self.responseReceived(self._buffer[start:end], tag)\\n\\n            # Advance start position to the beginning of the next line\\n            start = match.end() + 1\\n\\n        if start:\\n            self._buffer = self._buffer[start:]',\n",
       " 'def responseReceived(self, response, tag):\\n        \"\"\"\\n        Receives some characters of a netstring.\\n\\n        Whenever a complete response is received, this method calls the\\n        deferred associated with it.\\n\\n        @param response: A complete response generated by exiftool.\\n        @type response: C{bytes}\\n        @param tag: The tag associated with the response\\n        @type tag: C{int}\\n        \"\"\"\\n        self._queue.pop(tag).callback(response)',\n",
       " 'def execute(self, *args):\\n        \"\"\"\\n        Pass one command to exiftool and return a deferred which is fired as\\n        soon as the command completes.\\n\\n        @param *args: Command line arguments passed to exiftool\\n        @type *args: C{unicode}\\n\\n        @rtype: C{Deferred}\\n        @return: A deferred whose callback will be invoked when the command\\n        completed.\\n        \"\"\"\\n\\n        result = defer.Deferred()\\n        if self.connected and not self._stopped:\\n            self._tag += 1\\n\\n            args = tuple(args) + (\\'-execute{:d}\\'.format(self._tag), \\'\\')\\n            safe_args = [fsencode(arg) for arg in args]\\n            self.transport.write(b\\'\\\\n\\'.join(safe_args))\\n\\n            result = defer.Deferred()\\n            self._queue[self._tag] = result\\n        else:\\n            result.errback(error.ConnectionClosed(\\'Not connected to exiftool\\'))\\n\\n        return result',\n",
       " 'def loseConnection(self):\\n        \"\"\"\\n        Close the connection and terminate the exiftool process.\\n\\n        @rtype: C{Deferred}\\n        @return: A deferred whose callback will be invoked when the connection\\n        was closed.\\n        \"\"\"\\n        if self._stopped:\\n            result = self._stopped\\n        elif self.connected:\\n            result = defer.Deferred()\\n            self._stopped = result\\n            self.transport.write(b\\'\\\\n\\'.join((b\\'-stay_open\\', b\\'False\\', b\\'\\')))\\n        else:\\n            # Already disconnected.\\n            result = defer.succeed(self)\\n\\n        return result',\n",
       " 'def connectionLost(self, reason=protocol.connectionDone):\\n        \"\"\"\\n        Check whether termination was intended and invoke the deferred.\\n\\n        If the connection terminated unexpectedly, reraise the failure.\\n\\n        @type reason: L{twisted.python.failure.Failure}\\n        \"\"\"\\n        self.connected = 0\\n\\n        for pending in self._queue.values():\\n            pending.errback(reason)\\n        self._queue.clear()\\n\\n        if self._stopped:\\n            result = self if reason.check(error.ConnectionDone) else reason\\n            self._stopped.callback(result)\\n            self._stopped = None\\n        else:\\n            reason.raiseException()',\n",
       " 'def find_next_character(code, position, char):\\n    \"\"\"Find next char and return its first and last positions\"\"\"\\n    end = LineCol(code, *position)\\n    while not end.eof and end.char() in WHITESPACE:\\n        end.inc()\\n\\n    if not end.eof and end.char() == char:\\n        return end.tuple(), inc_tuple(end.tuple())\\n    return None, None',\n",
       " 'def from_value(value = None):\\n        \"\"\"\\n        Converts specified value into ProjectionParams.\\n\\n        :param value: value to be converted\\n\\n        :return: a newly created ProjectionParams.\\n        \"\"\"\\n        if isinstance(value, ProjectionParams):\\n            return value\\n        array = AnyValueArray.from_value(value) if value != None else AnyValueArray()\\n        return ProjectionParams(array)',\n",
       " 'def to_string(self):\\n        \"\"\"\\n        Gets a string representation of the object.\\n        The result is a comma-separated list of projection fields\\n        \"field1,field2.field21,field2.field22.field221\"\\n\\n        :return: a string representation of the object.\\n        \"\"\"\\n        builder = \"\"\\n\\n        index = 0\\n        while index < self.__len__():\\n            if index > 0:\\n                builder = builder + \\',\\'\\n            builder = builder + super(ProjectionParams, self).__getitem__(index)\\n            index = index + 1\\n\\n        return builder',\n",
       " 'def snake_case_backend_name(self):\\n        \"\"\" CamelCase -> camel_case\\n        \"\"\"\\n        s1 = re.sub(\\'(.)([A-Z][a-z]+)\\', r\\'\\\\1_\\\\2\\', type(self).__name__)\\n        return re.sub(\\'([a-z0-9])([A-Z])\\', r\\'\\\\1_\\\\2\\', s1).lower()',\n",
       " 'def get_setting(self, key, default=NOT_SET):\\n        \"\"\" Gets a setting for the key.\\n\\n        :raise KeyError: If the key is not set and default isn\\'t provided.\\n        \"\"\"\\n        if self._arca is None:\\n            raise LazySettingProperty.SettingsNotReady\\n        return self._arca.settings.get(*self.get_settings_keys(key), default=default)',\n",
       " 'def hash_file_contents(requirements_option: RequirementsOptions, path: Path) -> str:\\n        \"\"\" Returns a SHA256 hash of the contents of ``path`` combined with the Arca version.\\n        \"\"\"\\n        return hashlib.sha256(path.read_bytes() + bytes(\\n            requirements_option.name + arca.__version__, \"utf-8\"\\n        )).hexdigest()',\n",
       " 'def get_requirements_information(self, path: Path) -> Tuple[RequirementsOptions, Optional[str]]:\\n        \"\"\"\\n        Returns the information needed to install requirements for a repository - what kind is used and the hash\\n        of contents of the defining file.\\n        \"\"\"\\n        if self.pipfile_location is not None:\\n            pipfile = path / self.pipfile_location / \"Pipfile\"\\n            pipfile_lock = path / self.pipfile_location / \"Pipfile.lock\"\\n\\n            pipfile_exists = pipfile.exists()\\n            pipfile_lock_exists = pipfile_lock.exists()\\n\\n            if pipfile_exists and pipfile_lock_exists:\\n                option = RequirementsOptions.pipfile\\n                return option, self.hash_file_contents(option, pipfile_lock)\\n            elif pipfile_exists:\\n                raise BuildError(\"Only the Pipfile is included in the repository, Arca does not support that.\")\\n            elif pipfile_lock_exists:\\n                raise BuildError(\"Only the Pipfile.lock file is include in the repository, Arca does not support that.\")\\n\\n        if self.requirements_location:\\n            requirements_file = path / self.requirements_location\\n\\n            if requirements_file.exists():\\n                option = RequirementsOptions.requirements_txt\\n                return option, self.hash_file_contents(option, requirements_file)\\n\\n        return RequirementsOptions.no_requirements, None',\n",
       " 'def serialized_task(self, task: Task) -> Tuple[str, str]:\\n        \"\"\" Returns the name of the task definition file and its contents.\\n        \"\"\"\\n        return f\"{task.hash}.json\", task.json',\n",
       " 'def run(self, repo: str, branch: str, task: Task, git_repo: Repo, repo_path: Path) -> Result:  # pragma: no cover\\n        \"\"\"\\n        Executes the script and returns the result.\\n\\n        Must be implemented by subclasses.\\n\\n        :param repo: Repo URL\\n        :param branch: Branch name\\n        :param task: The requested :class:`Task`\\n        :param git_repo: A :class:`Repo <git.repo.base.Repo>` of the repo/branch\\n        :param repo_path: :class:`Path <pathlib.Path>` to the location where the repo is stored.\\n        :return: The output of the task in a :class:`Result` instance.\\n        \"\"\"\\n        raise NotImplementedError',\n",
       " 'def get_or_create_environment(self, repo: str, branch: str,\\n                                  git_repo: Repo, repo_path: Path) -> str:  # pragma: no cover\\n        \"\"\"\\n        Abstract method which must be implemented in subclasses, which must return a str path to a Python executable\\n        which will be used to run the script.\\n\\n        See :meth:`BaseBackend.run <arca.BaseBackend.run>` to see arguments description.\\n        \"\"\"\\n        raise NotImplementedError',\n",
       " 'def quote_names(db, names):\\n    \"\"\"psycopg2 doesn\\'t know how to quote identifier names, so we ask the server\"\"\"\\n    c = db.cursor()\\n    c.execute(\"SELECT pg_catalog.quote_ident(n) FROM pg_catalog.unnest(%s::text[]) n\", [list(names)])\\n    return [name for (name,) in c]',\n",
       " 'def execute_catch(c, sql, vars=None):\\n    \"\"\"Run a query, but ignore any errors. For error recovery paths where the error handler should not raise another.\"\"\"\\n    try:\\n        c.execute(sql, vars)\\n    except Exception as err:\\n        cmd = sql.split(\\' \\', 1)[0]\\n        log.error(\"Error executing %s: %s\", cmd, err)',\n",
       " 'def cmd_copy():\\n    \"\"\"Uses CREATE DATABASE ... TEMPLATE to create a duplicate of a database. Additionally copies over database-specific\\n    settings.\\n\\n    When used with --force, an existing database with the same name as DEST is replaced, the original is renamed out of\\n    place in the form DEST_old_YYYYMMDD (unless --no-backup is specified).\\n    \"\"\"\\n    db = connect()\\n\\n    if args.force and db_exists(db, args.dest):\\n        tmp_db = generate_alt_dbname(db, args.dest, \\'tmp\\')\\n        pg_copy(db, args.src, tmp_db)\\n\\n        pg_move_extended(db, tmp_db, args.dest)\\n\\n    else:\\n        pg_copy(db, args.src, args.dest)',\n",
       " 'def cmd_move(db=None):\\n    \"\"\"Rename a database within a server.\\n\\n    When used with --force, an existing database with the same name as DEST is replaced, the original is renamed out of\\n    place in the form DEST_old_YYYYMMDD (unless --no-backup is specified).\\n    \"\"\"\\n    if db is None:\\n        db = connect()\\n\\n    pg_move_extended(db, args.src, args.dest)',\n",
       " 'def cmd_reindex():\\n    \"\"\"Uses CREATE INDEX CONCURRENTLY to create a duplicate index, then tries to swap the new index for the original.\\n\\n    The index swap is done using a short lock timeout to prevent it from interfering with running queries. Retries until\\n    the rename succeeds.\\n    \"\"\"\\n    db = connect(args.database)\\n    for idx in args.indexes:\\n        pg_reindex(db, idx)',\n",
       " \"def align(s1, s2, gap=' ', eq=operator.eq):\\n    '''aligns two strings\\n\\n    >>> print(*align('pharmacy', 'farmcia', gap='_'), sep='\\\\\\\\n')\\n    pharmac_y\\n    _farmcia\\n\\n    >>> print(*align('advantage', 'vantagem', gap='_'), sep='\\\\\\\\n')\\n    advantage_\\n    __vantagem\\n\\n    '''\\n    # first we compute the dynamic programming table\\n    m, n = len(s1), len(s2)\\n    table = []  # the table is extended lazily, one row at a time\\n    row = list(range(n+1))  # the first row is 0, 1, 2, ..., n\\n    table.append(list(row))  # copy row and insert into table\\n    for i in range(m):\\n        p = i\\n        row[0] = i+1\\n        for j in range(n):\\n            t = 0 if eq(s1[i], s2[j]) else 1\\n            p, row[j+1] = row[j+1], min(p+t, row[j]+1, row[j+1]+1)\\n        table.append(list(row))  # copy row and insert into table\\n    # now we trace the best alignment path from cell [m][n] to cell [0],[0]\\n    s1_, s2_ = '', ''\\n\\n    i, j = m, n\\n    while i != 0 and j != 0:\\n        _, i, j, s1_, s2_ = min(\\n            (table[i-1][j-1], i-1, j-1, s1[i-1]+s1_, s2[j-1]+s2_),\\n            (table[i-1][j], i-1, j, s1[i-1]+s1_, gap+s2_),\\n            (table[i][j-1], i, j-1, gap+s1_, s2[j-1]+s2_)\\n        )\\n    if i != 0:\\n        s1_ = s1[:i]+s1_\\n        s2_ = gap*i+s2_\\n    if j != 0:\\n        s1_ = gap*j+s1_\\n        s2_ = s2[:j]+s2_\\n    return s1_, s2_\",\n",
       " \"def mismatches(s1, s2, context=0, eq=operator.eq):\\n    '''extract mismatched segments from aligned strings\\n\\n    >>> list(mismatches(*align('pharmacy', 'farmcia'), context=1))\\n    [('pha', ' fa'), ('mac', 'mc'), ('c y', 'cia')]\\n\\n    >>> list(mismatches(*align('constitution', 'constituio'), context=1))\\n    [('ution', 'uio')]\\n\\n    >>> list(mismatches(*align('idea', 'ideia'), context=1))\\n    [('e a', 'eia')]\\n\\n    >>> list(mismatches(*align('instructed', 'instrudo'), context=1))\\n    [('ucted', 'u do')]\\n\\n    >>> list(mismatches(*align('concluded', 'concludo'), context=1))\\n    [('uded', 'udo')]\\n    '''\\n    n = len(s1)\\n    assert(len(s2) == n)\\n    lct, rct = context, context if isinstance(context, int) else context\\n    i = None\\n    for j in range(n):\\n        if eq(s1[j], s2[j]):\\n            if i is not None:\\n                # report mismatch segment [i:j] with lct chars of left context\\n                # and rct chars of right context\\n                p, q = max(0, i-lct), min(j+rct, n)\\n                yield s1[p:q], s2[p:q]\\n                i = None\\n        elif i is None:\\n                i = j\\n    if i is not None:\\n        p = max(i-lct, 0)\\n        yield s1[p:], s2[p:]\",\n",
       " 'def _init():\\n    \"\"\" build connection and init it\"\"\"\\n    connection.connect()\\n\\n    # start track\\n    # all services were provided here:\\n    # https://android.googlesource.com/platform/system/core/+/jb-dev/adb/SERVICES.TXT\\n    ready_data = utils.encode_data(\\'host:track-devices\\')\\n    connection.adb_socket.send(ready_data)\\n\\n    # get status\\n    status = connection.adb_socket.recv(4)\\n\\n    # make sure track is ready\\n    if status != b\\'OKAY\\':\\n        raise RuntimeError(\\'adb server return \"{}\", not OKAY\\'.format(str(status)))',\n",
       " 'def get_comment_group_for_path(self, pathname, default_content_type=None):\\n        \"\"\"\\n        Obtains the comment group for a specified pathname.\\n\\n        :param pathname:\\n            The path for which the comment group will be obtained.\\n        :return:\\n            Returns the comment group for the specified pathname\\n            or raises a ``ValueError`` if a content type is not found\\n            or raises a ``KeyError`` if a comment group is not found.\\n\\n        Usage:\\n            >>> db = ContentTypesDatabase()\\n            >>> db.add_config(db._test_config, \\'test_config.yaml\\')\\n            >>> g = db.get_comment_group_for_path\\n            >>> g(\"foobar.py\")\\n            [[\\'#\\', \\'\\']]\\n            >>> g(\"foobar.js\")\\n            [[\\'/*\\', \\'*/\\'], [\\'//\\', \\'\\']]\\n\\n            >>> g(\\'foobar.rst\\')\\n            Traceback (most recent call last):\\n                ...\\n            KeyError: \\'No comment groups for content type `structured-text` for file `foobar.rst` found\\'\\n\\n            # If the content type cannot be determined, we assume the content\\n            # type to be ``python`` in this case.\\n            >>> g(\\'foobar.f37993ajdha73\\', default_content_type=\\'python\\')\\n            [[\\'#\\', \\'\\']]\\n\\n            >>> g(\"foobar.f37993ajdha73\")\\n            Traceback (most recent call last):\\n                ...\\n            ValueError: No content type defined for file path: foobar.f37993ajdha73\\n            >>> g(\"foobar.f37993ajdha73\", default_content_type=None)\\n            Traceback (most recent call last):\\n                ...\\n            ValueError: No content type defined for file path: foobar.f37993ajdha73\\n            \"\"\"\\n        content_type = self.guess_content_type(pathname)\\n        if not content_type:\\n            # Content type is not found.\\n            if default_content_type:\\n                content_type = default_content_type\\n                return self.get_comment_group(content_type)\\n            else:\\n                raise ValueError(\\n                    \"No content type defined for file path: %s\" % pathname)\\n        else:\\n            try:\\n                return self.get_comment_group(content_type)\\n            except KeyError:\\n                raise KeyError(\\n                    \"No comment groups for content type `%s` for file `%s` found\" % (\\n                    content_type, pathname))',\n",
       " 'def add_config_file(self, config_filename):\\n        \"\"\"\\n        Parses the content.types file and updates the content types database.\\n\\n        :param config_filename:\\n            The path to the configuration file.\\n        \"\"\"\\n        with open(config_filename, \\'rb\\') as f:\\n            content = f.read()\\n            config = yaml.load(content)\\n            self.add_config(config, config_filename)',\n",
       " 'def guess_content_type(self, pathname):\\n        \"\"\"Guess the content type for the given path.\\n\\n        :param path:\\n            The path of file for which to guess the content type.\\n        :return:\\n            Returns the content type or ``None`` if the content type\\n            could not be determined.\\n\\n        Usage:\\n            >>> db = ContentTypesDatabase()\\n            >>> db.add_config_file(\\'content-types.yaml\\')\\n            >>> g = db.guess_content_type\\n            >>> assert g(\"__init__.py\") == \"python\"\\n            >>> assert g(\"Makefile\") == \"Makefile\"\\n            >>> assert g(\"Makefile.gmake\") == \"Makefile\"\\n            >>> assert g(\"Makefile.py\") == \"python\"\\n            >>> assert g(\"foobar.rb\") == \"ruby\"\\n            >>> assert g(\"wscript\") == \"python\"\\n            >>> assert g(\"foo.coffee\") == \"coffee-script\"\\n            >>> assert g(\"Rakefile\") == \"ruby\"\\n            >>> assert g(\"foobar.xml\") == \"xml\"\\n            >>> assert g(\"foobar.html\") == \"html\"\\n            >>> assert g(\"foo7a738fg\") == None\\n            >>> assert g(\"foo.rst\") == \"structured-text\"\\n            >>> assert g(\"foo.md\") == \"structured-text\"\\n            >>> assert g(\"foo.markdown\") == \"structured-text\"\\n        \"\"\"\\n        file_basename = os.path.basename(pathname)\\n        content_type = None\\n\\n        # Try to determine from the path.\\n        if not content_type and self._filename_map.has_key(file_basename):\\n            content_type = self._filename_map[file_basename]\\n            #logger.debug(\"Content type of \\'%s\\' is \\'%s\\' (determined from full \"\\\\\\n            #             \"path).\", pathname, content_type)\\n\\n        # Try to determine from the suffix.\\n        if not content_type and \\'.\\' in file_basename:\\n            extension = \".\" + file_basename.split(\".\")[-1]\\n            extension = extension_case_transform_func(extension)\\n            try:\\n                content_type = self._extension_map[extension]\\n                #logger.debug(\"Content type of \\'%s\\' is \\'%s\\' (determined from \"\\\\\\n                #             \"suffix \\'%s\\').\", pathname, content_type, extension)\\n            except KeyError:\\n                pass\\n\\n        # Try to determine from the registered set of regular expression patterns.\\n        if not content_type:\\n            for regexp, _content_type in self._regexp_map.iteritems():\\n                if regexp.search(file_basename):\\n                    content_type = _content_type\\n                    #logger.debug(\\n                    #    \"Content type of \\'%s\\' is \\'%s\\' (matches regexp \\'%s\\')\",\\n                    #    pathname, content_type, regexp.pattern)\\n                    break\\n\\n        # Try to determine from the file contents.\\n        if os.path.exists(pathname):\\n            with open(pathname, \\'rb\\') as f:\\n                content = f.read()\\n                if content.startswith(\"<?xml\"):  # cheap XML sniffing\\n                    content_type = \"XML\"\\n\\n        # TODO: Try to determine from mime-type.\\n\\n        return content_type',\n",
       " 'def connect():\\n    \"\"\" create socket and connect to adb server \"\"\"\\n    global adb_socket\\n    if adb_socket is not None:\\n        raise RuntimeError(\\'connection already existed\\')\\n\\n    host, port = config.HOST, config.PORT\\n\\n    connection = socket.socket()\\n    try:\\n        connection.connect((host, port))\\n    except ConnectionError as _:\\n        warn_msg = \\'failed when connecting to adb server: {}:{}, retrying ...\\'.format(host, port)\\n        warnings.warn(warn_msg)\\n        reboot_adb_server()\\n        connect()\\n        return\\n\\n    adb_socket = connection',\n",
       " 'def reboot_adb_server():\\n    \"\"\" execute \\'adb devices\\' to start adb server \"\"\"\\n    _reboot_count = 0\\n    _max_retry = 1\\n\\n    def _reboot():\\n        nonlocal _reboot_count\\n        if _reboot_count >= _max_retry:\\n            raise RuntimeError(\\'fail after retry {} times\\'.format(_max_retry))\\n        _reboot_count += 1\\n\\n        return_code = subprocess.call([\\'adb\\', \\'devices\\'], stdout=subprocess.DEVNULL)\\n        if bool(return_code):\\n            warnings.warn(\\'return not zero, execute \"adb version\" failed\\')\\n            raise EnvironmentError(\\'adb did not work :(\\')\\n\\n    return _reboot',\n",
       " 'def escape_string(value):\\n    \"\"\"Converts a string to its S-expression representation, adding quotes\\n    and escaping funny characters.\\n    \"\"\"\\n    res = StringIO()\\n    res.write(\\'\"\\')\\n    for c in value:\\n        if c in CHAR_TO_ESCAPE:\\n            res.write(f\\'\\\\\\\\{CHAR_TO_ESCAPE[c]}\\')\\n        elif c.isprintable():\\n            res.write(c)\\n        elif ord(c) < 0x100:\\n            res.write(f\\'\\\\\\\\x{ord(c):02x}\\')\\n        elif ord(c) < 0x10000:\\n            res.write(f\\'\\\\\\\\u{ord(c):04x}\\')\\n        else:\\n            res.write(f\\'\\\\\\\\U{ord(c):06x}\\')\\n    res.write(\\'\"\\')\\n    return res.getvalue()',\n",
       " 'def compare(value1, operation, value2):\\n        \"\"\"\\n        Perform comparison operation over two arguments.\\n        The operation can be performed over values of any type.\\n\\n        :param value1: the first argument to compare\\n\\n        :param operation: the comparison operation: \"==\" (\"=\", \"EQ\"), \"!= \" (\"<>\", \"NE\"); \"<\"/\">\"\\n                                                    (\"LT\"/\"GT\"), \"<=\"/\">=\" (\"LE\"/\"GE\"); \"LIKE\".\\n\\n        :param value2: the second argument to compare\\n\\n        :return: result of the comparison operation\\n        \"\"\"\\n        if operation == None:\\n            return False\\n        \\n        operation = operation.upper()\\n\\n        if operation in [\"=\", \"==\", \"EQ\"]:\\n            return ObjectComparator.are_equal(value1, value2)\\n        if operation in [\"!=\", \"<>\", \"NE\"]:\\n            return ObjectComparator.are_not_equal(value1, value2)\\n        if operation in [\"<\", \"LT\"]:\\n            return ObjectComparator.less(value1, value2)\\n        if operation in [\"<=\", \"LE\"]:\\n            return ObjectComparator.are_equal(value1, value2) or ObjectComparator.less(value1, value2)\\n        if operation in [\">\", \"GT\"]:\\n            return ObjectComparator.more(value1, value2)\\n        if operation in [\">=\", \"GE\"]:\\n            return ObjectComparator.are_equal(value1, value2) or ObjectComparator.more(value1, value2)\\n        if operation == \"LIKE\":\\n            return ObjectComparator.match(value1, value2)\\n\\n        return True',\n",
       " 'def are_equal(value1, value2):\\n        \"\"\"\\n        Checks if two values are equal. The operation can be performed over values of any type.\\n\\n        :param value1: the first value to compare\\n\\n        :param value2: the second value to compare\\n\\n        :return: true if values are equal and false otherwise\\n        \"\"\"\\n        if value1 == None or value2 == None:\\n            return True\\n        if value1 == None or value2 == None:\\n            return False\\n        return value1 == value2',\n",
       " 'def less(value1, value2):\\n        \"\"\"\\n        Checks if first value is less than the second one.\\n        The operation can be performed over numbers or strings.\\n\\n        :param value1: the first value to compare\\n\\n        :param value2: the second value to compare\\n\\n        :return: true if the first value is less than second and false otherwise.\\n        \"\"\"\\n        number1 = FloatConverter.to_nullable_float(value1)\\n        number2 = FloatConverter.to_nullable_float(value2)\\n\\n        if number1 == None or number2 == None:\\n            return False\\n\\n        return number1 < number2',\n",
       " 'def more(value1, value2):\\n        \"\"\"\\n        Checks if first value is greater than the second one.\\n        The operation can be performed over numbers or strings.\\n\\n        :param value1: the first value to compare\\n\\n        :param value2: the second value to compare\\n\\n        :return: true if the first value is greater than second and false otherwise.\\n        \"\"\"\\n        number1 = FloatConverter.to_nullable_float(value1)\\n        number2 = FloatConverter.to_nullable_float(value2)\\n\\n        if number1 == None or number2 == None:\\n            return False\\n\\n        return number1 > number2',\n",
       " 'def match(value1, value2):\\n        \"\"\"\\n        Checks if string matches a regular expression\\n\\n        :param value1: a string value to match\\n\\n        :param value2: a regular expression string\\n\\n        :return: true if the value matches regular expression and false otherwise.\\n        \"\"\"\\n        if value1 == None and value2 == None:\\n            return True\\n        if value1 == None or value2 == None:\\n            return False\\n\\n        string1 = str(value1)\\n        string2 = str(value2)\\n        return re.match(string2, string1) != None',\n",
       " 'def register_view(self, view):\\n        \"\"\"Loads the text taking it from the model, then starts a\\n        timer to scroll it.\"\"\"\\n        self.view.set_text(self.model.credits)\\n        gobject.timeout_add(1500, self.on_begin_scroll)\\n        return',\n",
       " 'def on_scroll(self):\\n        \"\"\"Called to scroll text\"\"\"\\n        try:\\n            sw = self.view[\\'sw_scroller\\']\\n        except KeyError:\\n            return False # destroyed!        \\n        vadj = sw.get_vadjustment()\\n        if vadj is None: return False\\n        val = vadj.get_value()\\n        \\n        # is scrolling over?\\n        if val >= vadj.upper - vadj.page_size:\\n            self.view.show_vscrollbar()\\n            return False\\n        \\n        vadj.set_value(val+0.5)\\n        return True',\n",
       " 'def create_token(self, *, holder_name, card_number, credit_card_cvv, expiration_date, token_type=\\'credit_card\\',\\n                     identity_document=None, billing_address=None, additional_details=None):\\n        \"\"\"\\n        When creating a Token, remember to use the public-key header instead of the private-key header,\\n        and do not include the app-id header.\\n\\n        Args:\\n            holder_name: Name of the credit card holder.\\n            card_number: Credit card number.\\n            credit_card_cvv: The CVV number on the card (3 or 4 digits) to be encrypted.\\n            expiration_date: Credit card expiration date. Possible formats: mm-yyyy, mm-yy, mm.yyyy,\\n            mm.yy, mm/yy, mm/yyyy, mm yyyy, or mm yy.\\n            token_type: The type of token\\n            billing_address: Address.\\n            identity_document: National identity document of the card holder.\\n            additional_details: Optional additional data stored with your token in key/value pairs.\\n\\n        Returns:\\n\\n        \"\"\"\\n        headers = self.client._get_public_headers()\\n        payload = {\\n            \"token_type\": token_type,\\n            \"credit_card_cvv\": credit_card_cvv,\\n            \"card_number\": card_number,\\n            \"expiration_date\": expiration_date,\\n            \"holder_name\": holder_name,\\n            \"identity_document\": identity_document,\\n            \"billing_address\": billing_address,\\n            \"additional_details\": additional_details,\\n        }\\n        endpoint = \\'/tokens\\'\\n        return self.client._post(self.client.URL_BASE + endpoint, json=payload, headers=headers)',\n",
       " 'def retrieve_token(self, token):\\n        \"\"\"\\n        Retrieve Token details for a specific Token.\\n\\n        Args:\\n            token: The identifier of the token.\\n\\n\\n        Returns:\\n\\n        \"\"\"\\n        headers = self.client._get_private_headers()\\n        endpoint = \\'/tokens/{}\\'.format(token)\\n        return self.client._get(self.client.URL_BASE + endpoint, headers=headers)',\n",
       " 'def prj_created_data(project, role):\\n    \"\"\"Return the data for created\\n\\n    :param project: the project that holds the data\\n    :type project: :class:`jukeboxcore.djadapter.models.Project`\\n    :param role: item data role\\n    :type role: QtCore.Qt.ItemDataRole\\n    :returns: data for the created\\n    :rtype: depending on role\\n    :raises: None\\n    \"\"\"\\n    if role == QtCore.Qt.DisplayRole:\\n        return project.date_created.isoformat(\\' \\')',\n",
       " 'def prj_fps_data(project, role):\\n    \"\"\"Return the data for fps\\n\\n    :param project: the project that holds the data\\n    :type project: :class:`jukeboxcore.djadapter.models.Project`\\n    :param role: item data role\\n    :type role: QtCore.Qt.ItemDataRole\\n    :returns: data for the fps\\n    :rtype: depending on role\\n    :raises: None\\n    \"\"\"\\n    if role == QtCore.Qt.DisplayRole:\\n        return str(project.framerate)',\n",
       " 'def prj_resolution_data(project, role):\\n    \"\"\"Return the data for resolution\\n\\n    :param project: the project that holds the data\\n    :type project: :class:`jukeboxcore.djadapter.models.Project`\\n    :param role: item data role\\n    :type role: QtCore.Qt.ItemDataRole\\n    :returns: data for the resolution\\n    :rtype: depending on role\\n    :raises: None\\n    \"\"\"\\n    if role == QtCore.Qt.DisplayRole:\\n        return \\'%s x %s\\' % (project.resx, project.resy)',\n",
       " 'def shot_duration_data(shot, role):\\n    \"\"\"Return the data for duration\\n\\n    :param shot: the shot that holds the data\\n    :type shot: :class:`jukeboxcore.djadapter.models.Shot`\\n    :param role: item data role\\n    :type role: QtCore.Qt.ItemDataRole\\n    :returns: data for the duration\\n    :rtype: depending on role\\n    :raises: None\\n    \"\"\"\\n    if role == QtCore.Qt.DisplayRole:\\n        return str(shot.duration)',\n",
       " 'def shot_start_data(shot, role):\\n    \"\"\"Return the data for startframe\\n\\n    :param shot: the shot that holds the data\\n    :type shot: :class:`jukeboxcore.djadapter.models.Shot`\\n    :param role: item data role\\n    :type role: QtCore.Qt.ItemDataRole\\n    :returns: data for the start\\n    :rtype: depending on role\\n    :raises: None\\n    \"\"\"\\n    if role == QtCore.Qt.DisplayRole:\\n        return str(shot.startframe)',\n",
       " 'def shot_end_data(shot, role):\\n    \"\"\"Return the data for endframe\\n\\n    :param shot: the shot that holds the data\\n    :type shot: :class:`jukeboxcore.djadapter.models.Shot`\\n    :param role: item data role\\n    :type role: QtCore.Qt.ItemDataRole\\n    :returns: data for the end\\n    :rtype: depending on role\\n    :raises: None\\n    \"\"\"\\n    if role == QtCore.Qt.DisplayRole:\\n        return str(shot.endframe)',\n",
       " 'def note_content_data(note, role):\\n    \"\"\"Return the data for content\\n\\n    :param note: the note that holds the data\\n    :type note: :class:`jukeboxcore.djadapter.models.Note`\\n    :param role: item data role\\n    :type role: QtCore.Qt.ItemDataRole\\n    :returns: data for the created date\\n    :rtype: depending on role\\n    :raises: None\\n    \"\"\"\\n    if role == QtCore.Qt.DisplayRole or role == QtCore.Qt.EditRole:\\n        return note.content',\n",
       " 'def remove_adapter(widget_class, flavour=None):\\n    \"\"\"Removes the given widget class information from the default set\\n    of adapters.\\n\\n    If widget_class had been previously added by using add_adapter,\\n    the added adapter will be removed, restoring possibly previusly\\n    existing adapter(s). Notice that this function will remove only\\n    *one* adapter about given wiget_class (the first found in order),\\n    even if many are currently stored.\\n\\n    @param flavour has to be used when the entry was added with a\\n    particular flavour.\\n\\n    Returns True if one adapter was removed, False if no adapter was\\n    removed.\"\"\"\\n    for it,tu in enumerate(__def_adapter):\\n        if (widget_class == tu[WIDGET] and flavour == tu[FLAVOUR]):\\n            del __def_adapter[it]\\n            return True\\n\\n    return False',\n",
       " 'def get(self, key):\\n        \"\"\"\\n        Gets a map element specified by its key.\\n\\n        The key can be defined using dot notation\\n        and allows to recursively access elements of elements.\\n\\n        :param key: a key of the element to get.\\n\\n        :return: the value of the map element.\\n        \"\"\"\\n        if key == None or key == \\'\\':\\n            return None\\n        elif key.find(\\'.\\') > 0:\\n            return RecursiveObjectReader.get_property(self, key)\\n        else:\\n            return super(Parameters, self).get(key)',\n",
       " 'def put(self, key, value):\\n        \"\"\"\\n        Puts a new value into map element specified by its key.\\n\\n        The key can be defined using dot notation\\n        and allows to recursively access elements of elements.\\n\\n        :param key: a key of the element to put.\\n\\n        :param value: a new value for map element.\\n        \"\"\"\\n        if key == None or key == \\'\\':\\n            return None\\n        elif key.find(\\'.\\') > 0:\\n            RecursiveObjectWriter.set_property(self, key, value)\\n            return value\\n        else:\\n            self[key] = value\\n            return value',\n",
       " 'def get_as_nullable_parameters(self, key):\\n        \"\"\"\\n        Converts map element into an Parameters or returns null if conversion is not possible.\\n\\n        :param key: a key of element to get.\\n\\n        :return: Parameters value of the element or null if conversion is not supported.\\n        \"\"\"\\n        value = self.get_as_nullable_map(key)\\n        return Parameters(value) if value != None else None',\n",
       " 'def get_as_parameters_with_default(self, key, default_value):\\n        \"\"\"\\n        Converts map element into an Parameters or returns default value if conversion is not possible.\\n\\n        :param key: a key of element to get.\\n\\n        :param default_value: the default value\\n\\n        :return: Parameters value of the element or default value if conversion is not supported.\\n        \"\"\"\\n        result = self.get_as_nullable_parameters(key)\\n        return result if result != None else default_value',\n",
       " 'def override(self, parameters, recursive = False):\\n        \"\"\"\\n        Overrides parameters with new values from specified Parameters and returns a new Parameters object.\\n\\n        :param parameters: Parameters with parameters to override the current values.\\n\\n        :param recursive: (optional) true to perform deep copy, and false for shallow copy. Default: false\\n\\n        :return: a new Parameters object.\\n        \"\"\"\\n        result = Parameters()\\n\\n        if recursive:\\n            RecursiveObjectWriter.copy_properties(result, self)\\n            RecursiveObjectWriter.copy_properties(result, parameters)\\n        else:\\n            ObjectWriter.set_properties(result, self)\\n            ObjectWriter.set_properties(result, parameters)\\n\\n        return result',\n",
       " 'def set_defaults(self, default_values, recursive = False):\\n        \"\"\"\\n        Set default values from specified Parameters and returns a new Parameters object.\\n\\n        :param default_values: Parameters with default parameter values.\\n\\n        :param recursive: (optional) true to perform deep copy, and false for shallow copy. Default: false\\n\\n        :return: a new Parameters object.\\n        \"\"\"\\n        result = Parameters()\\n\\n        if recursive:\\n            RecursiveObjectWriter.copy_properties(result, default_values)\\n            RecursiveObjectWriter.copy_properties(result, self)\\n        else:\\n            ObjectWriter.set_properties(result, default_values)\\n            ObjectWriter.set_properties(result, self)\\n\\n        return result',\n",
       " 'def pick(self, *props):\\n        \"\"\"\\n        Picks select parameters from this Parameters and returns them as a new Parameters object.\\n\\n        :param props: keys to be picked and copied over to new Parameters.\\n\\n        :return: a new Parameters object.\\n        \"\"\"\\n        result = Parameters()\\n        for prop in props:\\n            if self.contains_key(prop):\\n                result.put(prop, self.get(prop))\\n        return result',\n",
       " 'def omit(self, *props):\\n        \"\"\"\\n        Omits selected parameters from this Parameters and returns the rest as a new Parameters object.\\n\\n        :param props: keys to be omitted from copying over to new Parameters.\\n\\n        :return: a new Parameters object.\\n        \"\"\"\\n        result = Parameters(self)\\n        for prop in props:\\n            del result[prop]\\n        return result',\n",
       " 'def from_value(value):\\n        \"\"\"\\n        Creates a new Parameters object filled with key-value pairs from specified object.\\n\\n        :param value: an object with key-value pairs used to initialize a new Parameters.\\n\\n        :return: a new Parameters object.\\n        \"\"\"\\n        map = value if isinstance(value, dict) else RecursiveObjectReader.get_properties(value)\\n        return Parameters(map)',\n",
       " 'def from_config(config):\\n        \"\"\"\\n        Creates new Parameters from ConfigMap object.\\n\\n        :param config: a ConfigParams that contain parameters.\\n\\n        :return: a new Parameters object.\\n        \"\"\"\\n        result = Parameters()\\n        \\n        if config == None or len(config) == 0:\\n            return result\\n        \\n        for (key, value) in config.items():\\n            result.put(key, value)\\n        \\n        return result',\n",
       " 'def execute(correlation_id, components, args = None):\\n        \"\"\"\\n        Executes multiple components.\\n\\n        To be executed components must implement [[IExecutable]] interface.\\n        If they don\\'t the call to this method has no effect.\\n\\n        :param correlation_id: (optional) transaction id to trace execution through call chain.\\n\\n        :param components: a list of components that are to be executed.\\n\\n        :param args: execution arguments.\\n\\n        :return: execution result\\n        \"\"\"\\n        results = []\\n\\n        if components == None:\\n            return\\n\\n        args = args if args != None else Parameters()\\n        for component in components:\\n            result = Executor.execute_one(correlation_id, component, args)\\n            results.append(result)\\n\\n        return results',\n",
       " 'def decorator(func):\\n        \"\"\"A function timer decorator.\"\"\"\\n\\n        def function_timer(*args, **kwargs):\\n            \"\"\"A nested function for timing other functions.\"\"\"\\n            # Capture start time\\n            start = time.time()\\n\\n            # Execute function with arguments\\n            value = func(*args, **kwargs)\\n\\n            # Capture end time\\n            end = time.time()\\n\\n            # Calculate run time\\n            runtime = end - start\\n            if runtime < 60:\\n                runtime = str(\\'sec: \\' + str(\\'{:f}\\'.format(runtime)))\\n            else:\\n                runtime = str(\\'min: \\' + str(\\'{:f}\\'.format(runtime / 60)))\\n            print(\\'{func:50} --> {time}\\'.format(func=func.__qualname__, time=runtime))\\n            return value\\n\\n        return function_timer',\n",
       " \"def populateImagesFromSurveys(self, surveys=dss2 + twomass):\\n        '''\\n        Load images from archives.\\n        '''\\n\\n        # what's the coordinate center?\\n        coordinatetosearch = '{0.ra.deg} {0.dec.deg}'.format(self.center)\\n\\n        # query sky view for those images\\n        paths = astroquery.skyview.SkyView.get_images(\\n                                    position=coordinatetosearch,\\n                                    radius=self.radius,\\n                                    survey=surveys)\\n\\n        # populate the images for each of these\\n        self.images = [Image(p[0], s) for p, s in zip(paths, surveys)]\",\n",
       " 'def global_instance(cls):\\n        \"\"\"Return a per-thread global batcher instance.\"\"\"\\n        try:\\n            return GLOBAL_BATCHER.instance\\n        except AttributeError:\\n\\n            instance = PrioritizedBatcher(\\n                **getattr(settings, \\'PRIORITIZED_BATCHER\\', {})\\n            )\\n            GLOBAL_BATCHER.instance = instance\\n            return instance',\n",
       " 'def commit(self):\\n        \"\"\"Commit a batch.\"\"\"\\n        assert self.batch is not None, \"No active batch, call start() first\"\\n\\n        logger.debug(\"Comitting batch from %d sources...\", len(self.batch))\\n\\n        # Determine item priority.\\n        by_priority = []\\n        for name in self.batch.keys():\\n            priority = self.priorities.get(name, self.default_priority)\\n            by_priority.append((priority, name))\\n\\n        for priority, name in sorted(by_priority, key=lambda key: key[0]):\\n            logger.debug(\"Processing items from \\'%s\\' (priority=%d)...\", name, priority)\\n            items = self.batch[name]\\n            for handlers in items.values():\\n                for agg, handler in handlers:\\n                    try:\\n                        if agg is None:\\n                            handler()\\n                        else:\\n                            handler(agg)\\n                    except Exception as error:\\n                        # Log errors and proceed to evaluate the next handler.\\n                        logger.exception(\"Error while invoking handler.\")\\n\\n        self.batch = None\\n\\n        logger.debug(\"Batch committed.\")',\n",
       " 'def add(self, name, handler, group_by=None, aggregator=None):\\n        \"\"\"Add a new handler to the current batch.\"\"\"\\n        assert self.batch is not None, \"No active batch, call start() first\"\\n\\n        items = self.batch.setdefault(name, collections.OrderedDict())\\n        if group_by is None:\\n            # None is special as it means no grouping. In this case we must store all\\n            # the different handlers and call them all.\\n            items.setdefault(group_by, []).append((None, handler))\\n        elif aggregator is not None:\\n            agg = items.get(group_by, [(None, None)])[0][0]\\n            items[group_by] = [(aggregator(agg), handler)]\\n        else:\\n            items[group_by] = [(None, handler)]',\n",
       " 'def configure(name, path=None):\\n    \"\"\" Configure logging and return a logger and the location of its logging\\n    configuration file.\\n\\n    This function expects:\\n\\n    + A Splunk app directory structure::\\n\\n        <app-root>\\n            bin\\n                ...\\n            default\\n                ...\\n            local\\n                ...\\n\\n    + The current working directory is *<app-root>***/bin**.\\n\\n      Splunk guarantees this. If you are running the app outside of Splunk, be\\n      sure to set the current working directory to *<app-root>***/bin** before\\n      calling.\\n\\n    This function looks for a logging configuration file at each of these\\n    locations, loading the first, if any, logging configuration file that it\\n    finds::\\n\\n        local/{name}.logging.conf\\n        default/{name}.logging.conf\\n        local/logging.conf\\n        default/logging.conf\\n\\n    The current working directory is set to *<app-root>* before the logging\\n    configuration file is loaded. Hence, paths in the logging configuration\\n    file are relative to *<app-root>*. The current directory is reset before\\n    return.\\n\\n    You may short circuit the search for a logging configuration file by\\n    providing an alternative file location in `path`. Logging configuration\\n    files must be in `ConfigParser format`_.\\n\\n    #Arguments:\\n\\n    :param name: Logger name\\n    :type name: str\\n    :param path: Location of an alternative logging configuration file or `None`\\n    :type path: str or NoneType\\n    :returns: A logger and the location of its logging configuration file\\n\\n    .. _ConfigParser format: http://goo.gl/K6edZ8\\n\\n    \"\"\"\\n    app_directory = os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0])))\\n\\n    if path is None:\\n        probing_path = [\\n            \\'local/%s.logging.conf\\' % name,\\n            \\'default/%s.logging.conf\\' % name,\\n            \\'local/logging.conf\\',\\n            \\'default/logging.conf\\']\\n        for relative_path in probing_path:\\n            configuration_file = os.path.join(app_directory, relative_path)\\n            if os.path.exists(configuration_file):\\n                path = configuration_file\\n                break\\n    elif not os.path.isabs(path):\\n        found = False\\n        for conf in \\'local\\', \\'default\\':\\n            configuration_file = os.path.join(app_directory, conf, path)\\n            if os.path.exists(configuration_file):\\n                path = configuration_file\\n                found = True\\n                break\\n        if not found:\\n            raise ValueError(\\n                \\'Logging configuration file \"%s\" not found in local or default \\'\\n                \\'directory\\' % path)\\n    elif not os.path.exists(path):\\n        raise ValueError(\\'Logging configuration file \"%s\" not found\\')\\n\\n    if path is not None:\\n        working_directory = os.getcwd()\\n        os.chdir(app_directory)\\n        try:\\n            splunk_home = os.path.normpath(os.path.join(working_directory, os.environ[\\'SPLUNK_HOME\\']))\\n        except KeyError:\\n            splunk_home = working_directory  # reasonable in debug scenarios\\n        try:\\n            path = os.path.abspath(path)\\n            fileConfig(path, {\\'SPLUNK_HOME\\': splunk_home})\\n        finally:\\n            os.chdir(working_directory)\\n\\n    if len(root.handlers) == 0:\\n        root.addHandler(StreamHandler())\\n\\n    logger = getLogger(name)\\n    return logger, path',\n",
       " 'def expand_user(path, user=None):\\n    \"\"\"Roughly the same as os.path.expanduser, but you can pass a default user.\"\"\"\\n\\n    def _replace(m):\\n        m_user = m.group(1) or user\\n        return pwd.getpwnam(m_user).pw_dir if m_user else pwd.getpwuid(os.getuid()).pw_dir\\n\\n    return re.sub(r\\'~(\\\\w*)\\', _replace, path)',\n",
       " 'def unique_list(input_, key=lambda x:x):\\n    \"\"\"Return the unique elements from the input, in order.\"\"\"\\n    seen = set()\\n    output = []\\n    for x in input_:\\n        keyx = key(x)\\n        if keyx not in seen:\\n            seen.add(keyx)\\n            output.append(x)\\n    return output',\n",
       " 'def get_environ_list(name, default=None):\\n    \"\"\"Return the split colon-delimited list from an environment variable.\\n\\n    Returns an empty list if the variable didn\\'t exist.\\n\\n    \"\"\"\\n    packed = os.environ.get(name)\\n    if packed is not None:\\n        return packed.split(\\':\\')\\n    elif default is not None:\\n        return default\\n    else:\\n        return []',\n",
       " 'def is_indel(reference_bases, alternate_bases):\\n    \"\"\" Return whether or not the variant is an INDEL \"\"\"\\n    if len(reference_bases) > 1:\\n        return True\\n    for alt in alternate_bases:\\n        if alt is None:\\n            return True\\n        elif len(alt) != len(reference_bases):\\n            return True\\n    return False',\n",
       " 'def is_snp(reference_bases, alternate_bases):\\n    \"\"\" Return whether or not the variant is a SNP \"\"\"\\n    if len(reference_bases) > 1:\\n        return False\\n    for alt in alternate_bases:\\n        if alt is None:\\n            return False\\n        if alt not in [\\'A\\', \\'C\\', \\'G\\', \\'T\\', \\'N\\', \\'*\\']:\\n            return False\\n    return True',\n",
       " 'def is_deletion(reference_bases, alternate_bases):\\n    \"\"\" Return whether or not the INDEL is a deletion \"\"\"\\n    # if multiple alts, it is unclear if we have a transition\\n    if len(alternate_bases) > 1:\\n        return False\\n\\n    if is_indel(reference_bases, alternate_bases):\\n        # just one alt allele\\n        alt_allele = alternate_bases[0]\\n        if alt_allele is None:\\n            return True\\n        if len(reference_bases) > len(alt_allele):\\n            return True\\n        else:\\n            return False\\n    else:\\n        return False',\n",
       " 'def overlapping(self, other):\\n        \"\"\"Do these variants overlap in the reference\"\"\"\\n        return (\\n            other.start in self.ref_range) or (\\n            self.start in other.ref_range)',\n",
       " 'def parse_pgurl(self, url):\\n        \"\"\"\\n        Given a Postgres url, return a dict with keys for user, password,\\n        host, port, and database.\\n        \"\"\"\\n        parsed = urlsplit(url)\\n\\n        return {\\n            \\'user\\': parsed.username,\\n            \\'password\\': parsed.password,\\n            \\'database\\': parsed.path.lstrip(\\'/\\'),\\n            \\'host\\': parsed.hostname,\\n            \\'port\\': parsed.port or 5432,\\n        }',\n",
       " 'def value_change(self, model, name, info):\\n        \"\"\"The model is changed and the view must be updated\"\"\"\\n        msg = self.model.get_message(info.new)\\n\\n        self.view.set_msg(msg)\\n        return',\n",
       " 'def reset_current_row(self, *args, **kwargs):\\n        \"\"\"Reset the selected rows value to its default value\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        i = self.configobj_treev.currentIndex()\\n        m = self.configobj_treev.model()\\n        m.restore_default(i)',\n",
       " 'def get_configs(self):\\n        \"\"\"Load all config files and return the configobjs\\n\\n        :returns: a list of configobjs\\n        :raises: None\\n\\n        It always loads the coreconfig.\\n        Then it looks for all configs inside the PLUGIN_CONFIG_DIR.\\n        It will find the corresponding spec of the plugins.\\n        If there is a spec, but no ini, it will also be loaded!\\n        \"\"\"\\n        # all loaded configs are stored in confs\\n        confs = []\\n        # always load core config. it is not part of the plugin configs\\n        try:\\n            confs.append(iniconf.get_core_config())\\n        except ConfigError, e:\\n            log.error(\"Could not load Core config! Reason was: %s\" % e)\\n\\n        # get config specs that lie in the plugin path\\n        # we have to watch the order we gather the specs\\n        # plugins can override each other, so can config specs\\n        # it depends on the order of the JUKEBOX_PLUGIN_PATH\\n        specs = {}\\n        pathenv = os.environ.get(\\'JUKEBOX_PLUGIN_PATH\\', \\'\\')\\n        paths = pathenv.split(\\';\\')\\n        paths.append(constants.BUILTIN_PLUGIN_PATH)\\n        for p in reversed(paths):\\n            if p:\\n                files = self.find_inifiles(p)\\n                for ini in files:\\n                    base = os.path.basename(ini)\\n                    specs[base] = ini\\n\\n        configs = {}\\n        files = self.find_inifiles(PLUGIN_CONFIG_DIR)\\n        for ini in files:\\n            base = os.path.basename(ini)\\n            configs[base] = ini\\n\\n        # find matching pairs of configs and specs\\n        # and load them\\n        for k in configs:\\n            spec = specs.pop(k, None)\\n            conf = configs[k]\\n            try:\\n                confs.append(iniconf.load_config(conf, spec))\\n            except ConfigError, e:\\n                log.error(\"Could not load config %s, Reason was: %s\" % (k ,e))\\n\\n        # the remaining configspecs can be used to create\\n        # empty configs\\n        for k in specs:\\n            spec = specs[k]\\n            conf = os.path.join(PLUGIN_CONFIG_DIR, k)\\n            try:\\n                confs.append(iniconf.load_config(conf, spec))\\n            except ConfigError, e:\\n                log.error(\"Could not load config %s, Reason was: %s\" % (k ,e))\\n\\n        return confs',\n",
       " 'def set_inifile(self, current, previous):\\n        \"\"\"Set the configobj to the current index of the files_lv\\n\\n        This is a slot for the currentChanged signal\\n\\n        :param current: the modelindex of a inifilesmodel that should be set for the configobj_treev\\n        :type current: QModelIndex\\n        :param previous: the previous selected index\\n        :type previous: QModelIndex\\n        :returns: None\\n        :raises: None\\n        \"\"\"\\n        c = self.inimodel.data(current, self.inimodel.confobjRole)\\n        self.confobjmodel = ConfigObjModel(c)\\n        self.configobj_treev.setModel(self.confobjmodel)\\n        self.configobj_treev.expandAll()\\n        self.confobjmodel.dataChanged.connect(self.iniedited)',\n",
       " 'def iniedited(self, *args, **kwargs):\\n        \"\"\"Set the current index of inimodel to modified\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        self.inimodel.set_index_edited(self.files_lv.currentIndex(), True)',\n",
       " 'def closeEvent(self, event):\\n        \"\"\"Handles closing of the window. If configs were edited, ask user to continue.\\n\\n        :param event: the close event\\n        :type event: QCloseEvent\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n        \"\"\"\\n        if self.inimodel.get_edited():\\n            r = self.doc_modified_prompt()\\n            if r == QtGui.QMessageBox.Yes:\\n                event.accept()\\n            else:\\n                event.ignore()\\n        else:\\n            event.accept()',\n",
       " 'def doc_modified_prompt(self, ):\\n        \"\"\"Create a message box, that asks the user to continue although files have been modified\\n\\n        :returns: value of the standard button of qmessagebox that has been pressed. Either Yes or Cancel.\\n        :rtype: QtGui.QMessageBox.StandardButton\\n        :raises: None\\n        \"\"\"\\n        msgbox = QtGui.QMessageBox()\\n        msgbox.setWindowTitle(\"Discard changes?\")\\n        msgbox.setText(\"Documents have been modified.\")\\n        msgbox.setInformativeText(\"Do you really want to exit? Changes will be lost!\")\\n        msgbox.setStandardButtons(msgbox.Yes | msgbox.Cancel)\\n        msgbox.setDefaultButton(msgbox.Cancel)\\n        msgbox.exec_()\\n        return msgbox.result()',\n",
       " 'def save_current_config(self, ):\\n        \"\"\"Saves the currently displayed config\\n\\n        :returns: None\\n        :rtype: None\\n        :raises: None\\n\\n        This resets the edited status of the file to False.\\n        Also asks the user to continue if config is invalid.\\n\\n        \"\"\"\\n        # check if all configs validate correctly\\n        btn = None\\n        for row in range(self.inimodel.rowCount()):\\n            i = self.inimodel.index(row, 0)\\n            r = self.inimodel.validate(i)\\n            if r is not True:\\n                btn = self.invalid_prompt()\\n                break\\n\\n        if btn == QtGui.QMessageBox.Cancel:\\n            return\\n        current = self.files_lv.currentIndex()\\n        c = self.inimodel.data(current, self.inimodel.confobjRole)\\n        c.write()\\n        self.inimodel.set_index_edited(current, False)',\n",
       " 'def get_virtualenv_path(self, requirements_option: RequirementsOptions, requirements_hash: Optional[str]) -> Path:\\n        \"\"\"\\n        Returns the path to the virtualenv the current state of the repository.\\n        \"\"\"\\n        if requirements_option == RequirementsOptions.no_requirements:\\n            venv_name = \"no_requirements\"\\n        else:\\n            venv_name = requirements_hash\\n\\n        return Path(self._arca.base_dir) / \"venvs\" / venv_name',\n",
       " 'def get_or_create_environment(self, repo: str, branch: str, git_repo: Repo, repo_path: Path) -> str:\\n        \"\"\" Handles the requirements in the target repository, returns a path to a executable of the virtualenv.\\n        \"\"\"\\n        return str(self.get_or_create_venv(repo_path).resolve() / \"bin\" / \"python\")',\n",
       " 'def annotate_mapper(**decargs):\\n    \"\"\"Add input and output watermarks to processed events.\"\"\"\\n    def decorator(func):\\n        \"\"\"Annotate events with entry and/or exit timestamps.\"\"\"\\n        def wrapper(event, *args, **kwargs):\\n            \"\"\"Add enter and exit annotations to the processed event.\"\"\"\\n            funcname = \":\".join([func.__module__, func.__name__])\\n            enter_ts = time.time()\\n            out = func(event, *args, **kwargs)\\n            enter_key = funcname + \"|enter\"\\n            out = annotate_event(out, enter_key, ts=enter_ts, **decargs)\\n            exit_key = funcname + \"|exit\"\\n            out = annotate_event(out, exit_key, ts=time.time(), **decargs)\\n            return out\\n\\n        return wrapper\\n    return decorator',\n",
       " 'def annotate_filter(**decargs):\\n    \"\"\"Add input and output watermarks to filtered events.\"\"\"\\n    def decorator(func):\\n        \"\"\"Annotate events with entry and/or exit timestamps.\"\"\"\\n        def wrapper(event, *args, **kwargs):\\n            \"\"\"Add enter and exit annotations to the processed event.\"\"\"\\n            funcname = \":\".join([func.__module__, func.__name__])\\n            enter_key = funcname + \"|enter\"\\n            annotate_event(event, enter_key, **decargs)\\n            out = func(event, *args, **kwargs)\\n            exit_key = funcname + \"|exit\"\\n            annotate_event(event, exit_key, **decargs)\\n            return out\\n\\n        return wrapper\\n    return decorator',\n",
       " 'def _error_repr(error):\\n    \"\"\"A compact unique representation of an error.\"\"\"\\n    error_repr = repr(error)\\n    if len(error_repr) > 200:\\n        error_repr = hash(type(error))\\n    return error_repr',\n",
       " 'def annotation_has_expired(event, key, timeout):\\n    \"\"\"Check if an event error has expired.\"\"\"\\n    anns = get_annotations(event, key)\\n    if anns:\\n        return (time.time() - anns[0][\"ts\"]) > timeout\\n    else:\\n        return False',\n",
       " 'def replace_event_annotations(event, newanns):\\n    \"\"\"Replace event annotations with the provided ones.\"\"\"\\n    _humilis = event.get(\"_humilis\", {})\\n    if not _humilis:\\n        event[\"_humilis\"] = {\"annotation\": newanns}\\n    else:\\n        event[\"_humilis\"][\"annotation\"] = newanns',\n",
       " 'def annotate_event(ev, key, ts=None, namespace=None, **kwargs):\\n    \"\"\"Add an annotation to an event.\"\"\"\\n    ann = {}\\n    if ts is None:\\n        ts = time.time()\\n    ann[\"ts\"] = ts\\n    ann[\"key\"] = key\\n    if namespace is None and \"HUMILIS_ENVIRONMENT\" in os.environ:\\n        namespace = \"{}:{}:{}\".format(\\n            os.environ.get(\"HUMILIS_ENVIRONMENT\"),\\n            os.environ.get(\"HUMILIS_LAYER\"),\\n            os.environ.get(\"HUMILIS_STAGE\"))\\n\\n    if namespace is not None:\\n        ann[\"namespace\"] = namespace\\n    ann.update(kwargs)\\n    _humilis = ev.get(\"_humilis\", {})\\n    if not _humilis:\\n        ev[\"_humilis\"] = {\"annotation\": [ann]}\\n    else:\\n        ev[\"_humilis\"][\"annotation\"] = _humilis.get(\"annotation\", [])\\n        # Clean up previous annotations with the same key\\n        delete_annotations(ev, key)\\n        ev[\"_humilis\"][\"annotation\"].append(ann)\\n\\n    return ev',\n",
       " 'def get_annotations(event, key, namespace=None, matchfunc=None):\\n    \"\"\"Produce the list of annotations for a given key.\"\"\"\\n    if matchfunc is None:\\n        matchfunc = _is_equal\\n    if isinstance(key, Exception):\\n        key = _error_repr(key)\\n    return [ann for ann in event.get(\"_humilis\", {}).get(\"annotation\", [])\\n            if (matchfunc(key, ann[\"key\"]) and\\n                (namespace is None or ann.get(\"namespace\") == namespace))]',\n",
       " 'def delete_annotations(event, key, namespace=None, matchfunc=None):\\n    \"\"\"Delete all event annotations with a matching key.\"\"\"\\n    if matchfunc is None:\\n        matchfunc = _is_equal\\n    if isinstance(key, Exception):\\n        key = _error_repr(key)\\n    newanns = [ann for ann in event.get(\"_humilis\", {}).get(\"annotation\", [])\\n               if not (matchfunc(key, ann[\"key\"]) and\\n                   (namespace is None or ann.get(\"namespace\") == namespace))]\\n    replace_event_annotations(event, newanns)',\n",
       " 'def get_function_annotations(event, funcname, type=None, namespace=None):\\n    \"\"\"Produce a list of function annotations in in this event.\"\"\"\\n    if type:\\n        postfix = \"|\" + type\\n    else:\\n        postfix = \"|.+\"\\n\\n    def matchfunc(key, annkey):\\n        \"\"\"Check if the provider regex matches an annotation key.\"\"\"\\n        return re.match(key, annkey) is not None\\n\\n    return get_annotations(event, funcname + postfix, namespace=namespace,\\n                           matchfunc=matchfunc)',\n",
       " 'def add_task(self, keywords, context, rule):\\n        \"\"\"Map a function to a list of keywords\\n\\n        Parameters\\n        ----------\\n        keywords : iterable of str\\n            sequence of strings which should trigger the given function\\n        context : Context\\n            A Context object created using desired function\\n        rule : tuple\\n            A tuple of integers, which act as relative indices using which data\\n            is extracted to be passed to the function passed via context.\\n        \"\"\"\\n        for keyword in keywords:\\n            self._tasks[keyword] = {\\'context\\': context, \\'rule\\': rule}',\n",
       " 'def add_modifier(self, modifier, keywords, relative_pos,\\n                     action, parameter=None):\\n        \"\"\"Modify existing tasks based on presence of a keyword.\\n\\n        Parameters\\n        ----------\\n        modifier : str\\n            A string value which would trigger the given Modifier.\\n        keywords : iterable of str\\n            sequence of strings which are keywords for some task,\\n            which has to be modified.\\n        relative_pos : int\\n            Relative position of the task which should be modified\\n            in the presence of `modifier`. It\\'s value can never be 0. Data\\n            fields should also be considered when calculating the relative\\n            position.\\n        action : str\\n            String value representing the action which should be performed\\n            on the task. Action represents calling a arbitrary function\\n            to perform th emodification.\\n        parameter : object\\n            value required by the `action`.(Default None)\\n        \"\"\"\\n        if relative_pos == 0:\\n            raise ValueError(\"relative_pos cannot be 0\")\\n        modifier_dict = self._modifiers.get(modifier, {})\\n        value = (action, parameter, relative_pos)\\n        for keyword in keywords:\\n            action_list = list(modifier_dict.get(keyword, []))\\n            action_list.append(value)\\n            modifier_dict[keyword] = tuple(action_list)\\n        self._modifiers[modifier] = modifier_dict',\n",
       " 'def parse(self, text):\\n        \"\"\"Parse the string `text` and return a tuple of left over Data fields.\\n\\n        Parameters\\n        ----------\\n        text : str\\n            A string to be parsed\\n\\n        Returns\\n        -------\\n        result : tuple\\n            A tuple of left over Data after processing\\n        \"\"\"\\n        self._parsed_list = []\\n        self._most_recent_report = []\\n        self._token_list = text.lower().split()\\n        modifier_index_list = []\\n        for item in self._token_list:\\n            \\n            if(self._is_token_data_callback(item)):\\n                self._parsed_list.append(self._clean_data_callback(item))\\n                \\n            if item in self._tasks:\\n                d = {}\\n                d[\\'context\\'] = self._tasks[item][\\'context\\']\\n                d[\\'rule\\'] = self._tasks[item][\\'rule\\']\\n                d[\\'task\\'] = item\\n                self._parsed_list.append(d)\\n\\n            if item in self._modifiers:\\n                modifier_index_list.append((len(self._parsed_list), item))\\n\\n        self._apply_modifiers(modifier_index_list)\\n        return self._evaluate()',\n",
       " 'def connectionLost(self, reason):\\n        \"\"\"\\n        Called when the response body has been completely delivered.\\n        @param reason: Either a twisted.web.client.ResponseDone exception or\\n        a twisted.web.http.PotentialDataLoss exception.\\n        \"\"\"\\n        self.remaining.reset()\\n\\n        try:\\n            result = json.load(self.remaining)\\n        except Exception, e:\\n            self.finished.errback(e)\\n            return\\n\\n        returnValue = result\\n        if self.heartbeater:\\n            self.heartbeater.nextToken = result[\\'token\\']\\n            returnValue = (result, self.heartbeater)\\n\\n        self.finished.callback(returnValue)',\n",
       " 'def request(self,\\n                method,\\n                path,\\n                options=None,\\n                payload=None,\\n                heartbeater=None,\\n                retry_count=0):\\n        \"\"\"\\n        Make a request to the Service Registry API.\\n        @param method: HTTP method (\\'POST\\', \\'GET\\', etc.).\\n        @type method: C{str}\\n        @param path: Path to be appended to base URL (\\'/sessions\\', etc.).\\n        @type path: C{str}\\n        @param options: Options to be encoded as query parameters in the URL.\\n        @type options: C{dict}\\n        @param payload: Optional body\\n        @type payload: C{dict}\\n        @param heartbeater: Optional heartbeater passed in when\\n        creating a session.\\n        @type heartbeater: L{HeartBeater}\\n        \"\"\"\\n        def _request(authHeaders, options, payload, heartbeater, retry_count):\\n            tenantId = authHeaders[\\'X-Tenant-Id\\']\\n            requestUrl = self.baseUrl + tenantId + path\\n            if options:\\n                requestUrl += \\'?\\' + urlencode(options)\\n            payload = StringProducer(json.dumps(payload)) if payload else None\\n\\n            d = self.agent.request(method=method,\\n                                   uri=requestUrl,\\n                                   headers=None,\\n                                   bodyProducer=payload)\\n            d.addCallback(self.cbRequest,\\n                          method,\\n                          path,\\n                          options,\\n                          payload,\\n                          heartbeater,\\n                          retry_count)\\n\\n            return d\\n\\n        d = self.agent.getAuthHeaders()\\n        d.addCallback(_request, options, payload, heartbeater, retry_count)\\n\\n        return d',\n",
       " 'def _initialized(self, partitioner):\\n        \"\"\"Store the partitioner and reset the internal state.\\n\\n        Now that we successfully got an actual\\n        :class:`kazoo.recipe.partitioner.SetPartitioner` object, we\\n        store it and reset our internal ``_state`` to ``None``,\\n        causing the ``state`` property to defer to the partitioner\\'s\\n        state.\\n\\n        \"\"\"\\n        self._partitioner = partitioner\\n        self._thimble = Thimble(self.reactor, self.pool,\\n                                partitioner, _blocking_partitioner_methods)\\n        self._state = None',\n",
       " 'def inject_arca(self, arca):\\n        \"\"\" Apart from the usual validation stuff it also creates log file for this instance.\\n        \"\"\"\\n        super().inject_arca(arca)\\n\\n        import vagrant\\n\\n        self.log_path = Path(self._arca.base_dir) / \"logs\" / (str(uuid4()) + \".log\")\\n        self.log_path.parent.mkdir(exist_ok=True, parents=True)\\n        logger.info(\"Storing vagrant log in %s\", self.log_path)\\n\\n        self.log_cm = vagrant.make_file_cm(self.log_path)',\n",
       " 'def init_vagrant(self, vagrant_file):\\n        \"\"\" Creates a Vagrantfile in the target dir, with only the base image pulled.\\n            Copies the runner script to the directory so it\\'s accessible from the VM.\\n        \"\"\"\\n        if self.inherit_image:\\n            image_name, image_tag = str(self.inherit_image).split(\":\")\\n        else:\\n            image_name = self.get_arca_base_name()\\n            image_tag = self.get_python_base_tag(self.get_python_version())\\n\\n        logger.info(\"Creating Vagrantfile located in %s, base image %s:%s\", vagrant_file, image_name, image_tag)\\n\\n        repos_dir = (Path(self._arca.base_dir) / \\'repos\\').resolve()\\n        vagrant_file.parent.mkdir(exist_ok=True, parents=True)\\n        vagrant_file.write_text(dedent(f\"\"\"\\n        # -*- mode: ruby -*-\\n        # vi: set ft=ruby :\\n\\n        Vagrant.configure(\"2\") do |config|\\n          config.vm.box = \"{self.box}\"\\n          config.ssh.insert_key = true\\n          config.vm.provision \"docker\" do |d|\\n            d.pull_images \"{image_name}:{image_tag}\"\\n          end\\n\\n          config.vm.synced_folder \".\", \"/vagrant\"\\n          config.vm.synced_folder \"{repos_dir}\", \"/srv/repos\"\\n          config.vm.provider \"{self.provider}\"\\n\\n        end\\n        \"\"\"))\\n\\n        (vagrant_file.parent / \"runner.py\").write_text(self.RUNNER.read_text())',\n",
       " 'def fabric_task(self):\\n        \"\"\" Returns a fabric task which executes the script in the Vagrant VM\\n        \"\"\"\\n        from fabric import api\\n\\n        @api.task\\n        def run_script(container_name, definition_filename, image_name, image_tag, repository, timeout):\\n            \"\"\" Sequence to run inside the VM.\\n                Starts up the container if the container is not running\\n                (and copies over the data and the runner script)\\n                Then the definition is copied over and the script launched.\\n                If the VM is gonna be shut down then kills the container as well.\\n            \"\"\"\\n            workdir = str((Path(\"/srv/data\") / self.cwd).resolve())\\n            cmd = \"sh\" if self.inherit_image else \"bash\"\\n\\n            api.run(f\"docker pull {image_name}:{image_tag}\")\\n\\n            container_running = int(api.run(f\"docker ps --format \\'{{.Names}}\\' -f name={container_name} | wc -l\"))\\n            container_stopped = int(api.run(f\"docker ps -a --format \\'{{.Names}}\\' -f name={container_name} | wc -l\"))\\n\\n            if container_running == 0:\\n                if container_stopped:\\n                    api.run(f\"docker rm -f {container_name}\")\\n\\n                api.run(f\"docker run \"\\n                        f\"--name {container_name} \"\\n                        f\"--workdir \\\\\"{workdir}\\\\\" \"\\n                        f\"-dt {image_name}:{image_tag} \"\\n                        f\"{cmd} -i\")\\n\\n                api.run(f\"docker exec {container_name} mkdir -p /srv/scripts\")\\n                api.run(f\"docker cp /srv/repos/{repository} {container_name}:/srv/branch\")\\n                api.run(f\"docker exec --user root {container_name} bash -c \\'mv /srv/branch/* /srv/data\\'\")\\n                api.run(f\"docker exec --user root {container_name} rm -rf /srv/branch\")\\n                api.run(f\"docker cp /vagrant/runner.py {container_name}:/srv/scripts/\")\\n\\n            api.run(f\"docker cp /vagrant/{definition_filename} {container_name}:/srv/scripts/\")\\n\\n            output = api.run(\\n                \" \".join([\\n                    \"docker\", \"exec\", container_name,\\n                    \"python\", \"/srv/scripts/runner.py\", f\"/srv/scripts/{definition_filename}\",\\n                ]),\\n                timeout=math.ceil(timeout)\\n            )\\n\\n            if not self.keep_container_running:\\n                api.run(f\"docker kill {container_name}\")\\n\\n            return output\\n\\n        return run_script',\n",
       " 'def ensure_vm_running(self, vm_location):\\n        \"\"\" Gets or creates a Vagrantfile in ``vm_location`` and calls ``vagrant up`` if the VM is not running.\\n        \"\"\"\\n        import vagrant\\n\\n        if self.vagrant is None:\\n            vagrant_file = vm_location / \"Vagrantfile\"\\n            if not vagrant_file.exists():\\n                self.init_vagrant(vagrant_file)\\n\\n            self.vagrant = vagrant.Vagrant(vm_location,\\n                                           quiet_stdout=self.quiet,\\n                                           quiet_stderr=self.quiet,\\n                                           out_cm=self.log_cm,\\n                                           err_cm=self.log_cm)\\n\\n        status = [x for x in self.vagrant.status() if x.name == \"default\"][0]\\n\\n        if status.state != \"running\":\\n            try:\\n                self.vagrant.up()\\n            except subprocess.CalledProcessError:\\n                raise BuildError(\"Vagrant VM couldn\\'t up launched. See output for details.\")',\n",
       " 'def run(self, repo: str, branch: str, task: Task, git_repo: Repo, repo_path: Path):\\n        \"\"\" Starts up a VM, builds an docker image and gets it to the VM, runs the script over SSH, returns result.\\n            Stops the VM if ``keep_vm_running`` is not set.\\n        \"\"\"\\n        from fabric import api\\n        from fabric.exceptions import CommandTimeout\\n\\n        # start up or get running VM\\n        vm_location = self.get_vm_location()\\n        self.ensure_vm_running(vm_location)\\n        logger.info(\"Running with VM located at %s\", vm_location)\\n\\n        # pushes the image to the registry so it can be pulled in the VM\\n        self.check_docker_access()  # init client\\n        self.get_image_for_repo(repo, branch, git_repo, repo_path)\\n\\n        requirements_option, requirements_hash = self.get_requirements_information(repo_path)\\n\\n        # getting things needed for execution over SSH\\n        image_tag = self.get_image_tag(requirements_option, requirements_hash, self.get_dependencies())\\n        image_name = self.use_registry_name\\n\\n        task_filename, task_json = self.serialized_task(task)\\n        (vm_location / task_filename).write_text(task_json)\\n\\n        container_name = self.get_container_name(repo, branch, git_repo)\\n\\n        # setting up Fabric\\n        api.env.hosts = [self.vagrant.user_hostname_port()]\\n        api.env.key_filename = self.vagrant.keyfile()\\n        api.env.disable_known_hosts = True  # useful for when the vagrant box ip changes.\\n        api.env.abort_exception = BuildError  # raises SystemExit otherwise\\n        api.env.shell = \"/bin/sh -l -c\"\\n        if self.quiet:\\n            api.output.everything = False\\n        else:\\n            api.output.everything = True\\n\\n        # executes the task\\n        try:\\n            res = api.execute(self.fabric_task,\\n                              container_name=container_name,\\n                              definition_filename=task_filename,\\n                              image_name=image_name,\\n                              image_tag=image_tag,\\n                              repository=str(repo_path.relative_to(Path(self._arca.base_dir).resolve() / \\'repos\\')),\\n                              timeout=task.timeout)\\n\\n            return Result(res[self.vagrant.user_hostname_port()].stdout)\\n        except CommandTimeout:\\n            raise BuildTimeoutError(f\"The task timeouted after {task.timeout} seconds.\")\\n        except BuildError:  # can be raised by  :meth:`Result.__init__`\\n            raise\\n        except Exception as e:\\n            logger.exception(e)\\n            raise BuildError(\"The build failed\", extra_info={\\n                \"exception\": e\\n            })\\n        finally:\\n            # stops or destroys the VM if it should not be kept running\\n            if not self.keep_vm_running:\\n                if self.destroy:\\n                    self.vagrant.destroy()\\n                    shutil.rmtree(self.vagrant.root, ignore_errors=True)\\n                    self.vagrant = None\\n                else:\\n                    self.vagrant.halt()',\n",
       " 'def stop_vm(self):\\n        \"\"\" Stops or destroys the VM used to launch tasks.\\n        \"\"\"\\n        if self.vagrant is not None:\\n            if self.destroy:\\n                self.vagrant.destroy()\\n                shutil.rmtree(self.vagrant.root, ignore_errors=True)\\n                self.vagrant = None\\n            else:\\n                self.vagrant.halt()',\n",
       " 'def url_content(url, cache_duration=None, from_cache_on_error=False):\\n    \"\"\"\\n      Get content for the given URL\\n\\n      :param str url: The URL to get content from\\n      :param int cache_duration: Optionally cache the content for the given duration to avoid downloading too often.\\n      :param bool from_cache_on_error: Return cached content on any HTTP request error if available.\\n    \"\"\"\\n    cache_file = _url_content_cache_file(url)\\n\\n    if cache_duration:\\n        if os.path.exists(cache_file):\\n            stat = os.stat(cache_file)\\n            cached_time = stat.st_mtime\\n            if time.time() - cached_time < cache_duration:\\n                with open(cache_file) as fp:\\n                    return fp.read()\\n\\n    try:\\n        response = requests.get(url, timeout=5)\\n        response.raise_for_status()\\n        content = response.text\\n\\n    except Exception as e:\\n        if from_cache_on_error and os.path.exists(cache_file):\\n            with open(cache_file) as fp:\\n                return fp.read()\\n        else:\\n            raise e.__class__(\"An error occurred when getting content for %s: %s\" % (url, e))\\n\\n    if cache_duration or from_cache_on_error:\\n        with open(cache_file, \\'w\\') as fp:\\n            fp.write(content)\\n\\n    return content',\n",
       " 'def route(**kwargs):\\n    \"\"\"\\n    Route a request to different views based on http verb.\\n\\n    Kwargs should be \\'GET\\', \\'POST\\', \\'PUT\\', \\'DELETE\\' or \\'ELSE\\',\\n    where the first four map to a view to route to for that type of\\n    request method/verb, and \\'ELSE\\' maps to a view to pass the request\\n    to if the given request method/verb was not specified.\\n    \"\"\"\\n    def routed(request, *args2, **kwargs2):\\n        method = request.method\\n        if method in kwargs:\\n            req_method = kwargs[method]\\n            return req_method(request, *args2, **kwargs2)\\n        elif \\'ELSE\\' in kwargs:\\n            return kwargs[\\'ELSE\\'](request, *args2, **kwargs2)\\n        else:\\n            raise Http404()\\n    return routed',\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SP2fCGi5quHg"
   },
   "source": [
    "Now that we have defined the function, let's call `.map()` on the HuggingFace Dataset object, which allows us to apply this function in batches (by default a batch size of 1,000 is used!) - hence super fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "9e4fb031ef254cdaac1e72377c015b09",
      "8a1c3f28469443e3aa0712b46f2a56f0",
      "4f7b7b249a0745f4be504aa6245d2f56",
      "69c8216e5dc64a10a7914936330bbd58",
      "a4c0a060006d4cc8aa34cb7740b4dbe7",
      "b46cc34480544768b88b22a775057cd3",
      "f64026e18bf6466096dc695c03111bc9",
      "f57bd76e77f84c8d9042cbce2e021221",
      "3f1d4f582efb432ba82a64ffd0a4dcf4",
      "9aa58eaebd6a493b86d29bd4c9879466",
      "48f0c88a67c7482fb885d04c0e5ac42d",
      "49f079c95eda4910948a3443ffdb87f4",
      "aa8cd1e4e53f4101b560b704be0b2158",
      "4729dcf5e9f14c8db22091829b85d72f",
      "6592366a32214e9494e2a08b99d80383",
      "c14afdc7abba41dfa2ccca801a5348e9",
      "c8032291f4d0431f9f8f9b72bebbbc0d",
      "24ca8dd9c383439ebe9032976ac34d4b",
      "4e5df10419ff4f968510945362fb5504",
      "043183f7aa364ea0b69847fb57c66723",
      "831ee902890b45c796ff669e9e8ee569",
      "e6bb1e6024ae40829da192c08c81d17e",
      "c6628f411c4d4a5cacd4ebb2dd6df146",
      "14b4ba6691c9492c9b6bca099f6021f7",
      "f555aa2401a74799abb3b1c7aa30d580",
      "0317c766423c431cbb648de18fec733e",
      "5049389da0954c1d822a02aae092d065",
      "22d5f11f33d14ba6a451419ff6b47865",
      "8cf6ca6607d54f3fad0c3839c8fae9bb",
      "9df52972b0c2498582285204d9fce746",
      "12a0cba83a0f44298eb0f7b9ec8dfbb9",
      "75d9fc5b37d34ab5ae80a703fa933809",
      "cb36532a8a684324b09f9462b5d701f2"
     ]
    },
    "id": "S2lYwT-ZWMk0",
    "outputId": "3993a513-58b4-4434-fbed-08f033a2992c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/shmuelaberman/.cache/huggingface/datasets/code_x_glue_ct_code_to_text/python/0.0.0/f8b7e9d51f609a87e7ec7c7431706d4ee0b402e3398560410313d4acc67060a0/cache-280c642655d3ec06.arrow\n",
      "Loading cached processed dataset at /home/shmuelaberman/.cache/huggingface/datasets/code_x_glue_ct_code_to_text/python/0.0.0/f8b7e9d51f609a87e7ec7c7431706d4ee0b402e3398560410313d4acc67060a0/cache-a2211e8276ebefeb.arrow\n",
      "Loading cached processed dataset at /home/shmuelaberman/.cache/huggingface/datasets/code_x_glue_ct_code_to_text/python/0.0.0/f8b7e9d51f609a87e7ec7c7431706d4ee0b402e3398560410313d4acc67060a0/cache-f5a93f2bee0f12fb.arrow\n"
     ]
    }
   ],
   "source": [
    "#tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "dataset = dataset.map(preprocess_examples, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nevKo-Sob21L",
    "outputId": "21c559aa-256b-416d-f173-ffd3ea9d9696"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 251820\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 13914\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14918\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mSM2_eDalx-"
   },
   "source": [
    "Next, let's set the format to \"torch\" and create PyTorch dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gq2-xLG_alXH"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask', 'labels'])\n",
    "train_dataloader = DataLoader(dataset['train'], shuffle=True, batch_size=7)\n",
    "valid_dataloader = DataLoader(dataset['validation'], batch_size=3)\n",
    "test_dataloader = DataLoader(dataset['test'], batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6y0l7v8obmml",
    "outputId": "19f19119-ac23-4213-fa21-ccd398dca61f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "print(batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YH4MIhxFc2BR"
   },
   "source": [
    "Let's verify an example, by decoding it back into text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "jsqjA1OHcn5V",
    "outputId": "f869a827-4b24-46d5-ccd8-1c7978225933"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Turn to Python: Returns a list of values stored under the property name corresponding\\n        to a list of units\\n\\n        Parameters\\n        ----------\\n        unit_ids: list\\n            The unit ids for which the property will be returned\\n            Defaults to get_unit_ids()\\n        property_name: str\\n            The name of the property\\n        Returns\\n        ----------\\n        values\\n            The list of values</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "sYQWyCDzcqzh",
    "outputId": "5b98b1b8-edb3-4269-fa1e-6770999f5921"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>def get_units_property(self, *, unit_ids=None, property_name):\\n        '''Returns a list of values stored under the property name corresponding\\n        to a list of units\\n\\n        Parameters\\n        ----------\\n        unit_ids: list\\n            The unit ids for which the property will be returned\\n            Defaults to get_unit_ids()\\n        property_name: str\\n            The name of the property\\n        Returns\\n        ----------\\n        values\\n            The list of values\\n        '''\\n        if unit_ids is None:\\n            unit_ids = self.get_unit_ids()\\n        values = [self.get_unit_property(unit_id=unit, property_name=property_name) for unit in unit_ids]\\n        return values</s>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = batch['labels'][0]\n",
    "tokenizer.decode([label for label in labels if label != -100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOxapqxzS0PO"
   },
   "source": [
    "## Fine-tune using PyTorch Lightning\n",
    "\n",
    "As we will train the model using PyTorch Lightning, we first need to define a `LightningModule`, which is an `nn.Module` with some additional functionalities. We just need to define the `forward` pass, `training_step` (and optionally `validation_step` and `test_step`), and the corresponding dataloaders. PyTorch Lightning will then automate the training for us, handling device placement (i.e. we don't need to type `.to(device)` anywhere), etc. It also comes with support for loggers (such as Tensorboard, Weights and Biases) and callbacks.\n",
    "\n",
    "Of course, you could also train the model in other ways:\n",
    "* using regular PyTorch\n",
    "* using the HuggingFace Trainer (in this case, the Seq2SeqTrainer)\n",
    "* using HuggingFace Accelerate\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "RuHlP1MuR_tJ"
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class CodeT5(pl.LightningModule):\n",
    "    def __init__(self, lr=5e-5, num_train_epochs=12, warmup_steps=1000):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):     \n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return outputs\n",
    "    \n",
    "    def common_step(self, batch, batch_idx):\n",
    "        outputs = self(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        return loss\n",
    "      \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.common_step(batch, batch_idx)     \n",
    "        # logs metrics for each training_step,\n",
    "        # and the average across the epoch\n",
    "        self.log(\"training_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.common_step(batch, batch_idx)     \n",
    "        self.log(\"validation_loss\", loss, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.common_step(batch, batch_idx)     \n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # create optimizer\n",
    "        optimizer = AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        # create learning rate scheduler\n",
    "        num_train_optimization_steps = self.hparams.num_train_epochs * len(train_dataloader)\n",
    "        lr_scheduler = {'scheduler': get_linear_schedule_with_warmup(optimizer,\n",
    "                                                    num_warmup_steps=self.hparams.warmup_steps,\n",
    "                                                    num_training_steps=num_train_optimization_steps),\n",
    "                        'name': 'learning_rate',\n",
    "                        'interval':'step',\n",
    "                        'frequency': 1}\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return valid_dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return test_dataloader\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuYF6-tYZuuN"
   },
   "source": [
    "Let's start up Weights and Biases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "HKDavW52ZuKv",
    "outputId": "631ad4c6-d320-43e9-f15c-e6aaa8b643f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshmublu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAxLx7_Td1G-"
   },
   "source": [
    "Next, we initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e1b093c9236649ab857c5b8eaad7016c",
      "3528a8a5a06246d590e8cd3f86b69add",
      "d112dc5b89be4ba8b749382d0ac98769",
      "704a7e4f5aca452ea7937875d5cdf0a8",
      "481ad2424d364b08b7f775dd3e8368d3",
      "531e7a37f13e4d62bb2bffd610ac2269",
      "41e92a0ab5ca4858a9bb08ab040c6145",
      "521c193c3bad47798a730ef321ec642e",
      "9826c15cac2f4077a398b11ff1225a28",
      "754e50605cb34e908c25a9b3d62e79a6",
      "27fc117f3c8c41099f0a167d6b944209",
      "8a59de4dc2164356ad07e9a4143e291f",
      "dcd0ac2e33d54aed835dff8490418ed0",
      "699c5ee0b125444090626ed1cd0c27b2",
      "540241e3de5746a297ee30315029c88a",
      "6f57502431d34979acc781ab11cfb7b1",
      "b738914e73c54766b549bde562db8020",
      "815b7b62c2da446f87c07bdb440a399d",
      "665f37a818da4e898ca0bd9a26ec0edf",
      "740c8ad0927e410191c7d087b61834bb",
      "1e78db819c04445cbb10d0a662c8ea5b",
      "1e46fd23daee406e96efd41f12952fe2"
     ]
    },
    "id": "ZtDmLYzEc9uP",
    "outputId": "339714e5-47c0-44c3-dba6-33bd726c569d"
   },
   "outputs": [],
   "source": [
    "model = CodeT5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#print(torch.cuda.is_available())\n",
    "#import gc\n",
    "#torch.cuda.empty_cache()\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPzgguodd2uS"
   },
   "source": [
    "We can now simply start training on Colab's GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502,
     "referenced_widgets": [
      "3c85b1e7f9744ae68f11ca67fc87c2d6",
      "d82f293aad02476499f6e1be29b848c6",
      "fccbe0b2d4cd431f91045430231f5b8d",
      "e89754d130754deb8a68f442ef00a038",
      "eeef782870bf4e1f8b973a0a746f7f94",
      "152236bb88c542d9859a6007ebb0a51f",
      "8206cb7266f84748ad3657fdb7f7886a",
      "d819f074fe4149b0ae516b4e9a38c3f3",
      "43fca214d7314eeb8600a5538005dece",
      "c876129819ee4d548e24d4b90f5e3b94",
      "35a1c25826274e81920afab89112619b",
      "510a1e9f532243e4b3e549d457d729e9",
      "066af1eb8857457bbb436c78ce584226",
      "06d0c551d723481fbf6591017171e267",
      "dc8da87b183549ba8806acaa8dad8633",
      "953444fee5064b60815cc5796e5c3eea",
      "b383ff48553a41ac89449b8f95244465",
      "2c98a5d85a9d436b849b66acba3ef5e6",
      "67f97175262f4436b03f1d77d201d4d0",
      "d4ab5427cac540c9a095b10bded11580",
      "ec09337a81944d339c9775c24437b76b",
      "5c6cae084087447eb1c53f0c33664c4b",
      "38f00d69cc404944945bfb420d30d051",
      "8a596e4d8ab74fc0b22ab6948fe82f85",
      "b83de46da11041afbc716bf8c2f4d82e",
      "cf6fd3a3e2cf4743919bad78bb6a1b96",
      "8b14722c59254e969de3f4784e696f69",
      "1a2f7dc4b47b49d6831cb063a16ebc8f",
      "1698a51bb25b4d12913fef003c3ef891",
      "38b8a6fa3762440494c7d3132e0451ae",
      "cefc5e6d778b4cb59c65c2c7ebccf8ca",
      "594991d99fee4d43bb27588a6ff8dd74",
      "858a05b337f04f92b3e194acb42d7eb7",
      "946acae857ab4e95a515dc9725c49171",
      "39238f7ae76c4917b770bba3cab35a89",
      "ed2408f1d1634f899625d1c572c4a6d2",
      "97c8b42621814e599c9b257f17a84379",
      "18097022050d4d78bce836970944747e",
      "efafe2ea1fec42a19bb44b26f6754c7e",
      "bd3a9997ba0449efaf7a31b02fef2a5e",
      "3413366e1dae412587517a526c4271fc",
      "9f497e7ac05844d8aace0dbf592bb8f4",
      "82df1eda83e8415cb3baacb73aeeb1a2",
      "e6c12a326f114b32abe72977dbae8135",
      "4a8218f8715946bb9fda1044a733e89c",
      "7bce47c861cd494d9a2c259597433352",
      "e11e3f16c62340f7adcdc80b2c84e8dc",
      "ba40b6de0ed94bbc887fe3d166c5cdc1",
      "f54cf361a2ab4286aed0d3739cf64224",
      "77d1e86ba1a44b9580c45a84e96b683c",
      "644395b0377a484cb3c3f273aac99769",
      "17e2e94bd572457188acc40b12337192",
      "0b53799e3e23493095a9397740a8b24a",
      "c321cea225764ee5a5c281f791dfc4b8",
      "4391404820c9418a91a42145463a77fd",
      "181208ae951f4c83bc9d12e9b61c2797",
      "3ebb64f43f554b9682e99c8a73153af6",
      "83f234641d1f458ba5ab6496ef9a324f",
      "6283b40a0b524155a0a1b69e032e21a4",
      "e763025cfded4ac4bdd4b3ff04a6a6c9",
      "ca86160348c3423fa4de0ab13d59679e",
      "4f16537778d84f46b4b71a8162fb893a",
      "49a861c313ec4442afd905947835bccb",
      "79559b9a9e2c40968d044dcb3d6c8d65",
      "58f6a90b68c6434883f40572c50af764",
      "efd3e63284d24519995b3543df8806ae",
      "f829335369404977ae3d4fd0907bba30",
      "908e26976d494bcc92fe220277e8a89b",
      "b02d46075fc24abd99182a0908cc0f12",
      "64408f82a6234466b2633ca5413e2ef2",
      "ccd0dc9a9bdd407094781c1e7e34f08c",
      "5387b07673fb40c88657f9dae4bdaa20",
      "fa646d15915846c6b6e02c6e0623cf1e",
      "4cebdb78303c4f819ecc5a9af7e238d0",
      "c39e4ff0515c4fa88f6902d57af8bd19",
      "0772c5df3eb446259634a645bceb0227",
      "12a6e915e97b47ceab3eb8f287a41080",
      "e254ffce245d413d87700847d3c6e7cc",
      "fe809085051144e0b4c9fa1e15410967",
      "ed5ba330061e4f5c99f833511a0bc791",
      "2d05f6075ab84c5895d583121a0b4bf0",
      "0a064be23e3a4cf2b3d8e325a7875fff",
      "459531a008724820af2272f5a963a804",
      "0522164eafb24ba1b6241b54809159eb",
      "8c950947a2704b4b8184b587807de80c",
      "18864ad7ebe64bf8b439072a2fb0c9bf",
      "031554342fe145cf9c2c30d1e1439758",
      "386bf18bde104fa89faf425adefeeef8",
      "aa0f3ba3281b42a795fcf7cb40fcedc5",
      "5b3ba494dbdf4ef283f8fec59eb757bf",
      "7588263041e94db5a76f3d639fa3f83d",
      "0cdc6c0c4653446387ea36dca5e2d56c",
      "359908f6803b4c15b359dc5b6e2f27d1",
      "8b5998d5e4424dd8962ea3cbc4dcfd64",
      "df800cd117b946c88137a1c46c427216",
      "d0f4f94047774e1aa4ea2200fe732b6b",
      "ad7e17e4626b4c6c9b0dd47deb19dcdd",
      "a3916440cfba4999b3a1874f6d59de94",
      "09ce1ccdf1704d739e888a87717a920f",
      "38568309247a48ab9315dfdd1fcafd4b"
     ]
    },
    "id": "WroP64V8dWuO",
    "outputId": "5ef87e53-16df-4ed7-cf4b-f2b400aea7ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230212_152658-1nefvt7b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/shmublu/CodeT5/runs/1nefvt7b\" target=\"_blank\">codet5-finetune-code-summarization-python-shuffle</a></strong> to <a href=\"https://wandb.ai/shmublu/CodeT5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/shmuelaberman/.local/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3\n",
      "/home/shmuelaberman/.local/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3\n",
      "/home/shmuelaberman/.local/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 3 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/shmuelaberman/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/shmuelaberman/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/shmuelaberman/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "241.969   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shmuelaberman/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:217: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True\n",
      "  rank_zero_warn(\n",
      "/home/shmuelaberman/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:537: PossibleUserWarning: It is recommended to use `self.log('validation_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfa50a611ac4aa0b72623f0bd135977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "\n",
    "\n",
    "wandb_logger = WandbLogger(name='codet5-finetune-code-summarization-python-shuffle', project='CodeT5')\n",
    "# for early stopping, see https://pytorch-lightning.readthedocs.io/en/1.0.0/early_stopping.html?highlight=early%20stopping\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='validation_loss',\n",
    "    patience=3,\n",
    "    strict=False,\n",
    "    verbose=False,\n",
    "    mode='min'\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "trainer = Trainer(accelerator='gpu', devices=3,\n",
    "                  default_root_dir=\"/content/drive/MyDrive/CodeT5/Notebooks/Checkpoints\", \n",
    "                  logger=wandb_logger, \n",
    "                  callbacks=[early_stop_callback, lr_monitor])\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMxAo19KIo9j"
   },
   "source": [
    "Once we're done training, we can also save the HuggingFace model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhfLMOAmhIG6"
   },
   "outputs": [],
   "source": [
    "save_directory =\"saved_model_test_2_10\" # save in the current working directory, you can change this of course\n",
    "model.model.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr0O3iN5IsdW"
   },
   "source": [
    "This allows us to easily load the trained model again using the `from_pretrained()` method, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzhasngvAwX3"
   },
   "source": [
    "## Inference\n",
    "\n",
    "Now that we've trained a model, let's test it on some examples from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPXM9tH8AyCN",
    "outputId": "b2bd427d-dfcd-405c-b22c-cfa6abe54421"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"code_x_glue_ct_code_to_text\", \"ruby\")\n",
    "print(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spbNHeE5ETpG",
    "outputId": "8fce8a4b-95e5-474d-a73b-2d9b71c9e1cc"
   },
   "outputs": [],
   "source": [
    "test_example = dataset['test'][2]\n",
    "print(\"Code:\", test_example['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XwCaigDI622"
   },
   "source": [
    "We can load our trained model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vu68VMzTEXek"
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2w7JC9CxJJ_F"
   },
   "source": [
    "We can prepare the example using `RobertaTokenizer`, and generate using the `.generate()` method. Note that there are several ways of doing generation (greedy decoding/beam search/top k sampling/etc.), for that I refer to Patrick's blog post which you can find [here](https://huggingface.co/blog/how-to-generate). Here we will just use the default settings (i.e. greedy decoding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NhpiAr6UE7vG",
    "outputId": "833a8244-7324-4113-dada-d4b7103cfbfe"
   },
   "source": [
    "### prepare for the model\n",
    "test_example = dataset['test'][3]\n",
    "input_ids = tokenizer(test_example['docstring'], return_tensors='pt').input_ids\n",
    "# generate\n",
    "outputs = model.generate(input_ids)\n",
    "print(test_example['docstring'])\n",
    "print(\"Generated Code:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_example = dataset['test'][100]\n",
    "input_ids = tokenizer(test_example['docstring'], return_tensors='pt').input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(\"Text Input: \",test_example['docstring'])\n",
    "print(\"Generated Code:\", tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(\"Ground truth:\", test_example['code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjxvMu0rKDzL"
   },
   "source": [
    "Let's compare this to the ground-truth docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLy5iUqHKHmy",
    "outputId": "582be69e-0594-4194-d337-01e530b1223e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nC_9q7BDF_cU"
   },
   "source": [
    "## Upload trained model to the hub\n",
    "\n",
    "Cool! We can also share our model with the world, by uploading it to [hf.co](https://hf.co). For that, we need to install Git-LFS, which is used for using git with large files (note that each model on the hub = a git repository!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_qTWbVoFKUi",
    "outputId": "9924bcad-efcf-49f5-a6e0-1ddcc55c1bfc"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install git-lfs\n",
    "!git config --global user.email \"niels.rogge1@gmail.com\"\n",
    "!git config --global user.name \"Niels Rogge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zKZKbHrJ05q"
   },
   "source": [
    "Next, we can login with the credentials of our HuggingFace account (you can sign up on [hf.co](https://hf.co) if you haven't already!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSVClVYvGBBn",
    "outputId": "af77f7d0-d2a3-4d7e-d196-4ad87883a3d9"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmWFxFncHA8l"
   },
   "outputs": [],
   "source": [
    "repo_url = \"https://huggingface.co/nielsr/codet5-small-code-summarization-ruby\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_9dhtuoHBnr",
    "outputId": "9741c2d3-6daa-4cb3-94ae-011dbbb79bb4"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "repo = Repository(local_dir=\"checkpoint\", # note that this directory must not exist already\n",
    "                  clone_from=repo_url,\n",
    "                  git_user=\"Niels Rogge\",\n",
    "                  git_email=\"niels.rogge1@gmail.com\",\n",
    "                  use_auth_token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3aKp8-JHNom"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/content/checkpoint\")\n",
    "tokenizer.save_pretrained(\"/content/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "b194e01ec8e4445ea89e658ff3a16e31",
      "607e13af157a4e3db72925f0e838ce09",
      "f426b19fbf4d4b688192c43e31710e6a",
      "551ec23b892d4d5dbc36dd58efe2ca01",
      "6ddb79d1d79d4d87b1fecbf92226d39b",
      "a4476b44ef6844e5b096299476e95b4f",
      "bd7eeaa744884b98a64b38af9cd5ff84",
      "e0fe868886b54b0c833d7469aeeb5eb9",
      "a927ba91200f45ff84a20511dc1ca738",
      "a7c75ea8186c4fb8ac274a00ea95a4d3",
      "cc626c2bb0fa4da38f11e0df0d08bf08"
     ]
    },
    "id": "B_LPaTJnHD9j",
    "outputId": "bfee5e95-0aea-4c44-ae1a-46c1f8895ead"
   },
   "outputs": [],
   "source": [
    "# push to hub\n",
    "repo.push_to_hub(commit_message=\"First commit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qo7cID0bHWVN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPSO2S0iKvG+BhJKBbBUC1J",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "13ObTK-U0A-e5EPjA9WnvH64eCpxy4yKr",
   "name": "Fine-tune CodeT5 for generating docstrings from Ruby code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00bd6b1cff9c46ea88fe8461bfc91110": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "015b52729d8a4772aaf5c6d5d119d62c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_20532cf9e1b7440fa08a8e6686f4c241",
       "IPY_MODEL_e074a7aae6bf43a7a8dabc99f19f82e7",
       "IPY_MODEL_84ce228c97aa4316b06e8422e7e04166"
      ],
      "layout": "IPY_MODEL_3f5af751540342eb89b72b404cb79ad5"
     }
    },
    "031554342fe145cf9c2c30d1e1439758": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0317c766423c431cbb648de18fec733e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12a0cba83a0f44298eb0f7b9ec8dfbb9",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9df52972b0c2498582285204d9fce746",
      "value": 2
     }
    },
    "03367643f26c454c87ea782d9818d8f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "043183f7aa364ea0b69847fb57c66723": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04c8521884ad4fb6b3b3b128c8da5a5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0510718c486045d7a63e7da5c62f018f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0522164eafb24ba1b6241b54809159eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0629e0af2b8b4e5d8d50f805c7618164": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "066af1eb8857457bbb436c78ce584226": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "06d0c551d723481fbf6591017171e267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c98a5d85a9d436b849b66acba3ef5e6",
      "placeholder": "",
      "style": "IPY_MODEL_b383ff48553a41ac89449b8f95244465",
      "value": "Epoch 7: 100%"
     }
    },
    "0772c5df3eb446259634a645bceb0227": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09ce1ccdf1704d739e888a87717a920f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a064be23e3a4cf2b3d8e325a7875fff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_031554342fe145cf9c2c30d1e1439758",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18864ad7ebe64bf8b439072a2fb0c9bf",
      "value": 350
     }
    },
    "0a5244bc948045b28ee01962ccb00cc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b53799e3e23493095a9397740a8b24a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0cdc6c0c4653446387ea36dca5e2d56c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0f4f94047774e1aa4ea2200fe732b6b",
      "placeholder": "",
      "style": "IPY_MODEL_df800cd117b946c88137a1c46c427216",
      "value": "Validating: 100%"
     }
    },
    "0d772e77f4f0471e9780c23fac8ebc7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "104908073b2649c0b72062df6c080d1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "112365319bcf40129659db76400faa13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "114b49d94c0241d6bba5282bd61b49a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11bd9e222d1b44a28cd7d6c7fcebd451": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_309b70b9ab83460cb9d62e76fec6ca81",
       "IPY_MODEL_be43828dc6f6435e89e867089aeec5f5",
       "IPY_MODEL_f2c922279a3b4bf89a03eff57fedb5f9"
      ],
      "layout": "IPY_MODEL_edf44a3ba26745eb8f4870e194968337"
     }
    },
    "12a0cba83a0f44298eb0f7b9ec8dfbb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12a6e915e97b47ceab3eb8f287a41080": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "134152d8121b4ff9820cb1356d90e339": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14b4ba6691c9492c9b6bca099f6021f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "152236bb88c542d9859a6007ebb0a51f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1624284d925f4f9992408eae7702dbab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "165843bfa23345318f8c4d87fd02ff5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "167ba739c8c54f6fb0c05841d6a62d6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1698a51bb25b4d12913fef003c3ef891": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "169ef19f604742aeac8f16d21602a657": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "174567f7776943d1aaf9630f3da113cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "178c992bd8c146eba83abf46b18d4714": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd958f6b4c64488ca2310a8fdf7249ae",
      "placeholder": "",
      "style": "IPY_MODEL_d7cd40c2e67b47e999fe3ae10594062f",
      "value": " 573k/573k [00:00&lt;00:00, 1.07MB/s]"
     }
    },
    "17e2e94bd572457188acc40b12337192": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18097022050d4d78bce836970944747e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6c12a326f114b32abe72977dbae8135",
      "placeholder": "",
      "style": "IPY_MODEL_82df1eda83e8415cb3baacb73aeeb1a2",
      "value": " 350/350 [00:27&lt;00:00, 12.65it/s]"
     }
    },
    "181208ae951f4c83bc9d12e9b61c2797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18864ad7ebe64bf8b439072a2fb0c9bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a2f7dc4b47b49d6831cb063a16ebc8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b0608364122417b97844f6045b8c014": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cb9fad43d09488c815f728a9dea82f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c365c5404e6b4231af0e3b88a52ffe9f",
      "max": 1027,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b7ae40af15894202b6eacb89cc05bf73",
      "value": 1027
     }
    },
    "1d5a50dae54845f381dbdf28f5f32654": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e2aa6397f3244ca85f27eac55b592f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e3a8e66e82e4bf09fce7d796c9e21f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa76ce7f2179453abf19231cf8879e8f",
      "max": 2493,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5fc824fd8fb645f5b151a25e60ebf5e6",
      "value": 2493
     }
    },
    "1e46fd23daee406e96efd41f12952fe2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e78db819c04445cbb10d0a662c8ea5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20532cf9e1b7440fa08a8e6686f4c241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67778684d44c4399bc16f52bc01b2eca",
      "placeholder": "",
      "style": "IPY_MODEL_7ecc9f1be8df4bda821dda665f2589a3",
      "value": "Downloading: 100%"
     }
    },
    "209a1bf047ed422093760683eea08f81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6fcbc79d2a584e00a3aa7992d8c78e1a",
       "IPY_MODEL_e7f77d44d5d5456bae98ab2496653ccb",
       "IPY_MODEL_497a4477cd52460bb6e742d6cabcdf89"
      ],
      "layout": "IPY_MODEL_165843bfa23345318f8c4d87fd02ff5a"
     }
    },
    "22d5f11f33d14ba6a451419ff6b47865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2340d60c25564efd945c5d47efd0bf45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24ca8dd9c383439ebe9032976ac34d4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24edde3d62b342a3aa7161a42843ef27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "264485d64c984aa7aea7cb26b9288ab1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27fc117f3c8c41099f0a167d6b944209": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c553dd1d368473aa5b1b86208c1fbd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c98a5d85a9d436b849b66acba3ef5e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cdef25032464dfb805a204704621d01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d05f6075ab84c5895d583121a0b4bf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c950947a2704b4b8184b587807de80c",
      "placeholder": "",
      "style": "IPY_MODEL_0522164eafb24ba1b6241b54809159eb",
      "value": "Validating: 100%"
     }
    },
    "2d5733b6a16c4b5e990f8393aaf55e01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "309b70b9ab83460cb9d62e76fec6ca81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2340d60c25564efd945c5d47efd0bf45",
      "placeholder": "",
      "style": "IPY_MODEL_fe554492308547a695c01c1e0ba2c359",
      "value": "Downloading: 100%"
     }
    },
    "339a03c1fb3f4b12aa0b5391d6aad42e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3413366e1dae412587517a526c4271fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3528a8a5a06246d590e8cd3f86b69add": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "359908f6803b4c15b359dc5b6e2f27d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3916440cfba4999b3a1874f6d59de94",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad7e17e4626b4c6c9b0dd47deb19dcdd",
      "value": 350
     }
    },
    "35a1c25826274e81920afab89112619b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35f62ba8591541b8b69f7a83ce48c3fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "38568309247a48ab9315dfdd1fcafd4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "386bf18bde104fa89faf425adefeeef8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38b8a6fa3762440494c7d3132e0451ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "38f00d69cc404944945bfb420d30d051": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b83de46da11041afbc716bf8c2f4d82e",
       "IPY_MODEL_cf6fd3a3e2cf4743919bad78bb6a1b96",
       "IPY_MODEL_8b14722c59254e969de3f4784e696f69"
      ],
      "layout": "IPY_MODEL_8a596e4d8ab74fc0b22ab6948fe82f85"
     }
    },
    "39238f7ae76c4917b770bba3cab35a89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "3ac401834f134962832f397ca22d9763": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c39b7a7e7784a6da57477548c5b27d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5dd560dadd4e4bec8fac429844d6be35",
       "IPY_MODEL_e33588e803404ba0a657bf04a2e83a43",
       "IPY_MODEL_961feb497a154f31aabcb94f8a26e527"
      ],
      "layout": "IPY_MODEL_1d5a50dae54845f381dbdf28f5f32654"
     }
    },
    "3c85b1e7f9744ae68f11ca67fc87c2d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fccbe0b2d4cd431f91045430231f5b8d",
       "IPY_MODEL_e89754d130754deb8a68f442ef00a038",
       "IPY_MODEL_eeef782870bf4e1f8b973a0a746f7f94"
      ],
      "layout": "IPY_MODEL_d82f293aad02476499f6e1be29b848c6"
     }
    },
    "3d34ddca08914391a642a5add2d1f5ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3d7c95ffc90c4c919068ce3c9340b567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff1eb62903644eee9e59a2678ad3b09c",
       "IPY_MODEL_5604c46d50a6459692cff6d337aa5ccd",
       "IPY_MODEL_81271cb9c29841f68cc2acd57a59fe1d"
      ],
      "layout": "IPY_MODEL_fdf46b1d75894b7fbf12e6795677e100"
     }
    },
    "3ebb64f43f554b9682e99c8a73153af6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6283b40a0b524155a0a1b69e032e21a4",
       "IPY_MODEL_e763025cfded4ac4bdd4b3ff04a6a6c9",
       "IPY_MODEL_ca86160348c3423fa4de0ab13d59679e"
      ],
      "layout": "IPY_MODEL_83f234641d1f458ba5ab6496ef9a324f"
     }
    },
    "3f1d4f582efb432ba82a64ffd0a4dcf4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f5af751540342eb89b72b404cb79ad5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41e7845b3a5046c2a0a4ae3a2e1c9a27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41e92a0ab5ca4858a9bb08ab040c6145": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42dd49d8d73044e6b39c83a35d2db768": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4391404820c9418a91a42145463a77fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43fca214d7314eeb8600a5538005dece": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4504a16a187241faba81bd5c394c4855": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d2286a99f5d4284aec975f52b96cc2f",
      "max": 475,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_480d096df7bf40b3b391352111620f7e",
      "value": 475
     }
    },
    "459531a008724820af2272f5a963a804": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa0f3ba3281b42a795fcf7cb40fcedc5",
      "placeholder": "",
      "style": "IPY_MODEL_386bf18bde104fa89faf425adefeeef8",
      "value": " 350/350 [00:27&lt;00:00, 12.66it/s]"
     }
    },
    "45f020f4a9064a45bdf2dcf618e8aece": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92d8f3076508447c8a04f8c3e83fe8f5",
       "IPY_MODEL_c971f8e40f104f0da20b4fb9c6e21daf",
       "IPY_MODEL_fb6688c00b964a96bacdac08a1c504a7"
      ],
      "layout": "IPY_MODEL_f0efe00a84ef43d391d70f0be759f17a"
     }
    },
    "4729dcf5e9f14c8db22091829b85d72f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24ca8dd9c383439ebe9032976ac34d4b",
      "placeholder": "",
      "style": "IPY_MODEL_c8032291f4d0431f9f8f9b72bebbbc0d",
      "value": "100%"
     }
    },
    "4733b16cce4641c7b77df670615dd6f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "480d096df7bf40b3b391352111620f7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "481ad2424d364b08b7f775dd3e8368d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27fc117f3c8c41099f0a167d6b944209",
      "placeholder": "",
      "style": "IPY_MODEL_754e50605cb34e908c25a9b3d62e79a6",
      "value": " 1.57k/1.57k [00:00&lt;00:00, 35.3kB/s]"
     }
    },
    "48f0c88a67c7482fb885d04c0e5ac42d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "497a4477cd52460bb6e742d6cabcdf89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8866c606c6b4cdfae4216c49507a756",
      "placeholder": "",
      "style": "IPY_MODEL_1b0608364122417b97844f6045b8c014",
      "value": " 1207/0 [00:00&lt;00:00, 2643.33 examples/s]"
     }
    },
    "49a861c313ec4442afd905947835bccb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49f079c95eda4910948a3443ffdb87f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4729dcf5e9f14c8db22091829b85d72f",
       "IPY_MODEL_6592366a32214e9494e2a08b99d80383",
       "IPY_MODEL_c14afdc7abba41dfa2ccca801a5348e9"
      ],
      "layout": "IPY_MODEL_aa8cd1e4e53f4101b560b704be0b2158"
     }
    },
    "4cafd1f64db942658339f45659d4f294": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cebdb78303c4f819ecc5a9af7e238d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e5df10419ff4f968510945362fb5504": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4f16537778d84f46b4b71a8162fb893a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f3b91f5202b4d9c9ee919b9bd6be698": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f7b7b249a0745f4be504aa6245d2f56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f64026e18bf6466096dc695c03111bc9",
      "placeholder": "",
      "style": "IPY_MODEL_b46cc34480544768b88b22a775057cd3",
      "value": "100%"
     }
    },
    "5049389da0954c1d822a02aae092d065": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb36532a8a684324b09f9462b5d701f2",
      "placeholder": "",
      "style": "IPY_MODEL_75d9fc5b37d34ab5ae80a703fa933809",
      "value": " 2/2 [00:02&lt;00:00,  1.18s/ba]"
     }
    },
    "510a1e9f532243e4b3e549d457d729e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06d0c551d723481fbf6591017171e267",
       "IPY_MODEL_dc8da87b183549ba8806acaa8dad8633",
       "IPY_MODEL_953444fee5064b60815cc5796e5c3eea"
      ],
      "layout": "IPY_MODEL_066af1eb8857457bbb436c78ce584226"
     }
    },
    "521c193c3bad47798a730ef321ec642e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "522858a2ac8040c2b5da36f44c60314a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6df6787275254c21ac4835056a5d738c",
      "placeholder": "",
      "style": "IPY_MODEL_41e7845b3a5046c2a0a4ae3a2e1c9a27",
      "value": "Downloading: 100%"
     }
    },
    "531e7a37f13e4d62bb2bffd610ac2269": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5387b07673fb40c88657f9dae4bdaa20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e254ffce245d413d87700847d3c6e7cc",
      "placeholder": "",
      "style": "IPY_MODEL_12a6e915e97b47ceab3eb8f287a41080",
      "value": " 350/350 [00:27&lt;00:00, 12.65it/s]"
     }
    },
    "53ca0a05eb2845908491c2d438cdf244": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "540241e3de5746a297ee30315029c88a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_740c8ad0927e410191c7d087b61834bb",
      "max": 242026427,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_665f37a818da4e898ca0bd9a26ec0edf",
      "value": 242026427
     }
    },
    "551ec23b892d4d5dbc36dd58efe2ca01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a927ba91200f45ff84a20511dc1ca738",
      "max": 242026427,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0fe868886b54b0c833d7469aeeb5eb9",
      "value": 242026427
     }
    },
    "5604c46d50a6459692cff6d337aa5ccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84806013dde14accad6128645c77a716",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf25b6526d1e46069a1e3aae2df96483",
      "value": 1
     }
    },
    "57962e5a7c0e4c979e9d32e3da4ee4db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "585b0b0cdbc342719793895b2441268d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e2aa6397f3244ca85f27eac55b592f9",
      "max": 1980,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d34ddca08914391a642a5add2d1f5ea",
      "value": 1980
     }
    },
    "58f6a90b68c6434883f40572c50af764": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "594991d99fee4d43bb27588a6ff8dd74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b3ba494dbdf4ef283f8fec59eb757bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0cdc6c0c4653446387ea36dca5e2d56c",
       "IPY_MODEL_359908f6803b4c15b359dc5b6e2f27d1",
       "IPY_MODEL_8b5998d5e4424dd8962ea3cbc4dcfd64"
      ],
      "layout": "IPY_MODEL_7588263041e94db5a76f3d639fa3f83d"
     }
    },
    "5b9d90ae7c574e6c85da1cb768ec2e64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c626facfda3400fa4c3ed8d90539edd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03367643f26c454c87ea782d9818d8f6",
      "max": 294364,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d0707f72859746d7982ee2996f3fe066",
      "value": 294364
     }
    },
    "5c6cae084087447eb1c53f0c33664c4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c9b400909d049ef8094a65442718aa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5dd560dadd4e4bec8fac429844d6be35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db29bda0f7a8454ca2dda2f7d1eed2dc",
      "placeholder": "",
      "style": "IPY_MODEL_78dffb80c2e748438a29ed2e5782bb95",
      "value": "Downloading: "
     }
    },
    "5ddc592112d442deac875ec3ab1308fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_169ef19f604742aeac8f16d21602a657",
      "placeholder": "",
      "style": "IPY_MODEL_d5155565c0a947aa9bc07db10dd93913",
      "value": " 1222/0 [00:00&lt;00:00, 2319.28 examples/s]"
     }
    },
    "5e75bd1fcea94c3c8964c69e3233a972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fc824fd8fb645f5b151a25e60ebf5e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "607e13af157a4e3db72925f0e838ce09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6283b40a0b524155a0a1b69e032e21a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49a861c313ec4442afd905947835bccb",
      "placeholder": "",
      "style": "IPY_MODEL_4f16537778d84f46b4b71a8162fb893a",
      "value": "Validating: 100%"
     }
    },
    "639433daeb204533b75ab55215969f5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64408f82a6234466b2633ca5413e2ef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cebdb78303c4f819ecc5a9af7e238d0",
      "placeholder": "",
      "style": "IPY_MODEL_fa646d15915846c6b6e02c6e0623cf1e",
      "value": "Validating: 100%"
     }
    },
    "644395b0377a484cb3c3f273aac99769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64e286b2803847378d00e6506f8baf23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6592366a32214e9494e2a08b99d80383": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_043183f7aa364ea0b69847fb57c66723",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4e5df10419ff4f968510945362fb5504",
      "value": 2
     }
    },
    "665f37a818da4e898ca0bd9a26ec0edf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6748404b0771495ba1c1cdda30c8465e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_522858a2ac8040c2b5da36f44c60314a",
       "IPY_MODEL_1cb9fad43d09488c815f728a9dea82f6",
       "IPY_MODEL_ede5d2ec080644019bb54ce08fe0b12a"
      ],
      "layout": "IPY_MODEL_4f3b91f5202b4d9c9ee919b9bd6be698"
     }
    },
    "675a054bb37343cf80e579a5ab70ce4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67778684d44c4399bc16f52bc01b2eca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6793eae05ffc4fb5b88ff64b0ea44de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b5ea5a9c3b34b909af041a1ddbad4b7",
       "IPY_MODEL_aa6c19aa8d6241fab71e9460848076bd",
       "IPY_MODEL_5ddc592112d442deac875ec3ab1308fa"
      ],
      "layout": "IPY_MODEL_89fb378844aa41ecac7dc43a6434cf47"
     }
    },
    "67b728fa9bf7427c814d7dfa5b506b0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67f97175262f4436b03f1d77d201d4d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68888ceba9074610ad72ad6e795893e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "699c5ee0b125444090626ed1cd0c27b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_815b7b62c2da446f87c07bdb440a399d",
      "placeholder": "",
      "style": "IPY_MODEL_b738914e73c54766b549bde562db8020",
      "value": "Downloading: 100%"
     }
    },
    "69a71178f16244bb83442e17f9d002b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8fed95bace543e18c1ee05aaa900c0d",
      "placeholder": "",
      "style": "IPY_MODEL_0a5244bc948045b28ee01962ccb00cc7",
      "value": " 3.74k/? [00:00&lt;00:00, 90.5kB/s]"
     }
    },
    "69c8216e5dc64a10a7914936330bbd58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f1d4f582efb432ba82a64ffd0a4dcf4",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f57bd76e77f84c8d9042cbce2e021221",
      "value": 25
     }
    },
    "6b51d213b8d949bf8b98494b7a3e2c5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57962e5a7c0e4c979e9d32e3da4ee4db",
      "placeholder": "",
      "style": "IPY_MODEL_1624284d925f4f9992408eae7702dbab",
      "value": " 12.4M/12.4M [00:00&lt;00:00, 30.9MB/s]"
     }
    },
    "6da9ad9c815d475ca0c08fd82660a9a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0629e0af2b8b4e5d8d50f805c7618164",
      "placeholder": "",
      "style": "IPY_MODEL_5c9b400909d049ef8094a65442718aa6",
      "value": "Downloading: "
     }
    },
    "6ddb79d1d79d4d87b1fecbf92226d39b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc626c2bb0fa4da38f11e0df0d08bf08",
      "placeholder": "",
      "style": "IPY_MODEL_a7c75ea8186c4fb8ac274a00ea95a4d3",
      "value": " 231M/231M [03:33&lt;00:00, 964kB/s]"
     }
    },
    "6df6787275254c21ac4835056a5d738c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ee98ec3a0b84a2f91b9f8b4fd8b9e76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f57502431d34979acc781ab11cfb7b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e46fd23daee406e96efd41f12952fe2",
      "placeholder": "",
      "style": "IPY_MODEL_1e78db819c04445cbb10d0a662c8ea5b",
      "value": " 242M/242M [00:07&lt;00:00, 37.2MB/s]"
     }
    },
    "6f69682f1ee24d918ef449bff4d9e8d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fcbc79d2a584e00a3aa7992d8c78e1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ee98ec3a0b84a2f91b9f8b4fd8b9e76",
      "placeholder": "",
      "style": "IPY_MODEL_f08cbf7762d34984b0dc2b3811ae2ce7",
      "value": ""
     }
    },
    "704a7e4f5aca452ea7937875d5cdf0a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9826c15cac2f4077a398b11ff1225a28",
      "max": 1566,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_521c193c3bad47798a730ef321ec642e",
      "value": 1566
     }
    },
    "740c8ad0927e410191c7d087b61834bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7462caae2b904f1ca916dd2d27780741": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "750fd64de713487ab332036b610ed998": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "754e50605cb34e908c25a9b3d62e79a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7588263041e94db5a76f3d639fa3f83d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "75d9fc5b37d34ab5ae80a703fa933809": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77d1e86ba1a44b9580c45a84e96b683c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_181208ae951f4c83bc9d12e9b61c2797",
      "placeholder": "",
      "style": "IPY_MODEL_4391404820c9418a91a42145463a77fd",
      "value": " 350/350 [00:27&lt;00:00, 12.66it/s]"
     }
    },
    "78dffb80c2e748438a29ed2e5782bb95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7903eecab2444baba3219ff8113a5450": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79559b9a9e2c40968d044dcb3d6c8d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b5ea5a9c3b34b909af041a1ddbad4b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_114b49d94c0241d6bba5282bd61b49a5",
      "placeholder": "",
      "style": "IPY_MODEL_d81a71fdaac94f07836d197a59344ed5",
      "value": ""
     }
    },
    "7bce47c861cd494d9a2c259597433352": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba40b6de0ed94bbc887fe3d166c5cdc1",
       "IPY_MODEL_f54cf361a2ab4286aed0d3739cf64224",
       "IPY_MODEL_77d1e86ba1a44b9580c45a84e96b683c"
      ],
      "layout": "IPY_MODEL_e11e3f16c62340f7adcdc80b2c84e8dc"
     }
    },
    "7c6a2548671140daaf62b3aa504dea0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c7a481a577a43728afb69c569c23be7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d2286a99f5d4284aec975f52b96cc2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ead66800c2b4d7ebf27cf70f731393a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3dc993fe8c04fc88206042968574728",
      "placeholder": "",
      "style": "IPY_MODEL_2d5733b6a16c4b5e990f8393aaf55e01",
      "value": "Downloading: 100%"
     }
    },
    "7ecc9f1be8df4bda821dda665f2589a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81271cb9c29841f68cc2acd57a59fe1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_339a03c1fb3f4b12aa0b5391d6aad42e",
      "placeholder": "",
      "style": "IPY_MODEL_85889af975274b4d974a1cba886b8ae4",
      "value": " 24891/0 [00:09&lt;00:00, 2660.17 examples/s]"
     }
    },
    "815b7b62c2da446f87c07bdb440a399d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8206cb7266f84748ad3657fdb7f7886a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8209394b79864698aafe780c9227ee8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ead66800c2b4d7ebf27cf70f731393a",
       "IPY_MODEL_1e3a8e66e82e4bf09fce7d796c9e21f5",
       "IPY_MODEL_b92e929ef89f4c3db23810bf0554c29c"
      ],
      "layout": "IPY_MODEL_b8b625053b604a908efaf9479d8895ac"
     }
    },
    "82272385957d43a2a4ce73fb64ad828d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "823793b805b64185a18eba8a45175459": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_104908073b2649c0b72062df6c080d1a",
      "max": 12396864,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_82272385957d43a2a4ce73fb64ad828d",
      "value": 12396864
     }
    },
    "82df1eda83e8415cb3baacb73aeeb1a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "831ee902890b45c796ff669e9e8ee569": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83f234641d1f458ba5ab6496ef9a324f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "84806013dde14accad6128645c77a716": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "84ce228c97aa4316b06e8422e7e04166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_264485d64c984aa7aea7cb26b9288ab1",
      "placeholder": "",
      "style": "IPY_MODEL_04c8521884ad4fb6b3b3b128c8da5a5f",
      "value": " 2.39k/2.39k [00:00&lt;00:00, 42.0kB/s]"
     }
    },
    "85889af975274b4d974a1cba886b8ae4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "858a05b337f04f92b3e194acb42d7eb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8677621581ab46d8bbfd819de52fcb9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aaabf064c35f4af6a46e04e631919c54",
       "IPY_MODEL_e3a94988506444ddbd8aa09c010d8c08",
       "IPY_MODEL_178c992bd8c146eba83abf46b18d4714"
      ],
      "layout": "IPY_MODEL_64e286b2803847378d00e6506f8baf23"
     }
    },
    "89fb378844aa41ecac7dc43a6434cf47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a1c3f28469443e3aa0712b46f2a56f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a596e4d8ab74fc0b22ab6948fe82f85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "8a59de4dc2164356ad07e9a4143e291f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_699c5ee0b125444090626ed1cd0c27b2",
       "IPY_MODEL_540241e3de5746a297ee30315029c88a",
       "IPY_MODEL_6f57502431d34979acc781ab11cfb7b1"
      ],
      "layout": "IPY_MODEL_dcd0ac2e33d54aed835dff8490418ed0"
     }
    },
    "8afd71c2059e4ea59a0ade99fd722c17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b14722c59254e969de3f4784e696f69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_858a05b337f04f92b3e194acb42d7eb7",
      "placeholder": "",
      "style": "IPY_MODEL_594991d99fee4d43bb27588a6ff8dd74",
      "value": " 350/350 [00:27&lt;00:00, 12.68it/s]"
     }
    },
    "8b5998d5e4424dd8962ea3cbc4dcfd64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38568309247a48ab9315dfdd1fcafd4b",
      "placeholder": "",
      "style": "IPY_MODEL_09ce1ccdf1704d739e888a87717a920f",
      "value": " 350/350 [00:27&lt;00:00, 12.63it/s]"
     }
    },
    "8c950947a2704b4b8184b587807de80c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cf6ca6607d54f3fad0c3839c8fae9bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f643600516b4e18bd01f5dcc1a605a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "908e26976d494bcc92fe220277e8a89b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64408f82a6234466b2633ca5413e2ef2",
       "IPY_MODEL_ccd0dc9a9bdd407094781c1e7e34f08c",
       "IPY_MODEL_5387b07673fb40c88657f9dae4bdaa20"
      ],
      "layout": "IPY_MODEL_b02d46075fc24abd99182a0908cc0f12"
     }
    },
    "92d8f3076508447c8a04f8c3e83fe8f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2cdef25032464dfb805a204704621d01",
      "placeholder": "",
      "style": "IPY_MODEL_bb6c838678914962a6be4ba005ceb7e3",
      "value": "Downloading: "
     }
    },
    "934c9d8773bc4a6fadcb649235a5f4c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ac401834f134962832f397ca22d9763",
      "placeholder": "",
      "style": "IPY_MODEL_8f643600516b4e18bd01f5dcc1a605a0",
      "value": " 294k/294k [00:00&lt;00:00, 1.65MB/s]"
     }
    },
    "946acae857ab4e95a515dc9725c49171": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed2408f1d1634f899625d1c572c4a6d2",
       "IPY_MODEL_97c8b42621814e599c9b257f17a84379",
       "IPY_MODEL_18097022050d4d78bce836970944747e"
      ],
      "layout": "IPY_MODEL_39238f7ae76c4917b770bba3cab35a89"
     }
    },
    "953444fee5064b60815cc5796e5c3eea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c6cae084087447eb1c53f0c33664c4b",
      "placeholder": "",
      "style": "IPY_MODEL_ec09337a81944d339c9775c24437b76b",
      "value": " 3466/3466 [24:00&lt;00:00,  2.41it/s, loss=1.97, v_num=mhop]"
     }
    },
    "961feb497a154f31aabcb94f8a26e527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_639433daeb204533b75ab55215969f5f",
      "placeholder": "",
      "style": "IPY_MODEL_b93bd272fec0432295b3513b386f2bd0",
      "value": " 2.35k/? [00:00&lt;00:00, 53.9kB/s]"
     }
    },
    "97c8b42621814e599c9b257f17a84379": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f497e7ac05844d8aace0dbf592bb8f4",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3413366e1dae412587517a526c4271fc",
      "value": 350
     }
    },
    "9826c15cac2f4077a398b11ff1225a28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99527c7b380c42cf983690bcf3d96a1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6da9ad9c815d475ca0c08fd82660a9a0",
       "IPY_MODEL_4504a16a187241faba81bd5c394c4855",
       "IPY_MODEL_69a71178f16244bb83442e17f9d002b3"
      ],
      "layout": "IPY_MODEL_b191d33bba614c5fb2bf0ba7f2b33035"
     }
    },
    "9aa58eaebd6a493b86d29bd4c9879466": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9df52972b0c2498582285204d9fce746": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9e4fb031ef254cdaac1e72377c015b09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f7b7b249a0745f4be504aa6245d2f56",
       "IPY_MODEL_69c8216e5dc64a10a7914936330bbd58",
       "IPY_MODEL_a4c0a060006d4cc8aa34cb7740b4dbe7"
      ],
      "layout": "IPY_MODEL_8a1c3f28469443e3aa0712b46f2a56f0"
     }
    },
    "9f497e7ac05844d8aace0dbf592bb8f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3674efae97e45df931c8478ab8195fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c7a481a577a43728afb69c569c23be7",
      "placeholder": "",
      "style": "IPY_MODEL_b4a0f7266fdb499ca8e47af2450a3fad",
      "value": " 5.91k/? [00:00&lt;00:00, 148kB/s]"
     }
    },
    "a3916440cfba4999b3a1874f6d59de94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4476b44ef6844e5b096299476e95b4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4c0a060006d4cc8aa34cb7740b4dbe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48f0c88a67c7482fb885d04c0e5ac42d",
      "placeholder": "",
      "style": "IPY_MODEL_9aa58eaebd6a493b86d29bd4c9879466",
      "value": " 25/25 [00:53&lt;00:00,  2.02s/ba]"
     }
    },
    "a73c3fb54a8f4b968b699ca465b532c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7c75ea8186c4fb8ac274a00ea95a4d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7da14f76fa9400ebe4deda59c900fd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ecd73584ed8347b6a1be5106326abf9f",
       "IPY_MODEL_823793b805b64185a18eba8a45175459",
       "IPY_MODEL_6b51d213b8d949bf8b98494b7a3e2c5f"
      ],
      "layout": "IPY_MODEL_24edde3d62b342a3aa7161a42843ef27"
     }
    },
    "a927ba91200f45ff84a20511dc1ca738": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa0f3ba3281b42a795fcf7cb40fcedc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa6c19aa8d6241fab71e9460848076bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35f62ba8591541b8b69f7a83ce48c3fa",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8ff2de5e4114698b17f1096a26ee56a",
      "value": 1
     }
    },
    "aa8cd1e4e53f4101b560b704be0b2158": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaabf064c35f4af6a46e04e631919c54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c553dd1d368473aa5b1b86208c1fbd0",
      "placeholder": "",
      "style": "IPY_MODEL_7462caae2b904f1ca916dd2d27780741",
      "value": "Downloading: 100%"
     }
    },
    "ad7e17e4626b4c6c9b0dd47deb19dcdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b02d46075fc24abd99182a0908cc0f12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "b14402f4a0c44de9b9ba6763c14611a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b191d33bba614c5fb2bf0ba7f2b33035": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b194e01ec8e4445ea89e658ff3a16e31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f426b19fbf4d4b688192c43e31710e6a",
       "IPY_MODEL_551ec23b892d4d5dbc36dd58efe2ca01",
       "IPY_MODEL_6ddb79d1d79d4d87b1fecbf92226d39b"
      ],
      "layout": "IPY_MODEL_607e13af157a4e3db72925f0e838ce09"
     }
    },
    "b383ff48553a41ac89449b8f95244465": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b46cc34480544768b88b22a775057cd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b47b2820b1c64882b40d2fb2148c41e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4a0f7266fdb499ca8e47af2450a3fad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b6de9fa4bbb249efa58f338b9479c3c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b738914e73c54766b549bde562db8020": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7ae40af15894202b6eacb89cc05bf73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b83de46da11041afbc716bf8c2f4d82e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1698a51bb25b4d12913fef003c3ef891",
      "placeholder": "",
      "style": "IPY_MODEL_1a2f7dc4b47b49d6831cb063a16ebc8f",
      "value": "Validating: 100%"
     }
    },
    "b8b625053b604a908efaf9479d8895ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b92e929ef89f4c3db23810bf0554c29c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cafd1f64db942658339f45659d4f294",
      "placeholder": "",
      "style": "IPY_MODEL_7903eecab2444baba3219ff8113a5450",
      "value": " 2.49k/2.49k [00:00&lt;00:00, 62.5kB/s]"
     }
    },
    "b93bd272fec0432295b3513b386f2bd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba40b6de0ed94bbc887fe3d166c5cdc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17e2e94bd572457188acc40b12337192",
      "placeholder": "",
      "style": "IPY_MODEL_644395b0377a484cb3c3f273aac99769",
      "value": "Validating: 100%"
     }
    },
    "bb6c838678914962a6be4ba005ceb7e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bce032a743904d73aa4fd4af2b848704": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_174567f7776943d1aaf9630f3da113cd",
      "placeholder": "",
      "style": "IPY_MODEL_134152d8121b4ff9820cb1356d90e339",
      "value": "Downloading: "
     }
    },
    "bd3a9997ba0449efaf7a31b02fef2a5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd7eeaa744884b98a64b38af9cd5ff84": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be43828dc6f6435e89e867089aeec5f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42dd49d8d73044e6b39c83a35d2db768",
      "max": 111758028,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0c827d492c647dfb351bdf210dcd578",
      "value": 111758028
     }
    },
    "bf25b6526d1e46069a1e3aae2df96483": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0c827d492c647dfb351bdf210dcd578": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c14afdc7abba41dfa2ccca801a5348e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6bb1e6024ae40829da192c08c81d17e",
      "placeholder": "",
      "style": "IPY_MODEL_831ee902890b45c796ff669e9e8ee569",
      "value": " 2/2 [00:02&lt;00:00,  1.34s/ba]"
     }
    },
    "c28272acb8fe413ea43fc72b6d4b3120": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c321cea225764ee5a5c281f791dfc4b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c365c5404e6b4231af0e3b88a52ffe9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c39e4ff0515c4fa88f6902d57af8bd19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c6628f411c4d4a5cacd4ebb2dd6df146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f555aa2401a74799abb3b1c7aa30d580",
       "IPY_MODEL_0317c766423c431cbb648de18fec733e",
       "IPY_MODEL_5049389da0954c1d822a02aae092d065"
      ],
      "layout": "IPY_MODEL_14b4ba6691c9492c9b6bca099f6021f7"
     }
    },
    "c8032291f4d0431f9f8f9b72bebbbc0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c876129819ee4d548e24d4b90f5e3b94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8866c606c6b4cdfae4216c49507a756": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c971f8e40f104f0da20b4fb9c6e21daf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b47b2820b1c64882b40d2fb2148c41e3",
      "max": 1940,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_167ba739c8c54f6fb0c05841d6a62d6c",
      "value": 1940
     }
    },
    "ca86160348c3423fa4de0ab13d59679e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f829335369404977ae3d4fd0907bba30",
      "placeholder": "",
      "style": "IPY_MODEL_efd3e63284d24519995b3543df8806ae",
      "value": " 350/350 [00:27&lt;00:00, 12.64it/s]"
     }
    },
    "cb36532a8a684324b09f9462b5d701f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc626c2bb0fa4da38f11e0df0d08bf08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccd0dc9a9bdd407094781c1e7e34f08c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0772c5df3eb446259634a645bceb0227",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c39e4ff0515c4fa88f6902d57af8bd19",
      "value": 350
     }
    },
    "cd478dfcbba0471db5d98455dee13268": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bce032a743904d73aa4fd4af2b848704",
       "IPY_MODEL_585b0b0cdbc342719793895b2441268d",
       "IPY_MODEL_a3674efae97e45df931c8478ab8195fa"
      ],
      "layout": "IPY_MODEL_53ca0a05eb2845908491c2d438cdf244"
     }
    },
    "cd958f6b4c64488ca2310a8fdf7249ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cefc5e6d778b4cb59c65c2c7ebccf8ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf6fd3a3e2cf4743919bad78bb6a1b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cefc5e6d778b4cb59c65c2c7ebccf8ca",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_38b8a6fa3762440494c7d3132e0451ae",
      "value": 350
     }
    },
    "d0707f72859746d7982ee2996f3fe066": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d0f4f94047774e1aa4ea2200fe732b6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d112dc5b89be4ba8b749382d0ac98769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41e92a0ab5ca4858a9bb08ab040c6145",
      "placeholder": "",
      "style": "IPY_MODEL_531e7a37f13e4d62bb2bffd610ac2269",
      "value": "Downloading: 100%"
     }
    },
    "d282bf3181cd4fe48be09cadcefb51ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4ab5427cac540c9a095b10bded11580": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5155565c0a947aa9bc07db10dd93913": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7cd40c2e67b47e999fe3ae10594062f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d819f074fe4149b0ae516b4e9a38c3f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d81a71fdaac94f07836d197a59344ed5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d82f293aad02476499f6e1be29b848c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "db29bda0f7a8454ca2dda2f7d1eed2dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc8da87b183549ba8806acaa8dad8633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4ab5427cac540c9a095b10bded11580",
      "max": 3466,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67f97175262f4436b03f1d77d201d4d0",
      "value": 3466
     }
    },
    "dcd0ac2e33d54aed835dff8490418ed0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df800cd117b946c88137a1c46c427216": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e074a7aae6bf43a7a8dabc99f19f82e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b14402f4a0c44de9b9ba6763c14611a5",
      "max": 2390,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_750fd64de713487ab332036b610ed998",
      "value": 2390
     }
    },
    "e0fe868886b54b0c833d7469aeeb5eb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e11e3f16c62340f7adcdc80b2c84e8dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e1b093c9236649ab857c5b8eaad7016c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d112dc5b89be4ba8b749382d0ac98769",
       "IPY_MODEL_704a7e4f5aca452ea7937875d5cdf0a8",
       "IPY_MODEL_481ad2424d364b08b7f775dd3e8368d3"
      ],
      "layout": "IPY_MODEL_3528a8a5a06246d590e8cd3f86b69add"
     }
    },
    "e254ffce245d413d87700847d3c6e7cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e33588e803404ba0a657bf04a2e83a43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c6a2548671140daaf62b3aa504dea0a",
      "max": 961,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d772e77f4f0471e9780c23fac8ebc7a",
      "value": 961
     }
    },
    "e3a94988506444ddbd8aa09c010d8c08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d282bf3181cd4fe48be09cadcefb51ec",
      "max": 572655,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67b728fa9bf7427c814d7dfa5b506b0c",
      "value": 572655
     }
    },
    "e3dc993fe8c04fc88206042968574728": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6bb1e6024ae40829da192c08c81d17e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6c12a326f114b32abe72977dbae8135": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e763025cfded4ac4bdd4b3ff04a6a6c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58f6a90b68c6434883f40572c50af764",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79559b9a9e2c40968d044dcb3d6c8d65",
      "value": 350
     }
    },
    "e7d14b8889cb40b7aa4a2d49c740666f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7f77d44d5d5456bae98ab2496653ccb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4733b16cce4641c7b77df670615dd6f4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f0c1b96ef18643779ddc4c757c6d6e66",
      "value": 1
     }
    },
    "e89754d130754deb8a68f442ef00a038": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43fca214d7314eeb8600a5538005dece",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d819f074fe4149b0ae516b4e9a38c3f3",
      "value": 0
     }
    },
    "e8fed95bace543e18c1ee05aaa900c0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e9525404a5284e95ad181f02a6e452a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c28272acb8fe413ea43fc72b6d4b3120",
      "placeholder": "",
      "style": "IPY_MODEL_b6de9fa4bbb249efa58f338b9479c3c4",
      "value": "Downloading: 100%"
     }
    },
    "ec09337a81944d339c9775c24437b76b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecd73584ed8347b6a1be5106326abf9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_675a054bb37343cf80e579a5ab70ce4e",
      "placeholder": "",
      "style": "IPY_MODEL_a73c3fb54a8f4b968b699ca465b532c1",
      "value": "Downloading: 100%"
     }
    },
    "ed2408f1d1634f899625d1c572c4a6d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd3a9997ba0449efaf7a31b02fef2a5e",
      "placeholder": "",
      "style": "IPY_MODEL_efafe2ea1fec42a19bb44b26f6754c7e",
      "value": "Validating: 100%"
     }
    },
    "ed5ba330061e4f5c99f833511a0bc791": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "edbe821067ac4630b6393b101e5e5260": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e9525404a5284e95ad181f02a6e452a2",
       "IPY_MODEL_5c626facfda3400fa4c3ed8d90539edd",
       "IPY_MODEL_934c9d8773bc4a6fadcb649235a5f4c5"
      ],
      "layout": "IPY_MODEL_e7d14b8889cb40b7aa4a2d49c740666f"
     }
    },
    "ede5d2ec080644019bb54ce08fe0b12a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f69682f1ee24d918ef449bff4d9e8d0",
      "placeholder": "",
      "style": "IPY_MODEL_5e75bd1fcea94c3c8964c69e3233a972",
      "value": " 1.03k/1.03k [00:00&lt;00:00, 17.5kB/s]"
     }
    },
    "edf44a3ba26745eb8f4870e194968337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eeef782870bf4e1f8b973a0a746f7f94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35a1c25826274e81920afab89112619b",
      "placeholder": "",
      "style": "IPY_MODEL_c876129819ee4d548e24d4b90f5e3b94",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "efafe2ea1fec42a19bb44b26f6754c7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efd3e63284d24519995b3543df8806ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f08cbf7762d34984b0dc2b3811ae2ce7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0c1b96ef18643779ddc4c757c6d6e66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0efe00a84ef43d391d70f0be759f17a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2c922279a3b4bf89a03eff57fedb5f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00bd6b1cff9c46ea88fe8461bfc91110",
      "placeholder": "",
      "style": "IPY_MODEL_112365319bcf40129659db76400faa13",
      "value": " 112M/112M [00:04&lt;00:00, 35.5MB/s]"
     }
    },
    "f426b19fbf4d4b688192c43e31710e6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd7eeaa744884b98a64b38af9cd5ff84",
      "placeholder": "",
      "style": "IPY_MODEL_a4476b44ef6844e5b096299476e95b4f",
      "value": "Upload file pytorch_model.bin: 100%"
     }
    },
    "f54cf361a2ab4286aed0d3739cf64224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c321cea225764ee5a5c281f791dfc4b8",
      "max": 350,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b53799e3e23493095a9397740a8b24a",
      "value": 350
     }
    },
    "f555aa2401a74799abb3b1c7aa30d580": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cf6ca6607d54f3fad0c3839c8fae9bb",
      "placeholder": "",
      "style": "IPY_MODEL_22d5f11f33d14ba6a451419ff6b47865",
      "value": "100%"
     }
    },
    "f57bd76e77f84c8d9042cbce2e021221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f64026e18bf6466096dc695c03111bc9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f829335369404977ae3d4fd0907bba30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8ff2de5e4114698b17f1096a26ee56a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa646d15915846c6b6e02c6e0623cf1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa76ce7f2179453abf19231cf8879e8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb6688c00b964a96bacdac08a1c504a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8afd71c2059e4ea59a0ade99fd722c17",
      "placeholder": "",
      "style": "IPY_MODEL_0510718c486045d7a63e7da5c62f018f",
      "value": " 17.9k/? [00:00&lt;00:00, 465kB/s]"
     }
    },
    "fccbe0b2d4cd431f91045430231f5b8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8206cb7266f84748ad3657fdb7f7886a",
      "placeholder": "",
      "style": "IPY_MODEL_152236bb88c542d9859a6007ebb0a51f",
      "value": "Validation sanity check:   0%"
     }
    },
    "fdf46b1d75894b7fbf12e6795677e100": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe554492308547a695c01c1e0ba2c359": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe809085051144e0b4c9fa1e15410967": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d05f6075ab84c5895d583121a0b4bf0",
       "IPY_MODEL_0a064be23e3a4cf2b3d8e325a7875fff",
       "IPY_MODEL_459531a008724820af2272f5a963a804"
      ],
      "layout": "IPY_MODEL_ed5ba330061e4f5c99f833511a0bc791"
     }
    },
    "ff1eb62903644eee9e59a2678ad3b09c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b9d90ae7c574e6c85da1cb768ec2e64",
      "placeholder": "",
      "style": "IPY_MODEL_68888ceba9074610ad72ad6e795893e9",
      "value": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
